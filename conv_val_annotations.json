[
    {
        "vid": "10712559773",
        "aid": "10712559773_36202",
        "original_caption": "the child in red clothes and black pants is watching the ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The child in red clothes and black pants is watching the ball."
            }
        ],
        "meta": {
            "split": [
                496,
                595
            ],
            "duration": 100,
            "token": {
                "<s0>": 14,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3783730077",
        "aid": "3783730077_36203",
        "original_caption": "an adult man plays a guitar on a stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man plays a guitar on a stage."
            }
        ],
        "meta": {
            "split": [
                0,
                963
            ],
            "duration": 964,
            "token": {
                "<s0>": 0,
                "<e0>": 964
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_36204",
        "original_caption": "an adult man in black holds a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds a black camera."
            }
        ],
        "meta": {
            "split": [
                0,
                296
            ],
            "duration": 297,
            "token": {
                "<s0>": 0,
                "<e0>": 262
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_36205",
        "original_caption": "an adult man in black holds a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds a black camera."
            }
        ],
        "meta": {
            "split": [
                296,
                570
            ],
            "duration": 275,
            "token": {
                "<s0>": 35,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_36206",
        "original_caption": "an adult man in black holds a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds a black camera."
            }
        ],
        "meta": {
            "split": [
                570,
                735
            ],
            "duration": 166,
            "token": {
                "<s0>": 28,
                "<e0>": 152
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8483279367",
        "aid": "8483279367_36207",
        "original_caption": "an adult plays the guitar inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult plays the guitar inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 381,
                "<e0>": 691
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6885601275",
        "aid": "6885601275_36208",
        "original_caption": "a baby in white watches a yellow bottle in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white watches a yellow bottle in the room."
            }
        ],
        "meta": {
            "split": [
                1534,
                1636
            ],
            "duration": 103,
            "token": {
                "<s0>": 35,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7907275512",
        "aid": "7907275512_36209",
        "original_caption": "a child in black leans on a yellow bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black leans on a yellow bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                1715
            ],
            "duration": 1716,
            "token": {
                "<s0>": 1352,
                "<e0>": 1498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_36210",
        "original_caption": "an adult is in front of another adult on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other adult on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5662898863",
        "aid": "5662898863_36211",
        "original_caption": "there is a lion biting another lion in the zoo.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat bites the other lion in the zoo from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A lion."
            }
        ],
        "meta": {
            "split": [
                0,
                193
            ],
            "duration": 194,
            "token": {
                "<s0>": 58,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5662898863",
        "aid": "5662898863_36212",
        "original_caption": "there is a lion biting another lion in the zoo.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a lion biting another lion in the zoo happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                193,
                333
            ],
            "duration": 141,
            "token": {
                "<s0>": 75,
                "<e0>": 141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_36213",
        "original_caption": "there is an elephant towards another elephant on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the elephant from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is an elephant towards another elephant on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 720,
                "<e0>": 870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3471851958",
        "aid": "3471851958_36214",
        "original_caption": "an adult man in white is speaking to adult man in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white is speaking to adult man in red."
            }
        ],
        "meta": {
            "split": [
                0,
                179
            ],
            "duration": 180,
            "token": {
                "<s0>": 92,
                "<e0>": 147
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36215",
        "original_caption": "an adult in blue t-shirt watches another adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue t-shirt watches another adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 0,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_36216",
        "original_caption": "there is a black dog above a motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black dog above a motorcycle."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 240,
                "<e0>": 707
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7465682132",
        "aid": "7465682132_36217",
        "original_caption": "there is a ball towards a child in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a ball towards a child in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 110,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3843663025",
        "aid": "3843663025_36218",
        "original_caption": "a child in white is above a bicycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white is above a bicycle outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                545
            ],
            "duration": 546,
            "token": {
                "<s0>": 0,
                "<e0>": 546
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_36219",
        "original_caption": "a child in white is away from another child in yellow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the other child in yellow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1343
            ],
            "duration": 1344,
            "token": {
                "<s0>": 0,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_36220",
        "original_caption": "there is a cake above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cake."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 0,
                "<e0>": 1080
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3004044251",
        "aid": "3004044251_36221",
        "original_caption": "an adult in black hugs a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black hug at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                663
            ],
            "duration": 664,
            "token": {
                "<s0>": 0,
                "<e0>": 664
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3865853855",
        "aid": "3865853855_36222",
        "original_caption": "a child in striped clothes waves a green toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in striped clothes waves a green toy on the beach."
            }
        ],
        "meta": {
            "split": [
                0,
                314
            ],
            "duration": 315,
            "token": {
                "<s0>": 53,
                "<e0>": 187
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3865853855",
        "aid": "3865853855_36223",
        "original_caption": "a child in striped clothes waves a green toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in striped clothes waves a green toy on the beach."
            }
        ],
        "meta": {
            "split": [
                314,
                701
            ],
            "duration": 388,
            "token": {
                "<s0>": 127,
                "<e0>": 311
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2494076437",
        "aid": "2494076437_36224",
        "original_caption": "a baby in pink clothes leans on a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in pink clothes leans on a baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1421
            ],
            "duration": 1422,
            "token": {
                "<s0>": 0,
                "<e0>": 1422
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6005023595",
        "aid": "6005023595_36225",
        "original_caption": "an adult woman in wathet blue speaks to a baby in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the baby in pink from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                83,
                184
            ],
            "duration": 102,
            "token": {
                "<s0>": 35,
                "<e0>": 77
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6005023595",
        "aid": "6005023595_36226",
        "original_caption": "an adult woman in wathet blue speaks to a baby in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the baby in pink from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                485,
                584
            ],
            "duration": 100,
            "token": {
                "<s0>": 13,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7308772034",
        "aid": "7308772034_36227",
        "original_caption": "an adult in black is away from a child in a lab.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the child in the lab from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2456
            ],
            "duration": 2457,
            "token": {
                "<s0>": 2040,
                "<e0>": 2130
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_36228",
        "original_caption": "a child is above a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is above a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                894,
                1007
            ],
            "duration": 114,
            "token": {
                "<s0>": 25,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4524702622",
        "aid": "4524702622_36229",
        "original_caption": "there is a blue chair next to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue chair next to a child."
            }
        ],
        "meta": {
            "split": [
                254,
                1098
            ],
            "duration": 845,
            "token": {
                "<s0>": 46,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_36230",
        "original_caption": "an adult pulls a baby on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pulls the baby on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                760
            ],
            "duration": 761,
            "token": {
                "<s0>": 371,
                "<e0>": 395
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6644166529",
        "aid": "6644166529_36231",
        "original_caption": "a child is next to a dish in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is next to a dish in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36232",
        "original_caption": "there is a bottle away a cake at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bottle away a cake at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 600,
                "<e0>": 690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2932667685",
        "aid": "2932667685_36233",
        "original_caption": "an adult is away from a blue backpack outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from a blue backpack outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1167
            ],
            "duration": 1168,
            "token": {
                "<s0>": 0,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_36234",
        "original_caption": "a child is towards another child in blue in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is towards another child in blue in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 185,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_36235",
        "original_caption": "there is a car behind another car beside the house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a car behind another car beside the house."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 316,
                "<e0>": 356
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_36236",
        "original_caption": "a baby is in front of a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby is in front of a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 120,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6247340440",
        "aid": "6247340440_36237",
        "original_caption": "an adult in red rides a ski on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red rides a ski on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                387
            ],
            "duration": 388,
            "token": {
                "<s0>": 0,
                "<e0>": 381
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_36238",
        "original_caption": "there is a moving bicycle towards an adult in black in a path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a moving bicycle towards an adult in black in a path."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 15,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3758307290",
        "aid": "3758307290_36239",
        "original_caption": "a child in gray plays a brown guitar in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in gray plays a brown guitar in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                657
            ],
            "duration": 658,
            "token": {
                "<s0>": 0,
                "<e0>": 492
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_36240",
        "original_caption": "an adult in red rides a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in red ride on the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 438
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36241",
        "original_caption": "a baby with blond-hair touches a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby with blond-hair touches a cake."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 1593,
                "<e0>": 1629
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36242",
        "original_caption": "a baby with blond-hair touches a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby with blond-hair touches a cake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1679,
                2696
            ],
            "duration": 1018,
            "token": {
                "<s0>": 50,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_36243",
        "original_caption": "a child is behind another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 0,
                "<e0>": 166
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_36244",
        "original_caption": "the horse is chasing the adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is chasing the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A horse."
            }
        ],
        "meta": {
            "split": [
                0,
                187
            ],
            "duration": 188,
            "token": {
                "<s0>": 0,
                "<e0>": 164
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_36245",
        "original_caption": "the horse is chasing the adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the horse from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The horse is chasing the adult on the grass."
            }
        ],
        "meta": {
            "split": [
                187,
                380
            ],
            "duration": 194,
            "token": {
                "<s0>": 23,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_36246",
        "original_caption": "the horse is chasing the adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The horse is chasing the adult on the grass."
            }
        ],
        "meta": {
            "split": [
                380,
                614
            ],
            "duration": 235,
            "token": {
                "<s0>": 25,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_36247",
        "original_caption": "an adult in blue is above a sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue is above a sofa in the room."
            }
        ],
        "meta": {
            "split": [
                1148,
                1458
            ],
            "duration": 311,
            "token": {
                "<s0>": 100,
                "<e0>": 311
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_36248",
        "original_caption": "a child in gray leans on a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the brown sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 0,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_36249",
        "original_caption": "a child in gray leans on a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the brown sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                98,
                535
            ],
            "duration": 438,
            "token": {
                "<s0>": 31,
                "<e0>": 85
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_36250",
        "original_caption": "a child in gray leans on a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in gray leans on a brown sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                535,
                1099
            ],
            "duration": 565,
            "token": {
                "<s0>": 353,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_36251",
        "original_caption": "a child in gray leans on a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in gray leans on a brown sofa."
            }
        ],
        "meta": {
            "split": [
                1099,
                1458
            ],
            "duration": 360,
            "token": {
                "<s0>": 159,
                "<e0>": 319
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3521372410",
        "aid": "3521372410_36252",
        "original_caption": "an adult caresses a baby in blue clothes at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult caresses a baby in blue clothes at home."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 404,
                "<e0>": 423
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36253",
        "original_caption": "a child in black clothes holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in black clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                403,
                765
            ],
            "duration": 363,
            "token": {
                "<s0>": 223,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36254",
        "original_caption": "a child in black clothes holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black clothes holds a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                765,
                1028
            ],
            "duration": 264,
            "token": {
                "<s0>": 105,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36255",
        "original_caption": "a child in red clothes holds a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 1095
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_36256",
        "original_caption": "an adult woman in gray is inside a black guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray is inside a black guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                105
            ],
            "duration": 106,
            "token": {
                "<s0>": 0,
                "<e0>": 83
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_36257",
        "original_caption": "an adult woman in gray is inside a black guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is outside the adult woman in gray from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                105,
                611
            ],
            "duration": 507,
            "token": {
                "<s0>": 23,
                "<e0>": 104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_36258",
        "original_caption": "an adult wears black coat is towards another adult wears white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wears black coat is towards another adult wears white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 17,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3811600452",
        "aid": "3811600452_36259",
        "original_caption": "the black cat is next to the yellow cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The black cat is next to the yellow cat."
            }
        ],
        "meta": {
            "split": [
                1309,
                2157
            ],
            "duration": 849,
            "token": {
                "<s0>": 326,
                "<e0>": 848
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_36260",
        "original_caption": "an adult in white is away the adult in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white is away the adult in red."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 60,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_36261",
        "original_caption": "an adult in red is inside a black sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red is inside a black sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                419
            ],
            "duration": 420,
            "token": {
                "<s0>": 0,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36262",
        "original_caption": "a child holds hand of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holds hand of an adult in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                315
            ],
            "duration": 316,
            "token": {
                "<s0>": 197,
                "<e0>": 293
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36263",
        "original_caption": "a child holds hand of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds hand of an adult in the room."
            }
        ],
        "meta": {
            "split": [
                315,
                409
            ],
            "duration": 95,
            "token": {
                "<s0>": 23,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36264",
        "original_caption": "a child holds hand of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the adult in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                535,
                640
            ],
            "duration": 106,
            "token": {
                "<s0>": 3,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36265",
        "original_caption": "a child holds hand of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the adult in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                640,
                818
            ],
            "duration": 179,
            "token": {
                "<s0>": 7,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36266",
        "original_caption": "a child holds hand of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child hold hand of in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                857,
                930
            ],
            "duration": 74,
            "token": {
                "<s0>": 11,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36267",
        "original_caption": "a child holds hand of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds hand of an adult in the room."
            }
        ],
        "meta": {
            "split": [
                1000,
                1305
            ],
            "duration": 306,
            "token": {
                "<s0>": 32,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3836995607",
        "aid": "3836995607_36268",
        "original_caption": "an adult in yellow is in front of another adult in white on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow is in front of another adult in white on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                96
            ],
            "duration": 97,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_36269",
        "original_caption": "a child in tan watches a white dish in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in tan watches a white dish in a room."
            }
        ],
        "meta": {
            "split": [
                637,
                780
            ],
            "duration": 144,
            "token": {
                "<s0>": 12,
                "<e0>": 144
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36270",
        "original_caption": "an adult with hands crossed points to a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with hands crossed points to a cake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 391,
                "<e0>": 408
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5634235912",
        "aid": "5634235912_36271",
        "original_caption": "a male adult speaks to a female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A male adult speaks to a female adult."
            }
        ],
        "meta": {
            "split": [
                0,
                192
            ],
            "duration": 193,
            "token": {
                "<s0>": 82,
                "<e0>": 170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5634235912",
        "aid": "5634235912_36272",
        "original_caption": "a male adult speaks to a female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the female adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                192,
                327
            ],
            "duration": 136,
            "token": {
                "<s0>": 22,
                "<e0>": 69
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5634235912",
        "aid": "5634235912_36273",
        "original_caption": "a male adult speaks to a female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A male adult speaks to a female adult."
            }
        ],
        "meta": {
            "split": [
                327,
                542
            ],
            "duration": 216,
            "token": {
                "<s0>": 67,
                "<e0>": 164
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5634235912",
        "aid": "5634235912_36274",
        "original_caption": "a male adult speaks to a female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a male adult speaks to a female adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                542,
                829
            ],
            "duration": 288,
            "token": {
                "<s0>": 51,
                "<e0>": 288
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3395849259",
        "aid": "3395849259_36275",
        "original_caption": "a baby holds hand of an adult on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby holds hand of an adult on the sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                320
            ],
            "duration": 321,
            "token": {
                "<s0>": 205,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3395849259",
        "aid": "3395849259_36276",
        "original_caption": "a baby holds hand of an adult on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby holds hand of an adult on the sofa."
            }
        ],
        "meta": {
            "split": [
                320,
                797
            ],
            "duration": 478,
            "token": {
                "<s0>": 68,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36277",
        "original_caption": "the adult in blue is leaning on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is leaning on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 402
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_36278",
        "original_caption": "there is a table beneath a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a child in blue clothes."
            }
        ],
        "meta": {
            "split": [
                396,
                1653
            ],
            "duration": 1258,
            "token": {
                "<s0>": 29,
                "<e0>": 1253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_36279",
        "original_caption": "a child in red is towards a ball on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is towards a ball on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                495,
                595
            ],
            "duration": 101,
            "token": {
                "<s0>": 45,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3433142502",
        "aid": "3433142502_36280",
        "original_caption": "a baby in pink is inside a brown tan baby walker in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in pink is inside a brown tan baby walker in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                768
            ],
            "duration": 769,
            "token": {
                "<s0>": 0,
                "<e0>": 769
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3852871000",
        "aid": "3852871000_36281",
        "original_caption": "there is a white cup above a brown table in a meeting room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white cup above a brown table in a meeting room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1949
            ],
            "duration": 1950,
            "token": {
                "<s0>": 0,
                "<e0>": 1950
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_36282",
        "original_caption": "an adult in white clothes cuts the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes cuts the fruits."
            }
        ],
        "meta": {
            "split": [
                0,
                90
            ],
            "duration": 91,
            "token": {
                "<s0>": 39,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_36283",
        "original_caption": "an adult in white clothes cuts the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes cuts the fruits."
            }
        ],
        "meta": {
            "split": [
                90,
                187
            ],
            "duration": 98,
            "token": {
                "<s0>": 25,
                "<e0>": 44
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_36284",
        "original_caption": "an adult in white clothes cuts the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes cuts the fruits."
            }
        ],
        "meta": {
            "split": [
                187,
                275
            ],
            "duration": 89,
            "token": {
                "<s0>": 54,
                "<e0>": 77
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_36285",
        "original_caption": "an adult in white clothes cuts the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes cuts the fruits."
            }
        ],
        "meta": {
            "split": [
                275,
                450
            ],
            "duration": 176,
            "token": {
                "<s0>": 11,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_36286",
        "original_caption": "there is a black watercraft towards an adult in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black watercraft towards an adult in pink clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 150,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_36287",
        "original_caption": "an adult in purple is away an adult in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in purple is away an adult in white outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 300,
                "<e0>": 362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_36288",
        "original_caption": "a child in orange leans on a horse in the yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the horse in the yard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 146,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_36289",
        "original_caption": "there is a brown dog leaning on a blue car on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown dog leaning on a blue car on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                324
            ],
            "duration": 325,
            "token": {
                "<s0>": 0,
                "<e0>": 293
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_36290",
        "original_caption": "there is a brown dog leaning on a blue car on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown dog leaning on a blue car on the ground."
            }
        ],
        "meta": {
            "split": [
                324,
                443
            ],
            "duration": 120,
            "token": {
                "<s0>": 31,
                "<e0>": 86
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8015524320",
        "aid": "8015524320_36291",
        "original_caption": "a child in red is in front of a monitor in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the monitor in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                255,
                435
            ],
            "duration": 181,
            "token": {
                "<s0>": 45,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2718262890",
        "aid": "2718262890_36292",
        "original_caption": "an adult man in black leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult mthe in black lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                467
            ],
            "duration": 468,
            "token": {
                "<s0>": 312,
                "<e0>": 374
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10729424884",
        "aid": "10729424884_36293",
        "original_caption": "an adult woman watches another adult woman in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman watch in the bar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                261,
                699
            ],
            "duration": 439,
            "token": {
                "<s0>": 40,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36294",
        "original_caption": "there is a bottle above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bottle above a table in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4452690447",
        "aid": "4452690447_36295",
        "original_caption": "an adult in black clothes is above a white car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is above a white car."
            }
        ],
        "meta": {
            "split": [
                0,
                614
            ],
            "duration": 615,
            "token": {
                "<s0>": 0,
                "<e0>": 615
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_36296",
        "original_caption": "there is a bicycle beneath a child on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bicycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bicycle beneath a child on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 94,
                "<e0>": 371
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3297776560",
        "aid": "3297776560_36297",
        "original_caption": "an adult on the left is next to another adult on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult on the left is next to another adult on the right happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1372
            ],
            "duration": 1373,
            "token": {
                "<s0>": 900,
                "<e0>": 1373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_36298",
        "original_caption": "an adult on the right points to another adult on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult on the right points to another adult on the left happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                979
            ],
            "duration": 980,
            "token": {
                "<s0>": 691,
                "<e0>": 712
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2642700076",
        "aid": "2642700076_36299",
        "original_caption": "an adult rides a surfboard on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a surfboard on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                99
            ],
            "duration": 100,
            "token": {
                "<s0>": 0,
                "<e0>": 81
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2642700076",
        "aid": "2642700076_36300",
        "original_caption": "an adult rides a surfboard on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a surfboard on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                99,
                554
            ],
            "duration": 456,
            "token": {
                "<s0>": 18,
                "<e0>": 456
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6595030215",
        "aid": "6595030215_36301",
        "original_caption": "a seated adult is beneath a baby in white on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the seated adult on the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                465
            ],
            "duration": 466,
            "token": {
                "<s0>": 0,
                "<e0>": 456
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_36302",
        "original_caption": "there is a dog towards a car outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the dog towards to outside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A car."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 0,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_36303",
        "original_caption": "there is a purple bicycle behind a foremost adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a purple bicycle behind a foremost adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                906,
                1007
            ],
            "duration": 102,
            "token": {
                "<s0>": 13,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047872014",
        "aid": "6047872014_36304",
        "original_caption": "an adult kisses another adult in front of green wall.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult kiss in front of green wall from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 58,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5139493061",
        "aid": "5139493061_36305",
        "original_caption": "an adult man leans on another adult man 1.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man leans on another adult man 1 happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1846
            ],
            "duration": 1847,
            "token": {
                "<s0>": 1283,
                "<e0>": 1439
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3771729228",
        "aid": "3771729228_36306",
        "original_caption": "the ball is in front of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The ball is in front of the adult."
            }
        ],
        "meta": {
            "split": [
                0,
                399
            ],
            "duration": 400,
            "token": {
                "<s0>": 0,
                "<e0>": 128
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_36307",
        "original_caption": "an adult man holds a guitar in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man holds a guitar in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                683
            ],
            "duration": 684,
            "token": {
                "<s0>": 321,
                "<e0>": 490
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_36308",
        "original_caption": "an adult man holds a guitar in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the guitar in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                683,
                1063
            ],
            "duration": 381,
            "token": {
                "<s0>": 194,
                "<e0>": 381
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2560146457",
        "aid": "2560146457_36309",
        "original_caption": "an adult speaks to a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                111
            ],
            "duration": 112,
            "token": {
                "<s0>": 15,
                "<e0>": 85
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2560146457",
        "aid": "2560146457_36310",
        "original_caption": "an adult speaks to a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby."
            }
        ],
        "meta": {
            "split": [
                111,
                309
            ],
            "duration": 199,
            "token": {
                "<s0>": 27,
                "<e0>": 104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2560146457",
        "aid": "2560146457_36311",
        "original_caption": "an adult speaks to a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby."
            }
        ],
        "meta": {
            "split": [
                309,
                1122
            ],
            "duration": 814,
            "token": {
                "<s0>": 95,
                "<e0>": 218
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8575941513",
        "aid": "8575941513_36312",
        "original_caption": "a baby leans on an adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the adult in black from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                2386
            ],
            "duration": 2387,
            "token": {
                "<s0>": 0,
                "<e0>": 998
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_36313",
        "original_caption": "a child grabs a ball in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child grabs a ball in the playground."
            }
        ],
        "meta": {
            "split": [
                346,
                743
            ],
            "duration": 398,
            "token": {
                "<s0>": 98,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36314",
        "original_caption": "an adult in white clothes holds hand of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes holds hand of a child."
            }
        ],
        "meta": {
            "split": [
                0,
                314
            ],
            "duration": 315,
            "token": {
                "<s0>": 130,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36315",
        "original_caption": "an adult in white clothes holds hand of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes holds hand of a child."
            }
        ],
        "meta": {
            "split": [
                314,
                824
            ],
            "duration": 511,
            "token": {
                "<s0>": 140,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36316",
        "original_caption": "an adult in white clothes holds hand of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes holds hand of a child."
            }
        ],
        "meta": {
            "split": [
                824,
                1437
            ],
            "duration": 614,
            "token": {
                "<s0>": 339,
                "<e0>": 369
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36317",
        "original_caption": "an adult in white clothes holds hand of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes holds hand of a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1437,
                1818
            ],
            "duration": 382,
            "token": {
                "<s0>": 245,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_36318",
        "original_caption": "there is a plastic bottle above an orange wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a plastic bottle above an orange wooden table."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 0,
                "<e0>": 766
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_36319",
        "original_caption": "an adult woman in purple plays a yellow guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in purple plays a yellow guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1204
            ],
            "duration": 1205,
            "token": {
                "<s0>": 0,
                "<e0>": 1120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_36320",
        "original_caption": "an adult woman in purple plays a yellow guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in purple plays a yellow guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1204,
                2196
            ],
            "duration": 993,
            "token": {
                "<s0>": 84,
                "<e0>": 993
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_36321",
        "original_caption": "an adult in white and black clothes is behind another adult in grey clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the other adult in grey clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2494076437",
        "aid": "2494076437_36322",
        "original_caption": "there is a baby seat beneath the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a baby seat beneath the baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1421
            ],
            "duration": 1422,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_36323",
        "original_caption": "a child in pink clothes presses another child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho presses the other child in red clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 444,
                "<e0>": 498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36324",
        "original_caption": "an adult man in gray leans on a wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in gray leans on a wooden table."
            }
        ],
        "meta": {
            "split": [
                0,
                430
            ],
            "duration": 431,
            "token": {
                "<s0>": 135,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36325",
        "original_caption": "an adult man in gray leans on a wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in gray leans on a wooden table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                430,
                1094
            ],
            "duration": 665,
            "token": {
                "<s0>": 25,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36326",
        "original_caption": "a child is behind another child on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is behind another child on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1025,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6113835875",
        "aid": "6113835875_36327",
        "original_caption": "there is a tiger hitting another tiger on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a tiger hitting another tiger on the ground."
            }
        ],
        "meta": {
            "split": [
                65,
                191
            ],
            "duration": 127,
            "token": {
                "<s0>": 8,
                "<e0>": 16
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6113835875",
        "aid": "6113835875_36328",
        "original_caption": "there is a tiger hitting another tiger on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a tiger hitting another tiger on the ground."
            }
        ],
        "meta": {
            "split": [
                191,
                312
            ],
            "duration": 122,
            "token": {
                "<s0>": 111,
                "<e0>": 119
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4367310435",
        "aid": "4367310435_36329",
        "original_caption": "an adult speaks to a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child in the room."
            }
        ],
        "meta": {
            "split": [
                56,
                264
            ],
            "duration": 209,
            "token": {
                "<s0>": 26,
                "<e0>": 46
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_36330",
        "original_caption": "a baby in blue leans on a baby walker.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in blue leans on a baby walker happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 1051,
                "<e0>": 1151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_36331",
        "original_caption": "a child in white holds a red toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white holds a red toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                146
            ],
            "duration": 147,
            "token": {
                "<s0>": 0,
                "<e0>": 16
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_36332",
        "original_caption": "a child in white holds a red toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white holds a red toy on the floor."
            }
        ],
        "meta": {
            "split": [
                146,
                379
            ],
            "duration": 234,
            "token": {
                "<s0>": 131,
                "<e0>": 217
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_36333",
        "original_caption": "a child in white holds a red toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white holds a red toy on the floor."
            }
        ],
        "meta": {
            "split": [
                379,
                1343
            ],
            "duration": 965,
            "token": {
                "<s0>": 17,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7609356686",
        "aid": "7609356686_36334",
        "original_caption": "a child in pink licks another child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink licks another child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 0,
                "<e0>": 17
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36335",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue speaks to another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                896
            ],
            "duration": 897,
            "token": {
                "<s0>": 12,
                "<e0>": 818
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36336",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue speaks to another adult."
            }
        ],
        "meta": {
            "split": [
                896,
                1089
            ],
            "duration": 194,
            "token": {
                "<s0>": 79,
                "<e0>": 132
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36337",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue speaks to another adult."
            }
        ],
        "meta": {
            "split": [
                1089,
                1180
            ],
            "duration": 92,
            "token": {
                "<s0>": 62,
                "<e0>": 81
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36338",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue speaks to another adult."
            }
        ],
        "meta": {
            "split": [
                1180,
                1340
            ],
            "duration": 161,
            "token": {
                "<s0>": 10,
                "<e0>": 137
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36339",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue speaks to another adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1340,
                1453
            ],
            "duration": 114,
            "token": {
                "<s0>": 23,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36340",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue speaks to another adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1453,
                1770
            ],
            "duration": 318,
            "token": {
                "<s0>": 55,
                "<e0>": 310
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36341",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1770,
                1975
            ],
            "duration": 206,
            "token": {
                "<s0>": 8,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36342",
        "original_caption": "an adult in blue speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue speaks to another adult."
            }
        ],
        "meta": {
            "split": [
                1975,
                2159
            ],
            "duration": 185,
            "token": {
                "<s0>": 50,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_36343",
        "original_caption": "an adult in yellow clothes rides a blue watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow clothes rides a blue watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_36344",
        "original_caption": "a child in red holds a bottle in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red holds a bottle in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                794
            ],
            "duration": 795,
            "token": {
                "<s0>": 576,
                "<e0>": 655
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_36345",
        "original_caption": "there is a toy above a baby in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy above a baby in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 540,
                "<e0>": 834
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36346",
        "original_caption": "an adult in black holds a cup at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black holds a cup at home."
            }
        ],
        "meta": {
            "split": [
                0,
                323
            ],
            "duration": 324,
            "token": {
                "<s0>": 84,
                "<e0>": 186
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36347",
        "original_caption": "an adult in black holds a cup at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black holds a cup at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                323,
                1094
            ],
            "duration": 772,
            "token": {
                "<s0>": 138,
                "<e0>": 772
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4717834858",
        "aid": "4717834858_36348",
        "original_caption": "there is a baby seat in white beneath a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a baby seat in white beneath a baby at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                213
            ],
            "duration": 214,
            "token": {
                "<s0>": 0,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_36349",
        "original_caption": "an adult holding flowers holds hand of another adult in black at wedding.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the other adult in black at wedding from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 315,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_36350",
        "original_caption": "a child holds a bottle in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child hold in the car from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                164
            ],
            "duration": 165,
            "token": {
                "<s0>": 39,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_36351",
        "original_caption": "a child holds a bottle in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a bottle in a car."
            }
        ],
        "meta": {
            "split": [
                164,
                273
            ],
            "duration": 110,
            "token": {
                "<s0>": 15,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_36352",
        "original_caption": "a child holds a bottle in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds a bottle in a car."
            }
        ],
        "meta": {
            "split": [
                273,
                407
            ],
            "duration": 135,
            "token": {
                "<s0>": 45,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_36353",
        "original_caption": "a child holds a bottle in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bottle in the car from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                407,
                566
            ],
            "duration": 160,
            "token": {
                "<s0>": 74,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_36354",
        "original_caption": "a child holds a bottle in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a bottle in a car."
            }
        ],
        "meta": {
            "split": [
                566,
                925
            ],
            "duration": 360,
            "token": {
                "<s0>": 34,
                "<e0>": 324
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_36355",
        "original_caption": "a child holds a bottle in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holds a bottle in a car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                925,
                1114
            ],
            "duration": 190,
            "token": {
                "<s0>": 36,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6572270403",
        "aid": "6572270403_36356",
        "original_caption": "an adult with glasses holds hand of a child with smile on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with glasses holds hand of a child with smile on the sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 0,
                "<e0>": 260
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6400812635",
        "aid": "6400812635_36357",
        "original_caption": "adult in white clothes is grabbing the ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see adult in white clothes is grabbing the ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                212
            ],
            "duration": 213,
            "token": {
                "<s0>": 174,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_36358",
        "original_caption": "a child is behind an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is behind an adult."
            }
        ],
        "meta": {
            "split": [
                326,
                1238
            ],
            "duration": 913,
            "token": {
                "<s0>": 13,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_36359",
        "original_caption": "an adult holds a hamster on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a hamster on the carpet."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 619,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2425461420",
        "aid": "2425461420_36360",
        "original_caption": "there is a yellow cat inside a black handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is inside the black handbag from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                1797
            ],
            "duration": 1798,
            "token": {
                "<s0>": 660,
                "<e0>": 870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8022217320",
        "aid": "8022217320_36361",
        "original_caption": "a child in pink is next to another child in blue in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink is next to another child in blue in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                322
            ],
            "duration": 323,
            "token": {
                "<s0>": 0,
                "<e0>": 323
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8575941513",
        "aid": "8575941513_36362",
        "original_caption": "an adult in black clothes holds hand of a baby in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes holds hand of a baby in pink clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2014
            ],
            "duration": 2015,
            "token": {
                "<s0>": 1428,
                "<e0>": 1952
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8575941513",
        "aid": "8575941513_36363",
        "original_caption": "an adult in black clothes holds hand of a baby in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes holds hand of a baby in pink clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                2014,
                2386
            ],
            "duration": 373,
            "token": {
                "<s0>": 62,
                "<e0>": 373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_36364",
        "original_caption": "there is a bicycle towards another bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle towards another bicycle on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 15,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_36365",
        "original_caption": "there is a screen above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_36366",
        "original_caption": "an adult is behind the guitar in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is behind the guitar in the room."
            }
        ],
        "meta": {
            "split": [
                922,
                1138
            ],
            "duration": 217,
            "token": {
                "<s0>": 107,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_36367",
        "original_caption": "an adult in green lifts a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho lifts the baby at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                116
            ],
            "duration": 117,
            "token": {
                "<s0>": 9,
                "<e0>": 24
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_36368",
        "original_caption": "an adult in green lifts a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green lifts a baby at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                116,
                245
            ],
            "duration": 130,
            "token": {
                "<s0>": 93,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_36369",
        "original_caption": "there is a guitar in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the guitar from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a guitar in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 0,
                "<e0>": 2010
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_36370",
        "original_caption": "a child in blue clothes is beneath a monitor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue clothes is beneath a monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                747
            ],
            "duration": 748,
            "token": {
                "<s0>": 0,
                "<e0>": 748
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3315181459",
        "aid": "3315181459_36371",
        "original_caption": "an adult man in white shakes hand with another adult woman in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white shakes hand with another adult woman in black."
            }
        ],
        "meta": {
            "split": [
                0,
                694
            ],
            "duration": 695,
            "token": {
                "<s0>": 652,
                "<e0>": 695
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_36372",
        "original_caption": "an adult holds hand of another adult in the dancing room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of another adult in the dancing room."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 0,
                "<e0>": 382
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4352200366",
        "aid": "4352200366_36373",
        "original_caption": "a child in red clothes is above a ski.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is above a ski."
            }
        ],
        "meta": {
            "split": [
                529,
                960
            ],
            "duration": 432,
            "token": {
                "<s0>": 20,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_36374",
        "original_caption": "a child in plaid shirt lifts a ball on the basketball court.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in plaid shirt lift on the basketball court from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                729,
                1246
            ],
            "duration": 518,
            "token": {
                "<s0>": 29,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4452690447",
        "aid": "4452690447_36375",
        "original_caption": "an adult man in black plays a brown guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the brown guitar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                614
            ],
            "duration": 615,
            "token": {
                "<s0>": 0,
                "<e0>": 615
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4677394937",
        "aid": "4677394937_36376",
        "original_caption": "an adult man in black is above a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the surfboard on the lake from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_36377",
        "original_caption": "a child in white clothes is next to a blue-orange bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes is next to a blue-orange bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                693,
                1114
            ],
            "duration": 422,
            "token": {
                "<s0>": 207,
                "<e0>": 266
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3146965691",
        "aid": "3146965691_36378",
        "original_caption": "there are the guitar behind an adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat behind the adult inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1745
            ],
            "duration": 1746,
            "token": {
                "<s0>": 0,
                "<e0>": 1746
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_36379",
        "original_caption": "there is a backpack in blue above a bicycle in the path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a backpack in blue above a bicycle in the path."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 120,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5913888440",
        "aid": "5913888440_36380",
        "original_caption": "an adult man in green carries a green backpack on  the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in green carries a green backpack on  the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                95
            ],
            "duration": 96,
            "token": {
                "<s0>": 29,
                "<e0>": 73
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5913888440",
        "aid": "5913888440_36381",
        "original_caption": "an adult man in green carries a green backpack on  the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in green carries a green backpack on  the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                95,
                316
            ],
            "duration": 222,
            "token": {
                "<s0>": 22,
                "<e0>": 99
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5913888440",
        "aid": "5913888440_36382",
        "original_caption": "an adult man in green carries a green backpack on  the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries the green backpack on  the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                316,
                803
            ],
            "duration": 488,
            "token": {
                "<s0>": 123,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_36383",
        "original_caption": "there is an elephant towards another elephant on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is an elephant towards another elephant on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 480,
                "<e0>": 690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_36384",
        "original_caption": "a child in green is towards a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in green is towards a chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                4260
            ],
            "duration": 4261,
            "token": {
                "<s0>": 3420,
                "<e0>": 3510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_36385",
        "original_caption": "a child in black speaks to an adult on the training ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black speaks to an adult on the training ground."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 350,
                "<e0>": 362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_36386",
        "original_caption": "there is a colorful toy above a pale yellow table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a colorful toy above a pale yellow table."
            }
        ],
        "meta": {
            "split": [
                0,
                1653
            ],
            "duration": 1654,
            "token": {
                "<s0>": 0,
                "<e0>": 1650
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_36387",
        "original_caption": "an adult standing in front is above another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult standing in front is above another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 76,
                "<e0>": 119
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_36388",
        "original_caption": "a child in pink clothes is away from a baby walker.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink clothes is away from a baby walker happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 1100,
                "<e0>": 1155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_36389",
        "original_caption": "an adult is next to another adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to another adult outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 0,
                "<e0>": 61
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2942623423",
        "aid": "2942623423_36390",
        "original_caption": "an adult in blue clothes is towards another adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes is towards another adult in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                734
            ],
            "duration": 735,
            "token": {
                "<s0>": 120,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8315788918",
        "aid": "8315788918_36391",
        "original_caption": "a child is hold hand of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is hold hand of the adult."
            }
        ],
        "meta": {
            "split": [
                0,
                874
            ],
            "duration": 875,
            "token": {
                "<s0>": 0,
                "<e0>": 478
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8315788918",
        "aid": "8315788918_36392",
        "original_caption": "a child is hold hand of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is hold hand of the adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                874,
                1576
            ],
            "duration": 703,
            "token": {
                "<s0>": 396,
                "<e0>": 582
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_36393",
        "original_caption": "a child in blue is above a wooden table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue is above a wooden table in the room."
            }
        ],
        "meta": {
            "split": [
                396,
                1653
            ],
            "duration": 1258,
            "token": {
                "<s0>": 29,
                "<e0>": 1253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2718262890",
        "aid": "2718262890_36394",
        "original_caption": "an adult in black watches another adult in white in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black watches another adult in white in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                467
            ],
            "duration": 468,
            "token": {
                "<s0>": 32,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7162478518",
        "aid": "7162478518_36395",
        "original_caption": "there are the guitar next to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There are the guitar next to an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                610
            ],
            "duration": 611,
            "token": {
                "<s0>": 0,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5258789985",
        "aid": "5258789985_36396",
        "original_caption": "an adult with a motorcycle helmet carrys a keyboard piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with a motorcycle helmet carrys a keyboard piano."
            }
        ],
        "meta": {
            "split": [
                0,
                349
            ],
            "duration": 350,
            "token": {
                "<s0>": 0,
                "<e0>": 341
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5258789985",
        "aid": "5258789985_36397",
        "original_caption": "an adult with a motorcycle helmet carrys a keyboard piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with a motorcycle helmet carrys a keyboard piano."
            }
        ],
        "meta": {
            "split": [
                349,
                544
            ],
            "duration": 196,
            "token": {
                "<s0>": 8,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_36398",
        "original_caption": "there is a black backpack behind an adult with gray-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black backpack behind an adult with gray-hair."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 280,
                "<e0>": 357
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_36399",
        "original_caption": "a child wearing a red hat holds a bat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child wearing the red hat hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bat."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 0,
                "<e0>": 777
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5504745801",
        "aid": "5504745801_36400",
        "original_caption": "an adult in orange pulls a child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in orange pulls a child in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                203
            ],
            "duration": 204,
            "token": {
                "<s0>": 115,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36401",
        "original_caption": "an adult with red clothes is towards the adult with white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with red clothes is towards the adult with white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1229,
                "<e0>": 1529
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8782055272",
        "aid": "8782055272_36402",
        "original_caption": "an adult man in blue lifts a bicycle on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in blue lifts a bicycle on the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 181,
                "<e0>": 205
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_36403",
        "original_caption": "there is a chair next to a baby on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair next to a baby on the ground."
            }
        ],
        "meta": {
            "split": [
                1275,
                2144
            ],
            "duration": 870,
            "token": {
                "<s0>": 465,
                "<e0>": 712
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5331141814",
        "aid": "5331141814_36404",
        "original_caption": "a child in black leans on an adult in red in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black leans on an adult in red in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                1291
            ],
            "duration": 1292,
            "token": {
                "<s0>": 0,
                "<e0>": 1292
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_36405",
        "original_caption": "a child in yellow is next to another child on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the other child on stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                162,
                1343
            ],
            "duration": 1182,
            "token": {
                "<s0>": 88,
                "<e0>": 413
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_36406",
        "original_caption": "a shirtless adult is towards another adult in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A shirtless adult is towards another adult in red."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 120,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833782462",
        "aid": "4833782462_36407",
        "original_caption": "there is a bicycle behind an adult man in pink outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the adult man in pink outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bicycle."
            }
        ],
        "meta": {
            "split": [
                404,
                703
            ],
            "duration": 300,
            "token": {
                "<s0>": 136,
                "<e0>": 184
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_36408",
        "original_caption": "an adult holds hand of another adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult hold hand of at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                810
            ],
            "duration": 811,
            "token": {
                "<s0>": 0,
                "<e0>": 82
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4876265566",
        "aid": "4876265566_36409",
        "original_caption": "there is a black cat behind a black cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black cat behind a black cat."
            }
        ],
        "meta": {
            "split": [
                0,
                891
            ],
            "duration": 892,
            "token": {
                "<s0>": 660,
                "<e0>": 844
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2932667685",
        "aid": "2932667685_36410",
        "original_caption": "an adult is behind another adult at the rock.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult at the rock."
            }
        ],
        "meta": {
            "split": [
                454,
                1167
            ],
            "duration": 714,
            "token": {
                "<s0>": 386,
                "<e0>": 448
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_36411",
        "original_caption": "a child in red is away a silver sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is away a silver sports ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 187,
                "<e0>": 263
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_36412",
        "original_caption": "there is a grey hamster towards a black hamster.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a grey hamster towards a black hamster happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                863,
                2639
            ],
            "duration": 1777,
            "token": {
                "<s0>": 37,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_36413",
        "original_caption": "an adult man in red is behind a brown guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in red is behind a brown guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 0,
                "<e0>": 2010
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_36414",
        "original_caption": "a male child is in front of an another female child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other female child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                242,
                681
            ],
            "duration": 440,
            "token": {
                "<s0>": 178,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_36415",
        "original_caption": "there is a backpack behind an adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a backpack behind an adult on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 737,
                "<e0>": 805
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_36416",
        "original_caption": "a baby is above a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby is above a chair in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                726
            ],
            "duration": 727,
            "token": {
                "<s0>": 613,
                "<e0>": 661
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36417",
        "original_caption": "an adult leans on a brown black table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult leans on a brown black table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 161,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5392563097",
        "aid": "5392563097_36418",
        "original_caption": "there is an elephant carrying an adult in the park.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is an elephant carrying an adult in the park happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                37,
                158
            ],
            "duration": 122,
            "token": {
                "<s0>": 11,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36419",
        "original_caption": "an adult in red presses a bench in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho presses the bench in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                968
            ],
            "duration": 969,
            "token": {
                "<s0>": 805,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36420",
        "original_caption": "an adult in red presses a bench in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red presses a bench in the gym."
            }
        ],
        "meta": {
            "split": [
                968,
                1323
            ],
            "duration": 356,
            "token": {
                "<s0>": 142,
                "<e0>": 163
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13828973545",
        "aid": "13828973545_36421",
        "original_caption": "there is a borwn dog biting another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a borwn dog biting another dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                624
            ],
            "duration": 625,
            "token": {
                "<s0>": 163,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_36422",
        "original_caption": "there is an adult with white shirt is behind the dancing adult woman.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is an adult with white shirt is behind the dancing adult woman."
            }
        ],
        "meta": {
            "split": [
                705,
                1011
            ],
            "duration": 307,
            "token": {
                "<s0>": 75,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_36423",
        "original_caption": "there is a motorcycle beneath a black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a motorcycle beneath a black dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 240,
                "<e0>": 707
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6108346853",
        "aid": "6108346853_36424",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white plays the guitar on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 308,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8670554760",
        "aid": "8670554760_36425",
        "original_caption": "an adult in yellow clothes holds a bat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in yellow clothes holds a bat."
            }
        ],
        "meta": {
            "split": [
                0,
                331
            ],
            "duration": 332,
            "token": {
                "<s0>": 0,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_36426",
        "original_caption": "the snowboard is slipping away from the adult with a green umbrella",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The snowboard is slipping away from the adult with a green umbrella"
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 240,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_36427",
        "original_caption": "a baby wearing green pants holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby wearing green pants holds a toy on the carpet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1955,
                2144
            ],
            "duration": 190,
            "token": {
                "<s0>": 81,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_36428",
        "original_caption": "a child in black is towards a baby in the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black is towards a baby in the beach."
            }
        ],
        "meta": {
            "split": [
                501,
                1385
            ],
            "duration": 885,
            "token": {
                "<s0>": 352,
                "<e0>": 428
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_36429",
        "original_caption": "an adult man in white hugs a child in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white hugs a child in orange happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 85,
                "<e0>": 154
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_36430",
        "original_caption": "an adult wearing black pants is away from a beige sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing black pants is away from a beige sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                637
            ],
            "duration": 638,
            "token": {
                "<s0>": 120,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_36431",
        "original_caption": "a child shakes hand with a white dog in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child shakes hand with a white dog in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                396
            ],
            "duration": 397,
            "token": {
                "<s0>": 59,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_36432",
        "original_caption": "a child shakes hand with a white dog in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child shakes hand with a white dog in the living room."
            }
        ],
        "meta": {
            "split": [
                396,
                1275
            ],
            "duration": 880,
            "token": {
                "<s0>": 275,
                "<e0>": 350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_36433",
        "original_caption": "a child shakes hand with a white dog in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child shakes hand with a white dog in the living room."
            }
        ],
        "meta": {
            "split": [
                1275,
                2595
            ],
            "duration": 1321,
            "token": {
                "<s0>": 530,
                "<e0>": 606
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3898106739",
        "aid": "3898106739_36434",
        "original_caption": "an adult man is towards a child in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man is towards a child in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                1232
            ],
            "duration": 1233,
            "token": {
                "<s0>": 840,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7162478518",
        "aid": "7162478518_36435",
        "original_caption": "an adult is playing a guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is playing a guitar on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                610
            ],
            "duration": 611,
            "token": {
                "<s0>": 0,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6789657160",
        "aid": "6789657160_36436",
        "original_caption": "an adult in red hugs a child in white at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red hugs a child in white at home."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 0,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_36437",
        "original_caption": "adult in a black suit blond hair above a stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adult in a black suit blond hair above a stool."
            }
        ],
        "meta": {
            "split": [
                0,
                5394
            ],
            "duration": 5395,
            "token": {
                "<s0>": 10,
                "<e0>": 1589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3761379939",
        "aid": "3761379939_36438",
        "original_caption": "a female adult is in front of a male adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the female adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1380
            ],
            "duration": 1381,
            "token": {
                "<s0>": 0,
                "<e0>": 774
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2867108011",
        "aid": "2867108011_36439",
        "original_caption": "a child is in front of the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is in front of the chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                391,
                875
            ],
            "duration": 485,
            "token": {
                "<s0>": 29,
                "<e0>": 479
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_36440",
        "original_caption": "there is a red bicycle away from a motorcycle at night.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bicycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a red bicycle away from a motorcycle at night."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 60,
                "<e0>": 295
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_36441",
        "original_caption": "the adult man is lift the white cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is lift the white cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1476
            ],
            "duration": 1477,
            "token": {
                "<s0>": 839,
                "<e0>": 868
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_36442",
        "original_caption": "the adult man is lift the white cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult man is lift the white cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1476,
                2159
            ],
            "duration": 684,
            "token": {
                "<s0>": 609,
                "<e0>": 646
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9975070616",
        "aid": "9975070616_36443",
        "original_caption": "a baby in striped clothes leans on an adult man in gray on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in striped clothes leans on an adult man in gray on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                660
            ],
            "duration": 661,
            "token": {
                "<s0>": 0,
                "<e0>": 661
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4729027639",
        "aid": "4729027639_36444",
        "original_caption": "an adult is next to a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to a child in the room."
            }
        ],
        "meta": {
            "split": [
                1552,
                2160
            ],
            "duration": 609,
            "token": {
                "<s0>": 153,
                "<e0>": 272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3151486948",
        "aid": "3151486948_36445",
        "original_caption": "an adult man in brown hugs a baby in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in brown hugs a baby in striped clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                372
            ],
            "duration": 373,
            "token": {
                "<s0>": 0,
                "<e0>": 373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3779800369",
        "aid": "3779800369_36446",
        "original_caption": "an adult in green rides a motorcycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green rides a motorcycle on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                311
            ],
            "duration": 312,
            "token": {
                "<s0>": 0,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3779800369",
        "aid": "3779800369_36447",
        "original_caption": "an adult in green rides a motorcycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green rides a motorcycle on the ground."
            }
        ],
        "meta": {
            "split": [
                311,
                956
            ],
            "duration": 646,
            "token": {
                "<s0>": 80,
                "<e0>": 646
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36448",
        "original_caption": "a child is away from a red toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from a red toy."
            }
        ],
        "meta": {
            "split": [
                668,
                1314
            ],
            "duration": 647,
            "token": {
                "<s0>": 52,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7506103208",
        "aid": "7506103208_36449",
        "original_caption": "there is a stool above an adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a stool above an adult on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1283
            ],
            "duration": 1284,
            "token": {
                "<s0>": 0,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3758307290",
        "aid": "3758307290_36450",
        "original_caption": "a child in white holds the guitar in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white holds the guitar in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                657
            ],
            "duration": 658,
            "token": {
                "<s0>": 536,
                "<e0>": 568
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_36451",
        "original_caption": "there is a child in purple behind a child in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind a child in blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 1380,
                "<e0>": 1459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11585587124",
        "aid": "11585587124_36452",
        "original_caption": "an adult woman in black waves hand to a black and white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black waves hand to a black and white dog."
            }
        ],
        "meta": {
            "split": [
                979,
                1649
            ],
            "duration": 671,
            "token": {
                "<s0>": 11,
                "<e0>": 47
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_36453",
        "original_caption": "an adult is next to a skateboard on the training ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is next to a skateboard on the training ground."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 126,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_36454",
        "original_caption": "an adult wearing black pants rides a snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the snowboard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                460
            ],
            "duration": 461,
            "token": {
                "<s0>": 229,
                "<e0>": 300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_36455",
        "original_caption": "an adult wearing black pants rides a snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing black pants rides a snowboard."
            }
        ],
        "meta": {
            "split": [
                460,
                818
            ],
            "duration": 359,
            "token": {
                "<s0>": 161,
                "<e0>": 294
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3457759630",
        "aid": "3457759630_36456",
        "original_caption": "a little baby bites a yellow toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A little baby bites a yellow toy on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1047
            ],
            "duration": 1048,
            "token": {
                "<s0>": 795,
                "<e0>": 875
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3457759630",
        "aid": "3457759630_36457",
        "original_caption": "a little baby bites a yellow toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A little baby bites a yellow toy on the ground."
            }
        ],
        "meta": {
            "split": [
                1047,
                1335
            ],
            "duration": 289,
            "token": {
                "<s0>": 173,
                "<e0>": 271
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_36458",
        "original_caption": "there is a brown dog biting a cloth toy on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the brown dog bite on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1396
            ],
            "duration": 1397,
            "token": {
                "<s0>": 1260,
                "<e0>": 1352
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_36459",
        "original_caption": "there is a brown dog biting a cloth toy on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown dog biting a cloth toy on the grass."
            }
        ],
        "meta": {
            "split": [
                1396,
                1616
            ],
            "duration": 221,
            "token": {
                "<s0>": 44,
                "<e0>": 138
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_36460",
        "original_caption": "there is a brown dog biting a cloth toy on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown dog biting a cloth toy on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1616,
                1926
            ],
            "duration": 311,
            "token": {
                "<s0>": 82,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36461",
        "original_caption": "an adult presses a bench in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult presses a bench in the room."
            }
        ],
        "meta": {
            "split": [
                967,
                1323
            ],
            "duration": 357,
            "token": {
                "<s0>": 145,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5680184714",
        "aid": "5680184714_36462",
        "original_caption": "there is a black cat next to a brown cat on the blanket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black cat next to a brown cat on the blanket."
            }
        ],
        "meta": {
            "split": [
                816,
                2696
            ],
            "duration": 1881,
            "token": {
                "<s0>": 159,
                "<e0>": 1767
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_36463",
        "original_caption": "an adult in black is above a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black is above a chair at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 0,
                "<e0>": 807
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8183766541",
        "aid": "8183766541_36464",
        "original_caption": "a child in white clothes holds a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in white clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 1958
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_36465",
        "original_caption": "there is a big black hamster beneath a small grey rat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the big black hamster from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1020,
                "<e0>": 1170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3306288227",
        "aid": "3306288227_36466",
        "original_caption": "a baby on the left bites another baby on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby on the left bites another baby on the right."
            }
        ],
        "meta": {
            "split": [
                0,
                1668
            ],
            "duration": 1669,
            "token": {
                "<s0>": 1520,
                "<e0>": 1555
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_36467",
        "original_caption": "an adult wearing jeans pats a balck dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pats the balck dog from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1354
            ],
            "duration": 1355,
            "token": {
                "<s0>": 1149,
                "<e0>": 1197
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_36468",
        "original_caption": "an adult wearing jeans pats a balck dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing jeans pats a balck dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1354,
                1769
            ],
            "duration": 416,
            "token": {
                "<s0>": 158,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_36469",
        "original_caption": "there is a smallest elephant behind a big leftmost elephant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a smallest elephant behind a big leftmost elephant."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 370,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36470",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in brown clothes holds a toy on the carpet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                133
            ],
            "duration": 134,
            "token": {
                "<s0>": 0,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36471",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in brown clothes holds a toy on the carpet."
            }
        ],
        "meta": {
            "split": [
                133,
                229
            ],
            "duration": 97,
            "token": {
                "<s0>": 11,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36472",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in brown clothes holds a toy on the carpet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                229,
                565
            ],
            "duration": 337,
            "token": {
                "<s0>": 22,
                "<e0>": 315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36473",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in brown clothes holds a toy on the carpet."
            }
        ],
        "meta": {
            "split": [
                565,
                659
            ],
            "duration": 95,
            "token": {
                "<s0>": 22,
                "<e0>": 46
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36474",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in brown clothes holds a toy on the carpet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                659,
                902
            ],
            "duration": 244,
            "token": {
                "<s0>": 48,
                "<e0>": 235
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36475",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in brown clothes holds a toy on the carpet."
            }
        ],
        "meta": {
            "split": [
                902,
                1118
            ],
            "duration": 217,
            "token": {
                "<s0>": 9,
                "<e0>": 204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36476",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in brown clothes holds a toy on the carpet."
            }
        ],
        "meta": {
            "split": [
                1118,
                1424
            ],
            "duration": 307,
            "token": {
                "<s0>": 13,
                "<e0>": 277
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_36477",
        "original_caption": "a child in brown clothes holds a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1424,
                1592
            ],
            "duration": 169,
            "token": {
                "<s0>": 30,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8426046231",
        "aid": "8426046231_36478",
        "original_caption": "a baby in dark blue holds a colorful plastic bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in dark blue holds a colorful plastic bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                530
            ],
            "duration": 531,
            "token": {
                "<s0>": 0,
                "<e0>": 531
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318165684",
        "aid": "5318165684_36479",
        "original_caption": "an adult in red clothes kicks a shortest adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes kicks a shortest adult."
            }
        ],
        "meta": {
            "split": [
                0,
                587
            ],
            "duration": 588,
            "token": {
                "<s0>": 0,
                "<e0>": 588
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_36480",
        "original_caption": "an adult in black unit kisses another adult in blue dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black unit kisses another adult in blue dress happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1799
            ],
            "duration": 1800,
            "token": {
                "<s0>": 377,
                "<e0>": 1206
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4866672246",
        "aid": "4866672246_36481",
        "original_caption": "a yellow white adult is behind a dog in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A yellow white adult is behind a dog in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 1140,
                "<e0>": 1234
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_36482",
        "original_caption": "an adult woman in green leans on a gray sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult woman in green lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 265,
                "<e0>": 475
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7246410056",
        "aid": "7246410056_36483",
        "original_caption": "a child in blue clothes is behind an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the adult in white clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1212
            ],
            "duration": 1213,
            "token": {
                "<s0>": 1020,
                "<e0>": 1213
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3142287520",
        "aid": "3142287520_36484",
        "original_caption": "there is a red car beneath an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a red car beneath an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 0,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_36485",
        "original_caption": "a child rides a skateboard on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child rides a skateboard on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                244
            ],
            "duration": 245,
            "token": {
                "<s0>": 86,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_36486",
        "original_caption": "a child rides a skateboard on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child rides a skateboard on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                244,
                411
            ],
            "duration": 168,
            "token": {
                "<s0>": 131,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5640939571",
        "aid": "5640939571_36487",
        "original_caption": "there is a black cat behind a baby in blue at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black cat behind a baby in blue at home."
            }
        ],
        "meta": {
            "split": [
                0,
                596
            ],
            "duration": 597,
            "token": {
                "<s0>": 0,
                "<e0>": 79
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_36488",
        "original_caption": "an adult with glasses speaks to a female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with glasses speaks to a female adult."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 320,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7808891456",
        "aid": "7808891456_36489",
        "original_caption": "an adult man in gray lifts a gray fish.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult man in gray lift from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A fish."
            }
        ],
        "meta": {
            "split": [
                0,
                2047
            ],
            "duration": 2048,
            "token": {
                "<s0>": 351,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_36490",
        "original_caption": "an adult in white kisses a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white kisses a baby at home."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 16
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_36491",
        "original_caption": "an skiing adult is behind an another adult walking on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An skiing adult is behind an another adult walking on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 301,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_36492",
        "original_caption": "a child in white chases another child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white chases another child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 310,
                "<e0>": 332
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_36493",
        "original_caption": "a child in white clothes is away from a baby on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white clothes is away from a baby on the grass."
            }
        ],
        "meta": {
            "split": [
                705,
                959
            ],
            "duration": 255,
            "token": {
                "<s0>": 75,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2503862291",
        "aid": "2503862291_36494",
        "original_caption": "there is a grey baby seat beneath a child in white at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_seat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a grey baby seat beneath a child in white at home."
            }
        ],
        "meta": {
            "split": [
                0,
                850
            ],
            "duration": 851,
            "token": {
                "<s0>": 0,
                "<e0>": 851
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36495",
        "original_caption": "there is a camera inside a child in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the camera from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a camera inside a child in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                542
            ],
            "duration": 543,
            "token": {
                "<s0>": 182,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36496",
        "original_caption": "there is a camera inside a child in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a camera inside a child in a room."
            }
        ],
        "meta": {
            "split": [
                542,
                1094
            ],
            "duration": 553,
            "token": {
                "<s0>": 136,
                "<e0>": 238
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5310031663",
        "aid": "5310031663_36497",
        "original_caption": "an adult is next to a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is next to a cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 0,
                "<e0>": 294
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_36498",
        "original_caption": "a child in white is towards a shirtless child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white is towards a shirtless child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                271,
                735
            ],
            "duration": 465,
            "token": {
                "<s0>": 11,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_36499",
        "original_caption": "a child in yellow clothes is away from another child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child in yellow clothes away from from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 120,
                "<e0>": 166
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_36500",
        "original_caption": "there is a beige table beneath a white cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a beige table beneath a white cup."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5606187654",
        "aid": "5606187654_36501",
        "original_caption": "an adult in yellow holds hand of a child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in yellow holds hand of a child in red."
            }
        ],
        "meta": {
            "split": [
                0,
                363
            ],
            "duration": 364,
            "token": {
                "<s0>": 0,
                "<e0>": 364
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_36502",
        "original_caption": "an adult lifts a camera in the cave.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho lifts the camera in the cave from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                484
            ],
            "duration": 485,
            "token": {
                "<s0>": 445,
                "<e0>": 465
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_36503",
        "original_caption": "an adult lifts a camera in the cave.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult lifts a camera in the cave happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                484,
                735
            ],
            "duration": 252,
            "token": {
                "<s0>": 19,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_36504",
        "original_caption": "a child in striped clothes uses a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in striped clothes uses a black cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                270
            ],
            "duration": 271,
            "token": {
                "<s0>": 55,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_36505",
        "original_caption": "a child in striped clothes uses a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in striped clothes uses a black cellphone happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                270,
                1349
            ],
            "duration": 1080,
            "token": {
                "<s0>": 51,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5211051388",
        "aid": "5211051388_36506",
        "original_caption": "a child plays the piano in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child play in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A piano."
            }
        ],
        "meta": {
            "split": [
                0,
                508
            ],
            "duration": 509,
            "token": {
                "<s0>": 0,
                "<e0>": 466
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5211051388",
        "aid": "5211051388_36507",
        "original_caption": "a child plays the piano in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child play in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A piano."
            }
        ],
        "meta": {
            "split": [
                508,
                636
            ],
            "duration": 129,
            "token": {
                "<s0>": 42,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36508",
        "original_caption": "the cat is towards the adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The cat is towards the adult in white."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1082,
                "<e0>": 1289
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_36509",
        "original_caption": "a baby bites a blue toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby bites a blue toy on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2383,
                "<e0>": 2585
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_36510",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 16,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36511",
        "original_caption": "there is a blue sports ball above a plastic bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the plastic bottle at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_36512",
        "original_caption": "there is a brown and white cat getting off a brown wooden chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown and white cat getting off a brown wooden chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1271
            ],
            "duration": 1272,
            "token": {
                "<s0>": 440,
                "<e0>": 480
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_36513",
        "original_caption": "a child in gray holds a plastic bottle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in gray holds a plastic bottle outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1151
            ],
            "duration": 1152,
            "token": {
                "<s0>": 0,
                "<e0>": 1069
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3656309376",
        "aid": "3656309376_36514",
        "original_caption": "an adult man in white holds a white ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the white ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                374
            ],
            "duration": 375,
            "token": {
                "<s0>": 47,
                "<e0>": 96
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6025039044",
        "aid": "6025039044_36515",
        "original_caption": "a baby in white is above a red toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white is above a red toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                128
            ],
            "duration": 129,
            "token": {
                "<s0>": 0,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_36516",
        "original_caption": "there is a smallest elephant towards another elephant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a smallest elephant towards another elephant happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 1740,
                "<e0>": 1815
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3521372410",
        "aid": "3521372410_36517",
        "original_caption": "an adult caresses a baby in blue on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult caress on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 394,
                "<e0>": 496
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36518",
        "original_caption": "a child is in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1059,
                "<e0>": 1169
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_36519",
        "original_caption": "a baby in red bites a bread in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho bites the bread in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                250
            ],
            "duration": 251,
            "token": {
                "<s0>": 59,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6821159131",
        "aid": "6821159131_36520",
        "original_caption": "there is a monitor in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a monitor in front of a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                207
            ],
            "duration": 208,
            "token": {
                "<s0>": 0,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6194807654",
        "aid": "6194807654_36521",
        "original_caption": "an adult on the right speaks to an adult on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult on the right speaks to an adult on the left outdoor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                650
            ],
            "duration": 651,
            "token": {
                "<s0>": 489,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6194807654",
        "aid": "6194807654_36522",
        "original_caption": "an adult on the right speaks to an adult on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult on the right speaks to an adult on the left outdoor."
            }
        ],
        "meta": {
            "split": [
                650,
                793
            ],
            "duration": 144,
            "token": {
                "<s0>": 80,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6194807654",
        "aid": "6194807654_36523",
        "original_caption": "an adult on the right speaks to an adult on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult on the right speaks to an adult on the left outdoor."
            }
        ],
        "meta": {
            "split": [
                793,
                1004
            ],
            "duration": 212,
            "token": {
                "<s0>": 42,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6194807654",
        "aid": "6194807654_36524",
        "original_caption": "an adult on the right speaks to an adult on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult on the right speaks to an adult on the left outdoor."
            }
        ],
        "meta": {
            "split": [
                1004,
                1273
            ],
            "duration": 270,
            "token": {
                "<s0>": 26,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6194807654",
        "aid": "6194807654_36525",
        "original_caption": "an adult on the right speaks to an adult on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult on the right speaks to an adult on the left outdoor."
            }
        ],
        "meta": {
            "split": [
                1273,
                2123
            ],
            "duration": 851,
            "token": {
                "<s0>": 149,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2573250257",
        "aid": "2573250257_36526",
        "original_caption": "an adult wearing sunglasses caresses a child with blond-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing sunglasses caresses a child with blond-hair."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 244,
                "<e0>": 337
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_36527",
        "original_caption": "a child holds a sports ball outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds a sports ball outside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                384
            ],
            "duration": 385,
            "token": {
                "<s0>": 248,
                "<e0>": 291
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_36528",
        "original_caption": "a child holds a sports ball outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holds a sports ball outside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                384,
                743
            ],
            "duration": 360,
            "token": {
                "<s0>": 93,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8996323211",
        "aid": "8996323211_36529",
        "original_caption": "an adult hugs a baby in blue on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult hugs a baby in blue on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1358
            ],
            "duration": 1359,
            "token": {
                "<s0>": 648,
                "<e0>": 745
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_36530",
        "original_caption": "an adult wearing a blue hat holds a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bicycle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 0,
                "<e0>": 91
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36531",
        "original_caption": "an adult is towards a child in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards a child in the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1422,
                "<e0>": 1529
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8575941513",
        "aid": "8575941513_36532",
        "original_caption": "an adult hugs a baby in the park.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hugs the baby in the park from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                822
            ],
            "duration": 823,
            "token": {
                "<s0>": 43,
                "<e0>": 655
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8575941513",
        "aid": "8575941513_36533",
        "original_caption": "an adult hugs a baby in the park.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult hugs a baby in the park."
            }
        ],
        "meta": {
            "split": [
                822,
                2386
            ],
            "duration": 1565,
            "token": {
                "<s0>": 167,
                "<e0>": 242
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_36534",
        "original_caption": "there is a grey sofa beneath a child in blue at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sofa from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a grey sofa beneath a child in blue at home."
            }
        ],
        "meta": {
            "split": [
                0,
                747
            ],
            "duration": 748,
            "token": {
                "<s0>": 0,
                "<e0>": 748
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_36535",
        "original_caption": "an adult watches another adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult watches another adult on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                611,
                2698
            ],
            "duration": 2088,
            "token": {
                "<s0>": 86,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5669212370",
        "aid": "5669212370_36536",
        "original_caption": "there is a car in front of another car on road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the car on road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A car."
            }
        ],
        "meta": {
            "split": [
                0,
                145
            ],
            "duration": 146,
            "token": {
                "<s0>": 102,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2955299637",
        "aid": "2955299637_36537",
        "original_caption": "there is a brown horse beneath an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the horse from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown horse beneath an adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 58,
                "<e0>": 574
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10403393365",
        "aid": "10403393365_36538",
        "original_caption": "there is a beige dog towards a pink bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a beige dog towards a pink bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                341
            ],
            "duration": 342,
            "token": {
                "<s0>": 161,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_36539",
        "original_caption": "a child in black clothes rides a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black clothes rides a snowboard in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 36,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36540",
        "original_caption": "there is a pale green ball above a plastic bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a pale green ball above a plastic bottle at home."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13816283384",
        "aid": "13816283384_36541",
        "original_caption": "there is a tiger toy above a green sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a tiger toy above a green sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                718
            ],
            "duration": 719,
            "token": {
                "<s0>": 0,
                "<e0>": 719
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_36542",
        "original_caption": "a sofa is next to a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the chair  from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                2278,
                4260
            ],
            "duration": 1983,
            "token": {
                "<s0>": 310,
                "<e0>": 1982
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_36543",
        "original_caption": "a child in green speaks to another child in green in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other child in green in the classroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 0,
                "<e0>": 235
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_36544",
        "original_caption": "a baby in white is above a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white is above a baby seat in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 0,
                "<e0>": 1806
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5049587564",
        "aid": "5049587564_36545",
        "original_caption": "a child in brown is in front of another child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in brown is in front of another child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                719
            ],
            "duration": 720,
            "token": {
                "<s0>": 0,
                "<e0>": 720
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_36546",
        "original_caption": "an adult is behind an another adult on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind an another adult on the river."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_36547",
        "original_caption": "there is a cake above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the cake inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                2225
            ],
            "duration": 2226,
            "token": {
                "<s0>": 1980,
                "<e0>": 2215
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12158830025",
        "aid": "12158830025_36548",
        "original_caption": "an adult in green clothes carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes carries a backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1368
            ],
            "duration": 1369,
            "token": {
                "<s0>": 765,
                "<e0>": 982
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4969801682",
        "aid": "4969801682_36549",
        "original_caption": "an adult in black clothes is in front of another adult with curly hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is in front of another adult with curly hair."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6991481998",
        "aid": "6991481998_36550",
        "original_caption": "an adult in green clothes pushes a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green clothes pushes a child in blue clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 795,
                "<e0>": 845
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_36551",
        "original_caption": "a baby in white clothes is towards a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes is towards a toy."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2050,
                "<e0>": 2125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_36552",
        "original_caption": "there is a faucet above a sink in the bathroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a faucet above a sink in the bathroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                821,
                915
            ],
            "duration": 95,
            "token": {
                "<s0>": 45,
                "<e0>": 94
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4352699187",
        "aid": "4352699187_36553",
        "original_caption": "a baby leans on an adult woman in red at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the baby lean on at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                779
            ],
            "duration": 780,
            "token": {
                "<s0>": 0,
                "<e0>": 780
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_36554",
        "original_caption": "there is a glass cup in front of an adult man in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a glass cup in front of an adult man in gray."
            }
        ],
        "meta": {
            "split": [
                0,
                1649
            ],
            "duration": 1650,
            "token": {
                "<s0>": 343,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_36555",
        "original_caption": "there is a golden chair beneath an adult woman in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a golden chair beneath an adult woman in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 0,
                "<e0>": 807
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4825511158",
        "aid": "4825511158_36556",
        "original_caption": "an adult in gray clothes holds a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in gray clothes holds a cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                494
            ],
            "duration": 495,
            "token": {
                "<s0>": 27,
                "<e0>": 273
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_36557",
        "original_caption": "an adult in striped clothes leans on a gray sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in striped clothes leans on a gray sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                419
            ],
            "duration": 420,
            "token": {
                "<s0>": 0,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4717834858",
        "aid": "4717834858_36558",
        "original_caption": "there is a baby walker next to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_walker from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a baby walker next to a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                213
            ],
            "duration": 214,
            "token": {
                "<s0>": 0,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13816283384",
        "aid": "13816283384_36559",
        "original_caption": "there is a grey sofa beneath a grey cat on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a grey sofa beneath a grey cat on a sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                718
            ],
            "duration": 719,
            "token": {
                "<s0>": 0,
                "<e0>": 719
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_36560",
        "original_caption": "a child in red clothes waves hand to another child in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho waves hand to the other child in pink clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 297,
                "<e0>": 312
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6885068488",
        "aid": "6885068488_36561",
        "original_caption": "a baby in white hits a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hits the toy on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                998
            ],
            "duration": 999,
            "token": {
                "<s0>": 88,
                "<e0>": 999
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2492711005",
        "aid": "2492711005_36562",
        "original_caption": "an adult man in shirt hugs a baby in colorful at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in shirt hugs a baby in colorful at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1111
            ],
            "duration": 1112,
            "token": {
                "<s0>": 0,
                "<e0>": 1112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7040233679",
        "aid": "7040233679_36563",
        "original_caption": "an adult woman in black watches a silver cellphone in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in black watches a silver cellphone in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                909
            ],
            "duration": 910,
            "token": {
                "<s0>": 847,
                "<e0>": 867
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3741114842",
        "aid": "3741114842_36564",
        "original_caption": "an adult touches a cake inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult touches a cake inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                482
            ],
            "duration": 483,
            "token": {
                "<s0>": 203,
                "<e0>": 242
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_36565",
        "original_caption": "a child is next to another child in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is next to another child in the classroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                527,
                666
            ],
            "duration": 140,
            "token": {
                "<s0>": 97,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7506103208",
        "aid": "7506103208_36566",
        "original_caption": "a female adult is towards a stool on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the stool on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1185,
                1283
            ],
            "duration": 99,
            "token": {
                "<s0>": 15,
                "<e0>": 99
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3306288227",
        "aid": "3306288227_36567",
        "original_caption": "a baby touches another baby on a bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the baby touch on the bed from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                162
            ],
            "duration": 163,
            "token": {
                "<s0>": 128,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3306288227",
        "aid": "3306288227_36568",
        "original_caption": "a baby touches another baby on a bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby touches another baby on a bed."
            }
        ],
        "meta": {
            "split": [
                162,
                562
            ],
            "duration": 401,
            "token": {
                "<s0>": 6,
                "<e0>": 23
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3306288227",
        "aid": "3306288227_36569",
        "original_caption": "a baby touches another baby on a bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby touches another baby on a bed."
            }
        ],
        "meta": {
            "split": [
                562,
                1183
            ],
            "duration": 622,
            "token": {
                "<s0>": 377,
                "<e0>": 442
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3306288227",
        "aid": "3306288227_36570",
        "original_caption": "a baby touches another baby on a bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby touches another baby on a bed."
            }
        ],
        "meta": {
            "split": [
                1183,
                1440
            ],
            "duration": 258,
            "token": {
                "<s0>": 180,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3306288227",
        "aid": "3306288227_36571",
        "original_caption": "a baby touches another baby on a bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby touches another baby on a bed."
            }
        ],
        "meta": {
            "split": [
                1440,
                1668
            ],
            "duration": 229,
            "token": {
                "<s0>": 49,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3275271763",
        "aid": "3275271763_36572",
        "original_caption": "a child speaks to another child in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child speaks to another child in white outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                593
            ],
            "duration": 594,
            "token": {
                "<s0>": 478,
                "<e0>": 499
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11585587124",
        "aid": "11585587124_36573",
        "original_caption": "there is a dog towards an in black adult in the play field.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog towards an in black adult in the play field."
            }
        ],
        "meta": {
            "split": [
                675,
                1649
            ],
            "duration": 975,
            "token": {
                "<s0>": 285,
                "<e0>": 375
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_36574",
        "original_caption": "an adult wearing a red hat is behind an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a red hat is behind an adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                629,
                1319
            ],
            "duration": 691,
            "token": {
                "<s0>": 244,
                "<e0>": 298
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6273445204",
        "aid": "6273445204_36575",
        "original_caption": "a baby holds a toy in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby hold in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                481
            ],
            "duration": 482,
            "token": {
                "<s0>": 0,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_36576",
        "original_caption": "there is a baby walker beneath a baby in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a baby walker beneath a baby in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1013,
                1516
            ],
            "duration": 504,
            "token": {
                "<s0>": 38,
                "<e0>": 138
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_36577",
        "original_caption": "an adult woman in black is towards another adult woman in black in the tent.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in black is towards another adult woman in black in the tent happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                5394
            ],
            "duration": 5395,
            "token": {
                "<s0>": 3720,
                "<e0>": 3870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_36578",
        "original_caption": "a child pulls an adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child pull in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1446
            ],
            "duration": 1447,
            "token": {
                "<s0>": 1123,
                "<e0>": 1295
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_36579",
        "original_caption": "there is a black skateboard away an adult man in balck.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black skateboard away an adult man in balck happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 144,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36580",
        "original_caption": "an adult in blue clothes pushes a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pushes the cake from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 543,
                "<e0>": 578
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_36581",
        "original_caption": "an adult speaks to a child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 237,
                "<e0>": 266
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_36582",
        "original_caption": "an adult speaks to a child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child inside a room."
            }
        ],
        "meta": {
            "split": [
                357,
                621
            ],
            "duration": 265,
            "token": {
                "<s0>": 92,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_36583",
        "original_caption": "an adult speaks to a child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult speak to inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                621,
                1145
            ],
            "duration": 525,
            "token": {
                "<s0>": 114,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36584",
        "original_caption": "a child is away from an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from an adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 240,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36585",
        "original_caption": "there is a brown sofa beneath an adult in blue at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown sofa beneath an adult in blue at party."
            }
        ],
        "meta": {
            "split": [
                1343,
                1441
            ],
            "duration": 99,
            "token": {
                "<s0>": 25,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_36586",
        "original_caption": "a child is behind a cyan toy outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is behind a cyan toy outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 0,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36587",
        "original_caption": "an adult man in blue is away a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in blue is away a brown cat."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1020,
                "<e0>": 1256
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_36588",
        "original_caption": "a child in purple is in front of an adult with white-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in purple is in front of an adult with white-hair."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 183,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3710885997",
        "aid": "3710885997_36589",
        "original_caption": "an adult with blond-hair watches a child in green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult with blond-hair watch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                497
            ],
            "duration": 498,
            "token": {
                "<s0>": 459,
                "<e0>": 498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_36590",
        "original_caption": "a child in white clothes rides a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white clothes rides a toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 986,
                "<e0>": 1041
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36591",
        "original_caption": "there is a blue ball above an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a blue ball above an adult at home."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_36592",
        "original_caption": "an adult in white is above a ski on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the ski on the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1563,
                "<e0>": 1722
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12624072313",
        "aid": "12624072313_36593",
        "original_caption": "an adult is away another adult on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away another adult on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                1278
            ],
            "duration": 1279,
            "token": {
                "<s0>": 120,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36594",
        "original_caption": "an adult is away from another adult in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult in living room."
            }
        ],
        "meta": {
            "split": [
                315,
                793
            ],
            "duration": 479,
            "token": {
                "<s0>": 165,
                "<e0>": 249
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_36595",
        "original_caption": "an adult pats a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pats the baby at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1496,
                1586
            ],
            "duration": 91,
            "token": {
                "<s0>": 40,
                "<e0>": 80
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_36596",
        "original_caption": "an adult pats a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult pats a baby at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1586,
                1683
            ],
            "duration": 98,
            "token": {
                "<s0>": 10,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3848996383",
        "aid": "3848996383_36597",
        "original_caption": "there is a bottle towards an adult without dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is towards the adult without dress from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                739
            ],
            "duration": 740,
            "token": {
                "<s0>": 501,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_36598",
        "original_caption": "the adult is hold hand of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is hold hand of by the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                349
            ],
            "duration": 350,
            "token": {
                "<s0>": 0,
                "<e0>": 321
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_36599",
        "original_caption": "the adult is hold hand of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult is hold hand of the adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                349,
                1011
            ],
            "duration": 663,
            "token": {
                "<s0>": 28,
                "<e0>": 663
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_36600",
        "original_caption": "a child with a watch uses a laptop in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with a watch uses a laptop in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 228,
                "<e0>": 245
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36601",
        "original_caption": "a child in white dress leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white dress leans on a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 184,
                "<e0>": 202
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36602",
        "original_caption": "a child in white dress leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white dress leans on a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                208,
                410
            ],
            "duration": 203,
            "token": {
                "<s0>": 6,
                "<e0>": 55
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36603",
        "original_caption": "a child in white dress leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white dress leans on a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                410,
                719
            ],
            "duration": 310,
            "token": {
                "<s0>": 148,
                "<e0>": 184
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36604",
        "original_caption": "a child in white dress leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white dress leans on a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                719,
                883
            ],
            "duration": 165,
            "token": {
                "<s0>": 126,
                "<e0>": 155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36605",
        "original_caption": "a child in white dress leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white dress leans on a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                883,
                1070
            ],
            "duration": 188,
            "token": {
                "<s0>": 10,
                "<e0>": 54
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36606",
        "original_caption": "a child in white dress leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white dress leans on a sofa in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1235,
                1560
            ],
            "duration": 326,
            "token": {
                "<s0>": 26,
                "<e0>": 77
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_36607",
        "original_caption": "a child with blond-hair rides a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair rides a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 1099,
                "<e0>": 1252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3588778325",
        "aid": "3588778325_36608",
        "original_caption": "an adult holds a laptop inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult hold inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                93
            ],
            "duration": 94,
            "token": {
                "<s0>": 7,
                "<e0>": 47
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3588778325",
        "aid": "3588778325_36609",
        "original_caption": "an adult holds a laptop inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult hold inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A laptop."
            }
        ],
        "meta": {
            "split": [
                93,
                391
            ],
            "duration": 299,
            "token": {
                "<s0>": 47,
                "<e0>": 237
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_36610",
        "original_caption": "there is a ski beneath an adult on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a ski beneath an adult on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1563,
                "<e0>": 1722
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_36611",
        "original_caption": "there is a table behind a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table behind a black camera happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 729,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_36612",
        "original_caption": "an adult in white watches a black horse on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white watches a black horse on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_36613",
        "original_caption": "there is a black and white dog behind a brown dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black and white dog behind a brown dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 200,
                "<e0>": 275
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_36614",
        "original_caption": "there is a bicycle beneath a child in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle beneath a child in the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                121,
                927
            ],
            "duration": 807,
            "token": {
                "<s0>": 34,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_36615",
        "original_caption": "the sink is in front of the oven.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the sink is in front of the oven happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                794
            ],
            "duration": 795,
            "token": {
                "<s0>": 275,
                "<e0>": 362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_36616",
        "original_caption": "a child in red clothes is above a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is above a bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 0,
                "<e0>": 290
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36617",
        "original_caption": "an adult in red clothes is above a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the bench from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 720,
                "<e0>": 1176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36618",
        "original_caption": "an adult in white clothes gets on a bench in purple clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes gets on a bench in purple clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                803
            ],
            "duration": 804,
            "token": {
                "<s0>": 735,
                "<e0>": 765
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36619",
        "original_caption": "an adult in white clothes gets on a bench in purple clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes gets on a bench in purple clothes."
            }
        ],
        "meta": {
            "split": [
                803,
                932
            ],
            "duration": 130,
            "token": {
                "<s0>": 39,
                "<e0>": 69
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36620",
        "original_caption": "an adult in white clothes gets on a bench in purple clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes gets on a bench in purple clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                932,
                1034
            ],
            "duration": 103,
            "token": {
                "<s0>": 61,
                "<e0>": 86
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36621",
        "original_caption": "an adult in white clothes gets on a bench in purple clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes gets on a bench in purple clothes."
            }
        ],
        "meta": {
            "split": [
                1034,
                1323
            ],
            "duration": 290,
            "token": {
                "<s0>": 17,
                "<e0>": 44
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_36622",
        "original_caption": "a child in orange clothes watches a monitor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in orange clothes watch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                186,
                637
            ],
            "duration": 452,
            "token": {
                "<s0>": 41,
                "<e0>": 452
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_36623",
        "original_caption": "an adult in roller skates pushes a bicycle in the path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in roller skates pushes a bicycle in the path."
            }
        ],
        "meta": {
            "split": [
                0,
                1007
            ],
            "duration": 1008,
            "token": {
                "<s0>": 827,
                "<e0>": 849
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8224546307",
        "aid": "8224546307_36624",
        "original_caption": "a baby in white leans on a white baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white leans on a white baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1457
            ],
            "duration": 1458,
            "token": {
                "<s0>": 0,
                "<e0>": 1458
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945327422",
        "aid": "5945327422_36625",
        "original_caption": "there is a black dog biting an adult man in black shoes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the black dog bite from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 294,
                "<e0>": 337
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945327422",
        "aid": "5945327422_36626",
        "original_caption": "there is a black dog biting an adult man in black shoes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black dog biting an adult man in black shoes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                706,
                1444
            ],
            "duration": 739,
            "token": {
                "<s0>": 369,
                "<e0>": 477
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2503862291",
        "aid": "2503862291_36627",
        "original_caption": "a child in white clothes is above a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white clothes is above a baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                850
            ],
            "duration": 851,
            "token": {
                "<s0>": 0,
                "<e0>": 851
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_36628",
        "original_caption": "there is a ski next to another ski.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the other ski from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ski."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 146,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6572270403",
        "aid": "6572270403_36629",
        "original_caption": "an adult woman lifts a child in colorful at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho lifts the child in colorful at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 380,
                "<e0>": 419
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10274034226",
        "aid": "10274034226_36630",
        "original_caption": "there is a dog behind another dog on the  grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog behind another dog on the  grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                422
            ],
            "duration": 423,
            "token": {
                "<s0>": 300,
                "<e0>": 379
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953736795",
        "aid": "6953736795_36631",
        "original_caption": "there is a car in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the car from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a car in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                133
            ],
            "duration": 134,
            "token": {
                "<s0>": 78,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_36632",
        "original_caption": "there is a snowboard beneath an adult in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a snowboard beneath an adult in the snow."
            }
        ],
        "meta": {
            "split": [
                460,
                818
            ],
            "duration": 359,
            "token": {
                "<s0>": 161,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4235961238",
        "aid": "4235961238_36633",
        "original_caption": "a child with brown-hair holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child with brown-hair hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                472
            ],
            "duration": 473,
            "token": {
                "<s0>": 10,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4235961238",
        "aid": "4235961238_36634",
        "original_caption": "a child with brown-hair holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child with brown-hair hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                472,
                564
            ],
            "duration": 93,
            "token": {
                "<s0>": 24,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36635",
        "original_caption": "an adult in purple clothes leans on a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the bench from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                967
            ],
            "duration": 968,
            "token": {
                "<s0>": 787,
                "<e0>": 827
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36636",
        "original_caption": "an adult in purple clothes leans on a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in purple clothes leans on a bench happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                967,
                1323
            ],
            "duration": 357,
            "token": {
                "<s0>": 140,
                "<e0>": 163
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_36637",
        "original_caption": "there is a hamster towards an adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the hamster/rat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a hamster towards an adult on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 960,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36638",
        "original_caption": "an adult man in red gets off a long bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in red gets off a long bench."
            }
        ],
        "meta": {
            "split": [
                885,
                1013
            ],
            "duration": 129,
            "token": {
                "<s0>": 87,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36639",
        "original_caption": "an adult man in red gets off a long bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in red gets off a long bench."
            }
        ],
        "meta": {
            "split": [
                1068,
                1323
            ],
            "duration": 256,
            "token": {
                "<s0>": 18,
                "<e0>": 35
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7290684468",
        "aid": "7290684468_36640",
        "original_caption": "there is a dog towards a baby in pink on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog towards a baby in pink on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                569
            ],
            "duration": 570,
            "token": {
                "<s0>": 503,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_36641",
        "original_caption": "there is a little child in front of the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a little child in front of the table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 0,
                "<e0>": 1080
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_36642",
        "original_caption": "an adult in blue clothes is behind another adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes is behind another adult in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 0,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_36643",
        "original_caption": "a child in red is next to a sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red is next to a sports ball in the room."
            }
        ],
        "meta": {
            "split": [
                219,
                595
            ],
            "duration": 377,
            "token": {
                "<s0>": 5,
                "<e0>": 376
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7506103208",
        "aid": "7506103208_36644",
        "original_caption": "an adult points to another adult at theshow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult points to another adult at theshow."
            }
        ],
        "meta": {
            "split": [
                0,
                1283
            ],
            "duration": 1284,
            "token": {
                "<s0>": 383,
                "<e0>": 413
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2977359466",
        "aid": "2977359466_36645",
        "original_caption": "an adult is towards another adult in a road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards another adult in a road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                568
            ],
            "duration": 569,
            "token": {
                "<s0>": 399,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36646",
        "original_caption": "an adult in red is away from another adult in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red is away from another adult in gray."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 144,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_36647",
        "original_caption": "there is a sports ball towards a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sports ball towards a child in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 25,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_36648",
        "original_caption": "an adult wearing a plaid clothes holds the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the guitar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                838,
                1135
            ],
            "duration": 298,
            "token": {
                "<s0>": 58,
                "<e0>": 71
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_36649",
        "original_caption": "an adult wearing a plaid clothes holds the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a plaid clothes holds the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1135,
                1583
            ],
            "duration": 449,
            "token": {
                "<s0>": 227,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6910682007",
        "aid": "6910682007_36650",
        "original_caption": "an adult caresses a baby on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult caresses a baby on the bed happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                110
            ],
            "duration": 111,
            "token": {
                "<s0>": 65,
                "<e0>": 81
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6910682007",
        "aid": "6910682007_36651",
        "original_caption": "an adult caresses a baby on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a baby on the bed."
            }
        ],
        "meta": {
            "split": [
                195,
                288
            ],
            "duration": 94,
            "token": {
                "<s0>": 30,
                "<e0>": 50
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6910682007",
        "aid": "6910682007_36652",
        "original_caption": "an adult caresses a baby on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a baby on the bed."
            }
        ],
        "meta": {
            "split": [
                288,
                396
            ],
            "duration": 109,
            "token": {
                "<s0>": 44,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_36653",
        "original_caption": "there is a white baby seat beneath a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                363,
                794
            ],
            "duration": 432,
            "token": {
                "<s0>": 297,
                "<e0>": 432
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36654",
        "original_caption": "a child in black clothes is away a child with long hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child in black clothes away from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1140,
                "<e0>": 1315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2882005417",
        "aid": "2882005417_36655",
        "original_caption": "an adult man holds a black camera on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the black camera on the wild from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                922
            ],
            "duration": 923,
            "token": {
                "<s0>": 643,
                "<e0>": 681
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5640939571",
        "aid": "5640939571_36656",
        "original_caption": "a baby in blue clothes leans on a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in blue clothes leans on a baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                596
            ],
            "duration": 597,
            "token": {
                "<s0>": 0,
                "<e0>": 597
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36657",
        "original_caption": "the adult is hold hand of the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is hold hand of the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 644,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2867108011",
        "aid": "2867108011_36658",
        "original_caption": "a child leans on a table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child leans on a table in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 0,
                "<e0>": 876
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_36659",
        "original_caption": "an adult in red carries the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in red carry on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1923
            ],
            "duration": 1924,
            "token": {
                "<s0>": 1858,
                "<e0>": 1906
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_36660",
        "original_caption": "an adult in red carries the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red carries the guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                1923,
                2024
            ],
            "duration": 102,
            "token": {
                "<s0>": 17,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_36661",
        "original_caption": "there is a sofa behind an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 10,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10304757716",
        "aid": "10304757716_36662",
        "original_caption": "a baby in green leans on a chair indoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in green leans on a chair indoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1622
            ],
            "duration": 1623,
            "token": {
                "<s0>": 0,
                "<e0>": 523
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_36663",
        "original_caption": "an adult in black clothes is beneath a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is beneath a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 0,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10548477625",
        "aid": "10548477625_36664",
        "original_caption": "an adult in white carries a green backpack on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in white carry on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 0,
                "<e0>": 77
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_36665",
        "original_caption": "an adult watches a skateboard on a stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult watches a skateboard on a stool."
            }
        ],
        "meta": {
            "split": [
                784,
                986
            ],
            "duration": 203,
            "token": {
                "<s0>": 179,
                "<e0>": 199
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_36666",
        "original_caption": "an adult in white clothes is towards another adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult in white clothes towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                929
            ],
            "duration": 930,
            "token": {
                "<s0>": 720,
                "<e0>": 784
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4329580374",
        "aid": "4329580374_36667",
        "original_caption": "a baby on the right watches another baby on the left on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby on the right watches another baby on the left on the bed happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                406,
                711
            ],
            "duration": 306,
            "token": {
                "<s0>": 64,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_36668",
        "original_caption": "a child in red is behind an adult outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is behind an adult outdoor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 665,
                "<e0>": 799
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_36669",
        "original_caption": "a child on the left kicks an another child on the right on the swing.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho kicks the other child on the right on the swing from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 101,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7162478518",
        "aid": "7162478518_36670",
        "original_caption": "a seated adult plays the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a seated adult plays the guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                610
            ],
            "duration": 611,
            "token": {
                "<s0>": 0,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13097816293",
        "aid": "13097816293_36671",
        "original_caption": "there is a sofa beneath an adult in beige clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sofa from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sofa beneath an adult in beige clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1104
            ],
            "duration": 1105,
            "token": {
                "<s0>": 0,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8136606220",
        "aid": "8136606220_36672",
        "original_caption": "there is a surfboard beneath an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the surfboard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                260
            ],
            "duration": 261,
            "token": {
                "<s0>": 48,
                "<e0>": 212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2422958285",
        "aid": "2422958285_36673",
        "original_caption": "there is a sofa beneath an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                185,
                456
            ],
            "duration": 272,
            "token": {
                "<s0>": 55,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_36674",
        "original_caption": "an adult rides a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the watercraft from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 486,
                "<e0>": 1393
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_36675",
        "original_caption": "the child is in front of the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 480
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_36676",
        "original_caption": "an adult in green carries a handbag on the mountain.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green carries a handbag on the mountain."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 37,
                "<e0>": 178
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_36677",
        "original_caption": "an adult man in white is behind another adult man in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult man in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36678",
        "original_caption": "an adult leans on a bench inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult leans on a bench inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                964
            ],
            "duration": 965,
            "token": {
                "<s0>": 805,
                "<e0>": 827
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36679",
        "original_caption": "an adult leans on a bench inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult leans on a bench inside a room."
            }
        ],
        "meta": {
            "split": [
                964,
                1323
            ],
            "duration": 360,
            "token": {
                "<s0>": 137,
                "<e0>": 217
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36680",
        "original_caption": "an adult with both hands on the back in front of the cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with both hands on the back in front of the cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 720,
                "<e0>": 964
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5640939571",
        "aid": "5640939571_36681",
        "original_caption": "a baby in blue touches a black dish at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby in blue touch at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dish."
            }
        ],
        "meta": {
            "split": [
                0,
                596
            ],
            "duration": 597,
            "token": {
                "<s0>": 173,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_36682",
        "original_caption": "an adult man in black an gray carries a black backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black an gray carries a black backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                188
            ],
            "duration": 189,
            "token": {
                "<s0>": 0,
                "<e0>": 53
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_36683",
        "original_caption": "an adult man in black an gray carries a black backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult man in black an gray carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                188,
                697
            ],
            "duration": 510,
            "token": {
                "<s0>": 135,
                "<e0>": 301
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_36684",
        "original_caption": "an adult man in black an gray carries a black backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black an gray carries a black backpack happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                697,
                1151
            ],
            "duration": 455,
            "token": {
                "<s0>": 209,
                "<e0>": 261
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_36685",
        "original_caption": "an adult is away from a stool in the bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult away from in the bar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A stool."
            }
        ],
        "meta": {
            "split": [
                915,
                1011
            ],
            "duration": 97,
            "token": {
                "<s0>": 45,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6542701985",
        "aid": "6542701985_36686",
        "original_caption": "an adult in black clothes is away from another adult wearing white pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is away from another adult wearing white pants."
            }
        ],
        "meta": {
            "split": [
                0,
                175
            ],
            "duration": 176,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_36687",
        "original_caption": "a baby is inside a baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby is inside a baby seat at home."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 0,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36688",
        "original_caption": "there is a baby seat beneath a blue ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a baby seat beneath a blue ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_36689",
        "original_caption": "there is a table beneath a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cup in the room."
            }
        ],
        "meta": {
            "split": [
                395,
                637
            ],
            "duration": 243,
            "token": {
                "<s0>": 25,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36690",
        "original_caption": "there is a red cup in front of an adult holding a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a red cup in front of an adult holding a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36691",
        "original_caption": "the adult in red is beneath the ball/sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in red is beneath the ball/sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3342105817",
        "aid": "3342105817_36692",
        "original_caption": "an adult woman in black holds a dark blue chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the dark blue chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                637
            ],
            "duration": 638,
            "token": {
                "<s0>": 0,
                "<e0>": 638
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4254574573",
        "aid": "4254574573_36693",
        "original_caption": "an adult touches a cellphone on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the cellphone on the right from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                974
            ],
            "duration": 975,
            "token": {
                "<s0>": 364,
                "<e0>": 393
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12577546265",
        "aid": "12577546265_36694",
        "original_caption": "there is a green snowboard beneath an adult with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a green snowboard beneath an adult with glasses happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                190
            ],
            "duration": 191,
            "token": {
                "<s0>": 66,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_36695",
        "original_caption": "an adult in white pushes a child in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white pushes a child in pink."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 220,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_36696",
        "original_caption": "an adult carries a sports ball in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult carries a sports ball in the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                382
            ],
            "duration": 383,
            "token": {
                "<s0>": 193,
                "<e0>": 355
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_36697",
        "original_caption": "an adult carries a sports ball in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult carry in the wild from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                382,
                523
            ],
            "duration": 142,
            "token": {
                "<s0>": 27,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8994675143",
        "aid": "8994675143_36698",
        "original_caption": "an adult wearing a watch is above a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a watch is above a chair."
            }
        ],
        "meta": {
            "split": [
                487,
                1005
            ],
            "duration": 519,
            "token": {
                "<s0>": 56,
                "<e0>": 518
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_36699",
        "original_caption": "an adult in green leans on a light grey sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in green lean on at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                334
            ],
            "duration": 335,
            "token": {
                "<s0>": 0,
                "<e0>": 335
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047939514",
        "aid": "6047939514_36700",
        "original_caption": "a child without dress shouts at a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho shouts at the baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                332
            ],
            "duration": 333,
            "token": {
                "<s0>": 276,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047939514",
        "aid": "6047939514_36701",
        "original_caption": "a child without dress shouts at a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child without dress shouts at a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                332,
                627
            ],
            "duration": 296,
            "token": {
                "<s0>": 8,
                "<e0>": 51
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_36702",
        "original_caption": "there is a black table beneath a yellow cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black table beneath a yellow cup."
            }
        ],
        "meta": {
            "split": [
                1632,
                2225
            ],
            "duration": 594,
            "token": {
                "<s0>": 528,
                "<e0>": 594
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_36703",
        "original_caption": "there is a blue bottle above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a blue bottle above a table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                303,
                726
            ],
            "duration": 424,
            "token": {
                "<s0>": 251,
                "<e0>": 351
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_36704",
        "original_caption": "an adult holds hand of a baby on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the baby on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                760
            ],
            "duration": 761,
            "token": {
                "<s0>": 440,
                "<e0>": 526
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_36705",
        "original_caption": "an adult in multi-color watches a child in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in multi-color watches a child in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                242,
                1079
            ],
            "duration": 838,
            "token": {
                "<s0>": 29,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6856075223",
        "aid": "6856075223_36706",
        "original_caption": "there is a grey goat away from another brown goat outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a grey goat away from another brown goat outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 300,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9562161527",
        "aid": "9562161527_36707",
        "original_caption": "there is a chair beneath an adult in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the chair in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                189
            ],
            "duration": 190,
            "token": {
                "<s0>": 120,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_36708",
        "original_caption": "there is adult away the adult in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is adult away the adult in green."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 40,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_36709",
        "original_caption": "a child in white clothes is in front of another child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes is in front of another child in red clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1412,
                1818
            ],
            "duration": 407,
            "token": {
                "<s0>": 188,
                "<e0>": 313
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8670554760",
        "aid": "8670554760_36710",
        "original_caption": "an adult holds a bat in the contest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a bat in the contest."
            }
        ],
        "meta": {
            "split": [
                0,
                132
            ],
            "duration": 133,
            "token": {
                "<s0>": 43,
                "<e0>": 77
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8670554760",
        "aid": "8670554760_36711",
        "original_caption": "an adult holds a bat in the contest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a bat in the contest."
            }
        ],
        "meta": {
            "split": [
                132,
                331
            ],
            "duration": 200,
            "token": {
                "<s0>": 56,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_36712",
        "original_caption": "an adult in green clothes holds hand of another adult in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes holds hand of another adult in striped clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                810
            ],
            "duration": 811,
            "token": {
                "<s0>": 0,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_36713",
        "original_caption": "a child in black clothes is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                334
            ],
            "duration": 335,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_36714",
        "original_caption": "a child in white leans on a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the chair in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 219,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7966428674",
        "aid": "7966428674_36715",
        "original_caption": "there is a bird towards another bird on thegrass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bird towards another bird on thegrass."
            }
        ],
        "meta": {
            "split": [
                0,
                880
            ],
            "duration": 881,
            "token": {
                "<s0>": 105,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_36716",
        "original_caption": "an adult is away from another adult in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult in a bar."
            }
        ],
        "meta": {
            "split": [
                705,
                1011
            ],
            "duration": 307,
            "token": {
                "<s0>": 255,
                "<e0>": 307
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4715441335",
        "aid": "4715441335_36717",
        "original_caption": "the baby presses the toy on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The baby presses the toy on the chair."
            }
        ],
        "meta": {
            "split": [
                1157,
                1733
            ],
            "duration": 577,
            "token": {
                "<s0>": 379,
                "<e0>": 423
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3802656968",
        "aid": "3802656968_36718",
        "original_caption": "the adult in white shirt is holding a snake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in white shirt is holding a snake."
            }
        ],
        "meta": {
            "split": [
                0,
                1481
            ],
            "duration": 1482,
            "token": {
                "<s0>": 133,
                "<e0>": 189
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3004044251",
        "aid": "3004044251_36719",
        "original_caption": "an adult in black clothes is next to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                285,
                663
            ],
            "duration": 379,
            "token": {
                "<s0>": 15,
                "<e0>": 379
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2641296813",
        "aid": "2641296813_36720",
        "original_caption": "there is a white and brown rabbit towards a white and brown rabbit in the cage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white and brown rabbit towards a white and brown rabbit in the cage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                507
            ],
            "duration": 508,
            "token": {
                "<s0>": 180,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114859483",
        "aid": "8114859483_36721",
        "original_caption": "there is a camera next to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a camera next to an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 180,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4715441335",
        "aid": "4715441335_36722",
        "original_caption": "there is a blue toy behind an adult in khaki trousers.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a blue toy behind an adult in khaki trousers happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1733
            ],
            "duration": 1734,
            "token": {
                "<s0>": 1662,
                "<e0>": 1733
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_36723",
        "original_caption": "an adult in blue clothes plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue clothes plays the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                290
            ],
            "duration": 291,
            "token": {
                "<s0>": 121,
                "<e0>": 243
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_36724",
        "original_caption": "an adult in blue clothes plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes plays the guitar."
            }
        ],
        "meta": {
            "split": [
                290,
                2249
            ],
            "duration": 1960,
            "token": {
                "<s0>": 48,
                "<e0>": 1960
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_36725",
        "original_caption": "the child in blue is watching the child in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The child in blue is watching the child in pink."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 49,
                "<e0>": 117
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4452690447",
        "aid": "4452690447_36726",
        "original_caption": "an adult man in black plays a brown guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black plays a brown guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                614
            ],
            "duration": 615,
            "token": {
                "<s0>": 0,
                "<e0>": 615
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36727",
        "original_caption": "there is a brown and white dog next to an adult man in wathet blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the adult man in wathet blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                1162,
                1441
            ],
            "duration": 280,
            "token": {
                "<s0>": 107,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4474456610",
        "aid": "4474456610_36728",
        "original_caption": "a child pats a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pats the toy inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1469,
                1892
            ],
            "duration": 424,
            "token": {
                "<s0>": 191,
                "<e0>": 205
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_36729",
        "original_caption": "an adult is above a stool in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in the bar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A stool."
            }
        ],
        "meta": {
            "split": [
                694,
                1011
            ],
            "duration": 318,
            "token": {
                "<s0>": 26,
                "<e0>": 318
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4474456610",
        "aid": "4474456610_36730",
        "original_caption": "there is a brown dog away a child in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown dog away a child in striped clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1330,
                "<e0>": 1384
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_36731",
        "original_caption": "a child leans on a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child leans on a sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                334
            ],
            "duration": 335,
            "token": {
                "<s0>": 0,
                "<e0>": 49
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11841865713",
        "aid": "11841865713_36732",
        "original_caption": "a baby holds an adult on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby holds an adult on the bed happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 18,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36733",
        "original_caption": "a child is towards a glass bottle in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is towards a glass bottle in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_36734",
        "original_caption": "a child with blond-hair leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair leans on a table."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 312,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_36735",
        "original_caption": "a baby leans on a baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the baby seat at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                393
            ],
            "duration": 394,
            "token": {
                "<s0>": 0,
                "<e0>": 315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_36736",
        "original_caption": "a baby leans on a baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby leans on a baby seat at home."
            }
        ],
        "meta": {
            "split": [
                393,
                825
            ],
            "duration": 433,
            "token": {
                "<s0>": 78,
                "<e0>": 433
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_36737",
        "original_caption": "a child releases a ball in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child release in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                1163,
                1691
            ],
            "duration": 529,
            "token": {
                "<s0>": 288,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_36738",
        "original_caption": "a child releases a ball in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child release in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                1691,
                2069
            ],
            "duration": 379,
            "token": {
                "<s0>": 225,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_36739",
        "original_caption": "a child in white clothes is away from a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white clothes is away from a ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4969801682",
        "aid": "4969801682_36740",
        "original_caption": "a groom adult speaks to a bride adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A groom adult speaks to a bride adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2382
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4968407890",
        "aid": "4968407890_36741",
        "original_caption": "an adult in yellow clothes rides a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow clothes rides a surfboard on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                275
            ],
            "duration": 276,
            "token": {
                "<s0>": 0,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4968407890",
        "aid": "4968407890_36742",
        "original_caption": "an adult in yellow clothes rides a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow clothes rides a surfboard on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                275,
                608
            ],
            "duration": 334,
            "token": {
                "<s0>": 21,
                "<e0>": 324
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4968407890",
        "aid": "4968407890_36743",
        "original_caption": "an adult in yellow clothes rides a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in yellow clothes rides a surfboard on the lake."
            }
        ],
        "meta": {
            "split": [
                608,
                939
            ],
            "duration": 332,
            "token": {
                "<s0>": 9,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_36744",
        "original_caption": "an adult leans on a brown table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult leans on a brown table at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 162,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6434469849",
        "aid": "6434469849_36745",
        "original_caption": "a black baby touches a dog in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A black baby touches a dog in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                485
            ],
            "duration": 486,
            "token": {
                "<s0>": 145,
                "<e0>": 235
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_36746",
        "original_caption": "a child standing still is above a skateboard indoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child standing still is above a skateboard indoors."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 293,
                "<e0>": 359
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_36747",
        "original_caption": "an adult in black clothes rides a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black clothes ride from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_36748",
        "original_caption": "a baby leans on a light yellow table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the light yellow table at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                307
            ],
            "duration": 308,
            "token": {
                "<s0>": 0,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_36749",
        "original_caption": "a baby leans on a light yellow table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby leans on a light yellow table at home."
            }
        ],
        "meta": {
            "split": [
                307,
                726
            ],
            "duration": 420,
            "token": {
                "<s0>": 247,
                "<e0>": 350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2718262890",
        "aid": "2718262890_36750",
        "original_caption": "an adult man in black speaks to another adult man in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black speaks to another adult man in white."
            }
        ],
        "meta": {
            "split": [
                0,
                467
            ],
            "duration": 468,
            "token": {
                "<s0>": 31,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_36751",
        "original_caption": "there is a hamster behind another hamster on the blanket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the hamster/rat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a hamster behind another hamster on the blanket."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1620,
                "<e0>": 1690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_36752",
        "original_caption": "the child is holding the dish and eating.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child holding from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dish."
            }
        ],
        "meta": {
            "split": [
                0,
                531
            ],
            "duration": 532,
            "token": {
                "<s0>": 0,
                "<e0>": 474
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_36753",
        "original_caption": "the child is holding the dish and eating.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The child is holding the dish and eating."
            }
        ],
        "meta": {
            "split": [
                531,
                780
            ],
            "duration": 250,
            "token": {
                "<s0>": 57,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36754",
        "original_caption": "an adult woman in gray grabs a white and blue cake in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray grabs a white and blue cake in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2466,
                "<e0>": 2617
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2867108011",
        "aid": "2867108011_36755",
        "original_caption": "there is a screen inside a table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is outside the screen in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 0,
                "<e0>": 870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_36756",
        "original_caption": "an adult woman in blue caresses a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in blue caresses a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                253
            ],
            "duration": 254,
            "token": {
                "<s0>": 3,
                "<e0>": 229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_36757",
        "original_caption": "an adult woman in blue caresses a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in blue caress from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                253,
                467
            ],
            "duration": 215,
            "token": {
                "<s0>": 25,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_36758",
        "original_caption": "an adult woman in blue caresses a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in blue caresses a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                467,
                620
            ],
            "duration": 154,
            "token": {
                "<s0>": 91,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_36759",
        "original_caption": "an adult woman in blue caresses a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in blue caresses a baby."
            }
        ],
        "meta": {
            "split": [
                620,
                711
            ],
            "duration": 92,
            "token": {
                "<s0>": 31,
                "<e0>": 50
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_36760",
        "original_caption": "an adult woman in blue caresses a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in blue caresses a baby."
            }
        ],
        "meta": {
            "split": [
                711,
                915
            ],
            "duration": 205,
            "token": {
                "<s0>": 42,
                "<e0>": 58
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36761",
        "original_caption": "an adult in grey lifts a cake in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in grey lifts a cake in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2632,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3843663025",
        "aid": "3843663025_36762",
        "original_caption": "a child wearing a red halmet leans on a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child wearing a red halmet leans on a bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                296
            ],
            "duration": 297,
            "token": {
                "<s0>": 0,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3843663025",
        "aid": "3843663025_36763",
        "original_caption": "a child wearing a red halmet leans on a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing a red halmet leans on a bicycle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                296,
                545
            ],
            "duration": 250,
            "token": {
                "<s0>": 163,
                "<e0>": 213
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4397142322",
        "aid": "4397142322_36764",
        "original_caption": "there is a three flower cat touching a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a three flower cat touching a bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                1128
            ],
            "duration": 1129,
            "token": {
                "<s0>": 405,
                "<e0>": 448
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4397142322",
        "aid": "4397142322_36765",
        "original_caption": "there is a three flower cat touching a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a three flower cat touching a bicycle."
            }
        ],
        "meta": {
            "split": [
                1128,
                1898
            ],
            "duration": 771,
            "token": {
                "<s0>": 681,
                "<e0>": 701
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4397142322",
        "aid": "4397142322_36766",
        "original_caption": "there is a three flower cat touching a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a three flower cat touching a bicycle."
            }
        ],
        "meta": {
            "split": [
                1898,
                2012
            ],
            "duration": 115,
            "token": {
                "<s0>": 70,
                "<e0>": 91
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4397142322",
        "aid": "4397142322_36767",
        "original_caption": "there is a three flower cat touching a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a three flower cat touching a bicycle."
            }
        ],
        "meta": {
            "split": [
                2012,
                2696
            ],
            "duration": 685,
            "token": {
                "<s0>": 24,
                "<e0>": 45
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4142450052",
        "aid": "4142450052_36768",
        "original_caption": "there is a frisbee away from a dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away from the dog from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A frisbee."
            }
        ],
        "meta": {
            "split": [
                0,
                503
            ],
            "duration": 504,
            "token": {
                "<s0>": 0,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36769",
        "original_caption": "the adult in orange is holding a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in orange is holding a toy."
            }
        ],
        "meta": {
            "split": [
                0,
                641
            ],
            "duration": 642,
            "token": {
                "<s0>": 569,
                "<e0>": 607
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36770",
        "original_caption": "the adult in orange is holding a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in orange is holding a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                641,
                1314
            ],
            "duration": 674,
            "token": {
                "<s0>": 34,
                "<e0>": 160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_36771",
        "original_caption": "a child rides a snowboard on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a snowboard on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 94,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_36772",
        "original_caption": "a child is next to an another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                677,
                872
            ],
            "duration": 196,
            "token": {
                "<s0>": 48,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3811600452",
        "aid": "3811600452_36773",
        "original_caption": "there is black cat next to the yellow cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is black cat next to the yellow cat."
            }
        ],
        "meta": {
            "split": [
                636,
                2157
            ],
            "duration": 1522,
            "token": {
                "<s0>": 36,
                "<e0>": 252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_36774",
        "original_caption": "an adult in green is in front of another adult in white in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green is in front of another adult in white in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36775",
        "original_caption": "a child in wathet blue is towards an adult man in wathet blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in wathet blue is towards an adult man in wathet blue."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 582,
                "<e0>": 647
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5270774640",
        "aid": "5270774640_36776",
        "original_caption": "there is a dog on the left hitting another dog on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dog on the left hitting another dog on the right."
            }
        ],
        "meta": {
            "split": [
                0,
                222
            ],
            "duration": 223,
            "token": {
                "<s0>": 13,
                "<e0>": 42
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5302457137",
        "aid": "5302457137_36777",
        "original_caption": "there is a golden cat biting a faucet silver in the bathroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the golden cat bite in the bathroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A faucet."
            }
        ],
        "meta": {
            "split": [
                0,
                224
            ],
            "duration": 225,
            "token": {
                "<s0>": 156,
                "<e0>": 213
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6885601275",
        "aid": "6885601275_36778",
        "original_caption": "an adult in red waves a yellow bottle in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red waves a yellow bottle in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1636
            ],
            "duration": 1637,
            "token": {
                "<s0>": 0,
                "<e0>": 1637
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9787043852",
        "aid": "9787043852_36779",
        "original_caption": "there is a black laptop above a white table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black laptop above a white table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1409
            ],
            "duration": 1410,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12212857646",
        "aid": "12212857646_36780",
        "original_caption": "an adult in black clothes chases a child in purple clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes chases a child in purple clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1170
            ],
            "duration": 1171,
            "token": {
                "<s0>": 137,
                "<e0>": 229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4624548287",
        "aid": "4624548287_36781",
        "original_caption": "an adult in white rides a sliver scooter in the evening.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white rides a sliver scooter in the evening."
            }
        ],
        "meta": {
            "split": [
                0,
                81
            ],
            "duration": 82,
            "token": {
                "<s0>": 0,
                "<e0>": 55
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4624548287",
        "aid": "4624548287_36782",
        "original_caption": "an adult in white rides a sliver scooter in the evening.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white rides a sliver scooter in the evening."
            }
        ],
        "meta": {
            "split": [
                81,
                671
            ],
            "duration": 591,
            "token": {
                "<s0>": 27,
                "<e0>": 408
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_36783",
        "original_caption": "there is a white screen behind a yellow toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white screen behind a yellow toy at home."
            }
        ],
        "meta": {
            "split": [
                1474,
                1868
            ],
            "duration": 395,
            "token": {
                "<s0>": 216,
                "<e0>": 394
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5455502386",
        "aid": "5455502386_36784",
        "original_caption": "a child touches an adult outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child touch outside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                268
            ],
            "duration": 269,
            "token": {
                "<s0>": 237,
                "<e0>": 269
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5134456273",
        "aid": "5134456273_36785",
        "original_caption": "an adult in black clothes holds a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                477
            ],
            "duration": 478,
            "token": {
                "<s0>": 311,
                "<e0>": 369
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5134456273",
        "aid": "5134456273_36786",
        "original_caption": "an adult in black clothes holds a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes holds a ball."
            }
        ],
        "meta": {
            "split": [
                477,
                672
            ],
            "duration": 196,
            "token": {
                "<s0>": 109,
                "<e0>": 167
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5134456273",
        "aid": "5134456273_36787",
        "original_caption": "an adult in black clothes holds a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                672,
                1139
            ],
            "duration": 468,
            "token": {
                "<s0>": 29,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953143775",
        "aid": "6953143775_36788",
        "original_caption": "an adult man in blue pulls another adult man in black on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult man in blue pull on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                188
            ],
            "duration": 189,
            "token": {
                "<s0>": 78,
                "<e0>": 130
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_36789",
        "original_caption": "an adult women is in front of another adult man.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women is in front of another adult man."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 1824,
                "<e0>": 1896
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_36790",
        "original_caption": "a baby in black clothes holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in black clothes holds a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                319
            ],
            "duration": 320,
            "token": {
                "<s0>": 0,
                "<e0>": 236
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_36791",
        "original_caption": "a baby in black clothes holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in black clothes holds a toy."
            }
        ],
        "meta": {
            "split": [
                319,
                998
            ],
            "duration": 680,
            "token": {
                "<s0>": 83,
                "<e0>": 615
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6045154695",
        "aid": "6045154695_36792",
        "original_caption": "a child with blond-hair is towards a white table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair is towards a white table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1485,
                1965
            ],
            "duration": 481,
            "token": {
                "<s0>": 375,
                "<e0>": 465
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_36793",
        "original_caption": "an adult speaks to another adult in the building.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to another adult in the building."
            }
        ],
        "meta": {
            "split": [
                0,
                1582
            ],
            "duration": 1583,
            "token": {
                "<s0>": 1328,
                "<e0>": 1452
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5020559269",
        "aid": "5020559269_36794",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white plays the guitar on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8136314361",
        "aid": "8136314361_36795",
        "original_caption": "an adult rides a skateboard in front of building.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a skateboard in front of building."
            }
        ],
        "meta": {
            "split": [
                0,
                110
            ],
            "duration": 111,
            "token": {
                "<s0>": 40,
                "<e0>": 66
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318165684",
        "aid": "5318165684_36796",
        "original_caption": "an adult in red clothes carries a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red clothes carries a bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                538
            ],
            "duration": 539,
            "token": {
                "<s0>": 0,
                "<e0>": 535
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3151486948",
        "aid": "3151486948_36797",
        "original_caption": "there is a monitor next to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a monitor next to an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                372
            ],
            "duration": 373,
            "token": {
                "<s0>": 0,
                "<e0>": 373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3185202077",
        "aid": "3185202077_36798",
        "original_caption": "an adult man holds a bottle in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man holds a bottle in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                409
            ],
            "duration": 410,
            "token": {
                "<s0>": 315,
                "<e0>": 359
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3457759630",
        "aid": "3457759630_36799",
        "original_caption": "there is a toy next to another toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy next to another toy on the floor."
            }
        ],
        "meta": {
            "split": [
                429,
                1388
            ],
            "duration": 960,
            "token": {
                "<s0>": 121,
                "<e0>": 409
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3471851958",
        "aid": "3471851958_36800",
        "original_caption": "the adult in red is above the motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the motorcycle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                179
            ],
            "duration": 180,
            "token": {
                "<s0>": 0,
                "<e0>": 180
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_36801",
        "original_caption": "an adult in black is beneath a screen in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black is beneath a screen in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_36802",
        "original_caption": "adults in red shoes are leaning on a motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adults in red shoes are leaning on a motorcycle."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 130,
                "<e0>": 707
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_36803",
        "original_caption": "there is a screen above an adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a screen above an adult in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                872,
                2271
            ],
            "duration": 1400,
            "token": {
                "<s0>": 662,
                "<e0>": 1399
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6273445204",
        "aid": "6273445204_36804",
        "original_caption": "a baby in black leans on an adult man in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in black leans on an adult man in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                481
            ],
            "duration": 482,
            "token": {
                "<s0>": 0,
                "<e0>": 404
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36805",
        "original_caption": "there is a toy behind a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy behind a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 420,
                "<e0>": 528
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_36806",
        "original_caption": "an adult with stride clothes speaks to a child in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with stride clothes speaks to a child in pink happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 272,
                "<e0>": 470
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047707188",
        "aid": "6047707188_36807",
        "original_caption": "an adult on the left is in front of another adult on the right in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult on the left is in front of another adult on the right in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 40,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_36808",
        "original_caption": "there is a table beneath a cup outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cup outside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572624205",
        "aid": "8572624205_36809",
        "original_caption": "a baby leans on a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby lean on  in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4670796220",
        "aid": "4670796220_36810",
        "original_caption": "a baby in white is inside a red toy in the path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white is inside a red toy in the path happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 0,
                "<e0>": 408
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7803526566",
        "aid": "7803526566_36811",
        "original_caption": "the baby plays the piano in the man's arms.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the baby plays the piano in the man's arms happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                748
            ],
            "duration": 749,
            "token": {
                "<s0>": 35,
                "<e0>": 749
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_36812",
        "original_caption": "a child in orange clothes is in front of a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in orange clothes is in front of a yellow toy."
            }
        ],
        "meta": {
            "split": [
                135,
                637
            ],
            "duration": 503,
            "token": {
                "<s0>": 25,
                "<e0>": 494
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_36813",
        "original_caption": "there is a beige table beneath a white dish.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a beige table beneath a white dish."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_36814",
        "original_caption": "an adult caresses a hamster on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the hamster on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1053
            ],
            "duration": 1054,
            "token": {
                "<s0>": 533,
                "<e0>": 585
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_36815",
        "original_caption": "an adult caresses a hamster on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult caresses a hamster on the floor."
            }
        ],
        "meta": {
            "split": [
                1053,
                2639
            ],
            "duration": 1587,
            "token": {
                "<s0>": 468,
                "<e0>": 572
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36816",
        "original_caption": "an adult in white carries a red backpack outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries the red backpack outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1706
            ],
            "duration": 1707,
            "token": {
                "<s0>": 1323,
                "<e0>": 1611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36817",
        "original_caption": "an adult in white carries a red backpack outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white carries a red backpack outdoors."
            }
        ],
        "meta": {
            "split": [
                1706,
                2024
            ],
            "duration": 319,
            "token": {
                "<s0>": 96,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3120535570",
        "aid": "3120535570_36818",
        "original_caption": "an adult in black leans on a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black leans on a table in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                147
            ],
            "duration": 148,
            "token": {
                "<s0>": 0,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_36819",
        "original_caption": "there is a guitar in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the guitar from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a guitar in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 0,
                "<e0>": 2010
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6298848190",
        "aid": "6298848190_36820",
        "original_caption": "an adult holds hand of a child in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of a child in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                864
            ],
            "duration": 865,
            "token": {
                "<s0>": 629,
                "<e0>": 848
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6298848190",
        "aid": "6298848190_36821",
        "original_caption": "an adult holds hand of a child in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of a child in the forest."
            }
        ],
        "meta": {
            "split": [
                864,
                1171
            ],
            "duration": 308,
            "token": {
                "<s0>": 16,
                "<e0>": 58
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114352772",
        "aid": "8114352772_36822",
        "original_caption": "an adult grabs a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult grabs a toy inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                449
            ],
            "duration": 450,
            "token": {
                "<s0>": 295,
                "<e0>": 312
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4240545211",
        "aid": "4240545211_36823",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                260
            ],
            "duration": 261,
            "token": {
                "<s0>": 69,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4240545211",
        "aid": "4240545211_36824",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                260,
                484
            ],
            "duration": 225,
            "token": {
                "<s0>": 11,
                "<e0>": 42
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6298848190",
        "aid": "6298848190_36825",
        "original_caption": "a child in blue clothes is towards an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue clothes is towards an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1171
            ],
            "duration": 1172,
            "token": {
                "<s0>": 420,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6086390405",
        "aid": "6086390405_36826",
        "original_caption": "a child is away a car in orange on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is away a car in orange on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1301
            ],
            "duration": 1302,
            "token": {
                "<s0>": 180,
                "<e0>": 244
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3761379939",
        "aid": "3761379939_36827",
        "original_caption": "a child in white dress is above a green sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white dress is above a green sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1380
            ],
            "duration": 1381,
            "token": {
                "<s0>": 0,
                "<e0>": 1381
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36828",
        "original_caption": "there is a bench next to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bench."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 624,
                "<e0>": 696
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2932667685",
        "aid": "2932667685_36829",
        "original_caption": "an adult is in front of another adult in the mountains.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is in front of another adult in the mountains happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1167
            ],
            "duration": 1168,
            "token": {
                "<s0>": 0,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7093500213",
        "aid": "7093500213_36830",
        "original_caption": "an adult in white speaks to another adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white speaks to another adult on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1109
            ],
            "duration": 1110,
            "token": {
                "<s0>": 780,
                "<e0>": 806
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13816283384",
        "aid": "13816283384_36831",
        "original_caption": "there is a sofa beneath a white tiger shaped toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the white tiger shaped toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                718
            ],
            "duration": 719,
            "token": {
                "<s0>": 0,
                "<e0>": 719
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_36832",
        "original_caption": "there is a black table beneath a red bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black table beneath a red bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                493,
                611
            ],
            "duration": 119,
            "token": {
                "<s0>": 6,
                "<e0>": 70
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4220838391",
        "aid": "4220838391_36833",
        "original_caption": "an adult in orange holds a crab in the kitchen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in orange holds a crab in the kitchen."
            }
        ],
        "meta": {
            "split": [
                0,
                2321
            ],
            "duration": 2322,
            "token": {
                "<s0>": 1354,
                "<e0>": 1580
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_36834",
        "original_caption": "a child holds a cellphone in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a cellphone in a car."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36835",
        "original_caption": "the audlt in black hugs the child .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The audlt in black hugs the child ."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 424
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_36836",
        "original_caption": "there is a horse chasing an adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the horse from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a horse chasing an adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                328
            ],
            "duration": 329,
            "token": {
                "<s0>": 0,
                "<e0>": 176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_36837",
        "original_caption": "there is a horse chasing an adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a horse chasing an adult on the grass."
            }
        ],
        "meta": {
            "split": [
                328,
                614
            ],
            "duration": 287,
            "token": {
                "<s0>": 153,
                "<e0>": 219
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_36838",
        "original_caption": "there is a shirtless adult away from an adult in white in a dock.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a shirtless adult away from an adult in white in a dock."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 240,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_36839",
        "original_caption": "an adult wearing blue pants plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing blue pants plays the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                746
            ],
            "duration": 747,
            "token": {
                "<s0>": 345,
                "<e0>": 667
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_36840",
        "original_caption": "an adult wearing blue pants plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing blue pants plays the guitar."
            }
        ],
        "meta": {
            "split": [
                746,
                1138
            ],
            "duration": 393,
            "token": {
                "<s0>": 80,
                "<e0>": 271
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_36841",
        "original_caption": "there is a screen in front of a child in blue at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a screen in front of a child in blue at home."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 0,
                "<e0>": 259
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_36842",
        "original_caption": "an adult dancing is away a stool in a ballroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away the stool in a ballroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1011
            ],
            "duration": 1012,
            "token": {
                "<s0>": 420,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5048454031",
        "aid": "5048454031_36843",
        "original_caption": "an adult man in dark blue watches a gray bird by the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the gray bird by the street from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                659
            ],
            "duration": 660,
            "token": {
                "<s0>": 0,
                "<e0>": 17
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3190400650",
        "aid": "3190400650_36844",
        "original_caption": "an adult is away another adult on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away another adult on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1769
            ],
            "duration": 1770,
            "token": {
                "<s0>": 1140,
                "<e0>": 1196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2867108011",
        "aid": "2867108011_36845",
        "original_caption": "a smiling child leans on a table with a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A smiling child leans on a table with a screen."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 0,
                "<e0>": 876
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6121794107",
        "aid": "6121794107_36846",
        "original_caption": "there is a cup above a ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup above a ball on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                883
            ],
            "duration": 884,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_36847",
        "original_caption": "an adult is away from a monitor in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away from a monitor in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 1320,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8223287911",
        "aid": "8223287911_36848",
        "original_caption": "an adult in red is behind a chair on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red is behind a chair on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1484
            ],
            "duration": 1485,
            "token": {
                "<s0>": 1383,
                "<e0>": 1424
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_36849",
        "original_caption": "an adult is away a child in the middle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away a child in the middle at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                517,
                1079
            ],
            "duration": 563,
            "token": {
                "<s0>": 443,
                "<e0>": 533
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_36850",
        "original_caption": "there is a white dog towards a gray dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white dog towards a gray dog."
            }
        ],
        "meta": {
            "split": [
                1364,
                2018
            ],
            "duration": 655,
            "token": {
                "<s0>": 16,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_36851",
        "original_caption": "there is a white bottle beneath a monitor in the kitchen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white bottle beneath a monitor in the kitchen happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1754,
                2696
            ],
            "duration": 943,
            "token": {
                "<s0>": 46,
                "<e0>": 943
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12212857646",
        "aid": "12212857646_36852",
        "original_caption": "a child in purple leans on an adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in purple leans on an adult man in black."
            }
        ],
        "meta": {
            "split": [
                0,
                1170
            ],
            "duration": 1171,
            "token": {
                "<s0>": 438,
                "<e0>": 698
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12624072313",
        "aid": "12624072313_36853",
        "original_caption": "an adult is away another adult on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away another adult on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1278
            ],
            "duration": 1279,
            "token": {
                "<s0>": 120,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4535557687",
        "aid": "4535557687_36854",
        "original_caption": "an adult is in front of the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is in front of the guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                335
            ],
            "duration": 336,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_36855",
        "original_caption": "a child in green is next to a yellow table in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in green is next to a yellow table in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 0,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_36856",
        "original_caption": "a baby releases a red bottle in the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby release in the baby seat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 356,
                "<e0>": 386
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_36857",
        "original_caption": "an adult in white clothes watches a fastest adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes watches a fastest adult."
            }
        ],
        "meta": {
            "split": [
                901,
                1221
            ],
            "duration": 321,
            "token": {
                "<s0>": 28,
                "<e0>": 187
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_36858",
        "original_caption": "there is a toy towards a baby in orange in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy towards a baby in orange in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5134456273",
        "aid": "5134456273_36859",
        "original_caption": "an adult woman in black holds a white sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the white sports ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                745
            ],
            "duration": 746,
            "token": {
                "<s0>": 0,
                "<e0>": 655
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5134456273",
        "aid": "5134456273_36860",
        "original_caption": "an adult woman in black holds a white sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the white sports ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                745,
                1139
            ],
            "duration": 395,
            "token": {
                "<s0>": 91,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_36861",
        "original_caption": "there is a bird towards an another bird.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bird from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bird towards an another bird."
            }
        ],
        "meta": {
            "split": [
                165,
                599
            ],
            "duration": 435,
            "token": {
                "<s0>": 15,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_36862",
        "original_caption": "a child in striped clothes rides a red scooter on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the red scooter on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                54,
                211
            ],
            "duration": 158,
            "token": {
                "<s0>": 3,
                "<e0>": 58
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_36863",
        "original_caption": "a child in striped clothes rides a red scooter on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in striped clothes rides a red scooter on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                211,
                346
            ],
            "duration": 136,
            "token": {
                "<s0>": 99,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_36864",
        "original_caption": "an adult in white leans on a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white leans on a table in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 0,
                "<e0>": 96
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_36865",
        "original_caption": "there is a bottle above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle above a table in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 30,
                "<e0>": 492
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_36866",
        "original_caption": "there is a toy towards a child in orange on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy towards a child in orange on the beach."
            }
        ],
        "meta": {
            "split": [
                0,
                1113
            ],
            "duration": 1114,
            "token": {
                "<s0>": 180,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3843663025",
        "aid": "3843663025_36867",
        "original_caption": "there is a baby walker inside the warehouse behind the bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the bicycle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_walker."
            }
        ],
        "meta": {
            "split": [
                0,
                545
            ],
            "duration": 546,
            "token": {
                "<s0>": 0,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_36868",
        "original_caption": "the adult in white is inside the watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in white is inside the watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36869",
        "original_caption": "an adult man in pale blue leans on a tan sofa in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the tan sofa in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1174
            ],
            "duration": 1175,
            "token": {
                "<s0>": 0,
                "<e0>": 1095
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36870",
        "original_caption": "an adult man in pale blue leans on a tan sofa in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the tan sofa in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1174,
                1346
            ],
            "duration": 173,
            "token": {
                "<s0>": 80,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_36871",
        "original_caption": "an adult man in pale blue leans on a tan sofa in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the tan sofa in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1346,
                1441
            ],
            "duration": 96,
            "token": {
                "<s0>": 22,
                "<e0>": 95
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7518834808",
        "aid": "7518834808_36872",
        "original_caption": "a seated baby presses a putple ball outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A seated baby presses a putple ball outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                697
            ],
            "duration": 698,
            "token": {
                "<s0>": 310,
                "<e0>": 339
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7518834808",
        "aid": "7518834808_36873",
        "original_caption": "a seated baby presses a putple ball outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a seated baby presses a putple ball outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                697,
                2696
            ],
            "duration": 2000,
            "token": {
                "<s0>": 359,
                "<e0>": 408
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4042316957",
        "aid": "4042316957_36874",
        "original_caption": "an adult woman in black hugs a child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black hugs a child in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                1201
            ],
            "duration": 1202,
            "token": {
                "<s0>": 0,
                "<e0>": 1202
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_36875",
        "original_caption": "an adult woman in black is above a silver motorcycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in black is above a silver motorcycle on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 120,
                "<e0>": 707
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7907275512",
        "aid": "7907275512_36876",
        "original_caption": "a child in black rides a yellow bicycle on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in black ride on the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 0,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7907275512",
        "aid": "7907275512_36877",
        "original_caption": "a child in black rides a yellow bicycle on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black rides a yellow bicycle on the playground."
            }
        ],
        "meta": {
            "split": [
                239,
                637
            ],
            "duration": 399,
            "token": {
                "<s0>": 94,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7907275512",
        "aid": "7907275512_36878",
        "original_caption": "a child in black rides a yellow bicycle on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black rides a yellow bicycle on the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                637,
                1715
            ],
            "duration": 1079,
            "token": {
                "<s0>": 27,
                "<e0>": 316
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5844813529",
        "aid": "5844813529_36879",
        "original_caption": "a small cat is waveing hand to the big cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a small cat is waveing hand to the big cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                153
            ],
            "duration": 154,
            "token": {
                "<s0>": 0,
                "<e0>": 100
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5844813529",
        "aid": "5844813529_36880",
        "original_caption": "a small cat is waveing hand to the big cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is waving hand to the big cat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                153,
                300
            ],
            "duration": 148,
            "token": {
                "<s0>": 53,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5844813529",
        "aid": "5844813529_36881",
        "original_caption": "a small cat is waveing hand to the big cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A small cat is waveing hand to the big cat."
            }
        ],
        "meta": {
            "split": [
                300,
                501
            ],
            "duration": 202,
            "token": {
                "<s0>": 24,
                "<e0>": 46
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5844813529",
        "aid": "5844813529_36882",
        "original_caption": "a small cat is waveing hand to the big cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A small cat is waveing hand to the big cat."
            }
        ],
        "meta": {
            "split": [
                501,
                1682
            ],
            "duration": 1182,
            "token": {
                "<s0>": 156,
                "<e0>": 211
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_36883",
        "original_caption": "there is a cat towards a chair on the blacket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the cat towards on the blacket from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                1613,
                2144
            ],
            "duration": 532,
            "token": {
                "<s0>": 445,
                "<e0>": 516
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5331141814",
        "aid": "5331141814_36884",
        "original_caption": "a child in black leans on an adult in red in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black leans on an adult in red in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                1291
            ],
            "duration": 1292,
            "token": {
                "<s0>": 0,
                "<e0>": 1292
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_36885",
        "original_caption": "there is adult hold hand of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is adult hold hand of the adult."
            }
        ],
        "meta": {
            "split": [
                0,
                929
            ],
            "duration": 930,
            "token": {
                "<s0>": 0,
                "<e0>": 583
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_36886",
        "original_caption": "an adult in black holds a bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bench in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 677,
                "<e0>": 728
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4101864233",
        "aid": "4101864233_36887",
        "original_caption": "a smiling baby is above a green baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A smiling baby is above a green baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                1100
            ],
            "duration": 1101,
            "token": {
                "<s0>": 0,
                "<e0>": 1101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_36888",
        "original_caption": "an adult in white clothes rides a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes rides a watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114352772",
        "aid": "8114352772_36889",
        "original_caption": "an adult releases a toy on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho releases the toy on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                449
            ],
            "duration": 450,
            "token": {
                "<s0>": 427,
                "<e0>": 447
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_36890",
        "original_caption": "a yellow wooden adult plays a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A yellow wooden adult plays a guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                397
            ],
            "duration": 398,
            "token": {
                "<s0>": 95,
                "<e0>": 311
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_36891",
        "original_caption": "a yellow wooden adult plays a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A yellow wooden adult plays a guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                397,
                1364
            ],
            "duration": 968,
            "token": {
                "<s0>": 87,
                "<e0>": 839
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_36892",
        "original_caption": "a yellow wooden adult plays a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A yellow wooden adult plays a guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                1364,
                1955
            ],
            "duration": 592,
            "token": {
                "<s0>": 128,
                "<e0>": 567
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_36893",
        "original_caption": "an adult in red clothes rides a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red clothes rides a watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_36894",
        "original_caption": "a baby holds hand of an adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby holds hand of an adult on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                760
            ],
            "duration": 761,
            "token": {
                "<s0>": 450,
                "<e0>": 524
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_36895",
        "original_caption": "an adult is towards a cat on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards a cat on the street happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1080,
                "<e0>": 1285
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36896",
        "original_caption": "an adult in black is away another adult woman in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black is away another adult woman in gray."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1152,
                "<e0>": 1289
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4825511158",
        "aid": "4825511158_36897",
        "original_caption": "an adult is in front of a cellphone .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the cellphone  from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                494
            ],
            "duration": 495,
            "token": {
                "<s0>": 27,
                "<e0>": 269
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5052259273",
        "aid": "5052259273_36898",
        "original_caption": "an adult wearing a watch is behind a child in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing a watch is behind a child in pink clothes."
            }
        ],
        "meta": {
            "split": [
                307,
                499
            ],
            "duration": 193,
            "token": {
                "<s0>": 13,
                "<e0>": 82
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_36899",
        "original_caption": "an adult in black clothes is towards a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is towards a child."
            }
        ],
        "meta": {
            "split": [
                0,
                2069
            ],
            "duration": 2070,
            "token": {
                "<s0>": 570,
                "<e0>": 629
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36900",
        "original_caption": "a child pulls a cake in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pulls the cake in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 545,
                "<e0>": 626
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3190400650",
        "aid": "3190400650_36901",
        "original_caption": "an adult speaks to another adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to another adult on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1769
            ],
            "duration": 1770,
            "token": {
                "<s0>": 265,
                "<e0>": 309
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_36902",
        "original_caption": "an adult wearing a white hat is next to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a white hat is next to another adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 301,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_36903",
        "original_caption": "an adult in short pants leans on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in short pants leans on a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                4260
            ],
            "duration": 4261,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_36904",
        "original_caption": "an adult is behind another adult woman in white in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult woman in white in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                1319
            ],
            "duration": 1320,
            "token": {
                "<s0>": 157,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4240545211",
        "aid": "4240545211_36905",
        "original_caption": "there is a gray backpack above a red bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray backpack above a red bicycle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                484
            ],
            "duration": 485,
            "token": {
                "<s0>": 152,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_36906",
        "original_caption": "there is a toy towards another toy in thr room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy towards another toy in thr room."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 74,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36907",
        "original_caption": "there is a white cake above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white cake above a table."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_36908",
        "original_caption": "a child in red is next to another child in pink on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red is next to another child in pink on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 0,
                "<e0>": 44
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_36909",
        "original_caption": "there is a white dog patting a child on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat pats the child on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                352
            ],
            "duration": 353,
            "token": {
                "<s0>": 48,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_36910",
        "original_caption": "there is a black laptop above a yellow table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the laptop from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black laptop above a yellow table."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 0,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_36911",
        "original_caption": "a child in plaid shirt holds a red sports ball on the basketball court.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in plaid shirt hold on the basketball court from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                216,
                502
            ],
            "duration": 287,
            "token": {
                "<s0>": 4,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_36912",
        "original_caption": "a child in plaid shirt holds a red sports ball on the basketball court.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in plaid shirt holds a red sports ball on the basketball court happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                574,
                719
            ],
            "duration": 146,
            "token": {
                "<s0>": 26,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_36913",
        "original_caption": "a child in plaid shirt holds a red sports ball on the basketball court.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in plaid shirt hold on the basketball court from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                719,
                1246
            ],
            "duration": 528,
            "token": {
                "<s0>": 19,
                "<e0>": 528
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_36914",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                322
            ],
            "duration": 323,
            "token": {
                "<s0>": 0,
                "<e0>": 271
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_36915",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                322,
                483
            ],
            "duration": 162,
            "token": {
                "<s0>": 51,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_36916",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                483,
                1208
            ],
            "duration": 726,
            "token": {
                "<s0>": 27,
                "<e0>": 682
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_36917",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                1208,
                1424
            ],
            "duration": 217,
            "token": {
                "<s0>": 44,
                "<e0>": 194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_36918",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult ride on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bicycle."
            }
        ],
        "meta": {
            "split": [
                1424,
                1571
            ],
            "duration": 148,
            "token": {
                "<s0>": 22,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_36919",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                1571,
                2100
            ],
            "duration": 530,
            "token": {
                "<s0>": 14,
                "<e0>": 530
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_36920",
        "original_caption": "a child is behind another child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is behind another child inside a room."
            }
        ],
        "meta": {
            "split": [
                602,
                1079
            ],
            "duration": 478,
            "token": {
                "<s0>": 396,
                "<e0>": 446
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5708481466",
        "aid": "5708481466_36921",
        "original_caption": "a child in orange clothes watches another child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in orange clothes watches another child in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1289
            ],
            "duration": 1290,
            "token": {
                "<s0>": 757,
                "<e0>": 886
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_36922",
        "original_caption": "a child in blue is above a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in blue in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                747
            ],
            "duration": 748,
            "token": {
                "<s0>": 0,
                "<e0>": 748
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_36923",
        "original_caption": "there is a sofa beneath an adult woman in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sofa beneath an adult woman in white."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945234319",
        "aid": "5945234319_36924",
        "original_caption": "a child is in front of an electric fan .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is in front of an electric fan  happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1550,
                1988
            ],
            "duration": 439,
            "token": {
                "<s0>": 104,
                "<e0>": 402
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_36925",
        "original_caption": "a child pushes a toy at the seaside.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child pushes a toy at the seaside."
            }
        ],
        "meta": {
            "split": [
                0,
                554
            ],
            "duration": 555,
            "token": {
                "<s0>": 461,
                "<e0>": 476
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_36926",
        "original_caption": "a child pushes a toy at the seaside.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child pushes a toy at the seaside happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                697,
                1113
            ],
            "duration": 417,
            "token": {
                "<s0>": 55,
                "<e0>": 73
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7211479772",
        "aid": "7211479772_36927",
        "original_caption": "a child watches another child in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child watches another child in the snow."
            }
        ],
        "meta": {
            "split": [
                297,
                465
            ],
            "duration": 169,
            "token": {
                "<s0>": 40,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_36928",
        "original_caption": "an adult in black pushes another adult in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black pushes another adult in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                684
            ],
            "duration": 685,
            "token": {
                "<s0>": 351,
                "<e0>": 479
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_36929",
        "original_caption": "an adult in black pushes another adult in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black pushes another adult in blue."
            }
        ],
        "meta": {
            "split": [
                684,
                1146
            ],
            "duration": 463,
            "token": {
                "<s0>": 206,
                "<e0>": 241
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_36930",
        "original_caption": "an adult in black pushes another adult in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black pushes another adult in blue."
            }
        ],
        "meta": {
            "split": [
                1146,
                1446
            ],
            "duration": 301,
            "token": {
                "<s0>": 221,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3521372410",
        "aid": "3521372410_36931",
        "original_caption": "an adult in black clothes holds a baby in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes holds a baby in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 0,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3436660277",
        "aid": "3436660277_36932",
        "original_caption": "a baby wearing a red hat watches an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the adult in blue clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                698,
                883
            ],
            "duration": 186,
            "token": {
                "<s0>": 6,
                "<e0>": 55
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_36933",
        "original_caption": "there is a handbag wathet blue next to an adult woman in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a handbag wathet blue next to an adult woman in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 675,
                "<e0>": 959
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_36934",
        "original_caption": "there is a cat on the left beneath another cat on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cat on the left beneath another cat on the right."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 850,
                "<e0>": 925
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3759767103",
        "aid": "3759767103_36935",
        "original_caption": "an adult is above a skateboard in the outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in the outdoor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A skateboard."
            }
        ],
        "meta": {
            "split": [
                0,
                359
            ],
            "duration": 360,
            "token": {
                "<s0>": 216,
                "<e0>": 263
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5202728101",
        "aid": "5202728101_36936",
        "original_caption": "there is a chair next to another chair in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair next to another chair in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 241
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5837297505",
        "aid": "5837297505_36937",
        "original_caption": "an adult with the least hair plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with the least hair plays the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                178
            ],
            "duration": 179,
            "token": {
                "<s0>": 0,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5837297505",
        "aid": "5837297505_36938",
        "original_caption": "an adult with the least hair plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with the least hair plays the guitar."
            }
        ],
        "meta": {
            "split": [
                178,
                663
            ],
            "duration": 486,
            "token": {
                "<s0>": 22,
                "<e0>": 461
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_36939",
        "original_caption": "a baby leans on an adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on an adult in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                760
            ],
            "duration": 761,
            "token": {
                "<s0>": 743,
                "<e0>": 761
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3924748616",
        "aid": "3924748616_36940",
        "original_caption": "an adult woman in black is above a gray tan skateboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black is above a gray tan skateboard."
            }
        ],
        "meta": {
            "split": [
                153,
                255
            ],
            "duration": 103,
            "token": {
                "<s0>": 5,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_36941",
        "original_caption": "a baby is away from a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby is away from a chair at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2533
            ],
            "duration": 2534,
            "token": {
                "<s0>": 1920,
                "<e0>": 2010
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_36942",
        "original_caption": "a child in black hugs a toy pale green and pale yellow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black hugs a toy pale green and pale yellow."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 0,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_36943",
        "original_caption": "there is a table beneath a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table beneath a cup in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                665,
                825
            ],
            "duration": 161,
            "token": {
                "<s0>": 18,
                "<e0>": 160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572624205",
        "aid": "8572624205_36944",
        "original_caption": "a baby is above a baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby is above a baby seat at home."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_36945",
        "original_caption": "a child in blue leans on a gray sofa in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue leans on a gray sofa in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                747
            ],
            "duration": 748,
            "token": {
                "<s0>": 0,
                "<e0>": 748
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_36946",
        "original_caption": "an adult in red clothes holds a pink toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes holds a pink toy."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 395,
                "<e0>": 444
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36947",
        "original_caption": "there is a big cake towards a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is towards the baby at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cake."
            }
        ],
        "meta": {
            "split": [
                625,
                2696
            ],
            "duration": 2072,
            "token": {
                "<s0>": 56,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4535557687",
        "aid": "4535557687_36948",
        "original_caption": "an adult man in white plays a brown guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white plays a brown guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                335
            ],
            "duration": 336,
            "token": {
                "<s0>": 0,
                "<e0>": 259
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_36949",
        "original_caption": "a baby leans on a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on a baby seat in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                227
            ],
            "duration": 228,
            "token": {
                "<s0>": 0,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_36950",
        "original_caption": "a baby leans on a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on a baby seat in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                227,
                1756
            ],
            "duration": 1530,
            "token": {
                "<s0>": 37,
                "<e0>": 1424
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8782055272",
        "aid": "8782055272_36951",
        "original_caption": "an adult gets off a bicycle in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult gets off a bicycle in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 146,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36952",
        "original_caption": "there is a cup beneath a blue ball at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the blue ball at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_36953",
        "original_caption": "there is a child girl in front of the adult man in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a child girl in front of the adult man in white."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4715441335",
        "aid": "4715441335_36954",
        "original_caption": "the blue chair is beneath the colorful toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the colorful toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1733
            ],
            "duration": 1734,
            "token": {
                "<s0>": 0,
                "<e0>": 1734
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_36955",
        "original_caption": "there is a table beneath a laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 1697,
                "<e0>": 1756
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36956",
        "original_caption": "there is a cup away from an adult in green in the dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup away from an adult in green in the dark room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 360,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8847930035",
        "aid": "8847930035_36957",
        "original_caption": "a child is in front of a child in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of a child in yellow clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                325
            ],
            "duration": 326,
            "token": {
                "<s0>": 180,
                "<e0>": 248
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_36958",
        "original_caption": "the watercraft is beneath the adult with no shirts.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The watercraft is beneath the adult with no shirts."
            }
        ],
        "meta": {
            "split": [
                0,
                2186
            ],
            "duration": 2187,
            "token": {
                "<s0>": 0,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_36959",
        "original_caption": "an adult is towards a child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards a child in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 360,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_36960",
        "original_caption": "an adult in green clothes watches a laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green clothes watches a laptop happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1319
            ],
            "duration": 1320,
            "token": {
                "<s0>": 108,
                "<e0>": 335
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13828973545",
        "aid": "13828973545_36961",
        "original_caption": "there is a yellow dog biting a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a yellow dog biting a white dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                624
            ],
            "duration": 625,
            "token": {
                "<s0>": 217,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_36962",
        "original_caption": "an in striped shirts adult waves hand to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An in striped shirts adult waves hand to a child."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 544,
                "<e0>": 644
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_36963",
        "original_caption": "there is a brown cat watching another cat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown cat watching another cat on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                923
            ],
            "duration": 924,
            "token": {
                "<s0>": 657,
                "<e0>": 924
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_36964",
        "original_caption": "there is a guitar man in white in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a guitar man in white in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36965",
        "original_caption": "a child is away from an adult at dinner.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from an adult at dinner."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 360,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_36966",
        "original_caption": "an adult is away from a table on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away from a table on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 960,
                "<e0>": 1012
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_36967",
        "original_caption": "a child is next to an another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the other child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                396,
                1709
            ],
            "duration": 1314,
            "token": {
                "<s0>": 187,
                "<e0>": 233
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_36968",
        "original_caption": "an adult man in blue is away a sports ball on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in blue is away a sports ball on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 180,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_36969",
        "original_caption": "there is a white laptop above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white laptop above a table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1271
            ],
            "duration": 1272,
            "token": {
                "<s0>": 960,
                "<e0>": 997
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_36970",
        "original_caption": "an adult points to a cake at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult points to a cake at party happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 137,
                "<e0>": 166
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_36971",
        "original_caption": "an adult with black skin plays a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1425
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_36972",
        "original_caption": "an adult in black plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black plays the guitar on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1024
            ],
            "duration": 1025,
            "token": {
                "<s0>": 393,
                "<e0>": 540
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_36973",
        "original_caption": "an adult in black plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the guitar on stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1024,
                1583
            ],
            "duration": 560,
            "token": {
                "<s0>": 485,
                "<e0>": 541
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8136606220",
        "aid": "8136606220_36974",
        "original_caption": "an adult rides a surfboard on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the surfboard on the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                260
            ],
            "duration": 261,
            "token": {
                "<s0>": 36,
                "<e0>": 212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_36975",
        "original_caption": "a child siting on the stool pats a baby in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child siting on the stool pats a baby in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 117,
                "<e0>": 184
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36976",
        "original_caption": "a baby leans on an adult in red at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult in red at home."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 390,
                "<e0>": 651
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_36977",
        "original_caption": "a baby leans on an adult in red at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult in red at home."
            }
        ],
        "meta": {
            "split": [
                666,
                2696
            ],
            "duration": 2031,
            "token": {
                "<s0>": 15,
                "<e0>": 2031
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_36978",
        "original_caption": "there is a black table beneath a transparent cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black table beneath a transparent cup."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_36979",
        "original_caption": "an adult in black watches another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black watches another adult."
            }
        ],
        "meta": {
            "split": [
                1811,
                2159
            ],
            "duration": 349,
            "token": {
                "<s0>": 35,
                "<e0>": 49
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_36980",
        "original_caption": "an adult in white clothes hugs the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes hugs the guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                97
            ],
            "duration": 98,
            "token": {
                "<s0>": 0,
                "<e0>": 62
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_36981",
        "original_caption": "an adult in white clothes hugs the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes hugs the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                97,
                1138
            ],
            "duration": 1042,
            "token": {
                "<s0>": 35,
                "<e0>": 160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_36982",
        "original_caption": "an adult in black clothes watches another adult in grey clothes at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes watches another adult in grey clothes at home."
            }
        ],
        "meta": {
            "split": [
                708,
                986
            ],
            "duration": 279,
            "token": {
                "<s0>": 233,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_36983",
        "original_caption": "a child in white leans on a red table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in white lean on in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 224,
                "<e0>": 873
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_36984",
        "original_caption": "there is a cellphone above a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cellphone from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cellphone above a table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 600,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9345245716",
        "aid": "9345245716_36985",
        "original_caption": "an adult in red clothes carries a black handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes carries a black handbag."
            }
        ],
        "meta": {
            "split": [
                0,
                485
            ],
            "duration": 486,
            "token": {
                "<s0>": 0,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_36986",
        "original_caption": "a child in gray is in front of an adult in black in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in gray is in front of an adult in black in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 19,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_36987",
        "original_caption": "there is a toy next to another toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy next to another toy on the ground."
            }
        ],
        "meta": {
            "split": [
                466,
                2159
            ],
            "duration": 1694,
            "token": {
                "<s0>": 62,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5363401248",
        "aid": "5363401248_36988",
        "original_caption": "an adult in black clothes carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes carries a backpack happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                656
            ],
            "duration": 657,
            "token": {
                "<s0>": 143,
                "<e0>": 476
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5363401248",
        "aid": "5363401248_36989",
        "original_caption": "an adult in black clothes carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes carries a backpack."
            }
        ],
        "meta": {
            "split": [
                656,
                1187
            ],
            "duration": 532,
            "token": {
                "<s0>": 180,
                "<e0>": 280
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5363401248",
        "aid": "5363401248_36990",
        "original_caption": "an adult in black clothes carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes carries a backpack."
            }
        ],
        "meta": {
            "split": [
                1187,
                2696
            ],
            "duration": 1510,
            "token": {
                "<s0>": 252,
                "<e0>": 338
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3761379939",
        "aid": "3761379939_36991",
        "original_caption": "an adult leans on a light green sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult leans on a light green sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1380
            ],
            "duration": 1381,
            "token": {
                "<s0>": 0,
                "<e0>": 864
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36992",
        "original_caption": "an adult man in black holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds hand of a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                315
            ],
            "duration": 316,
            "token": {
                "<s0>": 197,
                "<e0>": 291
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36993",
        "original_caption": "an adult man in black holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black holds hand of a child at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                315,
                411
            ],
            "duration": 97,
            "token": {
                "<s0>": 25,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36994",
        "original_caption": "an adult man in black holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds hand of a child at home."
            }
        ],
        "meta": {
            "split": [
                535,
                639
            ],
            "duration": 105,
            "token": {
                "<s0>": 3,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36995",
        "original_caption": "an adult man in black holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds hand of a child at home."
            }
        ],
        "meta": {
            "split": [
                863,
                935
            ],
            "duration": 73,
            "token": {
                "<s0>": 16,
                "<e0>": 58
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36996",
        "original_caption": "an adult man in black holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds hand of a child at home."
            }
        ],
        "meta": {
            "split": [
                1000,
                1071
            ],
            "duration": 72,
            "token": {
                "<s0>": 32,
                "<e0>": 69
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_36997",
        "original_caption": "an adult man in black holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black holds hand of a child at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1100,
                1305
            ],
            "duration": 206,
            "token": {
                "<s0>": 1,
                "<e0>": 51
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_36998",
        "original_caption": "there is a white table beneath a bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the white table at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                303,
                726
            ],
            "duration": 424,
            "token": {
                "<s0>": 251,
                "<e0>": 351
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3900000605",
        "aid": "3900000605_36999",
        "original_caption": "a child in blue is away from an adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue is away from an adult in white."
            }
        ],
        "meta": {
            "split": [
                0,
                404
            ],
            "duration": 405,
            "token": {
                "<s0>": 300,
                "<e0>": 353
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37000",
        "original_caption": "an adult wearing a ring is towards a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 540,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_37001",
        "original_caption": "an adult releases a ball in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho releases the ball in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                360,
                743
            ],
            "duration": 384,
            "token": {
                "<s0>": 106,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_37002",
        "original_caption": "an adult speaks to another adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                153
            ],
            "duration": 154,
            "token": {
                "<s0>": 0,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_37003",
        "original_caption": "an adult speaks to another adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to another adult at home."
            }
        ],
        "meta": {
            "split": [
                153,
                979
            ],
            "duration": 827,
            "token": {
                "<s0>": 36,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4184884354",
        "aid": "4184884354_37004",
        "original_caption": "a child is towards a sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is towards a sofa in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1502
            ],
            "duration": 1503,
            "token": {
                "<s0>": 100,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37005",
        "original_caption": "the adult is in front of the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult is in front of the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2215
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4063402763",
        "aid": "4063402763_37006",
        "original_caption": "an adult is in front of a baby in green in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is in front of a baby in green in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                790
            ],
            "duration": 791,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6262219324",
        "aid": "6262219324_37007",
        "original_caption": "an adult in white hugs a baby in red in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white hugs a baby in red in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 227,
                "<e0>": 300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_37008",
        "original_caption": "a child is towards an adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is towards an adult inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 816,
                "<e0>": 888
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_37009",
        "original_caption": "there is an elephant in front of another elephant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the elephant from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is an elephant in front of another elephant."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 1740,
                "<e0>": 1815
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12577546265",
        "aid": "12577546265_37010",
        "original_caption": "an adult is above a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is above a snowboard in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                190
            ],
            "duration": 191,
            "token": {
                "<s0>": 66,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_37011",
        "original_caption": "there is a baby seat beneath a bread in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the baby seat in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bread."
            }
        ],
        "meta": {
            "split": [
                144,
                250
            ],
            "duration": 107,
            "token": {
                "<s0>": 25,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_37012",
        "original_caption": "there is a snowboard beneath an adult in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the snowboard from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a snowboard beneath an adult in the snow."
            }
        ],
        "meta": {
            "split": [
                460,
                818
            ],
            "duration": 359,
            "token": {
                "<s0>": 161,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5392563097",
        "aid": "5392563097_37013",
        "original_caption": "an adult leans on an elephant on the zoo.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult leans on an elephant on the zoo happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                37,
                158
            ],
            "duration": 122,
            "token": {
                "<s0>": 11,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_37014",
        "original_caption": "a child in red and white is towards an adult man in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red and white is towards an adult man in green."
            }
        ],
        "meta": {
            "split": [
                0,
                743
            ],
            "duration": 744,
            "token": {
                "<s0>": 383,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6906256626",
        "aid": "6906256626_37015",
        "original_caption": "there is a child inside a toy pots.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a child inside a toy pots happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5606187654",
        "aid": "5606187654_37016",
        "original_caption": "the child in red holds hands of the adult in yellow .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the child in red holds hands of the adult in yellow  happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                363
            ],
            "duration": 364,
            "token": {
                "<s0>": 0,
                "<e0>": 364
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_37017",
        "original_caption": "the adult in a jeans is caressing the black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in a jeans is caressing the black dog."
            }
        ],
        "meta": {
            "split": [
                0,
                1306
            ],
            "duration": 1307,
            "token": {
                "<s0>": 946,
                "<e0>": 1150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_37018",
        "original_caption": "the adult in a jeans is caressing the black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is caressing the black dog from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1306,
                1528
            ],
            "duration": 223,
            "token": {
                "<s0>": 157,
                "<e0>": 191
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_37019",
        "original_caption": "the adult in a jeans is caressing the black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is caressing the black dog from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1528,
                1639
            ],
            "duration": 112,
            "token": {
                "<s0>": 31,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_37020",
        "original_caption": "the adult in a jeans is caressing the black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in a jeans is caressing the black dog."
            }
        ],
        "meta": {
            "split": [
                1639,
                1769
            ],
            "duration": 131,
            "token": {
                "<s0>": 55,
                "<e0>": 131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2718262890",
        "aid": "2718262890_37021",
        "original_caption": "an adult man in black leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black leans on a table."
            }
        ],
        "meta": {
            "split": [
                0,
                467
            ],
            "duration": 468,
            "token": {
                "<s0>": 312,
                "<e0>": 374
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37022",
        "original_caption": "an adult grabs a rat on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult grabs a rat on the carpet."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 596,
                "<e0>": 679
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2538515654",
        "aid": "2538515654_37023",
        "original_caption": "an adult in black clothes is above another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is above another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                452
            ],
            "duration": 453,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8068324821",
        "aid": "8068324821_37024",
        "original_caption": "an adult woman in white is behind a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in white is behind a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                469
            ],
            "duration": 470,
            "token": {
                "<s0>": 0,
                "<e0>": 470
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_37025",
        "original_caption": "an adult in green leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green leans on a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                245
            ],
            "duration": 246,
            "token": {
                "<s0>": 114,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_37026",
        "original_caption": "an adult with blond-hair leans on a stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with blond-hair leans on a stool."
            }
        ],
        "meta": {
            "split": [
                0,
                1011
            ],
            "duration": 1012,
            "token": {
                "<s0>": 0,
                "<e0>": 1012
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2492711005",
        "aid": "2492711005_37027",
        "original_caption": "an adult in white clothes kisses a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes kisses a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1111
            ],
            "duration": 1112,
            "token": {
                "<s0>": 1015,
                "<e0>": 1086
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5452090232",
        "aid": "5452090232_37028",
        "original_caption": "an adult rides a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a surfboard on the lake."
            }
        ],
        "meta": {
            "split": [
                0,
                139
            ],
            "duration": 140,
            "token": {
                "<s0>": 0,
                "<e0>": 132
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5452090232",
        "aid": "5452090232_37029",
        "original_caption": "an adult rides a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a surfboard on the lake."
            }
        ],
        "meta": {
            "split": [
                190,
                585
            ],
            "duration": 396,
            "token": {
                "<s0>": 6,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5452090232",
        "aid": "5452090232_37030",
        "original_caption": "an adult rides a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a surfboard on the lake."
            }
        ],
        "meta": {
            "split": [
                661,
                1033
            ],
            "duration": 373,
            "token": {
                "<s0>": 5,
                "<e0>": 365
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5345319548",
        "aid": "5345319548_37031",
        "original_caption": "an adult in black holds a white toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the white toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                790
            ],
            "duration": 791,
            "token": {
                "<s0>": 0,
                "<e0>": 791
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37032",
        "original_caption": "a child in gray is towards another child in red on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child in gray towards to on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                284,
                595
            ],
            "duration": 312,
            "token": {
                "<s0>": 76,
                "<e0>": 166
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37033",
        "original_caption": "a child in pink clothes is in front of another child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink clothes is in front of another child in red clothes."
            }
        ],
        "meta": {
            "split": [
                550,
                681
            ],
            "duration": 132,
            "token": {
                "<s0>": 52,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_37034",
        "original_caption": "an adult in black clothes is next to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes is next to a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1197
            ],
            "duration": 1198,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_37035",
        "original_caption": "the crocodile is in front of the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the crocodile from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The crocodile is in front of the adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 0,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_37036",
        "original_caption": "there is a brown table next to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown table next to a child at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                237,
                1349
            ],
            "duration": 1113,
            "token": {
                "<s0>": 13,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6379905555",
        "aid": "6379905555_37037",
        "original_caption": "an adult is in front of another adult man in red on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is in front of another adult man in red on the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 0,
                "<e0>": 480
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7431354614",
        "aid": "7431354614_37038",
        "original_caption": "an adult woman in purple caresses a baby in white diaper.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in purple caress from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                183
            ],
            "duration": 184,
            "token": {
                "<s0>": 3,
                "<e0>": 141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7431354614",
        "aid": "7431354614_37039",
        "original_caption": "an adult woman in purple caresses a baby in white diaper.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in purple caresses a baby in white diaper happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                183,
                455
            ],
            "duration": 273,
            "token": {
                "<s0>": 43,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_37040",
        "original_caption": "there is an elephant towards another elephant outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is an elephant towards another elephant outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 720,
                "<e0>": 930
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37041",
        "original_caption": "an adult is above a brown sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is above a brown sofa at home."
            }
        ],
        "meta": {
            "split": [
                1353,
                1441
            ],
            "duration": 89,
            "token": {
                "<s0>": 39,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37042",
        "original_caption": "there is a cat on the left kicking another cat on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cat on the left kicking another cat on the right happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1163
            ],
            "duration": 1164,
            "token": {
                "<s0>": 1094,
                "<e0>": 1141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37043",
        "original_caption": "there is a cat on the left kicking another cat on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cat on the left kicking another cat on the right."
            }
        ],
        "meta": {
            "split": [
                1337,
                1506
            ],
            "duration": 170,
            "token": {
                "<s0>": 141,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37044",
        "original_caption": "there is a cat on the left kicking another cat on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat kicks the other cat on the right from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                1547,
                2249
            ],
            "duration": 703,
            "token": {
                "<s0>": 12,
                "<e0>": 29
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_37045",
        "original_caption": "an adult in yellow rides a watercraft on the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow rides a watercraft on the sea happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 40,
                "<e0>": 1479
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3457759630",
        "aid": "3457759630_37046",
        "original_caption": "there is a small colorful toy next to a big toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a small colorful toy next to a big toy."
            }
        ],
        "meta": {
            "split": [
                427,
                1388
            ],
            "duration": 962,
            "token": {
                "<s0>": 123,
                "<e0>": 411
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37047",
        "original_caption": "a child wearing blue pants is away from a baby in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing blue pants is away from a baby in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1385
            ],
            "duration": 1386,
            "token": {
                "<s0>": 900,
                "<e0>": 967
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3771729228",
        "aid": "3771729228_37048",
        "original_caption": "an adult in black holds a bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black holds a bat on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                170
            ],
            "duration": 171,
            "token": {
                "<s0>": 0,
                "<e0>": 154
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3771729228",
        "aid": "3771729228_37049",
        "original_caption": "an adult in black holds a bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black holds a bat on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                170,
                399
            ],
            "duration": 230,
            "token": {
                "<s0>": 16,
                "<e0>": 199
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4101864233",
        "aid": "4101864233_37050",
        "original_caption": "a baby leans on a green baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the green baby seat at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1100
            ],
            "duration": 1101,
            "token": {
                "<s0>": 0,
                "<e0>": 1101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37051",
        "original_caption": "an adult in black clothes gets off a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes gets off a bench."
            }
        ],
        "meta": {
            "split": [
                838,
                1323
            ],
            "duration": 486,
            "token": {
                "<s0>": 50,
                "<e0>": 70
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9058170161",
        "aid": "9058170161_37052",
        "original_caption": "an adult in blue clothes caresses a yellow dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes caresses a yellow dog."
            }
        ],
        "meta": {
            "split": [
                0,
                133
            ],
            "duration": 134,
            "token": {
                "<s0>": 101,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_37053",
        "original_caption": "an adult in red speaks to a child with a tail in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red speaks to a child with a tail in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1145
            ],
            "duration": 1146,
            "token": {
                "<s0>": 483,
                "<e0>": 506
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5310031663",
        "aid": "5310031663_37054",
        "original_caption": "there is a cup next to another cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup next to another cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 480,
                "<e0>": 601
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3343411237",
        "aid": "3343411237_37055",
        "original_caption": "there is a surfboard beneath the child .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a surfboard beneath the child ."
            }
        ],
        "meta": {
            "split": [
                732,
                926
            ],
            "duration": 195,
            "token": {
                "<s0>": 18,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_37056",
        "original_caption": "an adult in yellow skin is behind another adult in black skin.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow skin is behind another adult in black skin happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_37057",
        "original_caption": "a child in white clothes rides a snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in white clothes ride from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 12,
                "<e0>": 599
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_37058",
        "original_caption": "an adult in a hat is above a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in a hat is above a watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5695366046",
        "aid": "5695366046_37059",
        "original_caption": "an adult in black plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7093500213",
        "aid": "7093500213_37060",
        "original_caption": "an adult on the right is away from another adult on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult on the right is away from another adult on the left happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1109
            ],
            "duration": 1110,
            "token": {
                "<s0>": 1020,
                "<e0>": 1100
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6856075223",
        "aid": "6856075223_37061",
        "original_caption": "there is a gray sheep pushing a bottle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray sheep pushing a bottle on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                232,
                368
            ],
            "duration": 137,
            "token": {
                "<s0>": 17,
                "<e0>": 33
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6856075223",
        "aid": "6856075223_37062",
        "original_caption": "there is a gray sheep pushing a bottle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a gray sheep pushing a bottle on the ground."
            }
        ],
        "meta": {
            "split": [
                519,
                824
            ],
            "duration": 306,
            "token": {
                "<s0>": 37,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_37063",
        "original_caption": "a child in pink clothes is towards an adult wearing jeans.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child in pink clothes towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                315,
                959
            ],
            "duration": 645,
            "token": {
                "<s0>": 105,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_37064",
        "original_caption": "there is a cup next to a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                98,
                637
            ],
            "duration": 540,
            "token": {
                "<s0>": 47,
                "<e0>": 136
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_37065",
        "original_caption": "an adult woman in purple is away a child in shorts outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in purple is away a child in shorts outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 480,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_37066",
        "original_caption": "there is a cup next to a bottle in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup next to a bottle in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                128,
                611
            ],
            "duration": 484,
            "token": {
                "<s0>": 52,
                "<e0>": 484
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4343935954",
        "aid": "4343935954_37067",
        "original_caption": "a pink child is pointing to the blue child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A pink child is pointing to the blue child."
            }
        ],
        "meta": {
            "split": [
                0,
                1674
            ],
            "duration": 1675,
            "token": {
                "<s0>": 91,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_37068",
        "original_caption": "an adult in black clothes watches another adult wearing a red ribbon.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes watches another adult wearing a red ribbon happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                522,
                929
            ],
            "duration": 408,
            "token": {
                "<s0>": 61,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_37069",
        "original_caption": "an adult in white clothes holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes holds a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1876,
                "<e0>": 1928
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5633850992",
        "aid": "5633850992_37070",
        "original_caption": "the child is away from the adult in a military uniform.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho away adult in a military uniform from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 780,
                "<e0>": 840
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13486822104",
        "aid": "13486822104_37071",
        "original_caption": "there is a grey bird getting on another bird on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bird from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a grey bird getting on another bird on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                688
            ],
            "duration": 689,
            "token": {
                "<s0>": 142,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_37072",
        "original_caption": "an adult watches another adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult watches another adult in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                979
            ],
            "duration": 980,
            "token": {
                "<s0>": 325,
                "<e0>": 373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8014277171",
        "aid": "8014277171_37073",
        "original_caption": "an adult woman in gray pulls a black dog on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in gray pulls a black dog on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                216
            ],
            "duration": 217,
            "token": {
                "<s0>": 136,
                "<e0>": 198
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8014277171",
        "aid": "8014277171_37074",
        "original_caption": "an adult woman in gray pulls a black dog on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pulls the black dog on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                460,
                1909
            ],
            "duration": 1450,
            "token": {
                "<s0>": 213,
                "<e0>": 308
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_37075",
        "original_caption": "an adult in black is leaning on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black is leaning on the table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 0,
                "<e0>": 42
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_37076",
        "original_caption": "an adult in black is leaning on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black is leaning on the table."
            }
        ],
        "meta": {
            "split": [
                299,
                726
            ],
            "duration": 428,
            "token": {
                "<s0>": 257,
                "<e0>": 356
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5153854160",
        "aid": "5153854160_37077",
        "original_caption": "there is a cellphone above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                2264
            ],
            "duration": 2265,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37078",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red clothes leans on a black sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                100,
                292
            ],
            "duration": 193,
            "token": {
                "<s0>": 10,
                "<e0>": 37
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37079",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                292,
                665
            ],
            "duration": 374,
            "token": {
                "<s0>": 156,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37080",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                665,
                982
            ],
            "duration": 318,
            "token": {
                "<s0>": 157,
                "<e0>": 201
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37081",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red clothes leans on a black sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                982,
                1251
            ],
            "duration": 270,
            "token": {
                "<s0>": 117,
                "<e0>": 260
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37082",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red clothes leans on a black sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1251,
                1458
            ],
            "duration": 208,
            "token": {
                "<s0>": 10,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37083",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                1458,
                1818
            ],
            "duration": 361,
            "token": {
                "<s0>": 143,
                "<e0>": 361
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_37084",
        "original_caption": "a baby wearing green pants is behind a black cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby wearing green pants is behind a black cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                795,
                2144
            ],
            "duration": 1350,
            "token": {
                "<s0>": 45,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_37085",
        "original_caption": "an adult in black clothes pulls a dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes pulls a dog."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 0,
                "<e0>": 61
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9562161527",
        "aid": "9562161527_37086",
        "original_caption": "an adult woman holding a red bang is behind a chair by the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman holding a red bang is behind a chair by the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                189
            ],
            "duration": 190,
            "token": {
                "<s0>": 21,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_37087",
        "original_caption": "an adult wearing balck pants is behind a child in orange clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing balck pants is behind a child in orange clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                153,
                637
            ],
            "duration": 485,
            "token": {
                "<s0>": 7,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_37088",
        "original_caption": "an adult in black is away from a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black is away from a child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 89,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5647072246",
        "aid": "5647072246_37089",
        "original_caption": "an adult in black clothes throws a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes throws a ball."
            }
        ],
        "meta": {
            "split": [
                0,
                364
            ],
            "duration": 365,
            "token": {
                "<s0>": 230,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_37090",
        "original_caption": "a child in pink clothes presses a green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho presses the green toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1700,
                "<e0>": 1780
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_37091",
        "original_caption": "an adult in white is away from another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white is away from another adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 120,
                "<e0>": 177
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_37092",
        "original_caption": "a pink bottle is above the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is a pink bottle above from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 0,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13884124143",
        "aid": "13884124143_37093",
        "original_caption": "an adult is away from a surfboard on the water slide.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away from a surfboard on the water slide happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                356,
                852
            ],
            "duration": 497,
            "token": {
                "<s0>": 6,
                "<e0>": 384
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5633850992",
        "aid": "5633850992_37094",
        "original_caption": "the adult is next to the other adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult is next to the other adult."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 100,
                "<e0>": 724
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3574819152",
        "aid": "3574819152_37095",
        "original_caption": "there is a duck next to another duck in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a duck next to another duck in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                1529
            ],
            "duration": 1530,
            "token": {
                "<s0>": 1020,
                "<e0>": 1530
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4654222137",
        "aid": "4654222137_37096",
        "original_caption": "there is a black dog chasing another dog in gray on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black dog chasing another dog in gray on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1159
            ],
            "duration": 1160,
            "token": {
                "<s0>": 963,
                "<e0>": 991
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_37097",
        "original_caption": "an adult man in black is away from the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is away from the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                285,
                1788
            ],
            "duration": 1504,
            "token": {
                "<s0>": 75,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_37098",
        "original_caption": "there is a toy towards another toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy towards another toy in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7972054306",
        "aid": "7972054306_37099",
        "original_caption": "there is a sofa behind a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sofa behind a chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                816
            ],
            "duration": 817,
            "token": {
                "<s0>": 501,
                "<e0>": 816
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3242157854",
        "aid": "3242157854_37100",
        "original_caption": "a baby in red clothes touches an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in red clothes touches an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                651
            ],
            "duration": 652,
            "token": {
                "<s0>": 262,
                "<e0>": 335
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_37101",
        "original_caption": "a baby is inside a baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby is inside a baby seat at home."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37102",
        "original_caption": "there is a black table beneath a cake at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black table beneath a cake at home."
            }
        ],
        "meta": {
            "split": [
                1857,
                2225
            ],
            "duration": 369,
            "token": {
                "<s0>": 46,
                "<e0>": 368
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5508264187",
        "aid": "5508264187_37103",
        "original_caption": "the adult is speaking to the baby on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult is speaking to the baby on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                1204
            ],
            "duration": 1205,
            "token": {
                "<s0>": 313,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_37104",
        "original_caption": "there is a toy away from a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy away from a child in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1876,
                "<e0>": 1943
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8782055272",
        "aid": "8782055272_37105",
        "original_caption": "there is a bicycle beneath an adult in the path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle beneath an adult in the path happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 61,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6392843945",
        "aid": "6392843945_37106",
        "original_caption": "the old adult is playing (instrument) the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The old adult is playing (instrument) the piano."
            }
        ],
        "meta": {
            "split": [
                0,
                1319
            ],
            "duration": 1320,
            "token": {
                "<s0>": 0,
                "<e0>": 1310
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7609356686",
        "aid": "7609356686_37107",
        "original_caption": "a child in grey clothes touches another child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in grey clothes touches another child in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 0,
                "<e0>": 24
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10440265715",
        "aid": "10440265715_37108",
        "original_caption": "there is a black car behind a child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black car behind a child in red clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                3434,
                3799
            ],
            "duration": 366,
            "token": {
                "<s0>": 166,
                "<e0>": 366
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_37109",
        "original_caption": "an adult in black clothes grabs a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes grabs a backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 917,
                "<e0>": 977
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_37110",
        "original_caption": "an adult man in green pats a red ball on the basketball court.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in green pats a red ball on the basketball court."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_37111",
        "original_caption": "an adult man in green pats a red ball on the basketball court.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in green pats a red ball on the basketball court happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                301,
                743
            ],
            "duration": 443,
            "token": {
                "<s0>": 82,
                "<e0>": 141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_37112",
        "original_caption": "an adult with a backpack is in front of another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with a backpack is in front of another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1260,
                "<e0>": 1315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_37113",
        "original_caption": "there is a blue toy above a colorful toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the colorful toy at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 540,
                "<e0>": 605
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_37114",
        "original_caption": "an adult lifts a ball in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult lifts a ball in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                743
            ],
            "duration": 744,
            "token": {
                "<s0>": 646,
                "<e0>": 670
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_37115",
        "original_caption": "an adult holds hand of another adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the other adult inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                934,
                1109
            ],
            "duration": 176,
            "token": {
                "<s0>": 147,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_37116",
        "original_caption": "an adult holds hand of another adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of another adult inside a room."
            }
        ],
        "meta": {
            "split": [
                1109,
                1305
            ],
            "duration": 197,
            "token": {
                "<s0>": 4,
                "<e0>": 37
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_37117",
        "original_caption": "a child in red clothes is above another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is above another child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 0,
                "<e0>": 166
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_37118",
        "original_caption": "a child in brown clothes waves a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in brown clothes wave from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                274
            ],
            "duration": 275,
            "token": {
                "<s0>": 144,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_37119",
        "original_caption": "a child in brown clothes waves a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho waves the toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                274,
                651
            ],
            "duration": 378,
            "token": {
                "<s0>": 67,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_37120",
        "original_caption": "a child in brown clothes waves a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho waves the toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                651,
                1148
            ],
            "duration": 498,
            "token": {
                "<s0>": 108,
                "<e0>": 179
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4797170987",
        "aid": "4797170987_37121",
        "original_caption": "a child in brown clothes waves a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in brown clothes waves a toy."
            }
        ],
        "meta": {
            "split": [
                1148,
                1592
            ],
            "duration": 445,
            "token": {
                "<s0>": 318,
                "<e0>": 383
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3036240821",
        "aid": "3036240821_37122",
        "original_caption": "a child in black holds a red toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black holds a red toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1875
            ],
            "duration": 1876,
            "token": {
                "<s0>": 0,
                "<e0>": 1876
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13715319605",
        "aid": "13715319605_37123",
        "original_caption": "an adult watches a horse on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult watch on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A horse."
            }
        ],
        "meta": {
            "split": [
                0,
                77
            ],
            "duration": 78,
            "token": {
                "<s0>": 39,
                "<e0>": 50
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_37124",
        "original_caption": "there is a blue watercraft beneath an adult on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue watercraft beneath an adult on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_37125",
        "original_caption": "an adult man in yellow speaks to another adult woman in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult man in yellow speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 2071,
                "<e0>": 2139
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6806981046",
        "aid": "6806981046_37126",
        "original_caption": "there is a yellow bus behind a silver car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bus/truck from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a yellow bus behind a silver car."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 0,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7211479772",
        "aid": "7211479772_37127",
        "original_caption": "a child on the left is behind a child on the right outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child on the left is behind a child on the right outdoor."
            }
        ],
        "meta": {
            "split": [
                120,
                465
            ],
            "duration": 346,
            "token": {
                "<s0>": 30,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_37128",
        "original_caption": "an adult plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult plays the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                509
            ],
            "duration": 510,
            "token": {
                "<s0>": 269,
                "<e0>": 342
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_37129",
        "original_caption": "an adult plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult plays the guitar."
            }
        ],
        "meta": {
            "split": [
                509,
                922
            ],
            "duration": 414,
            "token": {
                "<s0>": 168,
                "<e0>": 307
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_37130",
        "original_caption": "an adult plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult plays the guitar."
            }
        ],
        "meta": {
            "split": [
                922,
                1138
            ],
            "duration": 217,
            "token": {
                "<s0>": 107,
                "<e0>": 217
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4254574573",
        "aid": "4254574573_37131",
        "original_caption": "an adult touches a cellphone on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult touches a cellphone on the table."
            }
        ],
        "meta": {
            "split": [
                0,
                270
            ],
            "duration": 271,
            "token": {
                "<s0>": 202,
                "<e0>": 259
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4254574573",
        "aid": "4254574573_37132",
        "original_caption": "an adult touches a cellphone on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult touch on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                270,
                448
            ],
            "duration": 179,
            "token": {
                "<s0>": 11,
                "<e0>": 36
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4254574573",
        "aid": "4254574573_37133",
        "original_caption": "an adult touches a cellphone on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult touches a cellphone on the table."
            }
        ],
        "meta": {
            "split": [
                448,
                974
            ],
            "duration": 527,
            "token": {
                "<s0>": 143,
                "<e0>": 202
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37134",
        "original_caption": "an adult in blue clothes is next to a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult in blue clothes next to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                452,
                793
            ],
            "duration": 342,
            "token": {
                "<s0>": 33,
                "<e0>": 137
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_37135",
        "original_caption": "a baby wearing a black hat is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby wearing a black hat is above a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_37136",
        "original_caption": "an adult in brown hair holds a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in brown hair holds a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                1649
            ],
            "duration": 1650,
            "token": {
                "<s0>": 545,
                "<e0>": 578
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4184884354",
        "aid": "4184884354_37137",
        "original_caption": "there is a sofa in front of another sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the other sofa in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1502
            ],
            "duration": 1503,
            "token": {
                "<s0>": 0,
                "<e0>": 366
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5923454727",
        "aid": "5923454727_37138",
        "original_caption": "a child in white is behind an adult man in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white is behind an adult man in gray happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 0,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_37139",
        "original_caption": "there is a wooden chair beneath a child in blue in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a wooden chair beneath a child in blue in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 0,
                "<e0>": 300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37140",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gary clothes carries a handbag."
            }
        ],
        "meta": {
            "split": [
                0,
                558
            ],
            "duration": 559,
            "token": {
                "<s0>": 0,
                "<e0>": 524
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37141",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in gary clothes carries a handbag."
            }
        ],
        "meta": {
            "split": [
                558,
                665
            ],
            "duration": 108,
            "token": {
                "<s0>": 34,
                "<e0>": 86
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37142",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in gary clothes carries a handbag happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                711,
                2763
            ],
            "duration": 2053,
            "token": {
                "<s0>": 11,
                "<e0>": 2036
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37143",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in gary clothes carries a handbag."
            }
        ],
        "meta": {
            "split": [
                2763,
                3216
            ],
            "duration": 454,
            "token": {
                "<s0>": 16,
                "<e0>": 454
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_37144",
        "original_caption": "child wearing flower pants is away from child wearing green pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child wearing the flower pants away from from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                271,
                735
            ],
            "duration": 465,
            "token": {
                "<s0>": 11,
                "<e0>": 58
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8426046231",
        "aid": "8426046231_37145",
        "original_caption": "there is a bottle in front of a baby in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bottle in front of a baby in a car."
            }
        ],
        "meta": {
            "split": [
                0,
                530
            ],
            "duration": 531,
            "token": {
                "<s0>": 0,
                "<e0>": 531
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37146",
        "original_caption": "there is a white cup above a wooden table in a big room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the white cup in the big room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 44,
                "<e0>": 1094
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_37147",
        "original_caption": "an adult in black touches a black dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black touches a black dog outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 215,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4397142322",
        "aid": "4397142322_37148",
        "original_caption": "there is a cat above a bicycle in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the bicycle in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                1595,
                2696
            ],
            "duration": 1102,
            "token": {
                "<s0>": 25,
                "<e0>": 1102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_37149",
        "original_caption": "a adult in white speaks to an adult in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A adult in white speaks to an adult in orange."
            }
        ],
        "meta": {
            "split": [
                0,
                313
            ],
            "duration": 314,
            "token": {
                "<s0>": 95,
                "<e0>": 266
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_37150",
        "original_caption": "a adult in white speaks to an adult in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A adult in white speaks to an adult in orange."
            }
        ],
        "meta": {
            "split": [
                313,
                720
            ],
            "duration": 408,
            "token": {
                "<s0>": 48,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_37151",
        "original_caption": "a adult in white speaks to an adult in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A adult in white speaks to an adult in orange."
            }
        ],
        "meta": {
            "split": [
                720,
                1221
            ],
            "duration": 502,
            "token": {
                "<s0>": 144,
                "<e0>": 327
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_37152",
        "original_caption": "a baby wearing green pants pats a cat on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby wearing green pants pat on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                1268
            ],
            "duration": 1269,
            "token": {
                "<s0>": 932,
                "<e0>": 969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3055581786",
        "aid": "3055581786_37153",
        "original_caption": "an adult wearing a hat is behind another adult holding a stick.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a hat is behind another adult holding a stick."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 0,
                "<e0>": 480
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6122666405",
        "aid": "6122666405_37154",
        "original_caption": "an adult is next to a yellow table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is next to a yellow table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1376,
                1668
            ],
            "duration": 293,
            "token": {
                "<s0>": 133,
                "<e0>": 292
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37155",
        "original_caption": "an adult in black holds a cellphone in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cellphone in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                519
            ],
            "duration": 520,
            "token": {
                "<s0>": 0,
                "<e0>": 15
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37156",
        "original_caption": "an adult in black holds a cellphone in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black holds a cellphone in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                519,
                1441
            ],
            "duration": 923,
            "token": {
                "<s0>": 505,
                "<e0>": 546
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4861754967",
        "aid": "4861754967_37157",
        "original_caption": "an adult uses a silver laptop on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult uses a silver laptop on the table."
            }
        ],
        "meta": {
            "split": [
                0,
                520
            ],
            "duration": 521,
            "token": {
                "<s0>": 180,
                "<e0>": 425
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4861754967",
        "aid": "4861754967_37158",
        "original_caption": "an adult uses a silver laptop on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult use on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A laptop."
            }
        ],
        "meta": {
            "split": [
                520,
                755
            ],
            "duration": 236,
            "token": {
                "<s0>": 96,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37159",
        "original_caption": "the child in blue is towards the ball/sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the child in blue is towards the ball/sports ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                118,
                595
            ],
            "duration": 478,
            "token": {
                "<s0>": 28,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37160",
        "original_caption": "there is a red backpack in front of an adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1323,
                "<e0>": 1611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37161",
        "original_caption": "an adult in pink is inside another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is outside the adult in pink from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 540,
                "<e0>": 842
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8670554760",
        "aid": "8670554760_37162",
        "original_caption": "the adult with white helmet is holding a bat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult with white helmet is holding a bat."
            }
        ],
        "meta": {
            "split": [
                0,
                331
            ],
            "duration": 332,
            "token": {
                "<s0>": 294,
                "<e0>": 312
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13486822104",
        "aid": "13486822104_37163",
        "original_caption": "there is a bird getting off another bird on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat gets off the other bird on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bird."
            }
        ],
        "meta": {
            "split": [
                0,
                688
            ],
            "duration": 689,
            "token": {
                "<s0>": 301,
                "<e0>": 315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7093500213",
        "aid": "7093500213_37164",
        "original_caption": "an adult man in plaid shirt is away another adult man in orange on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt is away another adult man in orange on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1109
            ],
            "duration": 1110,
            "token": {
                "<s0>": 300,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_37165",
        "original_caption": "an adult on the right is towards to an adult on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult on the right is towards to an adult on the left outdoor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 182,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_37166",
        "original_caption": "an adult woman in blue carries a black backpack on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in blue carries a black backpack on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                180
            ],
            "duration": 181,
            "token": {
                "<s0>": 0,
                "<e0>": 47
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_37167",
        "original_caption": "an adult woman in blue carries a black backpack on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in blue carries a black backpack on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                180,
                647
            ],
            "duration": 468,
            "token": {
                "<s0>": 133,
                "<e0>": 468
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6106626461",
        "aid": "6106626461_37168",
        "original_caption": "a child is away an adult man in red outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is away an adult man in red outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                520
            ],
            "duration": 521,
            "token": {
                "<s0>": 180,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_37169",
        "original_caption": "a baby in green clothes holds a blue bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in green clothes holds a blue bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                209
            ],
            "duration": 210,
            "token": {
                "<s0>": 0,
                "<e0>": 191
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_37170",
        "original_caption": "a baby in green clothes holds a blue bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in green clothes holds a blue bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                209,
                509
            ],
            "duration": 301,
            "token": {
                "<s0>": 18,
                "<e0>": 277
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_37171",
        "original_caption": "a baby in green clothes holds a blue bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in green clothes holds a blue bottle."
            }
        ],
        "meta": {
            "split": [
                509,
                1114
            ],
            "duration": 606,
            "token": {
                "<s0>": 24,
                "<e0>": 76
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3811600452",
        "aid": "3811600452_37172",
        "original_caption": "there is a black cat watching a grey cat on bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black cat watching a grey cat on bed."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1766,
                "<e0>": 1823
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37173",
        "original_caption": "an adult woman in mint green is towards a red cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the red cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 480,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4715441335",
        "aid": "4715441335_37174",
        "original_caption": "a baby in black and red clothes leans on a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1733
            ],
            "duration": 1734,
            "token": {
                "<s0>": 0,
                "<e0>": 1734
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_37175",
        "original_caption": "an adult uses a laptop inside a house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult uses a laptop inside a house."
            }
        ],
        "meta": {
            "split": [
                0,
                141
            ],
            "duration": 142,
            "token": {
                "<s0>": 0,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_37176",
        "original_caption": "an adult uses a laptop inside a house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult uses a laptop inside a house."
            }
        ],
        "meta": {
            "split": [
                141,
                405
            ],
            "duration": 265,
            "token": {
                "<s0>": 14,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_37177",
        "original_caption": "an adult uses a laptop inside a house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult uses a laptop inside a house happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                405,
                606
            ],
            "duration": 202,
            "token": {
                "<s0>": 111,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_37178",
        "original_caption": "an adult uses a laptop inside a house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult uses a laptop inside a house."
            }
        ],
        "meta": {
            "split": [
                606,
                712
            ],
            "duration": 107,
            "token": {
                "<s0>": 56,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3711378974",
        "aid": "3711378974_37179",
        "original_caption": "there is adult in black next to the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is adult in black next to the chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1143
            ],
            "duration": 1144,
            "token": {
                "<s0>": 384,
                "<e0>": 477
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3059960651",
        "aid": "3059960651_37180",
        "original_caption": "there is a baby seat beneath a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_seat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a baby seat beneath a child."
            }
        ],
        "meta": {
            "split": [
                0,
                319
            ],
            "duration": 320,
            "token": {
                "<s0>": 0,
                "<e0>": 320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_37181",
        "original_caption": "there is a snowboard behind a child in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the snowboard from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a snowboard behind a child in the snow."
            }
        ],
        "meta": {
            "split": [
                496,
                818
            ],
            "duration": 323,
            "token": {
                "<s0>": 196,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4670796220",
        "aid": "4670796220_37182",
        "original_caption": "a baby inside the toy car points to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho points to the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 277,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8136606220",
        "aid": "8136606220_37183",
        "original_caption": "an adult is away another adult on the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away another adult on the sea happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                260
            ],
            "duration": 261,
            "token": {
                "<s0>": 96,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9970084224",
        "aid": "9970084224_37184",
        "original_caption": "there is a black dog in front of an another white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black dog in front of an another white dog."
            }
        ],
        "meta": {
            "split": [
                1298,
                1781
            ],
            "duration": 484,
            "token": {
                "<s0>": 82,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37185",
        "original_caption": "there is a cup towards a child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup towards a child inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_37186",
        "original_caption": "an adult is behind another adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult in white clothes."
            }
        ],
        "meta": {
            "split": [
                255,
                1011
            ],
            "duration": 757,
            "token": {
                "<s0>": 105,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37187",
        "original_caption": "there is a monitor above an adult wearing striped shirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a monitor above an adult wearing striped shirt happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_37188",
        "original_caption": "there is a wooden table beneath a black cup in a restaurant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a wooden table beneath a black cup in a restaurant."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 144,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37189",
        "original_caption": "an adult carries a cake in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult carry in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cake."
            }
        ],
        "meta": {
            "split": [
                0,
                286
            ],
            "duration": 287,
            "token": {
                "<s0>": 91,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37190",
        "original_caption": "an adult carries a cake in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult carries a cake in the living room."
            }
        ],
        "meta": {
            "split": [
                286,
                2696
            ],
            "duration": 2411,
            "token": {
                "<s0>": 36,
                "<e0>": 396
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6644166529",
        "aid": "6644166529_37191",
        "original_caption": "there is a green cup above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the green cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                360,
                2696
            ],
            "duration": 2337,
            "token": {
                "<s0>": 60,
                "<e0>": 2337
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37192",
        "original_caption": "an adult holds a rat on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a rat on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1245,
                "<e0>": 1447
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6086390405",
        "aid": "6086390405_37193",
        "original_caption": "a child in orange is away a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in orange is away a car."
            }
        ],
        "meta": {
            "split": [
                0,
                1301
            ],
            "duration": 1302,
            "token": {
                "<s0>": 180,
                "<e0>": 231
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_37194",
        "original_caption": "an adult leans on a black sofa in a big house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult leans on a black sofa in a big house happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 281,
                "<e0>": 557
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2457895589",
        "aid": "2457895589_37195",
        "original_caption": "an adult watches a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult watch at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1466,
                1752
            ],
            "duration": 287,
            "token": {
                "<s0>": 223,
                "<e0>": 287
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8136314361",
        "aid": "8136314361_37196",
        "original_caption": "an adult uses a camera outside the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho uses the camera outside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                110
            ],
            "duration": 111,
            "token": {
                "<s0>": 0,
                "<e0>": 111
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11264199933",
        "aid": "11264199933_37197",
        "original_caption": "an adult man in green holds a glass cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in green holds a glass cup."
            }
        ],
        "meta": {
            "split": [
                0,
                488
            ],
            "duration": 489,
            "token": {
                "<s0>": 212,
                "<e0>": 284
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_37198",
        "original_caption": "an adult with plaid shirt plays the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult with plaid shirt play on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                751
            ],
            "duration": 752,
            "token": {
                "<s0>": 88,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_37199",
        "original_caption": "an adult with plaid shirt plays the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with plaid shirt plays the guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                751,
                1583
            ],
            "duration": 833,
            "token": {
                "<s0>": 504,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7972054306",
        "aid": "7972054306_37200",
        "original_caption": "a child is behind a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is behind a chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                816
            ],
            "duration": 817,
            "token": {
                "<s0>": 501,
                "<e0>": 816
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_37201",
        "original_caption": "an adult rides a watercraft in the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a watercraft in the sea."
            }
        ],
        "meta": {
            "split": [
                0,
                1092
            ],
            "duration": 1093,
            "token": {
                "<s0>": 0,
                "<e0>": 1064
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_37202",
        "original_caption": "an adult rides a watercraft in the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a watercraft in the sea happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1092,
                1247
            ],
            "duration": 156,
            "token": {
                "<s0>": 29,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_37203",
        "original_caption": "a child is above a chair in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1653
            ],
            "duration": 1654,
            "token": {
                "<s0>": 1561,
                "<e0>": 1649
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37204",
        "original_caption": "a child in red watches another child in pink at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red watches another child in pink at home."
            }
        ],
        "meta": {
            "split": [
                0,
                2225
            ],
            "duration": 2226,
            "token": {
                "<s0>": 66,
                "<e0>": 169
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4677394937",
        "aid": "4677394937_37205",
        "original_caption": "an adult in orange rides a white surfboard on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in orange rides a white surfboard on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_37206",
        "original_caption": "child in grey suit leaning on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Child in grey suit leaning on the sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                287
            ],
            "duration": 288,
            "token": {
                "<s0>": 89,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_37207",
        "original_caption": "child in grey suit leaning on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see child in grey suit leaning on the sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                287,
                666
            ],
            "duration": 380,
            "token": {
                "<s0>": 172,
                "<e0>": 308
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37208",
        "original_caption": "there is a ball away another sports ball inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a ball away another sports ball inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 278,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5258789985",
        "aid": "5258789985_37209",
        "original_caption": "an adult holds a cellphone on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a cellphone on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                544
            ],
            "duration": 545,
            "token": {
                "<s0>": 320,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_37210",
        "original_caption": "there is a little white bird away another bird big white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the little white bird away from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bird."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 60,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_37211",
        "original_caption": "a child in pink is away an adult in black in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink is away an adult in black in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                647
            ],
            "duration": 648,
            "token": {
                "<s0>": 300,
                "<e0>": 373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4452690447",
        "aid": "4452690447_37212",
        "original_caption": "there is a brown guitar above a silver car on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the guitar from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown guitar above a silver car on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                614
            ],
            "duration": 615,
            "token": {
                "<s0>": 0,
                "<e0>": 615
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8616874413",
        "aid": "8616874413_37213",
        "original_caption": "an adult in black clothes uses a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes uses a camera."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_37214",
        "original_caption": "there is a bicycle towards a child in yellow in the dim light of night.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle towards a child in yellow in the dim light of night happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9975070616",
        "aid": "9975070616_37215",
        "original_caption": "an adult man in gray holds a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in gray holds a baby in white."
            }
        ],
        "meta": {
            "split": [
                0,
                660
            ],
            "duration": 661,
            "token": {
                "<s0>": 0,
                "<e0>": 661
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_37216",
        "original_caption": "there is a bottle in front of a black guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle in front of a black guitar."
            }
        ],
        "meta": {
            "split": [
                356,
                611
            ],
            "duration": 256,
            "token": {
                "<s0>": 130,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_37217",
        "original_caption": "a child in white is away a wooden chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white is away a wooden chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 100,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37218",
        "original_caption": "there is a sofa beneath an adult wearing a plaid clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sofa beneath an adult wearing a plaid clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1353,
                1441
            ],
            "duration": 89,
            "token": {
                "<s0>": 39,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9562161527",
        "aid": "9562161527_37219",
        "original_caption": "there is a chair behind a child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the chair in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                189
            ],
            "duration": 190,
            "token": {
                "<s0>": 61,
                "<e0>": 189
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37220",
        "original_caption": "there is a black screen above an adult woman in black in a showroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the adult woman in black in the showroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 1691
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3779800369",
        "aid": "3779800369_37221",
        "original_caption": "an adult in green is above a motorcycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green is above a motorcycle outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                311,
                956
            ],
            "duration": 646,
            "token": {
                "<s0>": 80,
                "<e0>": 645
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4672243606",
        "aid": "4672243606_37222",
        "original_caption": "an adult woman speaks to a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman speaks to a child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                151
            ],
            "duration": 152,
            "token": {
                "<s0>": 81,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4672243606",
        "aid": "4672243606_37223",
        "original_caption": "an adult woman speaks to a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman speaks to a child outdoors."
            }
        ],
        "meta": {
            "split": [
                151,
                681
            ],
            "duration": 531,
            "token": {
                "<s0>": 33,
                "<e0>": 61
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_37224",
        "original_caption": "an adult watches a child in white on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult watches a child in white on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 720,
                "<e0>": 778
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9562161527",
        "aid": "9562161527_37225",
        "original_caption": "a child is next to another child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child next to in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                189
            ],
            "duration": 190,
            "token": {
                "<s0>": 120,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9365549235",
        "aid": "9365549235_37226",
        "original_caption": "there is a sports ball in front of an adult holding a bat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sports ball in front of an adult holding a bat."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 12,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37227",
        "original_caption": "a child is in front of an adult on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is in front of an adult on the street happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1346,
                "<e0>": 1450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3891539754",
        "aid": "3891539754_37228",
        "original_caption": "an adult woman with glasses speaks to another adult man in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman with glasses speaks to another adult man in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                441
            ],
            "duration": 442,
            "token": {
                "<s0>": 295,
                "<e0>": 321
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2422958285",
        "aid": "2422958285_37229",
        "original_caption": "an adult is above a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the sofa in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                187,
                456
            ],
            "duration": 270,
            "token": {
                "<s0>": 53,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_37230",
        "original_caption": "there is a white sheep behind a pig beside the trees.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white sheep behind a pig beside the trees happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 443,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_37231",
        "original_caption": "there is a dog chasing another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dog chasing another dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                635
            ],
            "duration": 636,
            "token": {
                "<s0>": 13,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_37232",
        "original_caption": "there is a dog chasing another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog chasing another dog on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                635,
                1199
            ],
            "duration": 565,
            "token": {
                "<s0>": 526,
                "<e0>": 555
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_37233",
        "original_caption": "there is a dog chasing another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog chasing another dog on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1199,
                2018
            ],
            "duration": 820,
            "token": {
                "<s0>": 9,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4352200366",
        "aid": "4352200366_37234",
        "original_caption": "there is a ski beneath a child in red on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a ski beneath a child in red on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                529,
                960
            ],
            "duration": 432,
            "token": {
                "<s0>": 20,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_37235",
        "original_caption": "an adult is beneath another adult in the cave.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is beneath another adult in the cave."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 600,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_37236",
        "original_caption": "an adult in black clothes plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes plays the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                370,
                507
            ],
            "duration": 138,
            "token": {
                "<s0>": 20,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_37237",
        "original_caption": "an adult in black clothes plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes plays the guitar."
            }
        ],
        "meta": {
            "split": [
                507,
                2024
            ],
            "duration": 1518,
            "token": {
                "<s0>": 31,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3898106739",
        "aid": "3898106739_37238",
        "original_caption": "a child watches an adult in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the adult in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1232
            ],
            "duration": 1233,
            "token": {
                "<s0>": 325,
                "<e0>": 379
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_37239",
        "original_caption": "an adult woman in black speaks to another adult in the kitchen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult in the kitchen from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                929
            ],
            "duration": 930,
            "token": {
                "<s0>": 482,
                "<e0>": 574
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37240",
        "original_caption": "there is a cat on the right hitting another cat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat on the right hitting another cat on the left."
            }
        ],
        "meta": {
            "split": [
                0,
                902
            ],
            "duration": 903,
            "token": {
                "<s0>": 830,
                "<e0>": 856
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37241",
        "original_caption": "there is a cat on the right hitting another cat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cat on the right hitting another cat on the left."
            }
        ],
        "meta": {
            "split": [
                975,
                1089
            ],
            "duration": 115,
            "token": {
                "<s0>": 14,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37242",
        "original_caption": "there is a cat on the right hitting another cat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat on the right hitting another cat on the left."
            }
        ],
        "meta": {
            "split": [
                1238,
                1349
            ],
            "duration": 112,
            "token": {
                "<s0>": 7,
                "<e0>": 62
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37243",
        "original_caption": "there is a cat on the right hitting another cat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat on the right hitting another cat on the left."
            }
        ],
        "meta": {
            "split": [
                1349,
                1442
            ],
            "duration": 94,
            "token": {
                "<s0>": 50,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37244",
        "original_caption": "there is a cat on the right hitting another cat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat on the right hitting another cat on the left."
            }
        ],
        "meta": {
            "split": [
                1442,
                2249
            ],
            "duration": 808,
            "token": {
                "<s0>": 20,
                "<e0>": 76
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_37245",
        "original_caption": "an adult pushes a toy in the yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult pushes a toy in the yard."
            }
        ],
        "meta": {
            "split": [
                0,
                998
            ],
            "duration": 999,
            "token": {
                "<s0>": 61,
                "<e0>": 82
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_37246",
        "original_caption": "an adult in black clothes is next to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes is next to another adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 0,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37247",
        "original_caption": "a child in red holds a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red holds a sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 28,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37248",
        "original_caption": "a child in red is above a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is above a sofa at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1412,
                1818
            ],
            "duration": 407,
            "token": {
                "<s0>": 138,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6806981046",
        "aid": "6806981046_37249",
        "original_caption": "a adult in dark color is watching the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is watching the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 179,
                "<e0>": 197
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9787043852",
        "aid": "9787043852_37250",
        "original_caption": "an adult women leans on a table in the office.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult women leans on a table in the office."
            }
        ],
        "meta": {
            "split": [
                0,
                320
            ],
            "duration": 321,
            "token": {
                "<s0>": 0,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9787043852",
        "aid": "9787043852_37251",
        "original_caption": "an adult women leans on a table in the office.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women leans on a table in the office."
            }
        ],
        "meta": {
            "split": [
                320,
                759
            ],
            "duration": 440,
            "token": {
                "<s0>": 210,
                "<e0>": 340
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9787043852",
        "aid": "9787043852_37252",
        "original_caption": "an adult women leans on a table in the office.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult women lean on in the office from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                759,
                1170
            ],
            "duration": 412,
            "token": {
                "<s0>": 99,
                "<e0>": 357
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9787043852",
        "aid": "9787043852_37253",
        "original_caption": "an adult women leans on a table in the office.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult women leans on a table in the office happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1170,
                1409
            ],
            "duration": 240,
            "token": {
                "<s0>": 54,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_37254",
        "original_caption": "a child in black clothes presses a beige dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black clothes presses a beige dog."
            }
        ],
        "meta": {
            "split": [
                0,
                2595
            ],
            "duration": 2596,
            "token": {
                "<s0>": 1074,
                "<e0>": 1131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7431354614",
        "aid": "7431354614_37255",
        "original_caption": "an adult in black clothes kisses a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black clothes kiss from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                455
            ],
            "duration": 456,
            "token": {
                "<s0>": 296,
                "<e0>": 401
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37256",
        "original_caption": "a child in pink clothes leans on a pink table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink clothes leans on a pink table."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 21,
                "<e0>": 66
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37257",
        "original_caption": "a child in pink clothes leans on a pink table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink clothes leans on a pink table."
            }
        ],
        "meta": {
            "split": [
                98,
                418
            ],
            "duration": 321,
            "token": {
                "<s0>": 33,
                "<e0>": 213
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37258",
        "original_caption": "a child in pink clothes leans on a pink table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in pink clothes lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                418,
                872
            ],
            "duration": 455,
            "token": {
                "<s0>": 107,
                "<e0>": 258
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8716087070",
        "aid": "8716087070_37259",
        "original_caption": "an adult woman in pink carries a backpack on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries the backpack on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                771
            ],
            "duration": 772,
            "token": {
                "<s0>": 506,
                "<e0>": 566
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37260",
        "original_caption": "the child in red is leaning on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the child in red is leaning on the chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                311
            ],
            "duration": 312,
            "token": {
                "<s0>": 0,
                "<e0>": 245
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37261",
        "original_caption": "the child in red is leaning on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is lean on by the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                311,
                708
            ],
            "duration": 398,
            "token": {
                "<s0>": 66,
                "<e0>": 204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37262",
        "original_caption": "the child in red is leaning on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The child in red is leaning on the chair."
            }
        ],
        "meta": {
            "split": [
                708,
                2225
            ],
            "duration": 1518,
            "token": {
                "<s0>": 194,
                "<e0>": 347
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_37263",
        "original_caption": "an adult in white watches a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white watches a watercraft on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1657,
                2186
            ],
            "duration": 530,
            "token": {
                "<s0>": 17,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_37264",
        "original_caption": "an adult in jeans is next to another adult in white and black dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in jeans is next to another adult in white and black dress."
            }
        ],
        "meta": {
            "split": [
                225,
                810
            ],
            "duration": 586,
            "token": {
                "<s0>": 75,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5048454031",
        "aid": "5048454031_37265",
        "original_caption": "an adult with glasses watches another adult with a white hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses watches another adult with a white hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                659
            ],
            "duration": 660,
            "token": {
                "<s0>": 27,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6595030215",
        "aid": "6595030215_37266",
        "original_caption": "a baby leans on an adult in dark green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on an adult in dark green clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                465
            ],
            "duration": 466,
            "token": {
                "<s0>": 0,
                "<e0>": 466
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_37267",
        "original_caption": "an adult caresses a dog on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult caresses a dog on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                552
            ],
            "duration": 553,
            "token": {
                "<s0>": 104,
                "<e0>": 530
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_37268",
        "original_caption": "an adult caresses a dog on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult caresses a dog on the grass."
            }
        ],
        "meta": {
            "split": [
                552,
                673
            ],
            "duration": 122,
            "token": {
                "<s0>": 23,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_37269",
        "original_caption": "an adult caresses a dog on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the dog on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                673,
                803
            ],
            "duration": 131,
            "token": {
                "<s0>": 53,
                "<e0>": 100
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_37270",
        "original_caption": "an adult caresses a dog on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a dog on the grass."
            }
        ],
        "meta": {
            "split": [
                803,
                934
            ],
            "duration": 132,
            "token": {
                "<s0>": 31,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6882604194",
        "aid": "6882604194_37271",
        "original_caption": "an adult caresses a dog on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a dog on the grass."
            }
        ],
        "meta": {
            "split": [
                1143,
                1926
            ],
            "duration": 784,
            "token": {
                "<s0>": 72,
                "<e0>": 95
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37272",
        "original_caption": "there is a green sports ball above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_37273",
        "original_caption": "a child without shirt is in front of an adult in pink in the yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child without shirt is in front of an adult in pink in the yard."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 0,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4876265566",
        "aid": "4876265566_37274",
        "original_caption": "there is a black cat chasing a gray cat on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black cat chasing a gray cat on the carpet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                891
            ],
            "duration": 892,
            "token": {
                "<s0>": 775,
                "<e0>": 844
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_37275",
        "original_caption": "there is a white cup above a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white cup above a table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5093962680",
        "aid": "5093962680_37276",
        "original_caption": "an adult man in black uses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black uses a cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                184
            ],
            "duration": 185,
            "token": {
                "<s0>": 0,
                "<e0>": 104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3249035877",
        "aid": "3249035877_37277",
        "original_caption": "there is a penguin behind another penguin on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the penguin from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a penguin behind another penguin on the ground."
            }
        ],
        "meta": {
            "split": [
                529,
                821
            ],
            "duration": 293,
            "token": {
                "<s0>": 105,
                "<e0>": 286
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_37278",
        "original_caption": "a baby leans on an adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on an adult in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                419
            ],
            "duration": 420,
            "token": {
                "<s0>": 0,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3710885997",
        "aid": "3710885997_37279",
        "original_caption": "a child carries a surfboard by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child carries a surfboard by the sea happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                497
            ],
            "duration": 498,
            "token": {
                "<s0>": 319,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_37280",
        "original_caption": "an adult in pink hugs a child in pink in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hugs the child in pink in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1047
            ],
            "duration": 1048,
            "token": {
                "<s0>": 0,
                "<e0>": 1048
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_37281",
        "original_caption": "an adult man in orange is next to another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in orange is next to another adult on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1221
            ],
            "duration": 1222,
            "token": {
                "<s0>": 0,
                "<e0>": 478
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37282",
        "original_caption": "an adult in black holds a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black holds a black camera happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                496
            ],
            "duration": 497,
            "token": {
                "<s0>": 182,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37283",
        "original_caption": "an adult in black holds a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black holds a black camera happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                496,
                648
            ],
            "duration": 153,
            "token": {
                "<s0>": 89,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37284",
        "original_caption": "an adult in black holds a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black holds a black camera."
            }
        ],
        "meta": {
            "split": [
                648,
                1094
            ],
            "duration": 447,
            "token": {
                "<s0>": 30,
                "<e0>": 132
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37285",
        "original_caption": "a child in red is towards an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is towards an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 60,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37286",
        "original_caption": "a child in green on the left leans on a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in green on the left leans on a table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                544
            ],
            "duration": 545,
            "token": {
                "<s0>": 290,
                "<e0>": 473
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37287",
        "original_caption": "a child in green on the left leans on a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in green on the left leans on a table at home."
            }
        ],
        "meta": {
            "split": [
                544,
                872
            ],
            "duration": 329,
            "token": {
                "<s0>": 72,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7465682132",
        "aid": "7465682132_37288",
        "original_caption": "there is a colorful ball towards a child wearing a red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the colorful ball towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 110,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6991481998",
        "aid": "6991481998_37289",
        "original_caption": "there is a black car behind a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the child in blue clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A car."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 0,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_37290",
        "original_caption": "there is a red bottle above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a red bottle above a table."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 451
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3364754591",
        "aid": "3364754591_37291",
        "original_caption": "an adult in white hugs a baby in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white hugs a baby in green."
            }
        ],
        "meta": {
            "split": [
                0,
                484
            ],
            "duration": 485,
            "token": {
                "<s0>": 0,
                "<e0>": 485
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37292",
        "original_caption": "there is a bench beneath an adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bench beneath an adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 768,
                "<e0>": 1320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6485306977",
        "aid": "6485306977_37293",
        "original_caption": "a baby is inside a cup on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby is inside a cup on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                1889
            ],
            "duration": 1890,
            "token": {
                "<s0>": 0,
                "<e0>": 1827
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6485306977",
        "aid": "6485306977_37294",
        "original_caption": "a baby is inside a cup on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is inside the cup on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                1889,
                2696
            ],
            "duration": 808,
            "token": {
                "<s0>": 62,
                "<e0>": 807
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_37295",
        "original_caption": "an adult in white trousers is above a sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white trousers is above a sofa in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2698
            ],
            "duration": 2699,
            "token": {
                "<s0>": 0,
                "<e0>": 2699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_37296",
        "original_caption": "an adult man in white is away another adult woman in black shorts.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white is away another adult woman in black shorts."
            }
        ],
        "meta": {
            "split": [
                915,
                1011
            ],
            "duration": 97,
            "token": {
                "<s0>": 45,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_37297",
        "original_caption": "a child in gray black holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in gray black holds a yellow toy."
            }
        ],
        "meta": {
            "split": [
                0,
                626
            ],
            "duration": 627,
            "token": {
                "<s0>": 381,
                "<e0>": 594
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_37298",
        "original_caption": "a child in gray black holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the yellow toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                626,
                1314
            ],
            "duration": 689,
            "token": {
                "<s0>": 33,
                "<e0>": 111
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37299",
        "original_caption": "a child with smile watches an adult in red at the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with smile watches an adult in red at the table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 436,
                "<e0>": 477
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_37300",
        "original_caption": "an adult leans on a sofa on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult leans on a sofa on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2698
            ],
            "duration": 2699,
            "token": {
                "<s0>": 0,
                "<e0>": 2699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37301",
        "original_caption": "a child in yellow clothes is in front of an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in yellow clothes is in front of an adult in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37302",
        "original_caption": "there is a bench beneath an adult in red with pink hat in  the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bench beneath an adult in red with pink hat in  the gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 864,
                "<e0>": 1176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37303",
        "original_caption": "there is a bottle beneath a blue ball at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bottle beneath a blue ball at party."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10729424884",
        "aid": "10729424884_37304",
        "original_caption": "an adult in black watches another adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black watch in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                699
            ],
            "duration": 700,
            "token": {
                "<s0>": 0,
                "<e0>": 28
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5195700916",
        "aid": "5195700916_37305",
        "original_caption": "the adult in a red hat is speaking to the adult in a black hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in a red hat is speaking to the adult in a black hat."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 1284,
                "<e0>": 1546
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4914011323",
        "aid": "4914011323_37306",
        "original_caption": "there is a black cat patting a brown dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the black cat pat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                182
            ],
            "duration": 183,
            "token": {
                "<s0>": 38,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_37307",
        "original_caption": "a child watches another child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child watch in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1264,
                2696
            ],
            "duration": 1433,
            "token": {
                "<s0>": 240,
                "<e0>": 322
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6678892451",
        "aid": "6678892451_37308",
        "original_caption": "a child is away an adult on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is away an adult on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                164,
                643
            ],
            "duration": 480,
            "token": {
                "<s0>": 76,
                "<e0>": 286
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5310031663",
        "aid": "5310031663_37309",
        "original_caption": "an adult in black clothes grabs a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes grabs a cup."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 274,
                "<e0>": 294
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_37310",
        "original_caption": "there is a crocodile in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A crocodile."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 0,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_37311",
        "original_caption": "an adult is inside a watercraft on the dragon boat race.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is inside a watercraft on the dragon boat race."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12326753325",
        "aid": "12326753325_37312",
        "original_caption": "an adult is beneath a cat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the adult in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                997
            ],
            "duration": 998,
            "token": {
                "<s0>": 6,
                "<e0>": 989
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_37313",
        "original_caption": "there is a backpack behind an adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the backpack from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a backpack behind an adult outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 660,
                "<e0>": 716
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37314",
        "original_caption": "a cake is away from the yellow cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away from the yellow cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cake."
            }
        ],
        "meta": {
            "split": [
                0,
                2225
            ],
            "duration": 2226,
            "token": {
                "<s0>": 1020,
                "<e0>": 1082
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3190385624",
        "aid": "3190385624_37315",
        "original_caption": "there is a toy behind a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy behind a child in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1460
            ],
            "duration": 1461,
            "token": {
                "<s0>": 604,
                "<e0>": 1289
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2425461420",
        "aid": "2425461420_37316",
        "original_caption": "there is a cat next to a handbag on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cat next to a handbag on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1797
            ],
            "duration": 1798,
            "token": {
                "<s0>": 0,
                "<e0>": 1798
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5258789985",
        "aid": "5258789985_37317",
        "original_caption": "there is the piano in front of an adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the piano from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is the piano in front of an adult on stage."
            }
        ],
        "meta": {
            "split": [
                357,
                544
            ],
            "duration": 188,
            "token": {
                "<s0>": 28,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5053937486",
        "aid": "5053937486_37318",
        "original_caption": "there is a black car beneath an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the black car from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                246
            ],
            "duration": 247,
            "token": {
                "<s0>": 0,
                "<e0>": 218
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_37319",
        "original_caption": "there is a dish above a baby seat in room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dish above a baby seat in room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                576,
                1470
            ],
            "duration": 895,
            "token": {
                "<s0>": 49,
                "<e0>": 893
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5363401248",
        "aid": "5363401248_37320",
        "original_caption": "an adult holds a camera at the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the camera at the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                667
            ],
            "duration": 668,
            "token": {
                "<s0>": 56,
                "<e0>": 519
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5363401248",
        "aid": "5363401248_37321",
        "original_caption": "an adult holds a camera at the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the camera at the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                667,
                1407
            ],
            "duration": 741,
            "token": {
                "<s0>": 148,
                "<e0>": 720
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5363401248",
        "aid": "5363401248_37322",
        "original_caption": "an adult holds a camera at the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the camera at the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1407,
                2696
            ],
            "duration": 1290,
            "token": {
                "<s0>": 20,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_37323",
        "original_caption": "adults in white clothes are behind an adult wearing blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "Adults in white clothes are behind an adult wearing blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1799
            ],
            "duration": 1800,
            "token": {
                "<s0>": 0,
                "<e0>": 1325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37324",
        "original_caption": "an adult wearing green pants is towards another adult in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult wearing green pants towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 1020,
                "<e0>": 1095
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6106626461",
        "aid": "6106626461_37325",
        "original_caption": "a child in white is next to an adult in  red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white is next to an adult in  red happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                520
            ],
            "duration": 521,
            "token": {
                "<s0>": 120,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3453984843",
        "aid": "3453984843_37326",
        "original_caption": "an adult in black drives a motorcycle yellow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black drives a motorcycle yellow."
            }
        ],
        "meta": {
            "split": [
                62,
                509
            ],
            "duration": 448,
            "token": {
                "<s0>": 32,
                "<e0>": 426
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3453984843",
        "aid": "3453984843_37327",
        "original_caption": "an adult in black drives a motorcycle yellow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black drives a motorcycle yellow."
            }
        ],
        "meta": {
            "split": [
                509,
                816
            ],
            "duration": 308,
            "token": {
                "<s0>": 22,
                "<e0>": 308
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9307201044",
        "aid": "9307201044_37328",
        "original_caption": "an adult in red holds hand of a child in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red holds hand of a child in white outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                416
            ],
            "duration": 417,
            "token": {
                "<s0>": 0,
                "<e0>": 234
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_37329",
        "original_caption": "an adult in a sweater carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in a sweater carries a backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 280,
                "<e0>": 358
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_37330",
        "original_caption": "there is a skateboard behind a child in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the skateboard from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a skateboard behind a child in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 293,
                "<e0>": 359
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9703420062",
        "aid": "9703420062_37331",
        "original_caption": "an adult in red clothes is in front of a balck car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes is in front of a balck car."
            }
        ],
        "meta": {
            "split": [
                0,
                441
            ],
            "duration": 442,
            "token": {
                "<s0>": 0,
                "<e0>": 442
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2503862291",
        "aid": "2503862291_37332",
        "original_caption": "a child in white clothes leans on a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white clothes leans on a baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                850
            ],
            "duration": 851,
            "token": {
                "<s0>": 0,
                "<e0>": 851
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2717467340",
        "aid": "2717467340_37333",
        "original_caption": "an adult in red pulls a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red pulls a child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                506
            ],
            "duration": 507,
            "token": {
                "<s0>": 470,
                "<e0>": 503
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37334",
        "original_caption": "an adult in white is beneath a monitor in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white is beneath a monitor in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_37335",
        "original_caption": "a child in white clothes rides a green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes rides a green toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 0,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2867108011",
        "aid": "2867108011_37336",
        "original_caption": "a child in blue leans on a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue leans on a table in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 0,
                "<e0>": 876
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_37337",
        "original_caption": "an adult wearing glasses hugs a black cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hugs the black cat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1238
            ],
            "duration": 1239,
            "token": {
                "<s0>": 253,
                "<e0>": 1239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_37338",
        "original_caption": "an adult woman in gray leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 272,
                "<e0>": 548
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2494076437",
        "aid": "2494076437_37339",
        "original_caption": "an adult caresses a baby in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the baby in pink clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1421
            ],
            "duration": 1422,
            "token": {
                "<s0>": 1257,
                "<e0>": 1362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_37340",
        "original_caption": "the child in blue is leaning on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The child in blue is leaning on the chair."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 0,
                "<e0>": 300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8059684971",
        "aid": "8059684971_37341",
        "original_caption": "a child with blond-hair leans on a green sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair leans on a green sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                441
            ],
            "duration": 442,
            "token": {
                "<s0>": 0,
                "<e0>": 332
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8059684971",
        "aid": "8059684971_37342",
        "original_caption": "a child with blond-hair leans on a green sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the green sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                441,
                1379
            ],
            "duration": 939,
            "token": {
                "<s0>": 110,
                "<e0>": 939
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2462607486",
        "aid": "2462607486_37343",
        "original_caption": "an adult man in striped clothes plays a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in striped clothes plays a guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1251
            ],
            "duration": 1252,
            "token": {
                "<s0>": 509,
                "<e0>": 1252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37344",
        "original_caption": "there is a glass cup above a black table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a glass cup above a black table in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3758307290",
        "aid": "3758307290_37345",
        "original_caption": "there is a chair beneath a toy on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the chair on stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                657
            ],
            "duration": 658,
            "token": {
                "<s0>": 0,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_37346",
        "original_caption": "there is a monitor next to a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the screen/monitor from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a monitor next to a bottle."
            }
        ],
        "meta": {
            "split": [
                275,
                611
            ],
            "duration": 337,
            "token": {
                "<s0>": 6,
                "<e0>": 282
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_37347",
        "original_caption": "a baby is above a blue baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby is above a blue baby seat."
            }
        ],
        "meta": {
            "split": [
                227,
                1756
            ],
            "duration": 1530,
            "token": {
                "<s0>": 37,
                "<e0>": 1422
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5399895838",
        "aid": "5399895838_37348",
        "original_caption": "there is a white cat above a table outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white cat above a table outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1048
            ],
            "duration": 1049,
            "token": {
                "<s0>": 0,
                "<e0>": 857
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4352200366",
        "aid": "4352200366_37349",
        "original_caption": "a child rides a ski on the fucking snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child rides a ski on the fucking snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                533
            ],
            "duration": 534,
            "token": {
                "<s0>": 0,
                "<e0>": 517
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4352200366",
        "aid": "4352200366_37350",
        "original_caption": "a child rides a ski on the fucking snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a ski on the fucking snow."
            }
        ],
        "meta": {
            "split": [
                533,
                960
            ],
            "duration": 428,
            "token": {
                "<s0>": 16,
                "<e0>": 324
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_37351",
        "original_caption": "a child in red is towards another child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is towards another child outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 660,
                "<e0>": 745
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3066398259",
        "aid": "3066398259_37352",
        "original_caption": "a baby in white is above a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white is above a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                251,
                629
            ],
            "duration": 379,
            "token": {
                "<s0>": 9,
                "<e0>": 378
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_37353",
        "original_caption": "an adult in yellow is next to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in yellow is next to another adult in black."
            }
        ],
        "meta": {
            "split": [
                120,
                458
            ],
            "duration": 339,
            "token": {
                "<s0>": 30,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_37354",
        "original_caption": "an adult man in black watches another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black watches another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 714,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_37355",
        "original_caption": "a child in white is above a green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 0,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37356",
        "original_caption": "adult wearing a purple suit get off the bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adult wearing a purple suit get off the bench."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 766,
                "<e0>": 793
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37357",
        "original_caption": "adult wearing a purple suit get off the bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is get off the bench from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                875,
                998
            ],
            "duration": 124,
            "token": {
                "<s0>": 83,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37358",
        "original_caption": "adult wearing a purple suit get off the bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is get off the bench from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1058,
                1323
            ],
            "duration": 266,
            "token": {
                "<s0>": 24,
                "<e0>": 51
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_37359",
        "original_caption": "there is a faucet above a sink in the bathroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a faucet above a sink in the bathroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                821,
                915
            ],
            "duration": 95,
            "token": {
                "<s0>": 45,
                "<e0>": 94
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37360",
        "original_caption": "an adult with glasses hugs a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with glasses hugs a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2215
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37361",
        "original_caption": "an adult is behind a dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is behind a dog at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 960,
                "<e0>": 1055
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_37362",
        "original_caption": "a child in pink clothes bites a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink clothes bites a cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                926
            ],
            "duration": 927,
            "token": {
                "<s0>": 469,
                "<e0>": 635
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_37363",
        "original_caption": "a child in pink clothes bites a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink clothes bites a cellphone happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                926,
                1349
            ],
            "duration": 424,
            "token": {
                "<s0>": 291,
                "<e0>": 314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9038264963",
        "aid": "9038264963_37364",
        "original_caption": "there is a cup above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                525,
                5006
            ],
            "duration": 4482,
            "token": {
                "<s0>": 15,
                "<e0>": 4482
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12158830025",
        "aid": "12158830025_37365",
        "original_caption": "there is a backpack towards an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the backpack towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1368
            ],
            "duration": 1369,
            "token": {
                "<s0>": 457,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13715319605",
        "aid": "13715319605_37366",
        "original_caption": "the adult in black is away from the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in black is away from the adult."
            }
        ],
        "meta": {
            "split": [
                0,
                77
            ],
            "duration": 78,
            "token": {
                "<s0>": 26,
                "<e0>": 52
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37367",
        "original_caption": "there is a black hamster towards a black hamster on a bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the black hamster towards to on the bed from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 900,
                "<e0>": 953
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37368",
        "original_caption": "there is a monitor above an adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the monitor in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37369",
        "original_caption": "an adult in gray is next to a black backpack in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult in gray next to in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37370",
        "original_caption": "a child in blue is behind an another child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue is behind an another child in red."
            }
        ],
        "meta": {
            "split": [
                524,
                681
            ],
            "duration": 158,
            "token": {
                "<s0>": 16,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3862213653",
        "aid": "3862213653_37371",
        "original_caption": "an adult man leans on a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult man lean on in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                275
            ],
            "duration": 276,
            "token": {
                "<s0>": 0,
                "<e0>": 276
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_37372",
        "original_caption": "a child in orange holds a toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in orange hold at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 700,
                "<e0>": 834
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8782055272",
        "aid": "8782055272_37373",
        "original_caption": "an adult in blue clothes carries a bicycle in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in blue clothes carry in the wild from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 218,
                "<e0>": 301
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4866672246",
        "aid": "4866672246_37374",
        "original_caption": "there is a white dog next to an adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the white dog next to on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 722,
                "<e0>": 769
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_37375",
        "original_caption": "an adult in pink clothes is away from a black cattle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pink clothes is away from a black cattle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1151
            ],
            "duration": 1152,
            "token": {
                "<s0>": 960,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37376",
        "original_caption": "there is a toy beneath a green sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy beneath a green sports ball in the room."
            }
        ],
        "meta": {
            "split": [
                510,
                2696
            ],
            "duration": 2187,
            "token": {
                "<s0>": 11,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8115037154",
        "aid": "8115037154_37377",
        "original_caption": "an adult in black clothes holds a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1379
            ],
            "duration": 1380,
            "token": {
                "<s0>": 1090,
                "<e0>": 1250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8014277171",
        "aid": "8014277171_37378",
        "original_caption": "an adult woman in white caresses a black dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in white caresses a black dog outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1120
            ],
            "duration": 1121,
            "token": {
                "<s0>": 764,
                "<e0>": 1055
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8014277171",
        "aid": "8014277171_37379",
        "original_caption": "an adult woman in white caresses a black dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in white caresses a black dog outdoors."
            }
        ],
        "meta": {
            "split": [
                1120,
                1909
            ],
            "duration": 790,
            "token": {
                "<s0>": 65,
                "<e0>": 790
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4914011323",
        "aid": "4914011323_37380",
        "original_caption": "there is a toilet beneath a cat inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toilet from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toilet beneath a cat inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                182
            ],
            "duration": 183,
            "token": {
                "<s0>": 0,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7609356686",
        "aid": "7609356686_37381",
        "original_caption": "a child in pink licks another child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink licks another child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 0,
                "<e0>": 17
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_37382",
        "original_caption": "a child hugs a white dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hugs the white dog at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                364
            ],
            "duration": 365,
            "token": {
                "<s0>": 209,
                "<e0>": 252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_37383",
        "original_caption": "a child hugs a white dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child hugs a white dog at home."
            }
        ],
        "meta": {
            "split": [
                364,
                676
            ],
            "duration": 313,
            "token": {
                "<s0>": 113,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_37384",
        "original_caption": "a child hugs a white dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child hugs a white dog at home."
            }
        ],
        "meta": {
            "split": [
                676,
                1080
            ],
            "duration": 405,
            "token": {
                "<s0>": 98,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_37385",
        "original_caption": "a child hugs a white dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child hugs a white dog at home."
            }
        ],
        "meta": {
            "split": [
                1080,
                1859
            ],
            "duration": 780,
            "token": {
                "<s0>": 221,
                "<e0>": 292
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_37386",
        "original_caption": "a child hugs a white dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child hugs a white dog at home."
            }
        ],
        "meta": {
            "split": [
                1859,
                2595
            ],
            "duration": 737,
            "token": {
                "<s0>": 488,
                "<e0>": 553
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_37387",
        "original_caption": "adults in red clothes watch at adults in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho are the adults in red clothes watching at from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 45,
                "<e0>": 91
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_37388",
        "original_caption": "an adult in white clothes kisses a male adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes kisses a male adult."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 85,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37389",
        "original_caption": "an adult holds a bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult hold in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bench."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 650,
                "<e0>": 722
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_37390",
        "original_caption": "a child in white closes an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho closes the orange toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                930
            ],
            "duration": 931,
            "token": {
                "<s0>": 433,
                "<e0>": 457
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9203288179",
        "aid": "9203288179_37391",
        "original_caption": "a child is next to a table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is next to a table in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                419
            ],
            "duration": 420,
            "token": {
                "<s0>": 0,
                "<e0>": 405
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4981531978",
        "aid": "4981531978_37392",
        "original_caption": "there is a horse watching an adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the horse watch outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                614
            ],
            "duration": 615,
            "token": {
                "<s0>": 574,
                "<e0>": 615
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_37393",
        "original_caption": "there is a black sofa in front of an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 273,
                "<e0>": 548
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37394",
        "original_caption": "there is a hamster above another hamster on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the other hamster on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 420,
                "<e0>": 1170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3836995607",
        "aid": "3836995607_37395",
        "original_caption": "an adult wearing a no.15 jersey hugs a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult wearing the no.15 jersey hug from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                96
            ],
            "duration": 97,
            "token": {
                "<s0>": 0,
                "<e0>": 35
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6122666405",
        "aid": "6122666405_37396",
        "original_caption": "an adult in a hat is next to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in a hat is next to another adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1370,
                1668
            ],
            "duration": 299,
            "token": {
                "<s0>": 121,
                "<e0>": 298
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8224546307",
        "aid": "8224546307_37397",
        "original_caption": "a baby in white is above a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby in white in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                1457
            ],
            "duration": 1458,
            "token": {
                "<s0>": 0,
                "<e0>": 1458
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4656902106",
        "aid": "4656902106_37398",
        "original_caption": "an adult woman watches an orange and blue ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman watches an orange and blue ball on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 0,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8223287911",
        "aid": "8223287911_37399",
        "original_caption": "a green chair is in front of the white chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the white chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                323,
                1484
            ],
            "duration": 1162,
            "token": {
                "<s0>": 99,
                "<e0>": 801
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37400",
        "original_caption": "an adult in black clothes is behind another adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes is behind another adult in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1860,
                "<e0>": 2010
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8115037154",
        "aid": "8115037154_37401",
        "original_caption": "an adult in black clothes holds a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes holds a camera happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1379
            ],
            "duration": 1380,
            "token": {
                "<s0>": 1090,
                "<e0>": 1250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4535557687",
        "aid": "4535557687_37402",
        "original_caption": "an adult plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult plays the guitar on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                335
            ],
            "duration": 336,
            "token": {
                "<s0>": 0,
                "<e0>": 248
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_37403",
        "original_caption": "there is a black monitor above a white table in the office.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black monitor above a white table in the office."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6612282627",
        "aid": "6612282627_37404",
        "original_caption": "a baby holds a toy on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby holds a toy on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                229
            ],
            "duration": 230,
            "token": {
                "<s0>": 0,
                "<e0>": 141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6612282627",
        "aid": "6612282627_37405",
        "original_caption": "a baby holds a toy on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby holds a toy on the bed happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                229,
                450
            ],
            "duration": 222,
            "token": {
                "<s0>": 88,
                "<e0>": 170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6612282627",
        "aid": "6612282627_37406",
        "original_caption": "a baby holds a toy on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby holds a toy on the bed happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                450,
                1617
            ],
            "duration": 1168,
            "token": {
                "<s0>": 52,
                "<e0>": 1168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37407",
        "original_caption": "there is a hamster above another rat on the blanket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a hamster above another rat on the blanket happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 900,
                "<e0>": 953
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_37408",
        "original_caption": "an adult is towards another adult in a mall.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards another adult in a mall happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1215,
                1582
            ],
            "duration": 368,
            "token": {
                "<s0>": 45,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37409",
        "original_caption": "an adult in striped clothes is away from another adult wearing a plaid clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in striped clothes is away from another adult wearing a plaid clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                2055,
                2271
            ],
            "duration": 217,
            "token": {
                "<s0>": 45,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4935150377",
        "aid": "4935150377_37410",
        "original_caption": "an adult rides a bicycle on the bridge.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the bicycle on the bridge from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                197
            ],
            "duration": 198,
            "token": {
                "<s0>": 6,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5052259273",
        "aid": "5052259273_37411",
        "original_caption": "an adult in black clothes caresses a dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black clothes caress from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                499
            ],
            "duration": 500,
            "token": {
                "<s0>": 337,
                "<e0>": 415
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_37412",
        "original_caption": "an adult is away a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away a table in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 0,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37413",
        "original_caption": "an adult is behind another adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_37414",
        "original_caption": "there is a white and brown cat next to a grey laptop at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the white and brown cat next to at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                1271
            ],
            "duration": 1272,
            "token": {
                "<s0>": 890,
                "<e0>": 997
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_37415",
        "original_caption": "there is a table beneath a cup in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cup in a room."
            }
        ],
        "meta": {
            "split": [
                102,
                611
            ],
            "duration": 510,
            "token": {
                "<s0>": 26,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37416",
        "original_caption": "the child goes away from the adult sitting on the sofa to remove the gift.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child away from from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 240,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6777058251",
        "aid": "6777058251_37417",
        "original_caption": "a child wearing a red hat watches an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child wearing the red hat watch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1321
            ],
            "duration": 1322,
            "token": {
                "<s0>": 940,
                "<e0>": 980
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5783801873",
        "aid": "5783801873_37418",
        "original_caption": "there is a black motorcycle towards another motorcycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black motorcycle towards another motorcycle outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                844
            ],
            "duration": 845,
            "token": {
                "<s0>": 680,
                "<e0>": 729
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37419",
        "original_caption": "a child is towards an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is towards an adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 420,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_37420",
        "original_caption": "an adult woman in pale blue is above a brown sofa in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in pale blue is above a brown sofa in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                4260
            ],
            "duration": 4261,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37421",
        "original_caption": "there is a cup above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_37422",
        "original_caption": "a child in orange clothes is above a horse.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in orange clothes is above a horse happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 120,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13945442936",
        "aid": "13945442936_37423",
        "original_caption": "there is a brown table beneath a black laptop in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown table beneath a black laptop in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                949
            ],
            "duration": 950,
            "token": {
                "<s0>": 70,
                "<e0>": 874
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37424",
        "original_caption": "there is a ball towards a child on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a ball towards a child on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 278,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_37425",
        "original_caption": "there is a dog towards another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dog towards another dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 200,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13715319605",
        "aid": "13715319605_37426",
        "original_caption": "an adult watches a horse in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult watches a horse in the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                77
            ],
            "duration": 78,
            "token": {
                "<s0>": 0,
                "<e0>": 19
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37427",
        "original_caption": "a child in yellow clothes is behind another child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in yellow clothes is behind another child in red clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37428",
        "original_caption": "a child in red clothes holds a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cake from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                219
            ],
            "duration": 220,
            "token": {
                "<s0>": 0,
                "<e0>": 62
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37429",
        "original_caption": "a child in red clothes holds a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes holds a cake."
            }
        ],
        "meta": {
            "split": [
                219,
                710
            ],
            "duration": 492,
            "token": {
                "<s0>": 157,
                "<e0>": 288
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37430",
        "original_caption": "a child in red clothes holds a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cake from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                710,
                1096
            ],
            "duration": 387,
            "token": {
                "<s0>": 203,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37431",
        "original_caption": "a child in red clothes holds a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes holds a cake."
            }
        ],
        "meta": {
            "split": [
                1151,
                1394
            ],
            "duration": 244,
            "token": {
                "<s0>": 18,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37432",
        "original_caption": "a child in red clothes holds a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes holds a cake."
            }
        ],
        "meta": {
            "split": [
                1394,
                2225
            ],
            "duration": 832,
            "token": {
                "<s0>": 125,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5625562611",
        "aid": "5625562611_37433",
        "original_caption": "there is a silver bottle in front of an adult man in black in the barber shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a silver bottle in front of an adult man in black in the barber shop happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                736
            ],
            "duration": 737,
            "token": {
                "<s0>": 96,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_37434",
        "original_caption": "a child in white is away from an adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white is away from an adult on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1218,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37435",
        "original_caption": "an adult woman in black is towards a child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult woman in black towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 485,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5195700916",
        "aid": "5195700916_37436",
        "original_caption": "an adult wearing a red hat speaks to another adult with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a red hat speaks to another adult with glasses."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 1589,
                "<e0>": 1633
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4914011323",
        "aid": "4914011323_37437",
        "original_caption": "there is a cat above a toilet inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat above a toilet inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                182
            ],
            "duration": 183,
            "token": {
                "<s0>": 0,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_37438",
        "original_caption": "adults use the camera to shoot people on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see adults use the camera to shoot people on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2196
            ],
            "duration": 2197,
            "token": {
                "<s0>": 349,
                "<e0>": 520
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_37439",
        "original_caption": "there is a chair behind a baby with brown-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair behind a baby with brown-hair."
            }
        ],
        "meta": {
            "split": [
                0,
                2533
            ],
            "duration": 2534,
            "token": {
                "<s0>": 1860,
                "<e0>": 1973
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_37440",
        "original_caption": "a baby in orange holds a toy orange on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in orange holds a toy orange on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                225
            ],
            "duration": 226,
            "token": {
                "<s0>": 0,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_37441",
        "original_caption": "a baby in orange holds a toy orange on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in orange holds a toy orange on the floor."
            }
        ],
        "meta": {
            "split": [
                278,
                435
            ],
            "duration": 158,
            "token": {
                "<s0>": 6,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_37442",
        "original_caption": "a baby in orange holds a toy orange on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in orange holds a toy orange on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                435,
                575
            ],
            "duration": 141,
            "token": {
                "<s0>": 36,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_37443",
        "original_caption": "a baby in orange holds a toy orange on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby in orange hold on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                575,
                824
            ],
            "duration": 250,
            "token": {
                "<s0>": 63,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_37444",
        "original_caption": "a child pushes a toy at the seaside.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child pushes a toy at the seaside."
            }
        ],
        "meta": {
            "split": [
                0,
                554
            ],
            "duration": 555,
            "token": {
                "<s0>": 461,
                "<e0>": 476
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_37445",
        "original_caption": "a child pushes a toy at the seaside.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child pushes a toy at the seaside."
            }
        ],
        "meta": {
            "split": [
                697,
                1113
            ],
            "duration": 417,
            "token": {
                "<s0>": 55,
                "<e0>": 73
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_37446",
        "original_caption": "a child in grey waves a red bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in grey waves a red bat on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                417
            ],
            "duration": 418,
            "token": {
                "<s0>": 287,
                "<e0>": 385
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_37447",
        "original_caption": "a child in grey waves a red bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in grey waves a red bat on the grass."
            }
        ],
        "meta": {
            "split": [
                417,
                621
            ],
            "duration": 205,
            "token": {
                "<s0>": 32,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_37448",
        "original_caption": "a child in grey waves a red bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in grey waves a red bat on the grass."
            }
        ],
        "meta": {
            "split": [
                621,
                829
            ],
            "duration": 209,
            "token": {
                "<s0>": 116,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7442776522",
        "aid": "7442776522_37449",
        "original_caption": "there is a grey cat watching a yellow cat inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a grey cat watching a yellow cat inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2313
            ],
            "duration": 2314,
            "token": {
                "<s0>": 16,
                "<e0>": 81
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3779800369",
        "aid": "3779800369_37450",
        "original_caption": "an adult in gray is next to another adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in gray is next to another adult in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                956
            ],
            "duration": 957,
            "token": {
                "<s0>": 420,
                "<e0>": 482
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8996323211",
        "aid": "8996323211_37451",
        "original_caption": "there are the guitar behind a baby on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat behind the baby on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1358
            ],
            "duration": 1359,
            "token": {
                "<s0>": 0,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_37452",
        "original_caption": "an adult in green clothes leans on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in green clothes lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 258,
                "<e0>": 475
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_37453",
        "original_caption": "there is a black dog away from another dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black dog away from another dog outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 150,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_37454",
        "original_caption": "there is a white ball in front of a dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white ball in front of a dog."
            }
        ],
        "meta": {
            "split": [
                1205,
                1336
            ],
            "duration": 132,
            "token": {
                "<s0>": 17,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4624548287",
        "aid": "4624548287_37455",
        "original_caption": "an adult man in white is above a scooter on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white is above a scooter on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                81,
                671
            ],
            "duration": 591,
            "token": {
                "<s0>": 27,
                "<e0>": 408
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_37456",
        "original_caption": "a baby grabs a pink bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby grabs a pink bottle at home."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 310,
                "<e0>": 333
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37457",
        "original_caption": "there is a cake above a red table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cake above a red table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 164,
                "<e0>": 869
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37458",
        "original_caption": "a child is in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is in front of an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1422,
                "<e0>": 1550
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37459",
        "original_caption": "a child in wathet blue leans on a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in wathet blue leans on a brown sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                451
            ],
            "duration": 452,
            "token": {
                "<s0>": 0,
                "<e0>": 280
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37460",
        "original_caption": "a child in wathet blue leans on a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in wathet blue leans on a brown sofa."
            }
        ],
        "meta": {
            "split": [
                451,
                1158
            ],
            "duration": 708,
            "token": {
                "<s0>": 172,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37461",
        "original_caption": "a child in wathet blue leans on a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in wathet blue leans on a brown sofa."
            }
        ],
        "meta": {
            "split": [
                1158,
                1441
            ],
            "duration": 284,
            "token": {
                "<s0>": 96,
                "<e0>": 167
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_37462",
        "original_caption": "an adult man in black watches another adult woman in wedding dresses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black watches another adult woman in wedding dresses."
            }
        ],
        "meta": {
            "split": [
                170,
                479
            ],
            "duration": 310,
            "token": {
                "<s0>": 45,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3004044251",
        "aid": "3004044251_37463",
        "original_caption": "an adult in black clothes watches a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black clothes watch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                663
            ],
            "duration": 664,
            "token": {
                "<s0>": 243,
                "<e0>": 339
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_37464",
        "original_caption": "an adult wearing a camouflage hat carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a camouflage hat carries a backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 693,
                "<e0>": 800
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6113835875",
        "aid": "6113835875_37465",
        "original_caption": "there is a tiger hitting another tiger in the zoo.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the tiger from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a tiger hitting another tiger in the zoo."
            }
        ],
        "meta": {
            "split": [
                64,
                218
            ],
            "duration": 155,
            "token": {
                "<s0>": 8,
                "<e0>": 16
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6113835875",
        "aid": "6113835875_37466",
        "original_caption": "there is a tiger hitting another tiger in the zoo.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the tiger hit in the zoo from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A tiger."
            }
        ],
        "meta": {
            "split": [
                218,
                370
            ],
            "duration": 153,
            "token": {
                "<s0>": 139,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_37467",
        "original_caption": "an adult man in black chases a child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black chases a child on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                927
            ],
            "duration": 928,
            "token": {
                "<s0>": 820,
                "<e0>": 896
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_37468",
        "original_caption": "a baby in pink is in front of an adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in pink is in front of an adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 600,
                "<e0>": 870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37469",
        "original_caption": "a child in pink leans on a brown wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink leans on a brown wooden table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                129
            ],
            "duration": 130,
            "token": {
                "<s0>": 21,
                "<e0>": 66
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37470",
        "original_caption": "a child in pink leans on a brown wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink leans on a brown wooden table."
            }
        ],
        "meta": {
            "split": [
                129,
                681
            ],
            "duration": 553,
            "token": {
                "<s0>": 63,
                "<e0>": 535
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37471",
        "original_caption": "a child in pink leans on a brown wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink leans on a brown wooden table."
            }
        ],
        "meta": {
            "split": [
                681,
                872
            ],
            "duration": 192,
            "token": {
                "<s0>": 18,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_37472",
        "original_caption": "an adult man in black is next to a child in dark purple.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black is next to a child in dark purple happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_37473",
        "original_caption": "a child in blue  is next to the child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue  is next to the child in red."
            }
        ],
        "meta": {
            "split": [
                824,
                1709
            ],
            "duration": 886,
            "token": {
                "<s0>": 256,
                "<e0>": 635
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_37474",
        "original_caption": "there is a toy above a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy above a baby seat in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 540,
                "<e0>": 834
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3190400650",
        "aid": "3190400650_37475",
        "original_caption": "an adult in black clothes is next to another adult with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes is next to another adult with glasses happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1229,
                1769
            ],
            "duration": 541,
            "token": {
                "<s0>": 34,
                "<e0>": 352
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9562161527",
        "aid": "9562161527_37476",
        "original_caption": "an female adult is towards an another male adult at swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An female adult is towards an another male adult at swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                189
            ],
            "duration": 190,
            "token": {
                "<s0>": 10,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_37477",
        "original_caption": "a child holds a green ball in room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds a green ball in room."
            }
        ],
        "meta": {
            "split": [
                0,
                1001
            ],
            "duration": 1002,
            "token": {
                "<s0>": 662,
                "<e0>": 861
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_37478",
        "original_caption": "a child holds a green ball in room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a green ball in room."
            }
        ],
        "meta": {
            "split": [
                1001,
                1640
            ],
            "duration": 640,
            "token": {
                "<s0>": 141,
                "<e0>": 451
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_37479",
        "original_caption": "a child holds a green ball in room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds a green ball in room."
            }
        ],
        "meta": {
            "split": [
                1640,
                2069
            ],
            "duration": 430,
            "token": {
                "<s0>": 189,
                "<e0>": 277
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_37480",
        "original_caption": "there is a dog watching a sports ball outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog watching a sports ball outdoors."
            }
        ],
        "meta": {
            "split": [
                1113,
                1336
            ],
            "duration": 224,
            "token": {
                "<s0>": 130,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_37481",
        "original_caption": "an adult wearing orange shoes is in front of another adult wearing white scoks.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing orange shoes is in front of another adult wearing white scoks happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1877
            ],
            "duration": 1878,
            "token": {
                "<s0>": 76,
                "<e0>": 227
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_37482",
        "original_caption": "there is a pig behind another pig in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the other pig in the forest from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A pig."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 600,
                "<e0>": 690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_37483",
        "original_caption": "an adult with a hat holds the guitar at the show.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult with the hat hold at the show from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1080
            ],
            "duration": 1081,
            "token": {
                "<s0>": 546,
                "<e0>": 592
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_37484",
        "original_caption": "an adult with a hat holds the guitar at the show.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with a hat holds the guitar at the show."
            }
        ],
        "meta": {
            "split": [
                1080,
                1583
            ],
            "duration": 504,
            "token": {
                "<s0>": 488,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_37485",
        "original_caption": "a child in black is towards an adult in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child in black towards to in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                193,
                411
            ],
            "duration": 219,
            "token": {
                "<s0>": 75,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5640939571",
        "aid": "5640939571_37486",
        "original_caption": "there is a black-red dish above a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black-red dish above a baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                596
            ],
            "duration": 597,
            "token": {
                "<s0>": 0,
                "<e0>": 597
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7717953964",
        "aid": "7717953964_37487",
        "original_caption": "a male adult is behind another adult in the middle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a male adult is behind another adult in the middle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                678
            ],
            "duration": 679,
            "token": {
                "<s0>": 180,
                "<e0>": 679
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37488",
        "original_caption": "an adult is behind a child at a party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is behind a child at a party happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                983,
                1441
            ],
            "duration": 459,
            "token": {
                "<s0>": 383,
                "<e0>": 458
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37489",
        "original_caption": "there is a gray and white cat pressing a gray and white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray and white cat pressing a gray and white cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 1713,
                "<e0>": 1766
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_37490",
        "original_caption": "a child leans on a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child leans on a table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 2,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_37491",
        "original_caption": "an adult is above a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a watercraft on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                841,
                1478
            ],
            "duration": 638,
            "token": {
                "<s0>": 580,
                "<e0>": 628
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_37492",
        "original_caption": "an adult in black is next to an adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to an adult in white clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_37493",
        "original_caption": "there is a bicycle in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bicycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bicycle in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 16,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_37494",
        "original_caption": "there is a pig next to another pig on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the pig next to on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A pig."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 720,
                "<e0>": 785
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4617403206",
        "aid": "4617403206_37495",
        "original_caption": "there is a white dog biting a red sports ball outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white dog biting a red sports ball outdoors."
            }
        ],
        "meta": {
            "split": [
                33,
                144
            ],
            "duration": 112,
            "token": {
                "<s0>": 5,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_37496",
        "original_caption": "a child pats a ball in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child pats a ball in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 0,
                "<e0>": 581
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_37497",
        "original_caption": "a child pats a ball in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child pats a ball in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                604,
                1246
            ],
            "duration": 643,
            "token": {
                "<s0>": 2,
                "<e0>": 608
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3142287520",
        "aid": "3142287520_37498",
        "original_caption": "an adult drives a car in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult drives a car in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 0,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37499",
        "original_caption": "an adult man in red is away a child in pale blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in red is away a child in pale blue."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 96,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6273445204",
        "aid": "6273445204_37500",
        "original_caption": "an adult man in white speaks to a baby in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in white speaks to a baby in black."
            }
        ],
        "meta": {
            "split": [
                53,
                143
            ],
            "duration": 91,
            "token": {
                "<s0>": 23,
                "<e0>": 47
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6273445204",
        "aid": "6273445204_37501",
        "original_caption": "an adult man in white speaks to a baby in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white speaks to a baby in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                143,
                240
            ],
            "duration": 98,
            "token": {
                "<s0>": 44,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6273445204",
        "aid": "6273445204_37502",
        "original_caption": "an adult man in white speaks to a baby in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white speaks to a baby in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                240,
                481
            ],
            "duration": 242,
            "token": {
                "<s0>": 30,
                "<e0>": 49
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10250170546",
        "aid": "10250170546_37503",
        "original_caption": "an adult lifts a child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult lifts a child in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                141,
                393
            ],
            "duration": 253,
            "token": {
                "<s0>": 18,
                "<e0>": 40
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_37504",
        "original_caption": "an adult feeds a baby inside the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult feeds a baby inside the baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                692
            ],
            "duration": 693,
            "token": {
                "<s0>": 149,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_37505",
        "original_caption": "an adult feeds a baby inside the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult feeds a baby inside the baby seat."
            }
        ],
        "meta": {
            "split": [
                692,
                1470
            ],
            "duration": 779,
            "token": {
                "<s0>": 507,
                "<e0>": 618
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_37506",
        "original_caption": "an adult women in green speaks to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women in green speaks to a child."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 0,
                "<e0>": 155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_37507",
        "original_caption": "an adult women in green speaks to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult women in green speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                196,
                396
            ],
            "duration": 201,
            "token": {
                "<s0>": 42,
                "<e0>": 139
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_37508",
        "original_caption": "an adult women in green speaks to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult women in green speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                396,
                692
            ],
            "duration": 297,
            "token": {
                "<s0>": 62,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_37509",
        "original_caption": "an adult women in green speaks to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women in green speaks to a child."
            }
        ],
        "meta": {
            "split": [
                692,
                1063
            ],
            "duration": 372,
            "token": {
                "<s0>": 129,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5994899092",
        "aid": "5994899092_37510",
        "original_caption": "a child is towards a surfboard in the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child towards to in the sea from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A surfboard."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 986,
                "<e0>": 1109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6121794107",
        "aid": "6121794107_37511",
        "original_caption": "the child is next to the ball on the lawn.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The child is next to the ball on the lawn."
            }
        ],
        "meta": {
            "split": [
                0,
                883
            ],
            "duration": 884,
            "token": {
                "<s0>": 0,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_37512",
        "original_caption": "an adult in purple watches another adult in white in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in purple watches another adult in white in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 660,
                "<e0>": 1188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8429686679",
        "aid": "8429686679_37513",
        "original_caption": "an male adult is behind another female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An male adult is behind another female adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1573
            ],
            "duration": 1574,
            "token": {
                "<s0>": 26,
                "<e0>": 617
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_37514",
        "original_caption": "an adult in white is behind another adult in red in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white is behind another adult in red in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1582
            ],
            "duration": 1583,
            "token": {
                "<s0>": 1082,
                "<e0>": 1204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_37515",
        "original_caption": "an adult in black  is next to the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 0,
                "<e0>": 375
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_37516",
        "original_caption": "there is a table in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                979
            ],
            "duration": 980,
            "token": {
                "<s0>": 516,
                "<e0>": 979
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6197272373",
        "aid": "6197272373_37517",
        "original_caption": "an adult woman holds a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman holds a cup in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                638
            ],
            "duration": 639,
            "token": {
                "<s0>": 132,
                "<e0>": 155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3924748616",
        "aid": "3924748616_37518",
        "original_caption": "an adult in black rides a skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black rides a skateboard in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                153
            ],
            "duration": 154,
            "token": {
                "<s0>": 0,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3924748616",
        "aid": "3924748616_37519",
        "original_caption": "an adult in black rides a skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black rides a skateboard in the playground."
            }
        ],
        "meta": {
            "split": [
                153,
                255
            ],
            "duration": 103,
            "token": {
                "<s0>": 5,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4715441335",
        "aid": "4715441335_37520",
        "original_caption": "there is a toy above a chair in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy above a chair in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1733
            ],
            "duration": 1734,
            "token": {
                "<s0>": 0,
                "<e0>": 1734
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6039815844",
        "aid": "6039815844_37521",
        "original_caption": "an adult holds a baby in the bathroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult hold in the bathroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_37522",
        "original_caption": "there is a toy beneath a cellphone on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy beneath a cellphone on a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 840,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37523",
        "original_caption": "there is a chair beneath a child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair beneath a child in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1222,
                2225
            ],
            "duration": 1004,
            "token": {
                "<s0>": 54,
                "<e0>": 307
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37524",
        "original_caption": "there is a screen above an adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the screen in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 1691
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_37525",
        "original_caption": "there is a brown cat away a baby wearing green pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown cat away a baby wearing green pants."
            }
        ],
        "meta": {
            "split": [
                1755,
                2144
            ],
            "duration": 390,
            "token": {
                "<s0>": 45,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_37526",
        "original_caption": "a child in a orange t-shirt is away from a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in a orange t-shirt is away from a car."
            }
        ],
        "meta": {
            "split": [
                0,
                1113
            ],
            "duration": 1114,
            "token": {
                "<s0>": 1020,
                "<e0>": 1110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_37527",
        "original_caption": "an adult woman in green is away a baby in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in green is away a baby in red."
            }
        ],
        "meta": {
            "split": [
                0,
                245
            ],
            "duration": 246,
            "token": {
                "<s0>": 48,
                "<e0>": 120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_37528",
        "original_caption": "there is a cup above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 144,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_37529",
        "original_caption": "an adult man in black and yellow is behind a child in pink on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black and yellow is behind a child in pink on the road."
            }
        ],
        "meta": {
            "split": [
                892,
                1007
            ],
            "duration": 116,
            "token": {
                "<s0>": 23,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6121794107",
        "aid": "6121794107_37530",
        "original_caption": "there is a sports ball beneath a cup on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sports ball beneath a cup on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                883
            ],
            "duration": 884,
            "token": {
                "<s0>": 0,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_37531",
        "original_caption": "an adult is away from another adult in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away from another adult in the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 60,
                "<e0>": 310
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3896491824",
        "aid": "3896491824_37532",
        "original_caption": "an adult holds hand of a baby in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of a baby in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                1106
            ],
            "duration": 1107,
            "token": {
                "<s0>": 474,
                "<e0>": 511
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13097816293",
        "aid": "13097816293_37533",
        "original_caption": "an adult man in gray leans on a gray sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult man in gray lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1104
            ],
            "duration": 1105,
            "token": {
                "<s0>": 0,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37534",
        "original_caption": "an adult uses a cellphone in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult uses a cellphone in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2145,
                "<e0>": 2274
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7040233679",
        "aid": "7040233679_37535",
        "original_caption": "an adult is next to a cup inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the cup inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                909
            ],
            "duration": 910,
            "token": {
                "<s0>": 240,
                "<e0>": 312
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3145413102",
        "aid": "3145413102_37536",
        "original_caption": "an adult in white hugs another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white hugs another adult in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                624
            ],
            "duration": 625,
            "token": {
                "<s0>": 508,
                "<e0>": 613
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3145413102",
        "aid": "3145413102_37537",
        "original_caption": "an adult in white hugs another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white hugs another adult in black."
            }
        ],
        "meta": {
            "split": [
                624,
                775
            ],
            "duration": 152,
            "token": {
                "<s0>": 12,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047707188",
        "aid": "6047707188_37538",
        "original_caption": "an adult with orange hat watches another adult with red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with orange hat watches another adult with red hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 49,
                "<e0>": 57
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3342105817",
        "aid": "3342105817_37539",
        "original_caption": "an adult in black clothes touches a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes touches a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                637
            ],
            "duration": 638,
            "token": {
                "<s0>": 0,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_37540",
        "original_caption": "there is a green toy away from a light yellow toy on an orange table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a green toy away from a light yellow toy on an orange table."
            }
        ],
        "meta": {
            "split": [
                574,
                824
            ],
            "duration": 251,
            "token": {
                "<s0>": 10,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9038264963",
        "aid": "9038264963_37541",
        "original_caption": "there is a yellow table beneath a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a yellow table beneath a cup."
            }
        ],
        "meta": {
            "split": [
                0,
                5006
            ],
            "duration": 5007,
            "token": {
                "<s0>": 1920,
                "<e0>": 5007
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_37542",
        "original_caption": "a baby in striped clothes is above a gray sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in striped clothes is above a gray sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                419
            ],
            "duration": 420,
            "token": {
                "<s0>": 0,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37543",
        "original_caption": "there is a camera above a silver table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a camera above a silver table."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 182,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37544",
        "original_caption": "an adult in black clothes leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes leans on a table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                586
            ],
            "duration": 587,
            "token": {
                "<s0>": 0,
                "<e0>": 525
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37545",
        "original_caption": "an adult in black clothes leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                586,
                1499
            ],
            "duration": 914,
            "token": {
                "<s0>": 62,
                "<e0>": 788
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37546",
        "original_caption": "an adult in black clothes leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1499,
                2159
            ],
            "duration": 661,
            "token": {
                "<s0>": 126,
                "<e0>": 661
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2718262890",
        "aid": "2718262890_37547",
        "original_caption": "an adult siting on the ground is in front of another adult near a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult siting on the ground is in front of another adult near a table."
            }
        ],
        "meta": {
            "split": [
                0,
                467
            ],
            "duration": 468,
            "token": {
                "<s0>": 328,
                "<e0>": 413
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5345319548",
        "aid": "5345319548_37548",
        "original_caption": "there is a toy above a table in the playroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy above a table in the playroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                790
            ],
            "duration": 791,
            "token": {
                "<s0>": 0,
                "<e0>": 791
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2422958285",
        "aid": "2422958285_37549",
        "original_caption": "an adult woman in pink leans on a colorful sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult woman in pink lean on in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                184
            ],
            "duration": 185,
            "token": {
                "<s0>": 0,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2422958285",
        "aid": "2422958285_37550",
        "original_caption": "an adult woman in pink leans on a colorful sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in pink leans on a colorful sofa in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                184,
                456
            ],
            "duration": 273,
            "token": {
                "<s0>": 50,
                "<e0>": 217
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37551",
        "original_caption": "there is a ball away from an adult in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a ball away from an adult in a gym."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 180,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6121794107",
        "aid": "6121794107_37552",
        "original_caption": "a child in white and red holds an empty cup on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white and red holds an empty cup on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                805
            ],
            "duration": 806,
            "token": {
                "<s0>": 0,
                "<e0>": 793
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10304757716",
        "aid": "10304757716_37553",
        "original_caption": "a baby in green is above a black stool at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby in green at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A stool."
            }
        ],
        "meta": {
            "split": [
                0,
                1622
            ],
            "duration": 1623,
            "token": {
                "<s0>": 0,
                "<e0>": 1623
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5392563097",
        "aid": "5392563097_37554",
        "original_caption": "an adult is above a big elephant outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is above a big elephant outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                158
            ],
            "duration": 159,
            "token": {
                "<s0>": 48,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8481787117",
        "aid": "8481787117_37555",
        "original_caption": "a taller child is behind a shorter child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A taller child is behind a shorter child."
            }
        ],
        "meta": {
            "split": [
                564,
                719
            ],
            "duration": 156,
            "token": {
                "<s0>": 12,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_37556",
        "original_caption": "a child in orange kicks a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho kicks the toy on the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                629,
                766
            ],
            "duration": 138,
            "token": {
                "<s0>": 53,
                "<e0>": 82
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_37557",
        "original_caption": "a child in orange kicks a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in orange kicks a toy on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                766,
                967
            ],
            "duration": 202,
            "token": {
                "<s0>": 56,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_37558",
        "original_caption": "a child in orange kicks a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in orange kicks a toy on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                967,
                1113
            ],
            "duration": 147,
            "token": {
                "<s0>": 109,
                "<e0>": 147
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37559",
        "original_caption": "a child in red is towards to a child in white outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red is towards to a child in white outdoor."
            }
        ],
        "meta": {
            "split": [
                375,
                681
            ],
            "duration": 307,
            "token": {
                "<s0>": 165,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6572270403",
        "aid": "6572270403_37560",
        "original_caption": "an adult holds a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 304,
                "<e0>": 681
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8059684971",
        "aid": "8059684971_37561",
        "original_caption": "a child in black hits a pale green sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black hits a pale green sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                283
            ],
            "duration": 284,
            "token": {
                "<s0>": 0,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8059684971",
        "aid": "8059684971_37562",
        "original_caption": "a child in black hits a pale green sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black hits a pale green sofa at home."
            }
        ],
        "meta": {
            "split": [
                283,
                1379
            ],
            "duration": 1097,
            "token": {
                "<s0>": 176,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_37563",
        "original_caption": "an adult in red clothes holds a white toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes holds a white toy."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 471,
                "<e0>": 520
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_37564",
        "original_caption": "the white sheep/goat is behind the black sheep/goat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the black sheep/goat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sheep/goat."
            }
        ],
        "meta": {
            "split": [
                315,
                869
            ],
            "duration": 555,
            "token": {
                "<s0>": 46,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3479140840",
        "aid": "3479140840_37565",
        "original_caption": "an adult woman in red is towards a stool on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the stool on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                199
            ],
            "duration": 200,
            "token": {
                "<s0>": 150,
                "<e0>": 189
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37566",
        "original_caption": "an adult in red speaks to a child in light blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in red speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 448,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_37567",
        "original_caption": "a child in purple leans on a brown wooden table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in purple leans on a brown wooden table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 877,
                "<e0>": 1080
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8429686679",
        "aid": "8429686679_37568",
        "original_caption": "a female adult is away from another adult in brown clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A female adult is away from another adult in brown clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1573
            ],
            "duration": 1574,
            "token": {
                "<s0>": 0,
                "<e0>": 79
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7431354614",
        "aid": "7431354614_37569",
        "original_caption": "an adult in black touches a baby on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black touches a baby on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                455
            ],
            "duration": 456,
            "token": {
                "<s0>": 194,
                "<e0>": 219
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2551446323",
        "aid": "2551446323_37570",
        "original_caption": "an adult in white is towards another adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white is towards another adult outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                908
            ],
            "duration": 909,
            "token": {
                "<s0>": 841,
                "<e0>": 908
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5708481466",
        "aid": "5708481466_37571",
        "original_caption": "a child in white clothes is above a car toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes is above a car toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1289
            ],
            "duration": 1290,
            "token": {
                "<s0>": 0,
                "<e0>": 910
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_37572",
        "original_caption": "a child is above another child girl on the slide.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is above another child girl on the slide happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                218,
                518
            ],
            "duration": 301,
            "token": {
                "<s0>": 33,
                "<e0>": 231
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_37573",
        "original_caption": "an adult in black clothes is next to a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is next to a table."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5504745801",
        "aid": "5504745801_37574",
        "original_caption": "there is a ski beneath a child outside the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a ski beneath a child outside the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                203
            ],
            "duration": 204,
            "token": {
                "<s0>": 0,
                "<e0>": 204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_37575",
        "original_caption": "an adult in blue clothes holds a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes holds a camera."
            }
        ],
        "meta": {
            "split": [
                0,
                283
            ],
            "duration": 284,
            "token": {
                "<s0>": 130,
                "<e0>": 244
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_37576",
        "original_caption": "an adult in blue clothes holds a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                283,
                735
            ],
            "duration": 453,
            "token": {
                "<s0>": 40,
                "<e0>": 453
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3802656968",
        "aid": "3802656968_37577",
        "original_caption": "an adult in white clothes is next to a snake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes is next to a snake."
            }
        ],
        "meta": {
            "split": [
                0,
                1481
            ],
            "duration": 1482,
            "token": {
                "<s0>": 60,
                "<e0>": 1470
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37578",
        "original_caption": "there is a blue ball above a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a blue ball above a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37579",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                100,
                292
            ],
            "duration": 193,
            "token": {
                "<s0>": 10,
                "<e0>": 37
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37580",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red clothes leans on a black sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                292,
                665
            ],
            "duration": 374,
            "token": {
                "<s0>": 156,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37581",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red clothes leans on a black sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                665,
                982
            ],
            "duration": 318,
            "token": {
                "<s0>": 157,
                "<e0>": 201
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37582",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                982,
                1251
            ],
            "duration": 270,
            "token": {
                "<s0>": 117,
                "<e0>": 260
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37583",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                1251,
                1458
            ],
            "duration": 208,
            "token": {
                "<s0>": 10,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37584",
        "original_caption": "a child in red clothes leans on a black sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on a black sofa."
            }
        ],
        "meta": {
            "split": [
                1458,
                1818
            ],
            "duration": 361,
            "token": {
                "<s0>": 143,
                "<e0>": 361
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5049587564",
        "aid": "5049587564_37585",
        "original_caption": "there is a red car in front of another black car on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the red car on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A car."
            }
        ],
        "meta": {
            "split": [
                0,
                719
            ],
            "duration": 720,
            "token": {
                "<s0>": 0,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5202728101",
        "aid": "5202728101_37586",
        "original_caption": "there is a chair next to another chair in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a chair next to another chair in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 241
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_37587",
        "original_caption": "there is a black chair behind a child in skirt on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black chair behind a child in skirt on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6956445354",
        "aid": "6956445354_37588",
        "original_caption": "there is a panda pressing an another panda.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat presses the other panda from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A panda."
            }
        ],
        "meta": {
            "split": [
                0,
                215
            ],
            "duration": 216,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6956445354",
        "aid": "6956445354_37589",
        "original_caption": "there is a panda pressing an another panda.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the panda from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a panda pressing an another panda."
            }
        ],
        "meta": {
            "split": [
                215,
                403
            ],
            "duration": 189,
            "token": {
                "<s0>": 125,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37590",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult women caresses a baby in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 141,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37591",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult women caresses a baby in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                239,
                372
            ],
            "duration": 134,
            "token": {
                "<s0>": 71,
                "<e0>": 116
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37592",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the baby in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                595,
                843
            ],
            "duration": 249,
            "token": {
                "<s0>": 45,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37593",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the baby in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                843,
                1057
            ],
            "duration": 215,
            "token": {
                "<s0>": 175,
                "<e0>": 198
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37594",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult women caresses a baby in white."
            }
        ],
        "meta": {
            "split": [
                1143,
                1287
            ],
            "duration": 145,
            "token": {
                "<s0>": 45,
                "<e0>": 61
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37595",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women caresses a baby in white."
            }
        ],
        "meta": {
            "split": [
                1287,
                1604
            ],
            "duration": 318,
            "token": {
                "<s0>": 84,
                "<e0>": 117
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37596",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the baby in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1604,
                1978
            ],
            "duration": 375,
            "token": {
                "<s0>": 201,
                "<e0>": 228
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_37597",
        "original_caption": "an adult women caresses a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the baby in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1978,
                2696
            ],
            "duration": 719,
            "token": {
                "<s0>": 146,
                "<e0>": 181
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37598",
        "original_caption": "a child in red is away another child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red is away another child in red."
            }
        ],
        "meta": {
            "split": [
                332,
                681
            ],
            "duration": 350,
            "token": {
                "<s0>": 268,
                "<e0>": 341
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_37599",
        "original_caption": "an adult man in black watches another adult woman in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the other adult woman in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 429,
                "<e0>": 459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6949702600",
        "aid": "6949702600_37600",
        "original_caption": "there is a chair beneath a handbag in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair beneath a handbag in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 378,
                "<e0>": 430
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_37601",
        "original_caption": "an adult is towards another adult on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards another adult on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 135,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37602",
        "original_caption": "there is a backpack towards an adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the backpack towards to outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1323,
                "<e0>": 1611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37603",
        "original_caption": "an adult is away from a monitor in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the monitor in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1485,
                2271
            ],
            "duration": 787,
            "token": {
                "<s0>": 15,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_37604",
        "original_caption": "a child holds hand of an another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds hand of an another child."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 14,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37605",
        "original_caption": "a child in black is towards a baby in the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black is towards a baby in the beach."
            }
        ],
        "meta": {
            "split": [
                501,
                1385
            ],
            "duration": 885,
            "token": {
                "<s0>": 352,
                "<e0>": 428
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8019816081",
        "aid": "8019816081_37606",
        "original_caption": "there is a bottle in front of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bottle in front of an adult in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                88,
                732
            ],
            "duration": 645,
            "token": {
                "<s0>": 27,
                "<e0>": 350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_37607",
        "original_caption": "there is a red bottle above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a red bottle above a table."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 451
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3561394520",
        "aid": "3561394520_37608",
        "original_caption": "the adult in black hair is pointing to the adult in brown hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in black hair is pointing to the adult in brown hair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1337
            ],
            "duration": 1338,
            "token": {
                "<s0>": 835,
                "<e0>": 872
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37609",
        "original_caption": "a baby with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby with blond-hair holds a yellow toy."
            }
        ],
        "meta": {
            "split": [
                0,
                283
            ],
            "duration": 284,
            "token": {
                "<s0>": 26,
                "<e0>": 272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37610",
        "original_caption": "a baby with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby with blond-hair holds a yellow toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                283,
                802
            ],
            "duration": 520,
            "token": {
                "<s0>": 11,
                "<e0>": 493
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37611",
        "original_caption": "a baby with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby with blond-hair holds a yellow toy."
            }
        ],
        "meta": {
            "split": [
                802,
                1183
            ],
            "duration": 382,
            "token": {
                "<s0>": 26,
                "<e0>": 371
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37612",
        "original_caption": "a baby with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby with blond-hair hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                1183,
                1385
            ],
            "duration": 203,
            "token": {
                "<s0>": 11,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_37613",
        "original_caption": "an adult is away from a chair inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away from a chair inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 673,
                "<e0>": 808
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4204053300",
        "aid": "4204053300_37614",
        "original_caption": "a child is next to another child on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the other child on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_37615",
        "original_caption": "there is a wooden table beneath a grey laptop at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a wooden table beneath a grey laptop at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1271
            ],
            "duration": 1272,
            "token": {
                "<s0>": 890,
                "<e0>": 997
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4322158071",
        "aid": "4322158071_37616",
        "original_caption": "an adult wearing a black hat is behind another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing a black hat is behind another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                314
            ],
            "duration": 315,
            "token": {
                "<s0>": 0,
                "<e0>": 315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_37617",
        "original_caption": "there is a cattle biting a bottle on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cattle/cow from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cattle biting a bottle on the street."
            }
        ],
        "meta": {
            "split": [
                0,
                663
            ],
            "duration": 664,
            "token": {
                "<s0>": 413,
                "<e0>": 625
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_37618",
        "original_caption": "there is a cattle biting a bottle on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cattle biting a bottle on the street happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                663,
                845
            ],
            "duration": 183,
            "token": {
                "<s0>": 39,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_37619",
        "original_caption": "there is a cattle biting a bottle on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cattle biting a bottle on the street happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                845,
                1151
            ],
            "duration": 307,
            "token": {
                "<s0>": 34,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12557550424",
        "aid": "12557550424_37620",
        "original_caption": "a seated adult plays the piano in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a seated adult plays the piano in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 0,
                "<e0>": 235
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_37621",
        "original_caption": "an adult woman in green speaks to a child in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in green speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                245
            ],
            "duration": 246,
            "token": {
                "<s0>": 78,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_37622",
        "original_caption": "an adult woman in green speaks to a child in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in green speaks to a child in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                245,
                334
            ],
            "duration": 90,
            "token": {
                "<s0>": 37,
                "<e0>": 71
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9562161527",
        "aid": "9562161527_37623",
        "original_caption": "an adult is above a chair in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the chair in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                189
            ],
            "duration": 190,
            "token": {
                "<s0>": 120,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_37624",
        "original_caption": "a baby shouts at a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby shouts at a child in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 76,
                "<e0>": 352
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_37625",
        "original_caption": "a baby shouts at a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho shouts at the child in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                407,
                706
            ],
            "duration": 300,
            "token": {
                "<s0>": 55,
                "<e0>": 262
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_37626",
        "original_caption": "a baby shouts at a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby shouts at a child in the room."
            }
        ],
        "meta": {
            "split": [
                706,
                977
            ],
            "duration": 272,
            "token": {
                "<s0>": 38,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_37627",
        "original_caption": "a baby shouts at a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby shouts at a child in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                977,
                1197
            ],
            "duration": 221,
            "token": {
                "<s0>": 87,
                "<e0>": 221
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_37628",
        "original_caption": "there is a brown sofa beneath an adult man in black striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult man in black striped clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                1148,
                1458
            ],
            "duration": 311,
            "token": {
                "<s0>": 100,
                "<e0>": 311
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37629",
        "original_caption": "there is a white table beneath a blue sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the white table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37630",
        "original_caption": "a child is away from a ball in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from a ball in a gym."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 360,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8157245482",
        "aid": "8157245482_37631",
        "original_caption": "a child in red clothes leans on an adult with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes leans on an adult with glasses."
            }
        ],
        "meta": {
            "split": [
                0,
                191
            ],
            "duration": 192,
            "token": {
                "<s0>": 105,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572624205",
        "aid": "8572624205_37632",
        "original_caption": "there is a white baby seat beneath a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby in white clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_37633",
        "original_caption": "an adult is inside a watercraft in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is inside a watercraft in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4569009647",
        "aid": "4569009647_37634",
        "original_caption": "an adult wearing a gray plaid clothes carries a blue backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing a gray plaid clothes carries a blue backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                2436
            ],
            "duration": 2437,
            "token": {
                "<s0>": 2157,
                "<e0>": 2281
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3364754591",
        "aid": "3364754591_37635",
        "original_caption": "a baby in green leans on an adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in green leans on an adult in white."
            }
        ],
        "meta": {
            "split": [
                0,
                484
            ],
            "duration": 485,
            "token": {
                "<s0>": 0,
                "<e0>": 485
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_37636",
        "original_caption": "an adult is next to a child in blue in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult next to in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1724,
                2696
            ],
            "duration": 973,
            "token": {
                "<s0>": 496,
                "<e0>": 586
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37637",
        "original_caption": "a child in pink is in front of another child in white on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other child in white on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1422,
                "<e0>": 1550
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4352699187",
        "aid": "4352699187_37638",
        "original_caption": "an adult with glasses hugs a baby on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses hugs a baby on the sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                779
            ],
            "duration": 780,
            "token": {
                "<s0>": 0,
                "<e0>": 780
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3758307290",
        "aid": "3758307290_37639",
        "original_caption": "there is an orange toy above a white chair in the practice room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is an orange toy above a white chair in the practice room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                657
            ],
            "duration": 658,
            "token": {
                "<s0>": 0,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_37640",
        "original_caption": "there is a toy away from a baby in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy away from a baby in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                998
            ],
            "duration": 999,
            "token": {
                "<s0>": 900,
                "<e0>": 990
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7631378506",
        "aid": "7631378506_37641",
        "original_caption": "an adult speaks to another adult on a traveling boat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult speak to on the traveling boat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                463
            ],
            "duration": 464,
            "token": {
                "<s0>": 435,
                "<e0>": 459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7631378506",
        "aid": "7631378506_37642",
        "original_caption": "an adult speaks to another adult on a traveling boat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to another adult on a traveling boat."
            }
        ],
        "meta": {
            "split": [
                463,
                573
            ],
            "duration": 111,
            "token": {
                "<s0>": 5,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7631378506",
        "aid": "7631378506_37643",
        "original_caption": "an adult speaks to another adult on a traveling boat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult speaks to another adult on a traveling boat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                573,
                1180
            ],
            "duration": 608,
            "token": {
                "<s0>": 18,
                "<e0>": 43
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8115037154",
        "aid": "8115037154_37644",
        "original_caption": "an adult in dark blue releases a baby in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in dark blue releases a baby in dark blue happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1379
            ],
            "duration": 1380,
            "token": {
                "<s0>": 862,
                "<e0>": 890
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4535557687",
        "aid": "4535557687_37645",
        "original_caption": "an adult in the middle is in front of a standing adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the adult in the middle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                335
            ],
            "duration": 336,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_37646",
        "original_caption": "the adult is in front of another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult is in front of another adult."
            }
        ],
        "meta": {
            "split": [
                322,
                1877
            ],
            "duration": 1556,
            "token": {
                "<s0>": 121,
                "<e0>": 787
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37647",
        "original_caption": "an adult in black clothes is beneath a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the adult in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                872,
                2271
            ],
            "duration": 1400,
            "token": {
                "<s0>": 662,
                "<e0>": 1399
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5417864623",
        "aid": "5417864623_37648",
        "original_caption": "there is a ski in pink beneath a child in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ski."
            }
        ],
        "meta": {
            "split": [
                79,
                374
            ],
            "duration": 296,
            "token": {
                "<s0>": 21,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_37649",
        "original_caption": "an adult with glasses points to another adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses points to another adult in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 340,
                "<e0>": 351
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37650",
        "original_caption": "there is a sofa in front of an adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sofa in front of an adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                1231,
                1441
            ],
            "duration": 211,
            "token": {
                "<s0>": 137,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37651",
        "original_caption": "there is a cup above a table outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table outside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_37652",
        "original_caption": "there is adult away the adult in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away the adult in green from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 40,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2683780802",
        "aid": "2683780802_37653",
        "original_caption": "a child on the left pats another child on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child on the left pats another child on the right."
            }
        ],
        "meta": {
            "split": [
                114,
                208
            ],
            "duration": 95,
            "token": {
                "<s0>": 6,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8223287911",
        "aid": "8223287911_37654",
        "original_caption": "there is a chair next to an another chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair next to an another chair."
            }
        ],
        "meta": {
            "split": [
                348,
                1484
            ],
            "duration": 1137,
            "token": {
                "<s0>": 73,
                "<e0>": 800
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_37655",
        "original_caption": "there is a pig on the right towards a white goat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the pig from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a pig on the right towards a white goat."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 275,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37656",
        "original_caption": "child in blue trousers are away from child wearing blue blouses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see child in blue trousers are away from child wearing blue blouses happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                315,
                595
            ],
            "duration": 281,
            "token": {
                "<s0>": 225,
                "<e0>": 281
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37657",
        "original_caption": "there is a red toy beneath the blue ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a red toy beneath the blue ball."
            }
        ],
        "meta": {
            "split": [
                510,
                2696
            ],
            "duration": 2187,
            "token": {
                "<s0>": 11,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37658",
        "original_caption": "a child is in front of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37659",
        "original_caption": "an adult is towards another adult on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards another adult on the street happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1346,
                "<e0>": 1450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3059960651",
        "aid": "3059960651_37660",
        "original_caption": "the child in blue is above baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above baby seat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                319
            ],
            "duration": 320,
            "token": {
                "<s0>": 0,
                "<e0>": 320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_37661",
        "original_caption": "an adult in red clothes hugs a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in red clothes hug from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                901
            ],
            "duration": 902,
            "token": {
                "<s0>": 138,
                "<e0>": 811
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_37662",
        "original_caption": "an adult in red clothes hugs a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes hugs a child."
            }
        ],
        "meta": {
            "split": [
                901,
                1145
            ],
            "duration": 245,
            "token": {
                "<s0>": 90,
                "<e0>": 245
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2942623423",
        "aid": "2942623423_37663",
        "original_caption": "an adult woman is in front of another adult man in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman is in front of another adult man in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                624,
                734
            ],
            "duration": 111,
            "token": {
                "<s0>": 17,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37664",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds a toy on the beach."
            }
        ],
        "meta": {
            "split": [
                0,
                108
            ],
            "duration": 109,
            "token": {
                "<s0>": 16,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37665",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a toy on the beach."
            }
        ],
        "meta": {
            "split": [
                108,
                212
            ],
            "duration": 105,
            "token": {
                "<s0>": 10,
                "<e0>": 94
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37666",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a toy on the beach."
            }
        ],
        "meta": {
            "split": [
                212,
                311
            ],
            "duration": 100,
            "token": {
                "<s0>": 10,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37667",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds a toy on the beach."
            }
        ],
        "meta": {
            "split": [
                311,
                406
            ],
            "duration": 96,
            "token": {
                "<s0>": 33,
                "<e0>": 86
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37668",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holds a toy on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                406,
                689
            ],
            "duration": 284,
            "token": {
                "<s0>": 9,
                "<e0>": 120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37669",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a toy on the beach."
            }
        ],
        "meta": {
            "split": [
                689,
                1385
            ],
            "duration": 697,
            "token": {
                "<s0>": 164,
                "<e0>": 197
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_37670",
        "original_caption": "there is a black cup above a white table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black cup above a white table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114859483",
        "aid": "8114859483_37671",
        "original_caption": "there is an adult with jeans behind the child .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is an adult with jeans behind the child ."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 0,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_37672",
        "original_caption": "an adult in blue clothes carries a green handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue clothes carries a green handbag happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 616,
                "<e0>": 668
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6813862571",
        "aid": "6813862571_37673",
        "original_caption": "an adult man in black speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black speaks to another adult man in black."
            }
        ],
        "meta": {
            "split": [
                0,
                1754
            ],
            "duration": 1755,
            "token": {
                "<s0>": 741,
                "<e0>": 776
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3862213653",
        "aid": "3862213653_37674",
        "original_caption": "there is a chair beneath an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a chair beneath an adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                275
            ],
            "duration": 276,
            "token": {
                "<s0>": 0,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_37675",
        "original_caption": "an adult plays the guitar in the screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the guitar in the screen from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1320
            ],
            "duration": 1321,
            "token": {
                "<s0>": 497,
                "<e0>": 1235
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_37676",
        "original_caption": "an adult plays the guitar in the screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult plays the guitar in the screen happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1320,
                1955
            ],
            "duration": 636,
            "token": {
                "<s0>": 85,
                "<e0>": 412
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3077081235",
        "aid": "3077081235_37677",
        "original_caption": "an adult women is away another adult women in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult women is away another adult women in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                538
            ],
            "duration": 539,
            "token": {
                "<s0>": 480,
                "<e0>": 539
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8575941513",
        "aid": "8575941513_37678",
        "original_caption": "a baby in pink clothes holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                1341,
                2008
            ],
            "duration": 668,
            "token": {
                "<s0>": 143,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8575941513",
        "aid": "8575941513_37679",
        "original_caption": "a baby in pink clothes holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in pink clothes holds hand of an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                2008,
                2386
            ],
            "duration": 379,
            "token": {
                "<s0>": 56,
                "<e0>": 379
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_37680",
        "original_caption": "there is a dog towards a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog towards a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 240,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8483279367",
        "aid": "8483279367_37681",
        "original_caption": "an adult in purple clothes plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in purple clothes plays the guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 0,
                "<e0>": 876
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3066398259",
        "aid": "3066398259_37682",
        "original_caption": "a baby in red is away a stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in red is away a stool happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 120,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5270774640",
        "aid": "5270774640_37683",
        "original_caption": "there is a dog leaning on an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the dog lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                222
            ],
            "duration": 223,
            "token": {
                "<s0>": 0,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_37684",
        "original_caption": "an adult plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult play on stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1583
            ],
            "duration": 1584,
            "token": {
                "<s0>": 0,
                "<e0>": 131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7528671560",
        "aid": "7528671560_37685",
        "original_caption": "there is a bicycle beneath a child in the park.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle beneath a child in the park happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                539
            ],
            "duration": 540,
            "token": {
                "<s0>": 0,
                "<e0>": 540
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3343411237",
        "aid": "3343411237_37686",
        "original_caption": "a child wearing black pants is above a surfboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing black pants is above a surfboard."
            }
        ],
        "meta": {
            "split": [
                732,
                926
            ],
            "duration": 195,
            "token": {
                "<s0>": 18,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114859483",
        "aid": "8114859483_37687",
        "original_caption": "a camera is behind of the adult women.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the camera from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A camera is behind of the adult women."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 180,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3343411237",
        "aid": "3343411237_37688",
        "original_caption": "a child rides a surfboard in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a surfboard in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                77
            ],
            "duration": 78,
            "token": {
                "<s0>": 55,
                "<e0>": 71
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3343411237",
        "aid": "3343411237_37689",
        "original_caption": "a child rides a surfboard in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a surfboard in the water."
            }
        ],
        "meta": {
            "split": [
                77,
                329
            ],
            "duration": 253,
            "token": {
                "<s0>": 7,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3343411237",
        "aid": "3343411237_37690",
        "original_caption": "a child rides a surfboard in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child ride in the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A surfboard."
            }
        ],
        "meta": {
            "split": [
                329,
                735
            ],
            "duration": 407,
            "token": {
                "<s0>": 77,
                "<e0>": 385
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3343411237",
        "aid": "3343411237_37691",
        "original_caption": "a child rides a surfboard in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child rides a surfboard in the water."
            }
        ],
        "meta": {
            "split": [
                735,
                926
            ],
            "duration": 192,
            "token": {
                "<s0>": 21,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3136397594",
        "aid": "3136397594_37692",
        "original_caption": "an adult hugs a snake on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult hugs a snake on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                181
            ],
            "duration": 182,
            "token": {
                "<s0>": 0,
                "<e0>": 154
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3136397594",
        "aid": "3136397594_37693",
        "original_caption": "an adult hugs a snake on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult hug on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A snake."
            }
        ],
        "meta": {
            "split": [
                181,
                763
            ],
            "duration": 583,
            "token": {
                "<s0>": 27,
                "<e0>": 515
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_37694",
        "original_caption": "there is a wooden watercraft inside an adult by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a wooden watercraft inside an adult by the sea."
            }
        ],
        "meta": {
            "split": [
                0,
                2595
            ],
            "duration": 2596,
            "token": {
                "<s0>": 1620,
                "<e0>": 2550
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_37695",
        "original_caption": "there is a wooden watercraft inside an adult by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a wooden watercraft inside an adult by the sea."
            }
        ],
        "meta": {
            "split": [
                2595,
                2696
            ],
            "duration": 102,
            "token": {
                "<s0>": 45,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_37696",
        "original_caption": "an adult in black hits a child on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black hits a child on a sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 138,
                "<e0>": 158
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_37697",
        "original_caption": "an adult is above a bicycle in the path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a bicycle in the path happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 16,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_37698",
        "original_caption": "a sitting female adult is next to a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A sitting female adult is next to a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                611
            ],
            "duration": 612,
            "token": {
                "<s0>": 60,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6122666405",
        "aid": "6122666405_37699",
        "original_caption": "an adult man in white is next to another adult man in white in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in white is next to another adult man in white in a room."
            }
        ],
        "meta": {
            "split": [
                1341,
                1668
            ],
            "duration": 328,
            "token": {
                "<s0>": 99,
                "<e0>": 328
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189371905",
        "aid": "9189371905_37700",
        "original_caption": "an adult with blond-hair is away from a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with blond-hair is away from a cup."
            }
        ],
        "meta": {
            "split": [
                0,
                646
            ],
            "duration": 647,
            "token": {
                "<s0>": 316,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6197272373",
        "aid": "6197272373_37701",
        "original_caption": "an adult woman in yellow releases a glass cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in yellow releases a glass cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                638
            ],
            "duration": 639,
            "token": {
                "<s0>": 143,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6005023595",
        "aid": "6005023595_37702",
        "original_caption": "an adult in blue hugs a baby outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue hugs a baby outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 0,
                "<e0>": 585
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4184884354",
        "aid": "4184884354_37703",
        "original_caption": "a child in black pats the piano at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black pats the piano at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1502
            ],
            "duration": 1503,
            "token": {
                "<s0>": 706,
                "<e0>": 857
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12212857646",
        "aid": "12212857646_37704",
        "original_caption": "an adult man in black is towards a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the child outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1170
            ],
            "duration": 1171,
            "token": {
                "<s0>": 120,
                "<e0>": 265
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4670796220",
        "aid": "4670796220_37705",
        "original_caption": "a baby in white rides a red toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white rides a red toy."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_37706",
        "original_caption": "an adult woman in green is above a black sofa at meeting.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the black sofa at meeting from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2698
            ],
            "duration": 2699,
            "token": {
                "<s0>": 0,
                "<e0>": 2699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_37707",
        "original_caption": "there is a sports ball above an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the adult at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2069
            ],
            "duration": 2070,
            "token": {
                "<s0>": 1763,
                "<e0>": 1829
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5606187654",
        "aid": "5606187654_37708",
        "original_caption": "an adult in yellow holds hand of a child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow holds hand of a child in red happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                363
            ],
            "duration": 364,
            "token": {
                "<s0>": 0,
                "<e0>": 364
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12158830025",
        "aid": "12158830025_37709",
        "original_caption": "an adult carries a backpack near a pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult carries a backpack near a pool happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1368
            ],
            "duration": 1369,
            "token": {
                "<s0>": 457,
                "<e0>": 515
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37710",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in gary clothes carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A handbag."
            }
        ],
        "meta": {
            "split": [
                0,
                558
            ],
            "duration": 559,
            "token": {
                "<s0>": 0,
                "<e0>": 524
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37711",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in gary clothes carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A handbag."
            }
        ],
        "meta": {
            "split": [
                558,
                665
            ],
            "duration": 108,
            "token": {
                "<s0>": 34,
                "<e0>": 86
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37712",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gary clothes carries a handbag."
            }
        ],
        "meta": {
            "split": [
                711,
                2763
            ],
            "duration": 2053,
            "token": {
                "<s0>": 11,
                "<e0>": 2036
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13238637455",
        "aid": "13238637455_37713",
        "original_caption": "an adult in gary clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in gary clothes carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A handbag."
            }
        ],
        "meta": {
            "split": [
                2763,
                3216
            ],
            "duration": 454,
            "token": {
                "<s0>": 16,
                "<e0>": 454
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10403393365",
        "aid": "10403393365_37714",
        "original_caption": "there is a white dog smelling a child in white on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the white dog smell on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                341
            ],
            "duration": 342,
            "token": {
                "<s0>": 0,
                "<e0>": 14
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6595030215",
        "aid": "6595030215_37715",
        "original_caption": "an adult in black clothes squeezes a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes squeezes a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                465
            ],
            "duration": 466,
            "token": {
                "<s0>": 433,
                "<e0>": 453
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_37716",
        "original_caption": "there is a stool beneath an adult man in gray in a party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the stool in the party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1011
            ],
            "duration": 1012,
            "token": {
                "<s0>": 0,
                "<e0>": 1012
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2792480681",
        "aid": "2792480681_37717",
        "original_caption": "an adult man in white shorts is next to a white ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white shorts is next to a white ball on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                526
            ],
            "duration": 527,
            "token": {
                "<s0>": 60,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_37718",
        "original_caption": "an adult is above a ski in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a ski in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 146,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5296127747",
        "aid": "5296127747_37719",
        "original_caption": "an adult in grey holds hand of another adult in brown at wedding.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in grey hold hand of at wedding from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 107,
                "<e0>": 342
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5429475861",
        "aid": "5429475861_37720",
        "original_caption": "an adult woman in black skirt speaks to another adult woman in gray skirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black skirt speaks to another adult woman in gray skirt."
            }
        ],
        "meta": {
            "split": [
                0,
                143
            ],
            "duration": 144,
            "token": {
                "<s0>": 120,
                "<e0>": 144
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_37721",
        "original_caption": "an adult is away from another adult in the hole.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult in the hole."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 424,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12624072313",
        "aid": "12624072313_37722",
        "original_caption": "an adult is away from another adult in the afternoon.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult in the afternoon."
            }
        ],
        "meta": {
            "split": [
                0,
                1278
            ],
            "duration": 1279,
            "token": {
                "<s0>": 120,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_37723",
        "original_caption": "there is a watercraft beneath an adult on the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a watercraft beneath an adult on the sea."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1081
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_37724",
        "original_caption": "an adult is behind a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the child in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1200,
                "<e0>": 1315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5647072246",
        "aid": "5647072246_37725",
        "original_caption": "an adult in white clothes holds a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes holds a ball."
            }
        ],
        "meta": {
            "split": [
                0,
                138
            ],
            "duration": 139,
            "token": {
                "<s0>": 106,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9975070616",
        "aid": "9975070616_37726",
        "original_caption": "an adult man in black is beneath a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black is beneath a baby at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                660
            ],
            "duration": 661,
            "token": {
                "<s0>": 0,
                "<e0>": 661
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_37727",
        "original_caption": "an adult in a white chair on the left watches a skateboard at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in the white chair on the left watch at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A skateboard."
            }
        ],
        "meta": {
            "split": [
                244,
                986
            ],
            "duration": 743,
            "token": {
                "<s0>": 191,
                "<e0>": 374
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_37728",
        "original_caption": "an adult standing next to a bicycle watches at an adult wearing a pink helmet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult standing next to a bicycle watches at an adult wearing a pink helmet."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 16,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7093500213",
        "aid": "7093500213_37729",
        "original_caption": "an adult man in plaid shirt is away another adult man in orange on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt is away another adult man in orange on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1109
            ],
            "duration": 1110,
            "token": {
                "<s0>": 300,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6991481998",
        "aid": "6991481998_37730",
        "original_caption": "an adult is next to a backpack on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is next to a backpack on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 375,
                "<e0>": 1554
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_37731",
        "original_caption": "a child with black hair watches a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with black hair watches a sports ball."
            }
        ],
        "meta": {
            "split": [
                1874,
                2069
            ],
            "duration": 196,
            "token": {
                "<s0>": 33,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_37732",
        "original_caption": "there is a backpack next to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a backpack next to an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 420,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_37733",
        "original_caption": "a child in red is above a scooter outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red is above a scooter outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 0,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_37734",
        "original_caption": "an adult man in black holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult man in black hold hand of on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                70,
                163
            ],
            "duration": 94,
            "token": {
                "<s0>": 15,
                "<e0>": 57
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_37735",
        "original_caption": "an adult man in black holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black holds hand of another adult on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                163,
                398
            ],
            "duration": 236,
            "token": {
                "<s0>": 37,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_37736",
        "original_caption": "an adult man in black holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black holds hand of another adult on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                398,
                634
            ],
            "duration": 237,
            "token": {
                "<s0>": 176,
                "<e0>": 229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_37737",
        "original_caption": "an adult man in black holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black holds hand of another adult on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                634,
                732
            ],
            "duration": 99,
            "token": {
                "<s0>": 7,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_37738",
        "original_caption": "an adult man in black holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds hand of another adult on the floor."
            }
        ],
        "meta": {
            "split": [
                732,
                825
            ],
            "duration": 94,
            "token": {
                "<s0>": 6,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_37739",
        "original_caption": "an adult man in black holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black holds hand of another adult on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                891,
                1034
            ],
            "duration": 144,
            "token": {
                "<s0>": 17,
                "<e0>": 49
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3471851958",
        "aid": "3471851958_37740",
        "original_caption": "there is a black motorcycle beneath an adult man in red outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the motorcycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black motorcycle beneath an adult man in red outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                179
            ],
            "duration": 180,
            "token": {
                "<s0>": 0,
                "<e0>": 180
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_37741",
        "original_caption": "there is a table beneath a cup at dinner.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cup at dinner."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 115,
                "<e0>": 237
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37742",
        "original_caption": "a child in pink is above a black chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink is above a black chair."
            }
        ],
        "meta": {
            "split": [
                705,
                2225
            ],
            "duration": 1521,
            "token": {
                "<s0>": 197,
                "<e0>": 557
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4046101324",
        "aid": "4046101324_37743",
        "original_caption": "an adult in red clothes carries a handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in red clothes carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A handbag."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 4,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_37744",
        "original_caption": "the adult in jeans is waving hand to the adult in a short pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in jeans is waving hand to the adult in a short pants."
            }
        ],
        "meta": {
            "split": [
                0,
                788
            ],
            "duration": 789,
            "token": {
                "<s0>": 737,
                "<e0>": 771
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_37745",
        "original_caption": "the adult in jeans is waving hand to the adult in a short pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in jeans is waving hand to the adult in a short pants."
            }
        ],
        "meta": {
            "split": [
                788,
                1424
            ],
            "duration": 637,
            "token": {
                "<s0>": 17,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37746",
        "original_caption": "an adult in black clothes watches a camera inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black clothes watch inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A camera."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 182,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_37747",
        "original_caption": "an adult with the least hair holds the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with the least hair holds the guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1955
            ],
            "duration": 1956,
            "token": {
                "<s0>": 38,
                "<e0>": 137
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37748",
        "original_caption": "an adult in red clothes is away a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red clothes is away a cellphone happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 96,
                "<e0>": 144
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_37749",
        "original_caption": "there is a camera above an adult wearing a blue hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a camera above an adult wearing a blue hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                293,
                735
            ],
            "duration": 443,
            "token": {
                "<s0>": 38,
                "<e0>": 201
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_37750",
        "original_caption": "an adult man in blue carries a black backpack in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in blue carries a black backpack in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 132,
                "<e0>": 184
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_37751",
        "original_caption": "an adult man in blue carries a black backpack in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries the black backpack in the forest from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                231,
                357
            ],
            "duration": 127,
            "token": {
                "<s0>": 48,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8223287911",
        "aid": "8223287911_37752",
        "original_caption": "a baby on the carpet is behind a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the baby on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                1346,
                1484
            ],
            "duration": 139,
            "token": {
                "<s0>": 37,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37753",
        "original_caption": "there is a gray hamster behind a black rat on the white blanket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the gray hamster on the white blanket from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 720,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13715319605",
        "aid": "13715319605_37754",
        "original_caption": "an adult in black clothes pulls a white horse.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes pulls a white horse happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                77
            ],
            "duration": 78,
            "token": {
                "<s0>": 11,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2571578063",
        "aid": "2571578063_37755",
        "original_caption": "an adult in yellow carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow carries a backpack happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                158
            ],
            "duration": 159,
            "token": {
                "<s0>": 0,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_37756",
        "original_caption": "an adult in white clothes is towards another adult in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult in white clothes towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 422,
                "<e0>": 475
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_37757",
        "original_caption": "an adult holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                796
            ],
            "duration": 797,
            "token": {
                "<s0>": 773,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_37758",
        "original_caption": "an adult holds hand of a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of a child at home."
            }
        ],
        "meta": {
            "split": [
                1048,
                1305
            ],
            "duration": 258,
            "token": {
                "<s0>": 37,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37759",
        "original_caption": "a child in red clothes holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                524
            ],
            "duration": 525,
            "token": {
                "<s0>": 349,
                "<e0>": 374
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37760",
        "original_caption": "a child in red clothes holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                524,
                1134
            ],
            "duration": 611,
            "token": {
                "<s0>": 150,
                "<e0>": 217
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37761",
        "original_caption": "a child in red clothes holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes holds hand of an adult."
            }
        ],
        "meta": {
            "split": [
                1134,
                1574
            ],
            "duration": 441,
            "token": {
                "<s0>": 393,
                "<e0>": 418
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_37762",
        "original_caption": "there is a toy towards another toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is towards the other toy on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 600,
                "<e0>": 660
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_37763",
        "original_caption": "an adult in black is above a white watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black is above a white watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6956445354",
        "aid": "6956445354_37764",
        "original_caption": "a panda on the left touches the panda on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A panda on the left touches the panda on the right."
            }
        ],
        "meta": {
            "split": [
                0,
                403
            ],
            "duration": 404,
            "token": {
                "<s0>": 292,
                "<e0>": 308
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_37765",
        "original_caption": "an adult uses a camera in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult uses a camera in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 323,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_37766",
        "original_caption": "an adult in yellow is above a blue watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow is above a blue watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_37767",
        "original_caption": "an adult is behind another adult on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 438
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4254567713",
        "aid": "4254567713_37768",
        "original_caption": "an adult in red clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes plays the piano."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 0,
                "<e0>": 1689
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6885601275",
        "aid": "6885601275_37769",
        "original_caption": "an adult holds a bottle on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a bottle on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                1636
            ],
            "duration": 1637,
            "token": {
                "<s0>": 0,
                "<e0>": 1637
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2683780802",
        "aid": "2683780802_37770",
        "original_caption": "a child on the left watches another child on the right in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child on the left watch in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 152
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37771",
        "original_caption": "a child in pink is above a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink is above a chair at home."
            }
        ],
        "meta": {
            "split": [
                84,
                872
            ],
            "duration": 789,
            "token": {
                "<s0>": 36,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3453984843",
        "aid": "3453984843_37772",
        "original_caption": "an adult wearing a gray hat is above a ywllow motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing a gray hat is above a ywllow motorcycle."
            }
        ],
        "meta": {
            "split": [
                514,
                816
            ],
            "duration": 303,
            "token": {
                "<s0>": 26,
                "<e0>": 296
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13503103965",
        "aid": "13503103965_37773",
        "original_caption": "a child in the middle holds hand of another child on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in the middle holds hand of another child on the right."
            }
        ],
        "meta": {
            "split": [
                0,
                330
            ],
            "duration": 331,
            "token": {
                "<s0>": 0,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_37774",
        "original_caption": "an adult hugs a ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult hugs a ball on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                241,
                368
            ],
            "duration": 128,
            "token": {
                "<s0>": 18,
                "<e0>": 91
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_37775",
        "original_caption": "there is a brown elephant towards a brown elephant on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown elephant towards a brown elephant on the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 557,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_37776",
        "original_caption": "a child in red leans on an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red leans on an adult at home."
            }
        ],
        "meta": {
            "split": [
                0,
                901
            ],
            "duration": 902,
            "token": {
                "<s0>": 138,
                "<e0>": 811
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_37777",
        "original_caption": "a child in red leans on an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red leans on an adult at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                901,
                1145
            ],
            "duration": 245,
            "token": {
                "<s0>": 90,
                "<e0>": 245
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_37778",
        "original_caption": "there is a bicycle towards an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the bicycle towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 182,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_37779",
        "original_caption": "an adult in light blue clothes is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in light blue clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 272,
                "<e0>": 548
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2454477994",
        "aid": "2454477994_37780",
        "original_caption": "there is a colorful toy above a baby in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a colorful toy above a baby in striped clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                311
            ],
            "duration": 312,
            "token": {
                "<s0>": 0,
                "<e0>": 312
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10304757716",
        "aid": "10304757716_37781",
        "original_caption": "a baby in green leans on a black stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in green leans on a black stool."
            }
        ],
        "meta": {
            "split": [
                0,
                1622
            ],
            "duration": 1623,
            "token": {
                "<s0>": 404,
                "<e0>": 1623
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_37782",
        "original_caption": "there is a dog biting a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the dog bite in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                209
            ],
            "duration": 210,
            "token": {
                "<s0>": 30,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_37783",
        "original_caption": "there is a dog biting a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog biting a toy in the room."
            }
        ],
        "meta": {
            "split": [
                209,
                492
            ],
            "duration": 284,
            "token": {
                "<s0>": 111,
                "<e0>": 128
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_37784",
        "original_caption": "there is a dog biting a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog biting a toy in the room."
            }
        ],
        "meta": {
            "split": [
                492,
                696
            ],
            "duration": 205,
            "token": {
                "<s0>": 155,
                "<e0>": 177
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_37785",
        "original_caption": "there is a dog biting a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog biting a toy in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                696,
                863
            ],
            "duration": 168,
            "token": {
                "<s0>": 27,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_37786",
        "original_caption": "there is a dog biting a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog biting a toy in the room."
            }
        ],
        "meta": {
            "split": [
                863,
                1300
            ],
            "duration": 438,
            "token": {
                "<s0>": 76,
                "<e0>": 294
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3783730077",
        "aid": "3783730077_37787",
        "original_caption": "there are the guitar wearing slippers away an adult wearing kimonos.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the guitar from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There are the guitar wearing slippers away an adult wearing kimonos."
            }
        ],
        "meta": {
            "split": [
                0,
                963
            ],
            "duration": 964,
            "token": {
                "<s0>": 120,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37788",
        "original_caption": "there is a cellphone behind a dog in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cellphone from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cellphone behind a dog in the room."
            }
        ],
        "meta": {
            "split": [
                1162,
                1441
            ],
            "duration": 280,
            "token": {
                "<s0>": 107,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37789",
        "original_caption": "there is a black sofa beneath a child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in red from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                1437,
                1818
            ],
            "duration": 382,
            "token": {
                "<s0>": 113,
                "<e0>": 382
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37790",
        "original_caption": "there is a black cellphone towards a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the black cellphone towards to at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 1259,
                "<e0>": 1319
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_37791",
        "original_caption": "an adult in striped clothes is above a dark blue watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in striped clothes is above a dark blue watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9365549235",
        "aid": "9365549235_37792",
        "original_caption": "an adult in white waves a bat outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in white wave outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bat."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 38,
                "<e0>": 73
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13503103965",
        "aid": "13503103965_37793",
        "original_caption": "a child holds hand of another child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holds hand of another child in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                330
            ],
            "duration": 331,
            "token": {
                "<s0>": 0,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_37794",
        "original_caption": "a child is next to another child in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is next to another child in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 224,
                "<e0>": 869
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8616874413",
        "aid": "8616874413_37795",
        "original_caption": "an adult woman in balck is next to another adult man in balck.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in balck is next to another adult man in balck."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 120,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3521372410",
        "aid": "3521372410_37796",
        "original_caption": "an adult in blue pants is next to another adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the other adult in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                231,
                680
            ],
            "duration": 450,
            "token": {
                "<s0>": 144,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_37797",
        "original_caption": "a male adult watches another adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A male adult watches another adult in white clothes."
            }
        ],
        "meta": {
            "split": [
                329,
                381
            ],
            "duration": 53,
            "token": {
                "<s0>": 18,
                "<e0>": 53
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_37798",
        "original_caption": "a baby in grey clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in grey clothes plays the piano."
            }
        ],
        "meta": {
            "split": [
                0,
                639
            ],
            "duration": 640,
            "token": {
                "<s0>": 151,
                "<e0>": 590
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_37799",
        "original_caption": "a baby in grey clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in grey clothes plays the piano."
            }
        ],
        "meta": {
            "split": [
                639,
                815
            ],
            "duration": 177,
            "token": {
                "<s0>": 49,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_37800",
        "original_caption": "a baby in grey clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby in grey clothes play from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A piano."
            }
        ],
        "meta": {
            "split": [
                815,
                1485
            ],
            "duration": 671,
            "token": {
                "<s0>": 28,
                "<e0>": 468
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_37801",
        "original_caption": "a baby in grey clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in grey clothes plays the piano happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1485,
                1923
            ],
            "duration": 439,
            "token": {
                "<s0>": 203,
                "<e0>": 313
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_37802",
        "original_caption": "a baby in grey clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in grey clothes plays the piano happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1923,
                2533
            ],
            "duration": 611,
            "token": {
                "<s0>": 126,
                "<e0>": 350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13180454013",
        "aid": "13180454013_37803",
        "original_caption": "a child holding a yellow label is behind another child in blue in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holding a yellow label is behind another child in blue in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                405,
                699
            ],
            "duration": 295,
            "token": {
                "<s0>": 75,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_37804",
        "original_caption": "an adult in black leans on a yellow chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black leans on a yellow chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                449
            ],
            "duration": 450,
            "token": {
                "<s0>": 317,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_37805",
        "original_caption": "an adult in black leans on a yellow chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black lean on at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                449,
                765
            ],
            "duration": 317,
            "token": {
                "<s0>": 89,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_37806",
        "original_caption": "an adult in black leans on a yellow chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black leans on a yellow chair at home."
            }
        ],
        "meta": {
            "split": [
                765,
                1151
            ],
            "duration": 387,
            "token": {
                "<s0>": 107,
                "<e0>": 248
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_37807",
        "original_caption": "an adult in black leans on a yellow chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the yellow chair at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1151,
                2114
            ],
            "duration": 964,
            "token": {
                "<s0>": 139,
                "<e0>": 561
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_37808",
        "original_caption": "there is a brown table beneath a blue cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown table beneath a blue cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 0,
                "<e0>": 72
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4231951231",
        "aid": "4231951231_37809",
        "original_caption": "an adult man in black is pointing to the adult man in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is pointing to the adult man in red."
            }
        ],
        "meta": {
            "split": [
                0,
                754
            ],
            "duration": 755,
            "token": {
                "<s0>": 592,
                "<e0>": 614
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4828544178",
        "aid": "4828544178_37810",
        "original_caption": "an adult in black clothes holds a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes holds a camera."
            }
        ],
        "meta": {
            "split": [
                0,
                344
            ],
            "duration": 345,
            "token": {
                "<s0>": 305,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_37811",
        "original_caption": "the adult in black is lifting the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in black is lifting the baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1197
            ],
            "duration": 1198,
            "token": {
                "<s0>": 424,
                "<e0>": 458
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_37812",
        "original_caption": "an adult in white clothes is towards a snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the snowboard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 691,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2551446323",
        "aid": "2551446323_37813",
        "original_caption": "an adult in white touches a colorful bird outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white touches a colorful bird outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                752
            ],
            "duration": 753,
            "token": {
                "<s0>": 521,
                "<e0>": 719
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2551446323",
        "aid": "2551446323_37814",
        "original_caption": "an adult in white touches a colorful bird outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white touches a colorful bird outdoors."
            }
        ],
        "meta": {
            "split": [
                752,
                908
            ],
            "duration": 157,
            "token": {
                "<s0>": 34,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_37815",
        "original_caption": "there is an orange and white watercraft inside an adult on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is inside the adult on the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6115043636",
        "aid": "6115043636_37816",
        "original_caption": "an adult leftmost is next to second adult on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult leftmost is next to second adult on the left happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                863
            ],
            "duration": 864,
            "token": {
                "<s0>": 600,
                "<e0>": 864
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_37817",
        "original_caption": "a child in orange holds a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 1008,
                "<e0>": 1165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_37818",
        "original_caption": "there is a dog away a car on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog away a car on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 250,
                "<e0>": 324
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37819",
        "original_caption": "a child is away from another child in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is away from another child in a gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                138,
                595
            ],
            "duration": 458,
            "token": {
                "<s0>": 49,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5108744823",
        "aid": "5108744823_37820",
        "original_caption": "there are an orange vegetables above a table in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the vegetables from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There are an orange vegetables above a table in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                1084
            ],
            "duration": 1085,
            "token": {
                "<s0>": 0,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_37821",
        "original_caption": "a child in white pushes a baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white pushes a baby seat at home."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_37822",
        "original_caption": "an adult man in black feeds a cat outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black feeds a cat outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1238
            ],
            "duration": 1239,
            "token": {
                "<s0>": 253,
                "<e0>": 1239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_37823",
        "original_caption": "there is a bottle above a table in the dining room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle above a table in the dining room."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 61,
                "<e0>": 780
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37824",
        "original_caption": "a child in red watches a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red watches a sports ball."
            }
        ],
        "meta": {
            "split": [
                216,
                595
            ],
            "duration": 380,
            "token": {
                "<s0>": 62,
                "<e0>": 161
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_37825",
        "original_caption": "the child with white shirt walks towards the adult holding a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The child with white shirt walks towards the adult holding a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 240,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7506103208",
        "aid": "7506103208_37826",
        "original_caption": "an adult is in front of another adult on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is in front of another adult on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1283
            ],
            "duration": 1284,
            "token": {
                "<s0>": 180,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5202728101",
        "aid": "5202728101_37827",
        "original_caption": "a child in green chases a brown dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in green chases a brown dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 205
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_37828",
        "original_caption": "an adult in purple is next to another adult in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in purple is next to another adult in white outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 300,
                "<e0>": 362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12158830025",
        "aid": "12158830025_37829",
        "original_caption": "an adult is away a backpack on the ice.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away a backpack on the ice."
            }
        ],
        "meta": {
            "split": [
                0,
                1368
            ],
            "duration": 1369,
            "token": {
                "<s0>": 846,
                "<e0>": 950
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_37830",
        "original_caption": "the cat in white and black is away from the cat in brown.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The cat in white and black is away from the cat in brown."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 100,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_37831",
        "original_caption": "there is a watercraft beneath an adult wearing a black hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a watercraft beneath an adult wearing a black hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3758307290",
        "aid": "3758307290_37832",
        "original_caption": "a child in white is in front of a guitar in gray in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white is in front of a guitar in gray in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                657
            ],
            "duration": 658,
            "token": {
                "<s0>": 0,
                "<e0>": 233
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6273445204",
        "aid": "6273445204_37833",
        "original_caption": "an adult in white hugs a baby in black in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white hugs a baby in black in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                481
            ],
            "duration": 482,
            "token": {
                "<s0>": 0,
                "<e0>": 404
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_37834",
        "original_caption": "an adult in stride shirts watches a child in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in stride shirts watches a child in white."
            }
        ],
        "meta": {
            "split": [
                517,
                986
            ],
            "duration": 470,
            "token": {
                "<s0>": 8,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37835",
        "original_caption": "a child in white clothes is in front of another child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other child in red clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1412,
                1818
            ],
            "duration": 407,
            "token": {
                "<s0>": 188,
                "<e0>": 313
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37836",
        "original_caption": "there is a table behind an adult man in gray in kindergarten.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table behind an adult man in gray in kindergarten."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 44,
                "<e0>": 545
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37837",
        "original_caption": "adult in black suit behind adult wearing pink suit.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adult in black suit behind adult wearing pink suit."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1270,
                "<e0>": 1469
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_37838",
        "original_caption": "there is a black bottle above a black table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the black bottle at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                509,
                793
            ],
            "duration": 285,
            "token": {
                "<s0>": 91,
                "<e0>": 285
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_37839",
        "original_caption": "an adult is behind another adult on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                764,
                1007
            ],
            "duration": 244,
            "token": {
                "<s0>": 16,
                "<e0>": 244
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37840",
        "original_caption": "a child in yellow is next to a wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in yellow is next to a wooden table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_37841",
        "original_caption": "a baby is towards a child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the baby towards to on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 698,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37842",
        "original_caption": "an adult grabs a black hamster on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult grabs a black hamster on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1238,
                "<e0>": 1334
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5640939571",
        "aid": "5640939571_37843",
        "original_caption": "a baby in blue is above a baby seat in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby in blue in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                596
            ],
            "duration": 597,
            "token": {
                "<s0>": 0,
                "<e0>": 597
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_37844",
        "original_caption": "an adult is in front of a child in a white dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child in a white dress from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                338,
                1818
            ],
            "duration": 1481,
            "token": {
                "<s0>": 286,
                "<e0>": 336
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37845",
        "original_caption": "a child in white clothes is away from a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child in white clothes away from from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_37846",
        "original_caption": "there is a monitor in front of an adult in office.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in office from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_37847",
        "original_caption": "there is a skateboard in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a skateboard in front of an adult."
            }
        ],
        "meta": {
            "split": [
                558,
                986
            ],
            "duration": 429,
            "token": {
                "<s0>": 12,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37848",
        "original_caption": "the child in red is away from the child in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The child in red is away from the child in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 360,
                "<e0>": 508
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_37849",
        "original_caption": "there is a cake above a black table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cake from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cake above a black table in the room."
            }
        ],
        "meta": {
            "split": [
                1857,
                2225
            ],
            "duration": 369,
            "token": {
                "<s0>": 46,
                "<e0>": 368
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_37850",
        "original_caption": "an adult man in black holds a red sports ball on teh grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds a red sports ball on teh grass."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 347,
                "<e0>": 369
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_37851",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 542,
                "<e0>": 576
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_37852",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                589,
                1350
            ],
            "duration": 762,
            "token": {
                "<s0>": 13,
                "<e0>": 738
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_37853",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the guitar on stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1350,
                2196
            ],
            "duration": 847,
            "token": {
                "<s0>": 23,
                "<e0>": 104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4276511080",
        "aid": "4276511080_37854",
        "original_caption": "an adult in white watches another adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white watches another adult on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 1782,
                "<e0>": 1827
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3783730077",
        "aid": "3783730077_37855",
        "original_caption": "an adult is behind the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is behind the guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                963
            ],
            "duration": 964,
            "token": {
                "<s0>": 0,
                "<e0>": 964
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_37856",
        "original_caption": "an adult woman in blue kisses another adult man in black at the wedding.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in blue kisses another adult man in black at the wedding happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1799
            ],
            "duration": 1800,
            "token": {
                "<s0>": 381,
                "<e0>": 1202
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_37857",
        "original_caption": "a naked child watches another child in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A naked child watches another child in white outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 127,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945234319",
        "aid": "5945234319_37858",
        "original_caption": "the orange child is away the electric fan.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The orange child is away the electric fan."
            }
        ],
        "meta": {
            "split": [
                0,
                1988
            ],
            "duration": 1989,
            "token": {
                "<s0>": 1900,
                "<e0>": 1952
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5091773135",
        "aid": "5091773135_37859",
        "original_caption": "an adult with glasses plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the guitar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1770
            ],
            "duration": 1771,
            "token": {
                "<s0>": 0,
                "<e0>": 1284
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_37860",
        "original_caption": "there is a black and gray cat hugging a black and brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black and gray cat hugging a black and brown cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                260
            ],
            "duration": 261,
            "token": {
                "<s0>": 0,
                "<e0>": 173
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_37861",
        "original_caption": "there is a black and gray cat hugging a black and brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black and gray cat hugging a black and brown cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                260,
                923
            ],
            "duration": 664,
            "token": {
                "<s0>": 88,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_37862",
        "original_caption": "a child is towards a car on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is towards a car on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 0,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_37863",
        "original_caption": "there is a black chair in front of a child ion the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black chair in front of a child ion the room."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 60,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_37864",
        "original_caption": "there is a black hamster away from another black rat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the hamster/rat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black hamster away from another black rat on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1500,
                "<e0>": 1625
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6906256626",
        "aid": "6906256626_37865",
        "original_caption": "a child in white clothes leans on a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes leans on a yellow toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 2,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37866",
        "original_caption": "an adult in pink clothes is beneath a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the screen from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4914011323",
        "aid": "4914011323_37867",
        "original_caption": "there is a black cat leaning on a white toilet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat leans on the white toilet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                182
            ],
            "duration": 183,
            "token": {
                "<s0>": 0,
                "<e0>": 177
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4827728106",
        "aid": "4827728106_37868",
        "original_caption": "a child is next to a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is next to a toy in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                235
            ],
            "duration": 236,
            "token": {
                "<s0>": 0,
                "<e0>": 79
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_37869",
        "original_caption": "an adult kneeling on the ground is behind a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult kneeling on the ground is behind a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                304,
                705
            ],
            "duration": 402,
            "token": {
                "<s0>": 35,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_37870",
        "original_caption": "a baby in yellow clothes is towards a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in yellow clothes is towards a white dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 840,
                "<e0>": 930
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_37871",
        "original_caption": "a toy is away from the baby walker.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A toy is away from the baby walker."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 1100,
                "<e0>": 1155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37872",
        "original_caption": "there is a table beneath a cup in a restaurant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cup in a restaurant."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 44,
                "<e0>": 1094
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5417864623",
        "aid": "5417864623_37873",
        "original_caption": "a child is next to a blue ski in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is next to a blue ski in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                374
            ],
            "duration": 375,
            "token": {
                "<s0>": 0,
                "<e0>": 375
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4085549820",
        "aid": "4085549820_37874",
        "original_caption": "there is a black car behind a white car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black car behind a white car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 150,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2762796536",
        "aid": "2762796536_37875",
        "original_caption": "an adult is behind another adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                699
            ],
            "duration": 700,
            "token": {
                "<s0>": 209,
                "<e0>": 265
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_37876",
        "original_caption": "a baby watches an adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby watches an adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 381,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_37877",
        "original_caption": "there is a white laptop behind a wooden baby seat in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white laptop behind a wooden baby seat in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 48
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37878",
        "original_caption": "there is a ball towards a child in red in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a ball towards a child in red in a gym."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 25,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_37879",
        "original_caption": "a child is above another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is above another child in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 180,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_37880",
        "original_caption": "an adult carries a skateboard inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult carries a skateboard inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                74
            ],
            "duration": 75,
            "token": {
                "<s0>": 0,
                "<e0>": 23
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_37881",
        "original_caption": "an adult carries a skateboard inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult carries a skateboard inside a room."
            }
        ],
        "meta": {
            "split": [
                74,
                411
            ],
            "duration": 338,
            "token": {
                "<s0>": 52,
                "<e0>": 114
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_37882",
        "original_caption": "there is a green bottle above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a green bottle above a table."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 502
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6298848190",
        "aid": "6298848190_37883",
        "original_caption": "an adult is away from a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away from a child outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1171
            ],
            "duration": 1172,
            "token": {
                "<s0>": 120,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_37884",
        "original_caption": "an adult in vest is behind another adult woman in black shirt in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in vest is behind another adult woman in black shirt in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 1691
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_37885",
        "original_caption": "an adult in black clothes kisses another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes kisses another adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1446
            ],
            "duration": 1447,
            "token": {
                "<s0>": 1114,
                "<e0>": 1177
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_37886",
        "original_caption": "there is a sofa behind a child in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the sofa in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                2278,
                4260
            ],
            "duration": 1983,
            "token": {
                "<s0>": 310,
                "<e0>": 1982
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2503862291",
        "aid": "2503862291_37887",
        "original_caption": "an adult with glasses is away from the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with glasses is away from the baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                850
            ],
            "duration": 851,
            "token": {
                "<s0>": 300,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4251907980",
        "aid": "4251907980_37888",
        "original_caption": "an adult in black rides a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black rides a snowboard in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                129
            ],
            "duration": 130,
            "token": {
                "<s0>": 0,
                "<e0>": 40
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2801868426",
        "aid": "2801868426_37889",
        "original_caption": "an adult in grey leans on a bicycle in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in grey leans on a bicycle in a gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                527
            ],
            "duration": 528,
            "token": {
                "<s0>": 0,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2801868426",
        "aid": "2801868426_37890",
        "original_caption": "an adult in grey leans on a bicycle in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the bicycle in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                527,
                1312
            ],
            "duration": 786,
            "token": {
                "<s0>": 395,
                "<e0>": 786
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_37891",
        "original_caption": "a baby in yellow touches a gray dog in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in yellow touches a gray dog in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                476
            ],
            "duration": 477,
            "token": {
                "<s0>": 373,
                "<e0>": 388
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_37892",
        "original_caption": "a baby in yellow touches a gray dog in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in yellow touches a gray dog in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                476,
                1469
            ],
            "duration": 994,
            "token": {
                "<s0>": 88,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5049587564",
        "aid": "5049587564_37893",
        "original_caption": "a child is in front of another child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of another child on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                719
            ],
            "duration": 720,
            "token": {
                "<s0>": 0,
                "<e0>": 720
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7528671560",
        "aid": "7528671560_37894",
        "original_caption": "a child rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                539
            ],
            "duration": 540,
            "token": {
                "<s0>": 0,
                "<e0>": 540
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2717467340",
        "aid": "2717467340_37895",
        "original_caption": "an adult hugs a child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult hugs a child in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                506
            ],
            "duration": 507,
            "token": {
                "<s0>": 236,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7798737072",
        "aid": "7798737072_37896",
        "original_caption": "a child in blue is away a gray chair by the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue is away a gray chair by the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                229
            ],
            "duration": 230,
            "token": {
                "<s0>": 0,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_37897",
        "original_caption": "there is a chair behind a child wearing blue pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair behind a child wearing blue pants."
            }
        ],
        "meta": {
            "split": [
                0,
                2069
            ],
            "duration": 2070,
            "token": {
                "<s0>": 1080,
                "<e0>": 1170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8283493827",
        "aid": "8283493827_37898",
        "original_caption": "an adult on the left holds hand of another adult on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult on the left hold hand of from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 0,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8283493827",
        "aid": "8283493827_37899",
        "original_caption": "the adult muscle man leans on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is lean on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 0,
                "<e0>": 651
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2955299637",
        "aid": "2955299637_37900",
        "original_caption": "there is a brown horse carrying an adult woman in wathet blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown horse carrying an adult woman in wathet blue."
            }
        ],
        "meta": {
            "split": [
                44,
                629
            ],
            "duration": 586,
            "token": {
                "<s0>": 14,
                "<e0>": 537
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5258789985",
        "aid": "5258789985_37901",
        "original_caption": "an adult is behind another adult on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is behind another adult on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                366,
                544
            ],
            "duration": 179,
            "token": {
                "<s0>": 19,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4876265566",
        "aid": "4876265566_37902",
        "original_caption": "there is a cat in black clothes away an electric fan.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the cat in black clothes away from from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An electric_fan."
            }
        ],
        "meta": {
            "split": [
                0,
                891
            ],
            "duration": 892,
            "token": {
                "<s0>": 120,
                "<e0>": 191
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047707188",
        "aid": "6047707188_37903",
        "original_caption": "an adult with an orange hat kisses another adult with a red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho kisses the other adult with a red hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 56,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_37904",
        "original_caption": "the child is in front of another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the child is in front of another adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 12,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2852706689",
        "aid": "2852706689_37905",
        "original_caption": "there is a gray baby seat beneath a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the gray baby seat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                648
            ],
            "duration": 649,
            "token": {
                "<s0>": 0,
                "<e0>": 648
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6086390405",
        "aid": "6086390405_37906",
        "original_caption": "a child in orange rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in orange rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                1301
            ],
            "duration": 1302,
            "token": {
                "<s0>": 202,
                "<e0>": 668
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7717953964",
        "aid": "7717953964_37907",
        "original_caption": "an adult in pink clothes watches another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in pink clothes watch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                678
            ],
            "duration": 679,
            "token": {
                "<s0>": 0,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_37908",
        "original_caption": "a baby in white clothes is above a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes is above a baby seat."
            }
        ],
        "meta": {
            "split": [
                564,
                1470
            ],
            "duration": 907,
            "token": {
                "<s0>": 37,
                "<e0>": 905
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4988085277",
        "aid": "4988085277_37909",
        "original_caption": "an adult holds a snake in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a snake in the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                781
            ],
            "duration": 782,
            "token": {
                "<s0>": 0,
                "<e0>": 348
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2642700076",
        "aid": "2642700076_37910",
        "original_caption": "an adult is above a surfboard on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is above a surfboard on the water."
            }
        ],
        "meta": {
            "split": [
                100,
                554
            ],
            "duration": 455,
            "token": {
                "<s0>": 20,
                "<e0>": 455
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13884124143",
        "aid": "13884124143_37911",
        "original_caption": "an adult is away another adult in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is away another adult in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                852
            ],
            "duration": 853,
            "token": {
                "<s0>": 749,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5052259273",
        "aid": "5052259273_37912",
        "original_caption": "a child in pink clothes is towards a yellow dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink clothes is towards a yellow dog."
            }
        ],
        "meta": {
            "split": [
                0,
                499
            ],
            "duration": 500,
            "token": {
                "<s0>": 420,
                "<e0>": 500
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_37913",
        "original_caption": "an adult in black clothes rides a purple snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes rides a purple snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 166,
                "<e0>": 228
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_37914",
        "original_caption": "an adult woman in brown is towards another adult man in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the other adult man in gray from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 144,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6134739139",
        "aid": "6134739139_37915",
        "original_caption": "there is a green toy in front of a child in red at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the green toy at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1968
            ],
            "duration": 1969,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6821159131",
        "aid": "6821159131_37916",
        "original_caption": "there is a monitor in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the screen/monitor from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a monitor in front of a child."
            }
        ],
        "meta": {
            "split": [
                0,
                207
            ],
            "duration": 208,
            "token": {
                "<s0>": 0,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37917",
        "original_caption": "an adult in dark blue leans on a table ouside the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in dark blue leans on a table ouside the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                918
            ],
            "duration": 919,
            "token": {
                "<s0>": 0,
                "<e0>": 804
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37918",
        "original_caption": "an adult in dark blue leans on a table ouside the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in dark blue leans on a table ouside the room."
            }
        ],
        "meta": {
            "split": [
                918,
                2159
            ],
            "duration": 1242,
            "token": {
                "<s0>": 114,
                "<e0>": 1131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_37919",
        "original_caption": "an adult in white is away the adult in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white is away the adult in red happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 60,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2942623423",
        "aid": "2942623423_37920",
        "original_caption": "an adult wearing white shoes is towards another adult in purple clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing white shoes is towards another adult in purple clothes."
            }
        ],
        "meta": {
            "split": [
                259,
                734
            ],
            "duration": 476,
            "token": {
                "<s0>": 6,
                "<e0>": 70
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37921",
        "original_caption": "an adult woman in brown pushes a child in red on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in brown pushes a child in red on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 391,
                "<e0>": 410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_37922",
        "original_caption": "a child with black-hair grabs a green ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child with black-hair grabs a green ball."
            }
        ],
        "meta": {
            "split": [
                1477,
                2069
            ],
            "duration": 593,
            "token": {
                "<s0>": 335,
                "<e0>": 353
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8721006072",
        "aid": "8721006072_37923",
        "original_caption": "an adult with yellow hat speaks to an another adult woman on the tree.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult woman on the tree from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2224
            ],
            "duration": 2225,
            "token": {
                "<s0>": 2028,
                "<e0>": 2089
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8721006072",
        "aid": "8721006072_37924",
        "original_caption": "an adult with yellow hat speaks to an another adult woman on the tree.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult woman on the tree from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                2224,
                2696
            ],
            "duration": 473,
            "token": {
                "<s0>": 136,
                "<e0>": 292
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5331141814",
        "aid": "5331141814_37925",
        "original_caption": "an adult in red speaks to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red speaks to a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                168
            ],
            "duration": 169,
            "token": {
                "<s0>": 0,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5331141814",
        "aid": "5331141814_37926",
        "original_caption": "an adult in red speaks to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red speaks to a child at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                168,
                1291
            ],
            "duration": 1124,
            "token": {
                "<s0>": 94,
                "<e0>": 1124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8542940315",
        "aid": "8542940315_37927",
        "original_caption": "an adult caresses a dog in the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a dog in the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                405
            ],
            "duration": 406,
            "token": {
                "<s0>": 305,
                "<e0>": 399
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8542940315",
        "aid": "8542940315_37928",
        "original_caption": "an adult caresses a dog in the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a dog in the bed."
            }
        ],
        "meta": {
            "split": [
                405,
                755
            ],
            "duration": 351,
            "token": {
                "<s0>": 7,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_37929",
        "original_caption": "a cat is licking the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A cat is licking the adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                1238
            ],
            "duration": 1239,
            "token": {
                "<s0>": 304,
                "<e0>": 1239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_37930",
        "original_caption": "an adult in red is in front of another adult in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red is in front of another adult in red."
            }
        ],
        "meta": {
            "split": [
                614,
                854
            ],
            "duration": 241,
            "token": {
                "<s0>": 134,
                "<e0>": 218
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5708481466",
        "aid": "5708481466_37931",
        "original_caption": "a child is pulling a toy car on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is pulling a toy car on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                229
            ],
            "duration": 230,
            "token": {
                "<s0>": 207,
                "<e0>": 227
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5708481466",
        "aid": "5708481466_37932",
        "original_caption": "a child is pulling a toy car on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is pulling a toy car on the grass."
            }
        ],
        "meta": {
            "split": [
                260,
                1289
            ],
            "duration": 1030,
            "token": {
                "<s0>": 13,
                "<e0>": 33
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_37933",
        "original_caption": "an adult woman in striped clothes is next to another adult woman in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in striped clothes is next to another adult woman in orange happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                810
            ],
            "duration": 811,
            "token": {
                "<s0>": 480,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_37934",
        "original_caption": "a child in black holds hand of an adult in black at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black holds hand of an adult in black at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 782,
                "<e0>": 811
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_37935",
        "original_caption": "a child in black holds hand of an adult in black at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black holds hand of an adult in black at home."
            }
        ],
        "meta": {
            "split": [
                930,
                1024
            ],
            "duration": 95,
            "token": {
                "<s0>": 10,
                "<e0>": 34
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_37936",
        "original_caption": "a child in black holds hand of an adult in black at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child in black hold hand of at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1024,
                1305
            ],
            "duration": 282,
            "token": {
                "<s0>": 61,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114859483",
        "aid": "8114859483_37937",
        "original_caption": "there is a camera towards an adult on the white unknown object.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a camera towards an adult on the white unknown object."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 120,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_37938",
        "original_caption": "an adult in black is towards a motorcycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult in black towards to outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A motorcycle."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 60,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7162478518",
        "aid": "7162478518_37939",
        "original_caption": "there are the guitar in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there are the guitar in front of an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                610
            ],
            "duration": 611,
            "token": {
                "<s0>": 0,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4142450052",
        "aid": "4142450052_37940",
        "original_caption": "the dog watched at the frisbee on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the dog watched at the frisbee on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                503
            ],
            "duration": 504,
            "token": {
                "<s0>": 0,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4452690447",
        "aid": "4452690447_37941",
        "original_caption": "there is a car white beneath an adult with a guitar outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the car from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a car white beneath an adult with a guitar outdoor."
            }
        ],
        "meta": {
            "split": [
                0,
                614
            ],
            "duration": 615,
            "token": {
                "<s0>": 0,
                "<e0>": 615
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37942",
        "original_caption": "a child in pink holds hand of another child in white outside the house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink holds hand of another child in white outside the house happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_37943",
        "original_caption": "a child in yellow is towards a motorcycle at night.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in yellow is towards a motorcycle at night happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 240,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4474456610",
        "aid": "4474456610_37944",
        "original_caption": "there is a brown dog away a child in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away from the child in striped clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1330,
                "<e0>": 1384
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_37945",
        "original_caption": "an adult in green clothes is behind another adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes is behind another adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6700025711",
        "aid": "6700025711_37946",
        "original_caption": "a child shouts at another child on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho shouts at the other child on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 311,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_37947",
        "original_caption": "there is a dish in front of an adult woman in gray at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult woman in gray at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dish."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6025039044",
        "aid": "6025039044_37948",
        "original_caption": "a baby in white rides a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white rides a toy on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                128
            ],
            "duration": 129,
            "token": {
                "<s0>": 0,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7308772034",
        "aid": "7308772034_37949",
        "original_caption": "an adult man in black is away a child in colorful in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is away a child in colorful in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                2456
            ],
            "duration": 2457,
            "token": {
                "<s0>": 848,
                "<e0>": 903
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5708481466",
        "aid": "5708481466_37950",
        "original_caption": "the toy is towards a child wearing a yellow suit.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the toy is towards a child wearing a yellow suit happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                824,
                1289
            ],
            "duration": 466,
            "token": {
                "<s0>": 16,
                "<e0>": 87
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6400812635",
        "aid": "6400812635_37951",
        "original_caption": "an adult in white holds a sports ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the sports ball on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                212
            ],
            "duration": 213,
            "token": {
                "<s0>": 192,
                "<e0>": 213
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_37952",
        "original_caption": "an adult man with white shirt gets on a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man with white shirt gets on a watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1612,
                "<e0>": 1796
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_37953",
        "original_caption": "there is a black watercraft beneath an adult in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black watercraft beneath an adult in striped clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10440265715",
        "aid": "10440265715_37954",
        "original_caption": "there is a car in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A car."
            }
        ],
        "meta": {
            "split": [
                3105,
                3799
            ],
            "duration": 695,
            "token": {
                "<s0>": 255,
                "<e0>": 525
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_37955",
        "original_caption": "an adult in green holds a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green holds a baby at home."
            }
        ],
        "meta": {
            "split": [
                0,
                118
            ],
            "duration": 119,
            "token": {
                "<s0>": 10,
                "<e0>": 30
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_37956",
        "original_caption": "an adult in green holds a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green holds a baby at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                118,
                245
            ],
            "duration": 128,
            "token": {
                "<s0>": 89,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_37957",
        "original_caption": "there is a black bicycle beneath an adult man in red on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black bicycle beneath an adult man in red on the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 0,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_37958",
        "original_caption": "an adult is above a watercraft on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult on the river from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3561394520",
        "aid": "3561394520_37959",
        "original_caption": "a tallest adult speaks to another adult with brown-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A tallest adult speaks to another adult with brown-hair."
            }
        ],
        "meta": {
            "split": [
                0,
                1337
            ],
            "duration": 1338,
            "token": {
                "<s0>": 825,
                "<e0>": 861
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_37960",
        "original_caption": "an adult wearing brown hat holds a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing brown hat holds a bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                456
            ],
            "duration": 457,
            "token": {
                "<s0>": 0,
                "<e0>": 282
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_37961",
        "original_caption": "an adult wearing brown hat holds a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing brown hat holds a bottle."
            }
        ],
        "meta": {
            "split": [
                456,
                959
            ],
            "duration": 504,
            "token": {
                "<s0>": 174,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_37962",
        "original_caption": "an adult wearing brown hat holds a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bottle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                959,
                1649
            ],
            "duration": 691,
            "token": {
                "<s0>": 158,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_37963",
        "original_caption": "there is a table beneath a bottle on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a bottle on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_37964",
        "original_caption": "a child in yellow clothes is away from a car toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in yellow clothes is away from a car toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1113
            ],
            "duration": 1114,
            "token": {
                "<s0>": 840,
                "<e0>": 930
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_37965",
        "original_caption": "there is a brown cat towards an adult woman in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the brown cat towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1046,
                "<e0>": 1229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_37966",
        "original_caption": "an adult women watches a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult women watches a guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                2014,
                2196
            ],
            "duration": 183,
            "token": {
                "<s0>": 118,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_37967",
        "original_caption": "there is a sofa beneath a baby with black hat in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the sofa beneath in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5139493061",
        "aid": "5139493061_37968",
        "original_caption": "an adult man in blue leans on another adult woman in black in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in blue leans on another adult woman in black in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1846
            ],
            "duration": 1847,
            "token": {
                "<s0>": 1286,
                "<e0>": 1421
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_37969",
        "original_caption": "an adult in striped clothes holds hand of another adult in green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in striped clothes holds hand of another adult in green clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                810
            ],
            "duration": 811,
            "token": {
                "<s0>": 0,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953143775",
        "aid": "6953143775_37970",
        "original_caption": "there is a sports ball next to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sports ball next to an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                188
            ],
            "duration": 189,
            "token": {
                "<s0>": 120,
                "<e0>": 189
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37971",
        "original_caption": "an adult in red is towards a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red is towards a ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 420,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_37972",
        "original_caption": "a toy is next to the another toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a toy is next to the another toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1283,
                1385
            ],
            "duration": 103,
            "token": {
                "<s0>": 10,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_37973",
        "original_caption": "an adult is above a ski on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a ski on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 134,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_37974",
        "original_caption": "a child in blue is away another child in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue is away another child in dark blue."
            }
        ],
        "meta": {
            "split": [
                406,
                681
            ],
            "duration": 276,
            "token": {
                "<s0>": 196,
                "<e0>": 268
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_37975",
        "original_caption": "there is a white sports ball towards an adult woman outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white sports ball towards an adult woman outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1336
            ],
            "duration": 1337,
            "token": {
                "<s0>": 120,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_37976",
        "original_caption": "an adult in green clothes watches a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes watches a child."
            }
        ],
        "meta": {
            "split": [
                98,
                334
            ],
            "duration": 237,
            "token": {
                "<s0>": 15,
                "<e0>": 229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8283493827",
        "aid": "8283493827_37977",
        "original_caption": "an adult in black pushes a brown table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black pushes a brown table in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 628,
                "<e0>": 648
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_37978",
        "original_caption": "a naked baby holds a black and white toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A naked baby holds a black and white toy at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 530,
                "<e0>": 834
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_37979",
        "original_caption": "there is a table beneath a bottle on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a bottle on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 1320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_37980",
        "original_caption": "a baby in red leans on a baby seat indoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in red leans on a baby seat indoors."
            }
        ],
        "meta": {
            "split": [
                0,
                250
            ],
            "duration": 251,
            "token": {
                "<s0>": 0,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13548932733",
        "aid": "13548932733_37981",
        "original_caption": "a baby in striped clothes bites a plastic bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in striped clothes bites a plastic bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 0,
                "<e0>": 120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37982",
        "original_caption": "an adult wearing a beige hat leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a beige hat leans on a table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37983",
        "original_caption": "an adult wearing a beige hat leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a beige hat leans on a table."
            }
        ],
        "meta": {
            "split": [
                407,
                827
            ],
            "duration": 421,
            "token": {
                "<s0>": 77,
                "<e0>": 266
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_37984",
        "original_caption": "an adult wearing a beige hat leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a beige hat leans on a table."
            }
        ],
        "meta": {
            "split": [
                827,
                2159
            ],
            "duration": 1333,
            "token": {
                "<s0>": 155,
                "<e0>": 365
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_37985",
        "original_caption": "an adult is towards a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards a sports ball in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_37986",
        "original_caption": "a child in yellow clothes is behind another child in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in yellow clothes is behind another child in pink clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 60,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_37987",
        "original_caption": "there is a table beneath a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a black camera."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 60,
                "<e0>": 1095
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_37988",
        "original_caption": "an adult in white watches a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white watches a watercraft on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1657,
                2186
            ],
            "duration": 530,
            "token": {
                "<s0>": 17,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3802656968",
        "aid": "3802656968_37989",
        "original_caption": "an adult holds hand of a baby at the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of a baby at the table."
            }
        ],
        "meta": {
            "split": [
                0,
                1481
            ],
            "duration": 1482,
            "token": {
                "<s0>": 244,
                "<e0>": 1482
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6257015243",
        "aid": "6257015243_37990",
        "original_caption": "the adult is holding hands of the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is holding hands of the baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                551
            ],
            "duration": 552,
            "token": {
                "<s0>": 0,
                "<e0>": 552
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_37991",
        "original_caption": "an adult in black pushes a bicycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black pushes a bicycle outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                927
            ],
            "duration": 928,
            "token": {
                "<s0>": 65,
                "<e0>": 645
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6194807654",
        "aid": "6194807654_37992",
        "original_caption": "the adult in brown is away from the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in brown is away from the adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                2123
            ],
            "duration": 2124,
            "token": {
                "<s0>": 438,
                "<e0>": 629
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_37993",
        "original_caption": "a baby in white clothes is next to a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes is next to a toy."
            }
        ],
        "meta": {
            "split": [
                569,
                998
            ],
            "duration": 430,
            "token": {
                "<s0>": 299,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_37994",
        "original_caption": "a child is away another child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away another child in the room."
            }
        ],
        "meta": {
            "split": [
                333,
                411
            ],
            "duration": 79,
            "token": {
                "<s0>": 2,
                "<e0>": 26
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_37995",
        "original_caption": "an adult in black leans on a chair in a shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black lean on in the shop from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 0,
                "<e0>": 807
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13884124143",
        "aid": "13884124143_37996",
        "original_caption": "there is a surfboard beneath an adult in the stream.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the surfboard in the stream from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                356,
                852
            ],
            "duration": 497,
            "token": {
                "<s0>": 6,
                "<e0>": 384
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_37997",
        "original_caption": "an adult wearing a blue hat rides a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing a blue hat rides a watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6220387865",
        "aid": "6220387865_37998",
        "original_caption": "an adult man in white is towards another adult man in black at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white is towards another adult man in black at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                900
            ],
            "duration": 901,
            "token": {
                "<s0>": 151,
                "<e0>": 198
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5049587564",
        "aid": "5049587564_37999",
        "original_caption": "the child in black sunglasses speaks to the child on her right hand.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child wearing black sunglasses speaking to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                719
            ],
            "duration": 720,
            "token": {
                "<s0>": 575,
                "<e0>": 624
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4966797693",
        "aid": "4966797693_38000",
        "original_caption": "a baby in skirt is away a white and black cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in skirt is away a white and black cat."
            }
        ],
        "meta": {
            "split": [
                0,
                180
            ],
            "duration": 181,
            "token": {
                "<s0>": 60,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_38001",
        "original_caption": "a child wearing a hat feeds a cattle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing a hat feeds a cattle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_38002",
        "original_caption": "a child wearing a hat feeds a cattle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho feeds the cattle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                357,
                661
            ],
            "duration": 305,
            "token": {
                "<s0>": 56,
                "<e0>": 273
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_38003",
        "original_caption": "a child wearing a hat feeds a cattle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing a hat feeds a cattle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                661,
                846
            ],
            "duration": 186,
            "token": {
                "<s0>": 31,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_38004",
        "original_caption": "a child wearing a hat feeds a cattle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing a hat feeds a cattle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                846,
                1151
            ],
            "duration": 306,
            "token": {
                "<s0>": 32,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5093962680",
        "aid": "5093962680_38005",
        "original_caption": "an adult in black holds a black cellphone outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the black cellphone outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                184
            ],
            "duration": 185,
            "token": {
                "<s0>": 0,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38006",
        "original_caption": "adult wearing an orange suit hugs the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "Adult wearing an orange suit hugs the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 390,
                "<e0>": 651
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38007",
        "original_caption": "adult wearing an orange suit hugs the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "Adult wearing an orange suit hugs the baby."
            }
        ],
        "meta": {
            "split": [
                666,
                2696
            ],
            "duration": 2031,
            "token": {
                "<s0>": 15,
                "<e0>": 2031
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38008",
        "original_caption": "there is a yellow cat towards an adult in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the yellow cat towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1260,
                "<e0>": 1650
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38009",
        "original_caption": "there is a white cup in front of an adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white cup in front of an adult man in black."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38010",
        "original_caption": "there is a stool behind an adult man in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a stool behind an adult man in white."
            }
        ],
        "meta": {
            "split": [
                884,
                1011
            ],
            "duration": 128,
            "token": {
                "<s0>": 16,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38011",
        "original_caption": "a child is in front of an adult in purple in the canteen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of an adult in purple in the canteen."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_38012",
        "original_caption": "a baby in yellow holds a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bottle in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 63,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_38013",
        "original_caption": "a baby in yellow holds a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bottle in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                119,
                959
            ],
            "duration": 841,
            "token": {
                "<s0>": 14,
                "<e0>": 832
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_38014",
        "original_caption": "a baby in yellow holds a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bottle in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                959,
                1469
            ],
            "duration": 511,
            "token": {
                "<s0>": 8,
                "<e0>": 511
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_38015",
        "original_caption": "there is a toy in front of a baby in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the baby in white outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                352,
                998
            ],
            "duration": 647,
            "token": {
                "<s0>": 82,
                "<e0>": 637
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4063402763",
        "aid": "4063402763_38016",
        "original_caption": "an adult feeds a baby in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult feeds a baby in living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                341
            ],
            "duration": 342,
            "token": {
                "<s0>": 57,
                "<e0>": 79
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4063402763",
        "aid": "4063402763_38017",
        "original_caption": "an adult feeds a baby in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult feeds a baby in living room."
            }
        ],
        "meta": {
            "split": [
                341,
                790
            ],
            "duration": 450,
            "token": {
                "<s0>": 263,
                "<e0>": 288
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4569009647",
        "aid": "4569009647_38018",
        "original_caption": "an adult is next to an another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to an another adult."
            }
        ],
        "meta": {
            "split": [
                1870,
                2436
            ],
            "duration": 567,
            "token": {
                "<s0>": 50,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38019",
        "original_caption": "a child in black caresses a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black caresses a white dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                364
            ],
            "duration": 365,
            "token": {
                "<s0>": 145,
                "<e0>": 248
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38020",
        "original_caption": "a child in black caresses a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black caresses a white dog."
            }
        ],
        "meta": {
            "split": [
                364,
                672
            ],
            "duration": 309,
            "token": {
                "<s0>": 116,
                "<e0>": 212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38021",
        "original_caption": "a child in black caresses a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black caresses a white dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                672,
                1072
            ],
            "duration": 401,
            "token": {
                "<s0>": 97,
                "<e0>": 170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38022",
        "original_caption": "a child in black caresses a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black caresses a white dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1072,
                1632
            ],
            "duration": 561,
            "token": {
                "<s0>": 230,
                "<e0>": 293
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38023",
        "original_caption": "a child in black caresses a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black caresses a white dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1632,
                2595
            ],
            "duration": 964,
            "token": {
                "<s0>": 268,
                "<e0>": 333
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2776753352",
        "aid": "2776753352_38024",
        "original_caption": "an adult in black speaks to another adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black speak to outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1103
            ],
            "duration": 1104,
            "token": {
                "<s0>": 603,
                "<e0>": 633
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38025",
        "original_caption": "an adult in black is beneath a screen indoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black is beneath a screen indoors."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3758307290",
        "aid": "3758307290_38026",
        "original_caption": "a child in white holds the guitar in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the guitar in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                657
            ],
            "duration": 658,
            "token": {
                "<s0>": 536,
                "<e0>": 568
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6134739139",
        "aid": "6134739139_38027",
        "original_caption": "there is a green toy above a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a green toy above a chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1968
            ],
            "duration": 1969,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38028",
        "original_caption": "there is a white cake towards a child in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white cake towards a child in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 420,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3164903868",
        "aid": "3164903868_38029",
        "original_caption": "a child holds the guitar in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds the guitar in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                741
            ],
            "duration": 742,
            "token": {
                "<s0>": 0,
                "<e0>": 742
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_38030",
        "original_caption": "an adult rides a white watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a white watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                2186
            ],
            "duration": 2187,
            "token": {
                "<s0>": 0,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38031",
        "original_caption": "there is a sports ball away an adult man in blue on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sports ball away an adult man in blue on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 278,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38032",
        "original_caption": "an adult in purple clothes holds a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in purple clothes holds a bench."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 660,
                "<e0>": 728
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38033",
        "original_caption": "there is a blue sports ball above an orange toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue sports ball above an orange toy in the room."
            }
        ],
        "meta": {
            "split": [
                510,
                2696
            ],
            "duration": 2187,
            "token": {
                "<s0>": 11,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_38034",
        "original_caption": "a baby in yellow clothes leans on an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in yellow clothes leans on an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 702,
                "<e0>": 743
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3848996383",
        "aid": "3848996383_38035",
        "original_caption": "an adult man in white holds a black bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in white holds a black bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                633
            ],
            "duration": 634,
            "token": {
                "<s0>": 517,
                "<e0>": 612
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3848996383",
        "aid": "3848996383_38036",
        "original_caption": "an adult man in white holds a black bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white holds a black bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                633,
                739
            ],
            "duration": 107,
            "token": {
                "<s0>": 22,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_38037",
        "original_caption": "an adult pushes a child in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult pushes a child in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 19,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12158830025",
        "aid": "12158830025_38038",
        "original_caption": "the adult in green is towards another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in green is towards another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1368
            ],
            "duration": 1369,
            "token": {
                "<s0>": 762,
                "<e0>": 929
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8283493827",
        "aid": "8283493827_38039",
        "original_caption": "an adult in black leans on a table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black lean on in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 0,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945327422",
        "aid": "5945327422_38040",
        "original_caption": "an adult caresses a black dog on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult caresses a black dog on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                773
            ],
            "duration": 774,
            "token": {
                "<s0>": 578,
                "<e0>": 687
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945327422",
        "aid": "5945327422_38041",
        "original_caption": "an adult caresses a black dog on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult caress on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                773,
                894
            ],
            "duration": 122,
            "token": {
                "<s0>": 87,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945327422",
        "aid": "5945327422_38042",
        "original_caption": "an adult caresses a black dog on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult caresses a black dog on the floor."
            }
        ],
        "meta": {
            "split": [
                894,
                1080
            ],
            "duration": 187,
            "token": {
                "<s0>": 17,
                "<e0>": 31
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945327422",
        "aid": "5945327422_38043",
        "original_caption": "an adult caresses a black dog on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult caress on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                1080,
                1444
            ],
            "duration": 365,
            "token": {
                "<s0>": 156,
                "<e0>": 259
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_38044",
        "original_caption": "an adult in black clothes chases another adult wearing a white hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho chases the other adult wearing a white hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 338,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38045",
        "original_caption": "an adult in black clothes is next to a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is next to a camera."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 182,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3219139415",
        "aid": "3219139415_38046",
        "original_caption": "an adult is above a brown toy in a shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is above a brown toy in a shop."
            }
        ],
        "meta": {
            "split": [
                0,
                202
            ],
            "duration": 203,
            "token": {
                "<s0>": 0,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3865853855",
        "aid": "3865853855_38047",
        "original_caption": "a child in pink holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink holds a toy on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                42,
                216
            ],
            "duration": 175,
            "token": {
                "<s0>": 11,
                "<e0>": 137
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3865853855",
        "aid": "3865853855_38048",
        "original_caption": "a child in pink holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink holds a toy on the beach."
            }
        ],
        "meta": {
            "split": [
                308,
                671
            ],
            "duration": 364,
            "token": {
                "<s0>": 2,
                "<e0>": 358
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3066398259",
        "aid": "3066398259_38049",
        "original_caption": "a baby in red clothes is away from a red sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the baby in red clothes away from from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 120,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8721006072",
        "aid": "8721006072_38050",
        "original_caption": "an adult speaks to another adult in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to another adult in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                1961
            ],
            "duration": 1962,
            "token": {
                "<s0>": 1370,
                "<e0>": 1556
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8721006072",
        "aid": "8721006072_38051",
        "original_caption": "an adult speaks to another adult in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult speaks to another adult in the forest happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1961,
                2696
            ],
            "duration": 736,
            "token": {
                "<s0>": 406,
                "<e0>": 435
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7424038414",
        "aid": "7424038414_38052",
        "original_caption": "an adult wearing a no.8 jersey pushes another adult wearing red shoes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult wearing the no.8 jersey push from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                100
            ],
            "duration": 101,
            "token": {
                "<s0>": 0,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8616874413",
        "aid": "8616874413_38053",
        "original_caption": "an adult woman in black holds a black camera outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black holds a black camera outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38054",
        "original_caption": "the green ball/sports ball is above the bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the green ball/sports ball is above the bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 459,
                "<e0>": 621
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_38055",
        "original_caption": "a child is next to an adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is next to an adult outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 89,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_38056",
        "original_caption": "a baby wearing a white hat is inside a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby wearing a white hat is inside a baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                363
            ],
            "duration": 364,
            "token": {
                "<s0>": 0,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_38057",
        "original_caption": "a baby wearing a white hat is inside a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is outside the baby wearing the white hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                363,
                794
            ],
            "duration": 432,
            "token": {
                "<s0>": 297,
                "<e0>": 432
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38058",
        "original_caption": "a sofa is next to a cellphone at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a sofa is next to a cellphone at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                434,
                1441
            ],
            "duration": 1008,
            "token": {
                "<s0>": 125,
                "<e0>": 213
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3588778325",
        "aid": "3588778325_38059",
        "original_caption": "an adult opens a black laptop in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult opens a black laptop in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                391
            ],
            "duration": 392,
            "token": {
                "<s0>": 68,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3898106739",
        "aid": "3898106739_38060",
        "original_caption": "an adult is away from another adult in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                1232
            ],
            "duration": 1233,
            "token": {
                "<s0>": 840,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38061",
        "original_caption": "there is a cyan ball above a baby in white at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cyan ball above a baby in white at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_38062",
        "original_caption": "an adult is next to a table in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is next to a table in the classroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6906256626",
        "aid": "6906256626_38063",
        "original_caption": "there is a toy beneath a child outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy beneath a child outdoor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5341352435",
        "aid": "5341352435_38064",
        "original_caption": "an adult with jeans watches another adult lying on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with jeans watches another adult lying on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                433
            ],
            "duration": 434,
            "token": {
                "<s0>": 0,
                "<e0>": 142
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38065",
        "original_caption": "the child in red is grabbing the ball/sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is grabbing the ball/sports ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 29
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5270774640",
        "aid": "5270774640_38066",
        "original_caption": "there is a dog leaning on an adult 1.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat leans on the adult 1 from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                222
            ],
            "duration": 223,
            "token": {
                "<s0>": 0,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_38067",
        "original_caption": "there is a black sofa beneath an adult man in black at the meeting.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black sofa beneath an adult man in black at the meeting."
            }
        ],
        "meta": {
            "split": [
                0,
                2698
            ],
            "duration": 2699,
            "token": {
                "<s0>": 0,
                "<e0>": 2699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_38068",
        "original_caption": "a child in purple touches a colorful toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in purple touches a colorful toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                768
            ],
            "duration": 769,
            "token": {
                "<s0>": 627,
                "<e0>": 647
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_38069",
        "original_caption": "a child in purple touches a colorful toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in purple touches a colorful toy on the floor."
            }
        ],
        "meta": {
            "split": [
                768,
                998
            ],
            "duration": 231,
            "token": {
                "<s0>": 121,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_38070",
        "original_caption": "a child in purple touches a colorful toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in purple touches a colorful toy on the floor."
            }
        ],
        "meta": {
            "split": [
                998,
                1171
            ],
            "duration": 174,
            "token": {
                "<s0>": 86,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_38071",
        "original_caption": "a child in purple touches a colorful toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the colorful toy on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1171,
                1361
            ],
            "duration": 191,
            "token": {
                "<s0>": 77,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_38072",
        "original_caption": "a child in purple touches a colorful toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in purple touches a colorful toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1361,
                1530
            ],
            "duration": 170,
            "token": {
                "<s0>": 102,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38073",
        "original_caption": "there is a scooter beneath a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the scooter from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a scooter beneath a child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 0,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_38074",
        "original_caption": "a child rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                121
            ],
            "duration": 122,
            "token": {
                "<s0>": 65,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_38075",
        "original_caption": "a child rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                121,
                347
            ],
            "duration": 227,
            "token": {
                "<s0>": 34,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_38076",
        "original_caption": "a child rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                347,
                927
            ],
            "duration": 581,
            "token": {
                "<s0>": 125,
                "<e0>": 161
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_38077",
        "original_caption": "a child without dress pushes a green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child without dress pushes a green toy."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 0,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_38078",
        "original_caption": "a child in blue holds a monitor on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue holds a monitor on a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                747
            ],
            "duration": 748,
            "token": {
                "<s0>": 0,
                "<e0>": 748
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_38079",
        "original_caption": "there is a long and big cat biting a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a long and big cat biting a brown cat."
            }
        ],
        "meta": {
            "split": [
                0,
                392
            ],
            "duration": 393,
            "token": {
                "<s0>": 347,
                "<e0>": 371
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_38080",
        "original_caption": "there is a long and big cat biting a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat bites the brown cat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                392,
                923
            ],
            "duration": 532,
            "token": {
                "<s0>": 22,
                "<e0>": 50
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8616874413",
        "aid": "8616874413_38081",
        "original_caption": "there is a camera in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a camera in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3457759630",
        "aid": "3457759630_38082",
        "original_caption": "a baby holds a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1047
            ],
            "duration": 1048,
            "token": {
                "<s0>": 788,
                "<e0>": 982
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3457759630",
        "aid": "3457759630_38083",
        "original_caption": "a baby holds a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby holds a toy on the floor."
            }
        ],
        "meta": {
            "split": [
                1047,
                1388
            ],
            "duration": 342,
            "token": {
                "<s0>": 66,
                "<e0>": 342
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_38084",
        "original_caption": "a child in pale purple leans on another child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the other child in red from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 182,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5053937486",
        "aid": "5053937486_38085",
        "original_caption": "an adult wearing jeans is above a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing jeans is above a car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                246
            ],
            "duration": 247,
            "token": {
                "<s0>": 0,
                "<e0>": 218
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_38086",
        "original_caption": "an adult in red plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the guitar on stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1882
            ],
            "duration": 1883,
            "token": {
                "<s0>": 0,
                "<e0>": 1860
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_38087",
        "original_caption": "an adult in red plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                1882,
                2024
            ],
            "duration": 143,
            "token": {
                "<s0>": 23,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_38088",
        "original_caption": "an adult with glasses is next to a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses is next to a screen happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 300,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_38089",
        "original_caption": "an adult in plaid shirt leans on a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                979
            ],
            "duration": 980,
            "token": {
                "<s0>": 456,
                "<e0>": 632
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2882005417",
        "aid": "2882005417_38090",
        "original_caption": "an adult in green uses a camera outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in green use outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A camera."
            }
        ],
        "meta": {
            "split": [
                0,
                922
            ],
            "duration": 923,
            "token": {
                "<s0>": 734,
                "<e0>": 757
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9345245716",
        "aid": "9345245716_38091",
        "original_caption": "the handbag is behind the adult in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind an adult wearing red clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A handbag."
            }
        ],
        "meta": {
            "split": [
                0,
                485
            ],
            "duration": 486,
            "token": {
                "<s0>": 0,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38092",
        "original_caption": "an adult wearing a beige hat holds a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a beige hat holds a cup."
            }
        ],
        "meta": {
            "split": [
                0,
                1328
            ],
            "duration": 1329,
            "token": {
                "<s0>": 496,
                "<e0>": 526
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38093",
        "original_caption": "an adult wearing a beige hat holds a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a beige hat holds a cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1328,
                2159
            ],
            "duration": 832,
            "token": {
                "<s0>": 802,
                "<e0>": 832
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_38094",
        "original_caption": "an adult is away another adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away another adult at home."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 673,
                "<e0>": 808
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12624072313",
        "aid": "12624072313_38095",
        "original_caption": "an adult is behind another adult in the evening.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult in the evening."
            }
        ],
        "meta": {
            "split": [
                0,
                1278
            ],
            "duration": 1279,
            "token": {
                "<s0>": 120,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38096",
        "original_caption": "an adult in striped shirts is beneath a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in striped shirts is beneath a screen."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_38097",
        "original_caption": "an adult woman in white speaks to a child in purple trousers.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the child in purple trousers from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1762,
                "<e0>": 1894
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_38098",
        "original_caption": "an adult is above a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a watercraft on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38099",
        "original_caption": "an adult in purple gets off a brown bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in purple gets off a brown bench in a gym."
            }
        ],
        "meta": {
            "split": [
                0,
                868
            ],
            "duration": 869,
            "token": {
                "<s0>": 771,
                "<e0>": 789
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38100",
        "original_caption": "an adult in purple gets off a brown bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in purple gets off a brown bench in a gym."
            }
        ],
        "meta": {
            "split": [
                868,
                990
            ],
            "duration": 123,
            "token": {
                "<s0>": 80,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38101",
        "original_caption": "an adult in purple gets off a brown bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in purple get off in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bench."
            }
        ],
        "meta": {
            "split": [
                990,
                1064
            ],
            "duration": 75,
            "token": {
                "<s0>": 26,
                "<e0>": 49
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38102",
        "original_caption": "an adult in purple gets off a brown bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in purple gets off a brown bench in a gym."
            }
        ],
        "meta": {
            "split": [
                1064,
                1323
            ],
            "duration": 260,
            "token": {
                "<s0>": 25,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13715319605",
        "aid": "13715319605_38103",
        "original_caption": "there is a gray horse away a brown horse.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray horse away a brown horse happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                77
            ],
            "duration": 78,
            "token": {
                "<s0>": 0,
                "<e0>": 19
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_38104",
        "original_caption": "there is a sports ball above a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sports ball above a child."
            }
        ],
        "meta": {
            "split": [
                1644,
                2069
            ],
            "duration": 426,
            "token": {
                "<s0>": 119,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38105",
        "original_caption": "adults in black clothes are using the camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is using the camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                496
            ],
            "duration": 497,
            "token": {
                "<s0>": 182,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38106",
        "original_caption": "adults in black clothes are using the camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is using the camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                496,
                648
            ],
            "duration": 153,
            "token": {
                "<s0>": 89,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38107",
        "original_caption": "adults in black clothes are using the camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is using the camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                648,
                1094
            ],
            "duration": 447,
            "token": {
                "<s0>": 30,
                "<e0>": 132
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4914011323",
        "aid": "4914011323_38108",
        "original_caption": "there is a dog smelling a cat inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the dog smell inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                46,
                182
            ],
            "duration": 137,
            "token": {
                "<s0>": 12,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38109",
        "original_caption": "there is a skateboard beneath a child on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a skateboard beneath a child on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 293,
                "<e0>": 359
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38110",
        "original_caption": "the adult in red is beneath the ball/sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the ball/sports ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6236608754",
        "aid": "6236608754_38111",
        "original_caption": "there is a toy behind a child in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy behind a child in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                739
            ],
            "duration": 740,
            "token": {
                "<s0>": 480,
                "<e0>": 560
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38112",
        "original_caption": "a child is away from a skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from a skateboard in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 96,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6247340440",
        "aid": "6247340440_38113",
        "original_caption": "an adult in black is above a ski in the desert.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in black in the desert from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ski."
            }
        ],
        "meta": {
            "split": [
                0,
                387
            ],
            "duration": 388,
            "token": {
                "<s0>": 0,
                "<e0>": 381
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_38114",
        "original_caption": "there is a black backpack away a child wearing a blue hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away from the child wearing a blue hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1151
            ],
            "duration": 1152,
            "token": {
                "<s0>": 323,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3836995607",
        "aid": "3836995607_38115",
        "original_caption": "an adult pushes another adult on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult push on the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                96
            ],
            "duration": 97,
            "token": {
                "<s0>": 32,
                "<e0>": 48
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38116",
        "original_caption": "the black skateboard is behind the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The black skateboard is behind the adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 0,
                "<e0>": 348
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13097816293",
        "aid": "13097816293_38117",
        "original_caption": "there is a white stool behind a golden cat on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white stool behind a golden cat on the floor."
            }
        ],
        "meta": {
            "split": [
                676,
                1104
            ],
            "duration": 429,
            "token": {
                "<s0>": 47,
                "<e0>": 428
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10403393365",
        "aid": "10403393365_38118",
        "original_caption": "a child in white rides a red bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in white ride from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                341
            ],
            "duration": 342,
            "token": {
                "<s0>": 0,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38119",
        "original_caption": "there is a cup in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2882005417",
        "aid": "2882005417_38120",
        "original_caption": "an adult man in green holds a silver camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in green holds a silver camera."
            }
        ],
        "meta": {
            "split": [
                0,
                922
            ],
            "duration": 923,
            "token": {
                "<s0>": 734,
                "<e0>": 757
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6115043636",
        "aid": "6115043636_38121",
        "original_caption": "an adult is next to an another adult outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to an another adult outdoor."
            }
        ],
        "meta": {
            "split": [
                0,
                863
            ],
            "duration": 864,
            "token": {
                "<s0>": 378,
                "<e0>": 863
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_38122",
        "original_caption": "a child in gray is behind another child in black in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in gray is behind another child in black in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 94,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_38123",
        "original_caption": "a child in black leans on a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black leans on a chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 111,
                "<e0>": 513
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_38124",
        "original_caption": "there is a grey sofa beneath a child in blue at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sofa from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a grey sofa beneath a child in blue at home."
            }
        ],
        "meta": {
            "split": [
                0,
                747
            ],
            "duration": 748,
            "token": {
                "<s0>": 0,
                "<e0>": 748
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38125",
        "original_caption": "a child is above another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is above another child in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 251,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3891539754",
        "aid": "3891539754_38126",
        "original_caption": "there is a cup behind the adult man with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup behind the adult man with glasses happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                441
            ],
            "duration": 442,
            "token": {
                "<s0>": 63,
                "<e0>": 441
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_38127",
        "original_caption": "there is a beige dog away a purple sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a beige dog away a purple sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 960,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_38128",
        "original_caption": "a child in white holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white holds hand of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                315
            ],
            "duration": 316,
            "token": {
                "<s0>": 132,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_38129",
        "original_caption": "a child in white holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child in white hold hand of from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                315,
                619
            ],
            "duration": 305,
            "token": {
                "<s0>": 142,
                "<e0>": 170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_38130",
        "original_caption": "a child in white holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                619,
                998
            ],
            "duration": 380,
            "token": {
                "<s0>": 134,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_38131",
        "original_caption": "a child in white holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white holds hand of an adult."
            }
        ],
        "meta": {
            "split": [
                998,
                1441
            ],
            "duration": 444,
            "token": {
                "<s0>": 164,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_38132",
        "original_caption": "a child in white holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white holds hand of an adult."
            }
        ],
        "meta": {
            "split": [
                1441,
                1818
            ],
            "duration": 378,
            "token": {
                "<s0>": 247,
                "<e0>": 367
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_38133",
        "original_caption": "an adult in red-white clothes plays a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1425
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38134",
        "original_caption": "an adult is next to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to a child at home."
            }
        ],
        "meta": {
            "split": [
                1156,
                1441
            ],
            "duration": 286,
            "token": {
                "<s0>": 94,
                "<e0>": 163
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8269030910",
        "aid": "8269030910_38135",
        "original_caption": "a child wearing blue pants is towards an adult with beige clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing blue pants is towards an adult with beige clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                356
            ],
            "duration": 357,
            "token": {
                "<s0>": 243,
                "<e0>": 301
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_38136",
        "original_caption": "there is a cake towards a child in pink in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cake towards a child in pink in the living room."
            }
        ],
        "meta": {
            "split": [
                106,
                872
            ],
            "duration": 767,
            "token": {
                "<s0>": 58,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_38137",
        "original_caption": "a baby in black is in front of an adult in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in black is in front of an adult in white outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                315,
                998
            ],
            "duration": 684,
            "token": {
                "<s0>": 105,
                "<e0>": 675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_38138",
        "original_caption": "an adult in black watches another adult in blue in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black watches another adult in blue in the room."
            }
        ],
        "meta": {
            "split": [
                753,
                1799
            ],
            "duration": 1047,
            "token": {
                "<s0>": 468,
                "<e0>": 494
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_38139",
        "original_caption": "an adult carries a handbag in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult carry in the wild from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A handbag."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 785,
                "<e0>": 960
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5049587564",
        "aid": "5049587564_38140",
        "original_caption": "a child in red clothes is next to another child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is next to another child in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                719
            ],
            "duration": 720,
            "token": {
                "<s0>": 0,
                "<e0>": 720
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38141",
        "original_caption": "an adult is in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is in front of a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1046,
                "<e0>": 1229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_38142",
        "original_caption": "a child is behind another child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                2508,
                2696
            ],
            "duration": 189,
            "token": {
                "<s0>": 19,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_38143",
        "original_caption": "there is a brown and white cat above a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown and white cat above a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1271
            ],
            "duration": 1272,
            "token": {
                "<s0>": 0,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7506103208",
        "aid": "7506103208_38144",
        "original_caption": "a female adult speaks to a male adult on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the male adult on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1283
            ],
            "duration": 1284,
            "token": {
                "<s0>": 368,
                "<e0>": 411
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_38145",
        "original_caption": "a child in red watches an adult woman in gray at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red watches an adult woman in gray at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 44,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3077081235",
        "aid": "3077081235_38146",
        "original_caption": "an adult woman in red touches another adult woman in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in red touches another adult woman in black."
            }
        ],
        "meta": {
            "split": [
                0,
                538
            ],
            "duration": 539,
            "token": {
                "<s0>": 466,
                "<e0>": 496
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5994899092",
        "aid": "5994899092_38147",
        "original_caption": "a child pulls a surfboard by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child pulls a surfboard by the sea happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 1163,
                "<e0>": 1260
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_38148",
        "original_caption": "an adult in red clothes is above a blue watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the blue watercraft from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 438
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_38149",
        "original_caption": "there is a laptop above a table in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a laptop above a table in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 1697,
                "<e0>": 1756
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3891539754",
        "aid": "3891539754_38150",
        "original_caption": "there is a cup behind an adult woman in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup behind an adult woman in a gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                441
            ],
            "duration": 442,
            "token": {
                "<s0>": 63,
                "<e0>": 441
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5669212370",
        "aid": "5669212370_38151",
        "original_caption": "an adult wearing a no.78 jersey is away from another adult wearing black pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the other adult wearing black pants from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                145
            ],
            "duration": 146,
            "token": {
                "<s0>": 0,
                "<e0>": 76
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_38152",
        "original_caption": "there is a grey sofa beneath an adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the grey sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 258,
                "<e0>": 474
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_38153",
        "original_caption": "a child in pink is away an adult in black in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink is away an adult in black in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                647
            ],
            "duration": 648,
            "token": {
                "<s0>": 300,
                "<e0>": 373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_38154",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 3,
                "<e0>": 819
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_38155",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                869,
                969
            ],
            "duration": 101,
            "token": {
                "<s0>": 51,
                "<e0>": 79
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_38156",
        "original_caption": "an adult in white plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                969,
                1583
            ],
            "duration": 615,
            "token": {
                "<s0>": 22,
                "<e0>": 583
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_38157",
        "original_caption": "a pig is towards a goat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the pig from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A pig is towards a goat on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 540,
                "<e0>": 598
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38158",
        "original_caption": "a child in blue clothes is away from a silver ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the silver ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 278,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38159",
        "original_caption": "there is a bottle above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle above a table inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 750
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8302769229",
        "aid": "8302769229_38160",
        "original_caption": "an adult in black is behind the piano at the show.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black is behind the piano at the show."
            }
        ],
        "meta": {
            "split": [
                275,
                2696
            ],
            "duration": 2422,
            "token": {
                "<s0>": 126,
                "<e0>": 2421
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8115037154",
        "aid": "8115037154_38161",
        "original_caption": "a female adult uses a red camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A female adult uses a red camera."
            }
        ],
        "meta": {
            "split": [
                0,
                1379
            ],
            "duration": 1380,
            "token": {
                "<s0>": 1149,
                "<e0>": 1250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_38162",
        "original_caption": "there is an adult in white is watching the adult in a dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is an adult in white is watching the adult in a dress happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1582
            ],
            "duration": 1583,
            "token": {
                "<s0>": 1335,
                "<e0>": 1458
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_38163",
        "original_caption": "an adult in purple clothes is behind another adult in brown pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in purple clothes is behind another adult in brown pants."
            }
        ],
        "meta": {
            "split": [
                0,
                1238
            ],
            "duration": 1239,
            "token": {
                "<s0>": 0,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38164",
        "original_caption": "there is a black elephant away from another elephant in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black elephant away from another elephant in the forest happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 780,
                "<e0>": 1069
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12577546265",
        "aid": "12577546265_38165",
        "original_caption": "an adult holds a snowboard on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a snowboard on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                45,
                190
            ],
            "duration": 146,
            "token": {
                "<s0>": 21,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_38166",
        "original_caption": "an adult in blue clothes holds hand of a baby in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes holds hand of a baby in yellow clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                698
            ],
            "duration": 699,
            "token": {
                "<s0>": 0,
                "<e0>": 440
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_38167",
        "original_caption": "an adult in blue clothes holds hand of a baby in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes holds hand of a baby in yellow clothes."
            }
        ],
        "meta": {
            "split": [
                698,
                1230
            ],
            "duration": 533,
            "token": {
                "<s0>": 259,
                "<e0>": 357
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_38168",
        "original_caption": "an adult in blue clothes holds hand of a baby in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue clothes holds hand of a baby in yellow clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1230,
                1466
            ],
            "duration": 237,
            "token": {
                "<s0>": 175,
                "<e0>": 213
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5913888440",
        "aid": "5913888440_38169",
        "original_caption": "there is a backpack behind an adult in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the backpack from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a backpack behind an adult in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                803
            ],
            "duration": 804,
            "token": {
                "<s0>": 0,
                "<e0>": 677
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_38170",
        "original_caption": "an adult in white is behind a baby in white on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white is behind a baby in white on the grass."
            }
        ],
        "meta": {
            "split": [
                315,
                998
            ],
            "duration": 684,
            "token": {
                "<s0>": 105,
                "<e0>": 675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12577546265",
        "aid": "12577546265_38171",
        "original_caption": "an adult in black clothes pushes another adult in brown clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pushes the other adult in brown clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                190
            ],
            "duration": 191,
            "token": {
                "<s0>": 0,
                "<e0>": 22
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3963443256",
        "aid": "3963443256_38172",
        "original_caption": "an adult man in white speaks to another adult women in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white speaks to another adult women in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                390
            ],
            "duration": 391,
            "token": {
                "<s0>": 0,
                "<e0>": 40
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3963443256",
        "aid": "3963443256_38173",
        "original_caption": "an adult man in white speaks to another adult women in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white speaks to another adult women in blue."
            }
        ],
        "meta": {
            "split": [
                390,
                813
            ],
            "duration": 424,
            "token": {
                "<s0>": 350,
                "<e0>": 401
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3963443256",
        "aid": "3963443256_38174",
        "original_caption": "an adult man in white speaks to another adult women in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white speaks to another adult women in blue happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                813,
                1115
            ],
            "duration": 303,
            "token": {
                "<s0>": 22,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8847930035",
        "aid": "8847930035_38175",
        "original_caption": "a child in gray clothes holds a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in gray clothes holds a sports ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                213
            ],
            "duration": 214,
            "token": {
                "<s0>": 179,
                "<e0>": 194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8847930035",
        "aid": "8847930035_38176",
        "original_caption": "a child in gray clothes holds a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in gray clothes holds a sports ball."
            }
        ],
        "meta": {
            "split": [
                213,
                325
            ],
            "duration": 113,
            "token": {
                "<s0>": 19,
                "<e0>": 37
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_38177",
        "original_caption": "a child in red clothes pulls another child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes pulls another child in blue clothes."
            }
        ],
        "meta": {
            "split": [
                29,
                240
            ],
            "duration": 212,
            "token": {
                "<s0>": 23,
                "<e0>": 40
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_38178",
        "original_caption": "there is a snowboard beneath an adult in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the snowboard in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 180,
                "<e0>": 228
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38179",
        "original_caption": "a child is above a skateboard inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is above a skateboard inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 96,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4240545211",
        "aid": "4240545211_38180",
        "original_caption": "an adult in black carries a backpack in a road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black carries a backpack in a road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                257
            ],
            "duration": 258,
            "token": {
                "<s0>": 152,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4240545211",
        "aid": "4240545211_38181",
        "original_caption": "an adult in black carries a backpack in a road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black carries a backpack in a road."
            }
        ],
        "meta": {
            "split": [
                257,
                484
            ],
            "duration": 228,
            "token": {
                "<s0>": 11,
                "<e0>": 39
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38182",
        "original_caption": "an adult wearing gray pants leans on a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing gray pants leans on a bench."
            }
        ],
        "meta": {
            "split": [
                0,
                870
            ],
            "duration": 871,
            "token": {
                "<s0>": 789,
                "<e0>": 822
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38183",
        "original_caption": "an adult wearing gray pants leans on a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing gray pants leans on a bench."
            }
        ],
        "meta": {
            "split": [
                870,
                1323
            ],
            "duration": 454,
            "token": {
                "<s0>": 48,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38184",
        "original_caption": "an adult in pink clothes presses a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in pink clothes presses a cup."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 90,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6879186481",
        "aid": "6879186481_38185",
        "original_caption": "a child with blond-hair holds a blue toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair holds a blue toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 0,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6879186481",
        "aid": "6879186481_38186",
        "original_caption": "a child with blond-hair holds a blue toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the blue toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                293,
                469
            ],
            "duration": 177,
            "token": {
                "<s0>": 29,
                "<e0>": 46
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38187",
        "original_caption": "there is a dog above a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dog above a child in blue clothes."
            }
        ],
        "meta": {
            "split": [
                900,
                1441
            ],
            "duration": 542,
            "token": {
                "<s0>": 60,
                "<e0>": 155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38188",
        "original_caption": "an adult is in front of a cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is in front of a cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 631,
                "<e0>": 869
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_38189",
        "original_caption": "a baby in orange clothes watches a pink toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in orange clothes watches a pink toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 0,
                "<e0>": 468
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3482621813",
        "aid": "3482621813_38190",
        "original_caption": "a penguin on the right is towards to a penguin on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards to the penguin on the left from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A penguin."
            }
        ],
        "meta": {
            "split": [
                255,
                592
            ],
            "duration": 338,
            "token": {
                "<s0>": 165,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5048454031",
        "aid": "5048454031_38191",
        "original_caption": "there is a gray bird behind an adult man in brown outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bird from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a gray bird behind an adult man in brown outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                659
            ],
            "duration": 660,
            "token": {
                "<s0>": 24,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38192",
        "original_caption": "a child wearing black pants is towards a silver sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing black pants is towards a silver sports ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 557,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7093500213",
        "aid": "7093500213_38193",
        "original_caption": "an adult in orange is in front of another adult in a shirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in orange is in front of another adult in a shirt."
            }
        ],
        "meta": {
            "split": [
                914,
                1109
            ],
            "duration": 196,
            "token": {
                "<s0>": 106,
                "<e0>": 186
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_38194",
        "original_caption": "a child in multi-color is towards an another child in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in multi-color is towards an another child in green happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 546,
                "<e0>": 629
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38195",
        "original_caption": "an adult in orange clothes is getting on a left bench in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in orange clothes is getting on a left bench in the gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                815
            ],
            "duration": 816,
            "token": {
                "<s0>": 752,
                "<e0>": 772
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38196",
        "original_caption": "an adult in orange clothes is getting on a left bench in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in orange clothes is getting on a left bench in the gym."
            }
        ],
        "meta": {
            "split": [
                815,
                943
            ],
            "duration": 129,
            "token": {
                "<s0>": 43,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38197",
        "original_caption": "an adult in orange clothes is getting on a left bench in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in orange clothes is getting on a left bench in the gym."
            }
        ],
        "meta": {
            "split": [
                943,
                1041
            ],
            "duration": 99,
            "token": {
                "<s0>": 63,
                "<e0>": 76
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38198",
        "original_caption": "an adult in orange clothes is getting on a left bench in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in orange clothes is getting on a left bench in the gym."
            }
        ],
        "meta": {
            "split": [
                1041,
                1323
            ],
            "duration": 283,
            "token": {
                "<s0>": 23,
                "<e0>": 40
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_38199",
        "original_caption": "an adult touches a cellphone in the car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult touches a cellphone in the car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 889,
                "<e0>": 1041
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047707188",
        "aid": "6047707188_38200",
        "original_caption": "an adult on the right watches an another adult on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult on the right watches an another adult on the left."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 52,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4828544178",
        "aid": "4828544178_38201",
        "original_caption": "an adult carries a backpack in the open air.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult carries a backpack in the open air."
            }
        ],
        "meta": {
            "split": [
                0,
                344
            ],
            "duration": 345,
            "token": {
                "<s0>": 289,
                "<e0>": 340
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_38202",
        "original_caption": "there is a snowboard beneath a child in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the snowboard from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a snowboard beneath a child in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 94,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_38203",
        "original_caption": "an adult is towards a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards a table at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 131,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6777058251",
        "aid": "6777058251_38204",
        "original_caption": "a child in a hat hugs a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in a hat hugs a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                1321
            ],
            "duration": 1322,
            "token": {
                "<s0>": 709,
                "<e0>": 1045
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_38205",
        "original_caption": "there is a blue watercraft beneath an adult on water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue watercraft beneath an adult on water."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 438
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38206",
        "original_caption": "there is an elephant towards another elephant outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is an elephant towards another elephant outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 720,
                "<e0>": 930
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4085549820",
        "aid": "4085549820_38207",
        "original_caption": "the white car is behind the black car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the white car is behind the black car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2100,
                "<e0>": 2190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3561394520",
        "aid": "3561394520_38208",
        "original_caption": "an adult with green hair touches another adult with black hair by the stairs.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with green hair touches another adult with black hair by the stairs happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1337
            ],
            "duration": 1338,
            "token": {
                "<s0>": 1091,
                "<e0>": 1150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3137412934",
        "aid": "3137412934_38209",
        "original_caption": "there is a monitor behind a child in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a monitor behind a child in white."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 0,
                "<e0>": 810
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3436660277",
        "aid": "3436660277_38210",
        "original_caption": "an adult in blue touches a baby with red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the baby with red hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                221
            ],
            "duration": 222,
            "token": {
                "<s0>": 101,
                "<e0>": 152
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3436660277",
        "aid": "3436660277_38211",
        "original_caption": "an adult in blue touches a baby with red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue touches a baby with red hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                221,
                388
            ],
            "duration": 168,
            "token": {
                "<s0>": 69,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3436660277",
        "aid": "3436660277_38212",
        "original_caption": "an adult in blue touches a baby with red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue touches a baby with red hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                388,
                677
            ],
            "duration": 290,
            "token": {
                "<s0>": 62,
                "<e0>": 136
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3436660277",
        "aid": "3436660277_38213",
        "original_caption": "an adult in blue touches a baby with red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the baby with red hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                677,
                883
            ],
            "duration": 207,
            "token": {
                "<s0>": 154,
                "<e0>": 199
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5091773135",
        "aid": "5091773135_38214",
        "original_caption": "an adult wearing glasses is behind the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing glasses is behind the guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1770
            ],
            "duration": 1771,
            "token": {
                "<s0>": 0,
                "<e0>": 1770
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38215",
        "original_caption": "there is a green ball behind an adult wearing earrings.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a green ball behind an adult wearing earrings."
            }
        ],
        "meta": {
            "split": [
                2586,
                2696
            ],
            "duration": 111,
            "token": {
                "<s0>": 79,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_38216",
        "original_caption": "there is a snowboard away from an adult in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the snowboard from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a snowboard away from an adult in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 12,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_38217",
        "original_caption": "an adult in gray watches another adult in green at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gray watches another adult in green at home."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 168,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38218",
        "original_caption": "there is a cake towards a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cake towards a sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38219",
        "original_caption": "a child is beneath another child on the slide.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the child on the slide from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 360,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4220838391",
        "aid": "4220838391_38220",
        "original_caption": "an adult in red clothes holds a crab.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in red clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A crab."
            }
        ],
        "meta": {
            "split": [
                0,
                2321
            ],
            "duration": 2322,
            "token": {
                "<s0>": 10,
                "<e0>": 761
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_38221",
        "original_caption": "a child in white clothes is above a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white clothes is above a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 120,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38222",
        "original_caption": "there is a hamster beneath another hamster on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a hamster beneath another hamster on the carpet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 420,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_38223",
        "original_caption": "a child opens a toy in a shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child open in the shop from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                930
            ],
            "duration": 931,
            "token": {
                "<s0>": 332,
                "<e0>": 362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_38224",
        "original_caption": "there is a chair beneath a child with blond-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 0,
                "<e0>": 781
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_38225",
        "original_caption": "an adult in green is behind another adult with striped clothes in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green is behind another adult with striped clothes in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                585,
                810
            ],
            "duration": 226,
            "token": {
                "<s0>": 135,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38226",
        "original_caption": "a child is away from a white laptop at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is away from a white laptop at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 150,
                "<e0>": 275
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_38227",
        "original_caption": "an adult woman in white watches another adult man in black at wedding.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in white watch at wedding from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                278,
                479
            ],
            "duration": 202,
            "token": {
                "<s0>": 27,
                "<e0>": 43
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_38228",
        "original_caption": "a child in red is in front of another child in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red is in front of another child in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 180,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_38229",
        "original_caption": "there is a watercraft beneath an adult in black and blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the watercraft beneath from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3716834575",
        "aid": "3716834575_38230",
        "original_caption": "an adult woman holds hand of a baby in pink on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman holds hand of a baby in pink on the beach."
            }
        ],
        "meta": {
            "split": [
                0,
                565
            ],
            "duration": 566,
            "token": {
                "<s0>": 0,
                "<e0>": 566
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_38231",
        "original_caption": "there is a cup above a big round black table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup above a big round black table."
            }
        ],
        "meta": {
            "split": [
                665,
                825
            ],
            "duration": 161,
            "token": {
                "<s0>": 18,
                "<e0>": 160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_38232",
        "original_caption": "a baby holds hand of a child in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby holds hand of a child in living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                425
            ],
            "duration": 426,
            "token": {
                "<s0>": 60,
                "<e0>": 350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_38233",
        "original_caption": "a baby holds hand of a child in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby holds hand of a child in living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                425,
                1197
            ],
            "duration": 773,
            "token": {
                "<s0>": 75,
                "<e0>": 773
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_38234",
        "original_caption": "a baby in red holds a bread on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby in red hold on the chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bread."
            }
        ],
        "meta": {
            "split": [
                0,
                145
            ],
            "duration": 146,
            "token": {
                "<s0>": 0,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_38235",
        "original_caption": "a baby in red holds a bread on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the bread on the chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                145,
                250
            ],
            "duration": 106,
            "token": {
                "<s0>": 24,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_38236",
        "original_caption": "a child in white clothes is next to a blue-orange bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child in white clothes next to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                693,
                1114
            ],
            "duration": 422,
            "token": {
                "<s0>": 207,
                "<e0>": 266
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_38237",
        "original_caption": "an adult wearing a plaid clothes pushes a child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a plaid clothes pushes a child in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 657,
                "<e0>": 675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38238",
        "original_caption": "there is a camera above a table in the restaurant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the camera in the restaurant from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 60,
                "<e0>": 1095
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3759767103",
        "aid": "3759767103_38239",
        "original_caption": "an adult man in black rides a skateboard outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black rides a skateboard outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                359
            ],
            "duration": 360,
            "token": {
                "<s0>": 216,
                "<e0>": 254
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4235961238",
        "aid": "4235961238_38240",
        "original_caption": "a child in gray bites a yellow toy in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in gray bites a yellow toy in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 78,
                "<e0>": 243
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4235961238",
        "aid": "4235961238_38241",
        "original_caption": "a child in gray bites a yellow toy in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in gray bites a yellow toy in a room."
            }
        ],
        "meta": {
            "split": [
                299,
                564
            ],
            "duration": 266,
            "token": {
                "<s0>": 57,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38242",
        "original_caption": "the adult in suit is behind the other adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in suit is behind the other adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1011
            ],
            "duration": 1012,
            "token": {
                "<s0>": 0,
                "<e0>": 923
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_38243",
        "original_caption": "an adult woman in pale blue is above a brown sofa in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in pale blue is above a brown sofa in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                4260
            ],
            "duration": 4261,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2567306378",
        "aid": "2567306378_38244",
        "original_caption": "an adult in white clothes is in front of another adult in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other adult in yellow clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                241
            ],
            "duration": 242,
            "token": {
                "<s0>": 122,
                "<e0>": 206
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_38245",
        "original_caption": "an adult siting on the stool watches a skateboard in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult siting on the stool watches a skateboard in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                341,
                986
            ],
            "duration": 646,
            "token": {
                "<s0>": 125,
                "<e0>": 277
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38246",
        "original_caption": "an adult women in red is towards another adult man outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women in red is towards another adult man outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1229,
                "<e0>": 1429
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_38247",
        "original_caption": "a child in gray is away an adult woman in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away the adult woman in gray from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 100,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_38248",
        "original_caption": "an adult in light gray is above a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in light gray is above a watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                2595,
                2696
            ],
            "duration": 102,
            "token": {
                "<s0>": 45,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_38249",
        "original_caption": "there is a dog biting a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog biting a toy on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1300
            ],
            "duration": 1301,
            "token": {
                "<s0>": 969,
                "<e0>": 1102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38250",
        "original_caption": "an adult in yellow is above a watercraft on a boat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in yellow on the boat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 40,
                "<e0>": 1469
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10294585855",
        "aid": "10294585855_38251",
        "original_caption": "an adult in grey clothes caresses a cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in grey clothes caresses a cat."
            }
        ],
        "meta": {
            "split": [
                0,
                218
            ],
            "duration": 219,
            "token": {
                "<s0>": 86,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10294585855",
        "aid": "10294585855_38252",
        "original_caption": "an adult in grey clothes caresses a cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in grey clothes caresses a cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                218,
                473
            ],
            "duration": 256,
            "token": {
                "<s0>": 33,
                "<e0>": 191
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10294585855",
        "aid": "10294585855_38253",
        "original_caption": "an adult in grey clothes caresses a cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in grey clothes caress from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                473,
                642
            ],
            "duration": 170,
            "token": {
                "<s0>": 65,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10294585855",
        "aid": "10294585855_38254",
        "original_caption": "an adult in grey clothes caresses a cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in grey clothes caress from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                642,
                865
            ],
            "duration": 224,
            "token": {
                "<s0>": 36,
                "<e0>": 120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10294585855",
        "aid": "10294585855_38255",
        "original_caption": "an adult in grey clothes caresses a cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in grey clothes caresses a cat."
            }
        ],
        "meta": {
            "split": [
                865,
                1457
            ],
            "duration": 593,
            "token": {
                "<s0>": 104,
                "<e0>": 446
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_38256",
        "original_caption": "an adult pats the guitar in the screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult pats the guitar in the screen."
            }
        ],
        "meta": {
            "split": [
                0,
                1955
            ],
            "duration": 1956,
            "token": {
                "<s0>": 0,
                "<e0>": 39
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_38257",
        "original_caption": "an adult in black clothes carries a beige backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black clothes carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 974,
                "<e0>": 1057
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6379905555",
        "aid": "6379905555_38258",
        "original_caption": "an adult in red clothes is next to a naked upper body adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes is next to a naked upper body adult."
            }
        ],
        "meta": {
            "split": [
                345,
                479
            ],
            "duration": 135,
            "token": {
                "<s0>": 15,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4729027639",
        "aid": "4729027639_38259",
        "original_caption": "the child in pink is towards the child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the child in pink is towards the child in red happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1005,
                2160
            ],
            "duration": 1156,
            "token": {
                "<s0>": 555,
                "<e0>": 645
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2573250257",
        "aid": "2573250257_38260",
        "original_caption": "an adult speaks to a child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult speak to on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 104,
                "<e0>": 230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38261",
        "original_caption": "there is a screen above an adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a screen above an adult in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_38262",
        "original_caption": "there is a bottle above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bottle above a table inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                102,
                611
            ],
            "duration": 510,
            "token": {
                "<s0>": 26,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38263",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat hits the white cat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                894
            ],
            "duration": 895,
            "token": {
                "<s0>": 823,
                "<e0>": 847
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38264",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the brown cat hit from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                894,
                986
            ],
            "duration": 93,
            "token": {
                "<s0>": 47,
                "<e0>": 62
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38265",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown cat hitting a white cat."
            }
        ],
        "meta": {
            "split": [
                986,
                1065
            ],
            "duration": 80,
            "token": {
                "<s0>": 30,
                "<e0>": 44
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38266",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown cat hitting a white cat."
            }
        ],
        "meta": {
            "split": [
                1065,
                1203
            ],
            "duration": 139,
            "token": {
                "<s0>": 35,
                "<e0>": 80
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38267",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown cat hitting a white cat."
            }
        ],
        "meta": {
            "split": [
                1203,
                1348
            ],
            "duration": 146,
            "token": {
                "<s0>": 59,
                "<e0>": 76
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38268",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown cat hitting a white cat."
            }
        ],
        "meta": {
            "split": [
                1348,
                1438
            ],
            "duration": 91,
            "token": {
                "<s0>": 70,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38269",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown cat hitting a white cat."
            }
        ],
        "meta": {
            "split": [
                1438,
                1634
            ],
            "duration": 197,
            "token": {
                "<s0>": 6,
                "<e0>": 138
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_38270",
        "original_caption": "there is a brown cat hitting a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown cat hitting a white cat."
            }
        ],
        "meta": {
            "split": [
                1634,
                2249
            ],
            "duration": 616,
            "token": {
                "<s0>": 59,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5048454031",
        "aid": "5048454031_38271",
        "original_caption": "an adult in blue clothes is next to another adult wearing a beige hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes is next to another adult wearing a beige hat."
            }
        ],
        "meta": {
            "split": [
                465,
                659
            ],
            "duration": 195,
            "token": {
                "<s0>": 15,
                "<e0>": 62
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2492711005",
        "aid": "2492711005_38272",
        "original_caption": "an adult feeds a baby in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult feeds a baby in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                496
            ],
            "duration": 497,
            "token": {
                "<s0>": 90,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2492711005",
        "aid": "2492711005_38273",
        "original_caption": "an adult feeds a baby in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult feeds a baby in the living room."
            }
        ],
        "meta": {
            "split": [
                496,
                1111
            ],
            "duration": 616,
            "token": {
                "<s0>": 226,
                "<e0>": 343
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_38274",
        "original_caption": "a child in blue is behind an adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue is behind an adult on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 360,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_38275",
        "original_caption": "a child wearing a dress is towards a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child wearing a dress is towards a table."
            }
        ],
        "meta": {
            "split": [
                535,
                1079
            ],
            "duration": 545,
            "token": {
                "<s0>": 386,
                "<e0>": 454
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_38276",
        "original_caption": "there is a white dog away a black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white dog away a black dog."
            }
        ],
        "meta": {
            "split": [
                0,
                2018
            ],
            "duration": 2019,
            "token": {
                "<s0>": 900,
                "<e0>": 967
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5302457137",
        "aid": "5302457137_38277",
        "original_caption": "there is a silver faucet above a silver sink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a silver faucet above a silver sink happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                521
            ],
            "duration": 522,
            "token": {
                "<s0>": 0,
                "<e0>": 521
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_38278",
        "original_caption": "there is a dog away another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog away another dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 50,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4367310435",
        "aid": "4367310435_38279",
        "original_caption": "an adult holds hand of a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult hold hand of in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                264
            ],
            "duration": 265,
            "token": {
                "<s0>": 171,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4367310435",
        "aid": "4367310435_38280",
        "original_caption": "a child in blue watches an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue watches an adult at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                139,
                264
            ],
            "duration": 126,
            "token": {
                "<s0>": 37,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3120535570",
        "aid": "3120535570_38281",
        "original_caption": "an adult leans on a table in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult lean on in the classroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                147
            ],
            "duration": 148,
            "token": {
                "<s0>": 0,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3802656968",
        "aid": "3802656968_38282",
        "original_caption": "a baby is behind an adult at the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby is behind an adult at the table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1481
            ],
            "duration": 1482,
            "token": {
                "<s0>": 273,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2815147671",
        "aid": "2815147671_38283",
        "original_caption": "the adult is next to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1233
            ],
            "duration": 1234,
            "token": {
                "<s0>": 600,
                "<e0>": 679
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38284",
        "original_caption": "an adult woman in purple presses a brown wooden bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in purple presses a brown wooden bench happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                967
            ],
            "duration": 968,
            "token": {
                "<s0>": 788,
                "<e0>": 823
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6997648741",
        "aid": "6997648741_38285",
        "original_caption": "an adult is towards another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the other adult on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                194
            ],
            "duration": 195,
            "token": {
                "<s0>": 155,
                "<e0>": 194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4825511158",
        "aid": "4825511158_38286",
        "original_caption": "there is adult in gray using a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is adult in gray using a cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                494
            ],
            "duration": 495,
            "token": {
                "<s0>": 27,
                "<e0>": 263
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38287",
        "original_caption": "a child leans on a table next to the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child leans on a table next to the chair."
            }
        ],
        "meta": {
            "split": [
                0,
                910
            ],
            "duration": 911,
            "token": {
                "<s0>": 674,
                "<e0>": 864
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38288",
        "original_caption": "a child leans on a table next to the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child lean on next to the chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                910,
                1349
            ],
            "duration": 440,
            "token": {
                "<s0>": 46,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875494562",
        "aid": "5875494562_38289",
        "original_caption": "an adult caresses a brown cat on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho caresses the brown cat on the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                994
            ],
            "duration": 995,
            "token": {
                "<s0>": 202,
                "<e0>": 863
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4866672246",
        "aid": "4866672246_38290",
        "original_caption": "there is a brown dog biting another dog in a box.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown dog biting another dog in a box happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                97,
                1259
            ],
            "duration": 1163,
            "token": {
                "<s0>": 12,
                "<e0>": 35
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4729027639",
        "aid": "4729027639_38291",
        "original_caption": "a child in red is in front of another child in pink in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the child in red in the classroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1395,
                2160
            ],
            "duration": 766,
            "token": {
                "<s0>": 165,
                "<e0>": 315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2942623423",
        "aid": "2942623423_38292",
        "original_caption": "an adult is towards another adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards another adult in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                448,
                734
            ],
            "duration": 287,
            "token": {
                "<s0>": 59,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5270774640",
        "aid": "5270774640_38293",
        "original_caption": "an adult woman in red is behind a white gray dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the white gray dog from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                222
            ],
            "duration": 223,
            "token": {
                "<s0>": 0,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_38294",
        "original_caption": "a child in pink is above a black chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink is above a black chair in the room."
            }
        ],
        "meta": {
            "split": [
                1222,
                2225
            ],
            "duration": 1004,
            "token": {
                "<s0>": 54,
                "<e0>": 307
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38295",
        "original_caption": "a child in wathet blue is towards a silver sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in wathet blue is towards a silver sports ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                314,
                595
            ],
            "duration": 282,
            "token": {
                "<s0>": 46,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_38296",
        "original_caption": "there is a table beneath a bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a bottle at home."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 30,
                "<e0>": 492
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38297",
        "original_caption": "there is a hamster on the right beneath another rat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a hamster on the right beneath another rat on the left happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1140,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9124536624",
        "aid": "9124536624_38298",
        "original_caption": "an adult wearing a black hat waves a bat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a black hat waves a bat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                100
            ],
            "duration": 101,
            "token": {
                "<s0>": 48,
                "<e0>": 73
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6813862571",
        "aid": "6813862571_38299",
        "original_caption": "an adult in brown clothes speaks to another adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in brown clothes speaks to another adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1754
            ],
            "duration": 1755,
            "token": {
                "<s0>": 691,
                "<e0>": 731
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11841865713",
        "aid": "11841865713_38300",
        "original_caption": "an adult in yellow hugs a sleeping baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hugs the sleeping baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 0,
                "<e0>": 675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11162376856",
        "aid": "11162376856_38301",
        "original_caption": "an older child watches a younger child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An older child watches a younger child on the grass."
            }
        ],
        "meta": {
            "split": [
                393,
                511
            ],
            "duration": 119,
            "token": {
                "<s0>": 12,
                "<e0>": 119
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_38302",
        "original_caption": "there is a white pig in front of an adult woman in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white pig in front of an adult woman in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                495,
                869
            ],
            "duration": 375,
            "token": {
                "<s0>": 45,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3457759630",
        "aid": "3457759630_38303",
        "original_caption": "there is a toy next to another toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy next to another toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                429,
                1388
            ],
            "duration": 960,
            "token": {
                "<s0>": 121,
                "<e0>": 409
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38304",
        "original_caption": "an adult with jeans is towards a sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with jeans is towards a sports ball in the room."
            }
        ],
        "meta": {
            "split": [
                345,
                595
            ],
            "duration": 251,
            "token": {
                "<s0>": 15,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_38305",
        "original_caption": "an adult in blue pats a black dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue pats a black dog outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1561
            ],
            "duration": 1562,
            "token": {
                "<s0>": 1491,
                "<e0>": 1551
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_38306",
        "original_caption": "an adult in blue pats a black dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue pats a black dog outdoors."
            }
        ],
        "meta": {
            "split": [
                1561,
                1769
            ],
            "duration": 209,
            "token": {
                "<s0>": 11,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2513630909",
        "aid": "2513630909_38307",
        "original_caption": "there is a black dog beneath a white table on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black dog beneath a white table on the floor."
            }
        ],
        "meta": {
            "split": [
                855,
                1456
            ],
            "duration": 602,
            "token": {
                "<s0>": 45,
                "<e0>": 555
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_38308",
        "original_caption": "an adult holds a bottle in the karaoke room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult hold in the karaoke room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                611
            ],
            "duration": 612,
            "token": {
                "<s0>": 63,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4462691651",
        "aid": "4462691651_38309",
        "original_caption": "an adult wearing a hat is behind another adult holding a mike.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a hat is behind another adult holding a mike happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                749
            ],
            "duration": 750,
            "token": {
                "<s0>": 0,
                "<e0>": 750
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38310",
        "original_caption": "there is a car next to a bicycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the car from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a car next to a bicycle on the ground."
            }
        ],
        "meta": {
            "split": [
                90,
                371
            ],
            "duration": 282,
            "token": {
                "<s0>": 4,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6236608754",
        "aid": "6236608754_38311",
        "original_caption": "a child is in front of an adult wearing white socks on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of an adult wearing white socks on the carpet."
            }
        ],
        "meta": {
            "split": [
                0,
                739
            ],
            "duration": 740,
            "token": {
                "<s0>": 240,
                "<e0>": 740
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_38312",
        "original_caption": "there is a snowboard beneath a child in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A snowboard."
            }
        ],
        "meta": {
            "split": [
                645,
                818
            ],
            "duration": 174,
            "token": {
                "<s0>": 47,
                "<e0>": 164
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8068324821",
        "aid": "8068324821_38313",
        "original_caption": "there is a bicycle beneath a child on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bicycle beneath a child on the road."
            }
        ],
        "meta": {
            "split": [
                286,
                469
            ],
            "duration": 184,
            "token": {
                "<s0>": 27,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5504745801",
        "aid": "5504745801_38314",
        "original_caption": "a child in pale purple is above a black ski.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pale purple is above a black ski happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                203
            ],
            "duration": 204,
            "token": {
                "<s0>": 0,
                "<e0>": 204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_38315",
        "original_caption": "there is a white goat in front of a black sheep.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the black sheep from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sheep/goat."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 699,
                "<e0>": 749
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38316",
        "original_caption": "there is a sports ball above a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sports ball above a cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 601
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38317",
        "original_caption": "there is a stool in brown beneath a black camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a stool in brown beneath a black camera."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 678,
                "<e0>": 780
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7290684468",
        "aid": "7290684468_38318",
        "original_caption": "there is a black dog towards a blue toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is towards the blue toy at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                569
            ],
            "duration": 570,
            "token": {
                "<s0>": 503,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7308772034",
        "aid": "7308772034_38319",
        "original_caption": "an adult on the right speaks to an adult in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult on the right speaks to an adult in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                2456
            ],
            "duration": 2457,
            "token": {
                "<s0>": 2377,
                "<e0>": 2439
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_38320",
        "original_caption": "adults in long-sleeved clothes speak to adults in short-sleeved clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adults in long-sleeved clothes speak to adults in short-sleeved clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1877
            ],
            "duration": 1878,
            "token": {
                "<s0>": 1667,
                "<e0>": 1841
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_38321",
        "original_caption": "a child woman in white is in front of another child by the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child woman in white is in front of another child by the street."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 180,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10304757716",
        "aid": "10304757716_38322",
        "original_caption": "a baby in green clothes gets on a stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in green clothes gets on a stool."
            }
        ],
        "meta": {
            "split": [
                0,
                1622
            ],
            "duration": 1623,
            "token": {
                "<s0>": 0,
                "<e0>": 137
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_38323",
        "original_caption": "an adult in light yellow lifts a child in orange outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in light yellow lifts a child in orange outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 89,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6220387865",
        "aid": "6220387865_38324",
        "original_caption": "there is a cup next to an adult in blue in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the adult in blue in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                900
            ],
            "duration": 901,
            "token": {
                "<s0>": 801,
                "<e0>": 869
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38325",
        "original_caption": "a child in pink is towards an adult man in gray outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink is towards an adult man in gray outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1152,
                "<e0>": 1229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_38326",
        "original_caption": "a baby in yellow is above a purple sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby in yellow in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 120,
                "<e0>": 750
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_38327",
        "original_caption": "there is a crocodile in front of a bird by the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a crocodile in front of a bird by the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 360,
                "<e0>": 600
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3783730077",
        "aid": "3783730077_38328",
        "original_caption": "there is the guitar next to another guitar outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is the guitar next to another guitar outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                963
            ],
            "duration": 964,
            "token": {
                "<s0>": 180,
                "<e0>": 964
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_38329",
        "original_caption": "a child in white is behind another child in red outside the house.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child in white outside the house from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 0,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_38330",
        "original_caption": "an adult in blue uses a laptop at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue uses a laptop at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 1682,
                "<e0>": 1757
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_38331",
        "original_caption": "an adult is next to another adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to another adult on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1955
            ],
            "duration": 1956,
            "token": {
                "<s0>": 496,
                "<e0>": 1949
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3479140840",
        "aid": "3479140840_38332",
        "original_caption": "an adult in red is away from another adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red is away from another adult at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                199
            ],
            "duration": 200,
            "token": {
                "<s0>": 150,
                "<e0>": 200
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_38333",
        "original_caption": "there is a dog getting on a motorcycle out of room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat gets on the motorcycle out of room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 187,
                "<e0>": 207
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_38334",
        "original_caption": "an adult in green rides a watercraft in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in green ride  in the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4827728106",
        "aid": "4827728106_38335",
        "original_caption": "an adult holds a toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a toy at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                235
            ],
            "duration": 236,
            "token": {
                "<s0>": 0,
                "<e0>": 40
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38336",
        "original_caption": "an adult in white clothes is towards another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult in white clothes towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                585,
                1011
            ],
            "duration": 427,
            "token": {
                "<s0>": 75,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_38337",
        "original_caption": "there is a gray cat releasing a gray cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a gray cat releasing a gray cat."
            }
        ],
        "meta": {
            "split": [
                0,
                923
            ],
            "duration": 924,
            "token": {
                "<s0>": 172,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114352772",
        "aid": "8114352772_38338",
        "original_caption": "an adult in black holds a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black holds a toy in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                449
            ],
            "duration": 450,
            "token": {
                "<s0>": 202,
                "<e0>": 285
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38339",
        "original_caption": "a toy is next to the another toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to by the toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                1283,
                1385
            ],
            "duration": 103,
            "token": {
                "<s0>": 10,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7803526566",
        "aid": "7803526566_38340",
        "original_caption": "a baby touches an adult man in blue in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby touches an adult man in blue in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                156
            ],
            "duration": 157,
            "token": {
                "<s0>": 0,
                "<e0>": 45
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7803526566",
        "aid": "7803526566_38341",
        "original_caption": "a baby touches an adult man in blue in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby touches an adult man in blue in a room."
            }
        ],
        "meta": {
            "split": [
                156,
                360
            ],
            "duration": 205,
            "token": {
                "<s0>": 112,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7803526566",
        "aid": "7803526566_38342",
        "original_caption": "a baby touches an adult man in blue in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby touches an adult man in blue in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                360,
                748
            ],
            "duration": 389,
            "token": {
                "<s0>": 15,
                "<e0>": 130
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4322158071",
        "aid": "4322158071_38343",
        "original_caption": "the adult in a black hat is pulling the snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in a black hat is pulling the snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                314
            ],
            "duration": 315,
            "token": {
                "<s0>": 0,
                "<e0>": 315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38344",
        "original_caption": "a girl child watches an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A girl child watches an adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                398,
                518
            ],
            "duration": 121,
            "token": {
                "<s0>": 36,
                "<e0>": 83
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2407844647",
        "aid": "2407844647_38345",
        "original_caption": "an adult watches another adult on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult watches another adult on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                953
            ],
            "duration": 954,
            "token": {
                "<s0>": 669,
                "<e0>": 692
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_38346",
        "original_caption": "an adult in blue clothes rides a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes rides a watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1136
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_38347",
        "original_caption": "a child touches another child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child touch on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 742,
                "<e0>": 764
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38348",
        "original_caption": "there is a hamster licking an adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the hamster lick on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 2034,
                "<e0>": 2086
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2867108011",
        "aid": "2867108011_38349",
        "original_caption": "a child in light blue clothes is in front of another child with blond-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the child in light blue clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 0,
                "<e0>": 870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2573250257",
        "aid": "2573250257_38350",
        "original_caption": "an adult in red clothes uses a camera on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in red clothes use on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A camera."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 386,
                "<e0>": 433
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38351",
        "original_caption": "a child shakes hand with a white dog in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child shakes hand with a white dog in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                396
            ],
            "duration": 397,
            "token": {
                "<s0>": 59,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38352",
        "original_caption": "a child shakes hand with a white dog in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child shakes hand with a white dog in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                396,
                1275
            ],
            "duration": 880,
            "token": {
                "<s0>": 275,
                "<e0>": 350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5810255954",
        "aid": "5810255954_38353",
        "original_caption": "a child shakes hand with a white dog in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child shakes hand with a white dog in the living room."
            }
        ],
        "meta": {
            "split": [
                1275,
                2595
            ],
            "duration": 1321,
            "token": {
                "<s0>": 530,
                "<e0>": 606
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_38354",
        "original_caption": "an adult is away from a child on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away from a child on the street."
            }
        ],
        "meta": {
            "split": [
                0,
                1151
            ],
            "duration": 1152,
            "token": {
                "<s0>": 960,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13503103965",
        "aid": "13503103965_38355",
        "original_caption": "a child in the middle holds hand of another child on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in the middle holds hand of another child on the left."
            }
        ],
        "meta": {
            "split": [
                0,
                330
            ],
            "duration": 331,
            "token": {
                "<s0>": 0,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3862213653",
        "aid": "3862213653_38356",
        "original_caption": "an adult siting on the stool watches a laptop in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult siting on the stool watches a laptop in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                83,
                275
            ],
            "duration": 193,
            "token": {
                "<s0>": 50,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_38357",
        "original_caption": "a child in red rides a red bicycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red rides a red bicycle on the ground."
            }
        ],
        "meta": {
            "split": [
                79,
                411
            ],
            "duration": 333,
            "token": {
                "<s0>": 42,
                "<e0>": 211
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6997648741",
        "aid": "6997648741_38358",
        "original_caption": "adult watching at an adult wearing a green hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see adult watching at an adult wearing a green hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                194
            ],
            "duration": 195,
            "token": {
                "<s0>": 0,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5994899092",
        "aid": "5994899092_38359",
        "original_caption": "a child in blue short grabs a surfboard purple in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho grabs the surfboard purple in the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 1064,
                "<e0>": 1109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38360",
        "original_caption": "there is a screen above an adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a screen above an adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38361",
        "original_caption": "an adult woman in black uses a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult woman in black use from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                669
            ],
            "duration": 670,
            "token": {
                "<s0>": 132,
                "<e0>": 593
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38362",
        "original_caption": "an adult woman in black uses a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black uses a black cellphone."
            }
        ],
        "meta": {
            "split": [
                669,
                858
            ],
            "duration": 190,
            "token": {
                "<s0>": 77,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38363",
        "original_caption": "an adult woman in black uses a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black uses a black cellphone."
            }
        ],
        "meta": {
            "split": [
                858,
                1021
            ],
            "duration": 164,
            "token": {
                "<s0>": 67,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38364",
        "original_caption": "an adult woman in black uses a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black uses a black cellphone."
            }
        ],
        "meta": {
            "split": [
                1021,
                1441
            ],
            "duration": 421,
            "token": {
                "<s0>": 16,
                "<e0>": 55
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_38365",
        "original_caption": "an adult in gray is above a wooden watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gray is above a wooden watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38366",
        "original_caption": "an adult in blue lifts a child in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho lifts the child in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 539,
                "<e0>": 561
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_38367",
        "original_caption": "a child is above a snowboard in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38368",
        "original_caption": "a child wearing a hat is away from a gray car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child wearing a hat is away from a gray car."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 0,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38369",
        "original_caption": "a child wearing blue pants grabs a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child wearing blue pants grab from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 139,
                "<e0>": 154
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9250740172",
        "aid": "9250740172_38370",
        "original_caption": "a baby in pink clothes leans on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in pink clothes leans on a sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                800
            ],
            "duration": 801,
            "token": {
                "<s0>": 379,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9250740172",
        "aid": "9250740172_38371",
        "original_caption": "a baby in pink clothes leans on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in pink clothes leans on a sofa."
            }
        ],
        "meta": {
            "split": [
                800,
                2001
            ],
            "duration": 1202,
            "token": {
                "<s0>": 171,
                "<e0>": 818
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38372",
        "original_caption": "an adult watches a child on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the child on the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1114,
                1441
            ],
            "duration": 328,
            "token": {
                "<s0>": 154,
                "<e0>": 169
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5994365464",
        "aid": "5994365464_38373",
        "original_caption": "a baby in black clothes is next to a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in black clothes is next to a yellow toy."
            }
        ],
        "meta": {
            "split": [
                1698,
                2696
            ],
            "duration": 999,
            "token": {
                "<s0>": 86,
                "<e0>": 998
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3082591243",
        "aid": "3082591243_38374",
        "original_caption": "a baby in orange watches a child in blue in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the child in blue in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1892
            ],
            "duration": 1893,
            "token": {
                "<s0>": 31,
                "<e0>": 154
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38375",
        "original_caption": "there is a watercraft beneath an adult on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a watercraft beneath an adult on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 486,
                "<e0>": 1393
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_38376",
        "original_caption": "there is a sofa next to the toy in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sofa next to the toy in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                1868
            ],
            "duration": 1869,
            "token": {
                "<s0>": 0,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38377",
        "original_caption": "there is a cup above a table outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the cup outside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_38378",
        "original_caption": "there is a cake next to a dish inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cake next to a dish inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38379",
        "original_caption": "adult wearing an orange suit hugs the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "Adult wearing an orange suit hugs the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 390,
                "<e0>": 651
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38380",
        "original_caption": "adult wearing an orange suit hugs the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "Adult wearing an orange suit hugs the baby."
            }
        ],
        "meta": {
            "split": [
                666,
                2696
            ],
            "duration": 2031,
            "token": {
                "<s0>": 15,
                "<e0>": 2031
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6997648741",
        "aid": "6997648741_38381",
        "original_caption": "an adult in blue is towards another adult with white helmet on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue is towards another adult with white helmet on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                194
            ],
            "duration": 195,
            "token": {
                "<s0>": 155,
                "<e0>": 194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_38382",
        "original_caption": "an adult plays the guitar inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult plays the guitar inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1229
            ],
            "duration": 1230,
            "token": {
                "<s0>": 161,
                "<e0>": 1135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_38383",
        "original_caption": "an adult plays the guitar inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult plays the guitar inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1229,
                1587
            ],
            "duration": 359,
            "token": {
                "<s0>": 94,
                "<e0>": 293
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_38384",
        "original_caption": "an adult plays the guitar inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult plays the guitar inside a room."
            }
        ],
        "meta": {
            "split": [
                1587,
                1788
            ],
            "duration": 202,
            "token": {
                "<s0>": 66,
                "<e0>": 202
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_38385",
        "original_caption": "a child watches an adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child watches an adult inside a room."
            }
        ],
        "meta": {
            "split": [
                425,
                1063
            ],
            "duration": 639,
            "token": {
                "<s0>": 175,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_38386",
        "original_caption": "an adult in a sunglasses is above a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the watercraft from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                749,
                2186
            ],
            "duration": 1438,
            "token": {
                "<s0>": 56,
                "<e0>": 167
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9345245716",
        "aid": "9345245716_38387",
        "original_caption": "there is a black backpack behind an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black backpack behind an adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                485
            ],
            "duration": 486,
            "token": {
                "<s0>": 219,
                "<e0>": 425
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_38388",
        "original_caption": "there is a bottle above a table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bottle above a table in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                493,
                611
            ],
            "duration": 119,
            "token": {
                "<s0>": 6,
                "<e0>": 70
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3855730364",
        "aid": "3855730364_38389",
        "original_caption": "there is a fish in front of another fish under water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the fish from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a fish in front of another fish under water."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 20,
                "<e0>": 269
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38390",
        "original_caption": "there is an elephant behind another elephant by the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the elephant behind by the river from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An elephant."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 900,
                "<e0>": 1194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_38391",
        "original_caption": "there is a table in blue beneath a black chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table in blue beneath a black chair at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1653
            ],
            "duration": 1654,
            "token": {
                "<s0>": 1500,
                "<e0>": 1650
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38392",
        "original_caption": "there is a black hamster above another rat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black hamster above another rat on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 300,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3137412934",
        "aid": "3137412934_38393",
        "original_caption": "a child in white lifts a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white lifts a cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 207,
                "<e0>": 235
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3943678441",
        "aid": "3943678441_38394",
        "original_caption": "an adult in striped clothes is away a black backpack outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in striped clothes is away a black backpack outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 288,
                "<e0>": 382
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_38395",
        "original_caption": "there is a white baby seat beneath a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white baby seat beneath a baby at home."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 0,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38396",
        "original_caption": "a child is beneath a dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the child at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                900,
                1441
            ],
            "duration": 542,
            "token": {
                "<s0>": 60,
                "<e0>": 155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_38397",
        "original_caption": "the adult with a camera is behind the horse.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the horse from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_38398",
        "original_caption": "a child wearing a diaper holds the hand of a baby beside the stair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing a diaper holds the hand of a baby beside the stair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                421
            ],
            "duration": 422,
            "token": {
                "<s0>": 47,
                "<e0>": 352
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_38399",
        "original_caption": "a child wearing a diaper holds the hand of a baby beside the stair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing a diaper holds the hand of a baby beside the stair."
            }
        ],
        "meta": {
            "split": [
                421,
                1197
            ],
            "duration": 777,
            "token": {
                "<s0>": 70,
                "<e0>": 777
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4063402763",
        "aid": "4063402763_38400",
        "original_caption": "a baby leans on a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on a baby seat in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                790
            ],
            "duration": 791,
            "token": {
                "<s0>": 0,
                "<e0>": 791
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_38401",
        "original_caption": "an adult in white clothes rides a watercraft on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes rides a watercraft on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9346210096",
        "aid": "9346210096_38402",
        "original_caption": "a child watches another child in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child watches another child in the classroom."
            }
        ],
        "meta": {
            "split": [
                242,
                479
            ],
            "duration": 238,
            "token": {
                "<s0>": 179,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_38403",
        "original_caption": "a baby wearing green pants holds a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby wearing green pants holds a brown cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2144
            ],
            "duration": 2145,
            "token": {
                "<s0>": 102,
                "<e0>": 685
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_38404",
        "original_caption": "the pink toy is away from the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The pink toy is away from the fruits."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2150,
                "<e0>": 2206
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_38405",
        "original_caption": "an adult man in black is next to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is next to another adult man in black."
            }
        ],
        "meta": {
            "split": [
                1719,
                2698
            ],
            "duration": 980,
            "token": {
                "<s0>": 4,
                "<e0>": 979
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5296127747",
        "aid": "5296127747_38406",
        "original_caption": "an adult in grey clothes hugs another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in grey clothes hugs another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 107,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3078133866",
        "aid": "3078133866_38407",
        "original_caption": "a baby leans on an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1037
            ],
            "duration": 1038,
            "token": {
                "<s0>": 0,
                "<e0>": 1016
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3078133866",
        "aid": "3078133866_38408",
        "original_caption": "a baby leans on an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the adult in white clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                1037,
                1438
            ],
            "duration": 402,
            "token": {
                "<s0>": 21,
                "<e0>": 402
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2718262890",
        "aid": "2718262890_38409",
        "original_caption": "an adult siting on the ground is in front of another adult near a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult siting on the ground is in front of another adult near a table."
            }
        ],
        "meta": {
            "split": [
                0,
                467
            ],
            "duration": 468,
            "token": {
                "<s0>": 328,
                "<e0>": 413
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6501432541",
        "aid": "6501432541_38410",
        "original_caption": "there is a faucet above a sink inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a faucet above a sink inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                173
            ],
            "duration": 174,
            "token": {
                "<s0>": 0,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6086390405",
        "aid": "6086390405_38411",
        "original_caption": "there is a bicycle with only one wheel beneath a child in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bicycle with only one wheel beneath a child in orange."
            }
        ],
        "meta": {
            "split": [
                0,
                1301
            ],
            "duration": 1302,
            "token": {
                "<s0>": 0,
                "<e0>": 668
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_38412",
        "original_caption": "a child in a pink shirt is away from an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in a pink shirt is away from an adult."
            }
        ],
        "meta": {
            "split": [
                705,
                959
            ],
            "duration": 255,
            "token": {
                "<s0>": 75,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318165684",
        "aid": "5318165684_38413",
        "original_caption": "a shortest adult kicks another adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A shortest adult kicks another adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                587
            ],
            "duration": 588,
            "token": {
                "<s0>": 0,
                "<e0>": 588
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38414",
        "original_caption": "there is a blue ball above a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue ball above a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 459,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7907275512",
        "aid": "7907275512_38415",
        "original_caption": "a child in black clothes is above a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black clothes is above a bicycle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1090,
                1715
            ],
            "duration": 626,
            "token": {
                "<s0>": 110,
                "<e0>": 408
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_38416",
        "original_caption": "there is a green toy behind of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a green toy behind of the adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1231,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_38417",
        "original_caption": "a child in black holds a toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black holds a toy at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 359,
                "<e0>": 456
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4184884354",
        "aid": "4184884354_38418",
        "original_caption": "a child in black is away a red stool in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black is away a red stool in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1502
            ],
            "duration": 1503,
            "token": {
                "<s0>": 0,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_38419",
        "original_caption": "an adult man in black speaks to another adult in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult in the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 193,
                "<e0>": 254
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8315788918",
        "aid": "8315788918_38420",
        "original_caption": "the adult is holding hands of the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is holding hands of the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                878
            ],
            "duration": 879,
            "token": {
                "<s0>": 0,
                "<e0>": 507
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8315788918",
        "aid": "8315788918_38421",
        "original_caption": "the adult is holding hands of the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is holding hands of the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                878,
                1576
            ],
            "duration": 699,
            "token": {
                "<s0>": 371,
                "<e0>": 577
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38422",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                108
            ],
            "duration": 109,
            "token": {
                "<s0>": 16,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38423",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                108,
                212
            ],
            "duration": 105,
            "token": {
                "<s0>": 10,
                "<e0>": 94
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38424",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                212,
                311
            ],
            "duration": 100,
            "token": {
                "<s0>": 10,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38425",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                311,
                406
            ],
            "duration": 96,
            "token": {
                "<s0>": 33,
                "<e0>": 86
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38426",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a toy on the beach."
            }
        ],
        "meta": {
            "split": [
                406,
                689
            ],
            "duration": 284,
            "token": {
                "<s0>": 9,
                "<e0>": 120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38427",
        "original_caption": "a child holds a toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holds a toy on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                689,
                1385
            ],
            "duration": 697,
            "token": {
                "<s0>": 164,
                "<e0>": 197
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_38428",
        "original_caption": "an adult in white clothes holds the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes holds the fruits."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 423
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_38429",
        "original_caption": "a child on the left hugs a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hugs the ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1246
            ],
            "duration": 1247,
            "token": {
                "<s0>": 1221,
                "<e0>": 1247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6086390405",
        "aid": "6086390405_38430",
        "original_caption": "a child in orange is above a bicycle outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the bicycle outdoor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1301
            ],
            "duration": 1302,
            "token": {
                "<s0>": 0,
                "<e0>": 668
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_38431",
        "original_caption": "a baby in white clothes leans on a white baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes leans on a white baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                564
            ],
            "duration": 565,
            "token": {
                "<s0>": 0,
                "<e0>": 528
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_38432",
        "original_caption": "a baby in white clothes leans on a white baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white clothes leans on a white baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                564,
                1470
            ],
            "duration": 907,
            "token": {
                "<s0>": 37,
                "<e0>": 907
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_38433",
        "original_caption": "there is a red toy next to a baby in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a red toy next to a baby in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                998
            ],
            "duration": 999,
            "token": {
                "<s0>": 600,
                "<e0>": 796
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38434",
        "original_caption": "an adult near a cup is in front of another adult holding a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult near a cup is in front of another adult holding a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3865853855",
        "aid": "3865853855_38435",
        "original_caption": "a child in striped clothes holds a green toy on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in striped clothes holds a green toy on the beach."
            }
        ],
        "meta": {
            "split": [
                0,
                701
            ],
            "duration": 702,
            "token": {
                "<s0>": 0,
                "<e0>": 702
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_38436",
        "original_caption": "there is a cup above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table inside a room."
            }
        ],
        "meta": {
            "split": [
                443,
                825
            ],
            "duration": 383,
            "token": {
                "<s0>": 37,
                "<e0>": 383
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2527311673",
        "aid": "2527311673_38437",
        "original_caption": "a child is in front of another child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of another child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                277
            ],
            "duration": 278,
            "token": {
                "<s0>": 0,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_38438",
        "original_caption": "there is a goat towards a pig on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a goat towards a pig on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                447,
                869
            ],
            "duration": 423,
            "token": {
                "<s0>": 93,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_38439",
        "original_caption": "an adult photoing is beneath the adult in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult photoing is beneath the adult in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 540,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_38440",
        "original_caption": "a child hugs an adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child hugs an adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1145
            ],
            "duration": 1146,
            "token": {
                "<s0>": 146,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_38441",
        "original_caption": "an adult wearing a green scarf is in front of another adult in gray clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a green scarf is in front of another adult in gray clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 281,
                "<e0>": 557
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_38442",
        "original_caption": "an adult in white clothes is in front of a child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes is in front of a child in red clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 0,
                "<e0>": 375
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_38443",
        "original_caption": "there is a chair next to a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                1203,
                2225
            ],
            "duration": 1023,
            "token": {
                "<s0>": 94,
                "<e0>": 326
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3937218319",
        "aid": "3937218319_38444",
        "original_caption": "there is a dog in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dog in front of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1315
            ],
            "duration": 1316,
            "token": {
                "<s0>": 0,
                "<e0>": 1316
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38445",
        "original_caption": "there is a scooter beneath a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A scooter."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 0,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6997433070",
        "aid": "6997433070_38446",
        "original_caption": "a child in yellow is in front of an adult in the yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult in the yard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                113
            ],
            "duration": 114,
            "token": {
                "<s0>": 0,
                "<e0>": 114
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7465682132",
        "aid": "7465682132_38447",
        "original_caption": "a child with red hat lifts another child with white hat in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho lifts the other child with white hat in the pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 89,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_38448",
        "original_caption": "there is a golden chair behind an adult woman in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the golden chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 420,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_38449",
        "original_caption": "there is sofa beneath the child in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sofa from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is sofa beneath the child in gray."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 480,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38450",
        "original_caption": "an adult in purple gets on a bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in purple gets on a bench in a gym."
            }
        ],
        "meta": {
            "split": [
                0,
                803
            ],
            "duration": 804,
            "token": {
                "<s0>": 733,
                "<e0>": 766
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38451",
        "original_caption": "an adult in purple gets on a bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in purple gets on a bench in a gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                803,
                927
            ],
            "duration": 125,
            "token": {
                "<s0>": 38,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38452",
        "original_caption": "an adult in purple gets on a bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in purple get on in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bench."
            }
        ],
        "meta": {
            "split": [
                927,
                1030
            ],
            "duration": 104,
            "token": {
                "<s0>": 57,
                "<e0>": 87
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38453",
        "original_caption": "an adult in purple gets on a bench in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in purple gets on a bench in a gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1030,
                1323
            ],
            "duration": 294,
            "token": {
                "<s0>": 16,
                "<e0>": 46
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38454",
        "original_caption": "an adult in gray pants leans on a stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gray pants leans on a stool."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 544,
                "<e0>": 840
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38455",
        "original_caption": "there is a white cake towards a black cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cake from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white cake towards a black cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 601
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4715441335",
        "aid": "4715441335_38456",
        "original_caption": "the baby presses the toy on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The baby presses the toy on the chair."
            }
        ],
        "meta": {
            "split": [
                1157,
                1733
            ],
            "duration": 577,
            "token": {
                "<s0>": 379,
                "<e0>": 423
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6542785403",
        "aid": "6542785403_38457",
        "original_caption": "an adult with red clothes is away an another adult with black vent.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with red clothes is away an another adult with black vent happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                530
            ],
            "duration": 531,
            "token": {
                "<s0>": 0,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38458",
        "original_caption": "there is a skateboard towards an another skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a skateboard towards an another skateboard in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 96,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_38459",
        "original_caption": "an adult in green clothes holds a baby on sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes holds a baby on sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                279
            ],
            "duration": 280,
            "token": {
                "<s0>": 0,
                "<e0>": 258
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_38460",
        "original_caption": "an adult in green clothes holds a baby on sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes holds a baby on sofa."
            }
        ],
        "meta": {
            "split": [
                279,
                474
            ],
            "duration": 196,
            "token": {
                "<s0>": 22,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_38461",
        "original_caption": "an adult in red clothes is beneath a blue backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes is beneath a blue backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 120,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_38462",
        "original_caption": "an adult man in gray is behind a guitar in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in gray is behind a guitar in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_38463",
        "original_caption": "there are a red fruits towards a toy in the shape of a bear.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There are a red fruits towards a toy in the shape of a bear."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2150,
                "<e0>": 2225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_38464",
        "original_caption": "an adult in beige clothes rides a ski.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in beige clothes rides a ski happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 342,
                "<e0>": 382
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_38465",
        "original_caption": "an adult is next to another adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult next to at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 281,
                "<e0>": 557
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7246410056",
        "aid": "7246410056_38466",
        "original_caption": "an adult lifts a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho lifts the child in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1212
            ],
            "duration": 1213,
            "token": {
                "<s0>": 20,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_38467",
        "original_caption": "there is a black table beneath a clear bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the clear bottle at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 451
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3471851958",
        "aid": "3471851958_38468",
        "original_caption": "an adult man in white is speaking to adult man in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white is speaking to adult man in red happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                179
            ],
            "duration": 180,
            "token": {
                "<s0>": 92,
                "<e0>": 147
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4569009647",
        "aid": "4569009647_38469",
        "original_caption": "an adult in red clothes is next to another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the other adult in blue clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2436
            ],
            "duration": 2437,
            "token": {
                "<s0>": 2280,
                "<e0>": 2392
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38470",
        "original_caption": "there is a watercraft beneath an adult on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a watercraft beneath an adult on the river."
            }
        ],
        "meta": {
            "split": [
                905,
                1478
            ],
            "duration": 574,
            "token": {
                "<s0>": 516,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38471",
        "original_caption": "there is a hamster behind another rat on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the other rat on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 0,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_38472",
        "original_caption": "a child in red watches an adult woman in black outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red watches an adult woman in black outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 482,
                "<e0>": 559
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_38473",
        "original_caption": "there is a bottle above a table in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bottle above a table in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                275,
                611
            ],
            "duration": 337,
            "token": {
                "<s0>": 6,
                "<e0>": 336
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_38474",
        "original_caption": "there is a brown table next to a child on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown table next to a child on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 98,
                "<e0>": 1049
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_38475",
        "original_caption": "a child rides a bicycle on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child rides a bicycle on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 44,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2567306378",
        "aid": "2567306378_38476",
        "original_caption": "an adult is in front of an another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                241
            ],
            "duration": 242,
            "token": {
                "<s0>": 122,
                "<e0>": 206
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3771729228",
        "aid": "3771729228_38477",
        "original_caption": "an adult in blue is next to a bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue is next to a bat on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                168,
                399
            ],
            "duration": 232,
            "token": {
                "<s0>": 18,
                "<e0>": 201
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_38478",
        "original_caption": "an adult in blue touches a faucet in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the faucet in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                895
            ],
            "duration": 896,
            "token": {
                "<s0>": 866,
                "<e0>": 889
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_38479",
        "original_caption": "an adult wearing a hat is next to a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing a hat is next to a bottle."
            }
        ],
        "meta": {
            "split": [
                434,
                611
            ],
            "duration": 178,
            "token": {
                "<s0>": 72,
                "<e0>": 177
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38480",
        "original_caption": "there is a car next to a bicycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a car next to a bicycle on the ground."
            }
        ],
        "meta": {
            "split": [
                90,
                371
            ],
            "duration": 282,
            "token": {
                "<s0>": 4,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_38481",
        "original_caption": "there is a sofa next to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sofa from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sofa next to a child."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 459,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8302769229",
        "aid": "8302769229_38482",
        "original_caption": "an adult in black clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes plays the piano happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                298
            ],
            "duration": 299,
            "token": {
                "<s0>": 105,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8302769229",
        "aid": "8302769229_38483",
        "original_caption": "an adult in black clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes plays the piano."
            }
        ],
        "meta": {
            "split": [
                298,
                2696
            ],
            "duration": 2399,
            "token": {
                "<s0>": 103,
                "<e0>": 2399
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_38484",
        "original_caption": "an adult woman in blue is away a white and black pig.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away the white and black pig from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 443,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4154183202",
        "aid": "4154183202_38485",
        "original_caption": "a child in red pats a toy red and yellow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red pats a toy red and yellow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                517
            ],
            "duration": 518,
            "token": {
                "<s0>": 461,
                "<e0>": 478
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4154183202",
        "aid": "4154183202_38486",
        "original_caption": "a child in red pats a toy red and yellow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pats the toy red and yellow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                517,
                782
            ],
            "duration": 266,
            "token": {
                "<s0>": 39,
                "<e0>": 55
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7465682132",
        "aid": "7465682132_38487",
        "original_caption": "a child leans on another child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child leans on another child in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 0,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9124536624",
        "aid": "9124536624_38488",
        "original_caption": "an adult in black holds a bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black holds a bat on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                100
            ],
            "duration": 101,
            "token": {
                "<s0>": 0,
                "<e0>": 73
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7397286464",
        "aid": "7397286464_38489",
        "original_caption": "an adult woman in red lifts a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in red lifts a baby in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                420,
                603
            ],
            "duration": 184,
            "token": {
                "<s0>": 76,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7397286464",
        "aid": "7397286464_38490",
        "original_caption": "an adult woman in red lifts a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in red lifts a baby in white."
            }
        ],
        "meta": {
            "split": [
                603,
                944
            ],
            "duration": 342,
            "token": {
                "<s0>": 87,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_38491",
        "original_caption": "there are the fruits inside a baby in white on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the fruits from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There are the fruits inside a baby in white on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2119,
                "<e0>": 2249
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_38492",
        "original_caption": "a child in pink clothes hugs another child with blond-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink clothes hugs another child with blond-hair."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 183,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3315181459",
        "aid": "3315181459_38493",
        "original_caption": "the adult man touches the adult woman on the shoulder.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touch the adult woman  from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                340
            ],
            "duration": 341,
            "token": {
                "<s0>": 0,
                "<e0>": 21
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3315181459",
        "aid": "3315181459_38494",
        "original_caption": "the adult man touches the adult woman on the shoulder.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult man touches the adult woman on the shoulder."
            }
        ],
        "meta": {
            "split": [
                340,
                694
            ],
            "duration": 355,
            "token": {
                "<s0>": 319,
                "<e0>": 355
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5202728101",
        "aid": "5202728101_38495",
        "original_caption": "a child in cyan is behind a dog in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in cyan is behind a dog in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 221
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38496",
        "original_caption": "there is a black elephant away from another elephant in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black elephant away from another elephant in the forest happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 780,
                "<e0>": 1069
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_38497",
        "original_caption": "the adult in yellow is next to the bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the bottle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1649
            ],
            "duration": 1650,
            "token": {
                "<s0>": 330,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3716834575",
        "aid": "3716834575_38498",
        "original_caption": "an adult woman holds hand of a baby in pink on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman holds hand of a baby in pink on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                565
            ],
            "duration": 566,
            "token": {
                "<s0>": 0,
                "<e0>": 566
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38499",
        "original_caption": "an adult is behind another adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult in a room."
            }
        ],
        "meta": {
            "split": [
                1485,
                2271
            ],
            "duration": 787,
            "token": {
                "<s0>": 15,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7415842388",
        "aid": "7415842388_38500",
        "original_caption": "a baby holds a toy horse in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby holds a toy horse in the room."
            }
        ],
        "meta": {
            "split": [
                180,
                495
            ],
            "duration": 316,
            "token": {
                "<s0>": 13,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7415842388",
        "aid": "7415842388_38501",
        "original_caption": "a baby holds a toy horse in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby holds a toy horse in the room."
            }
        ],
        "meta": {
            "split": [
                711,
                1100
            ],
            "duration": 390,
            "token": {
                "<s0>": 3,
                "<e0>": 43
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2792480681",
        "aid": "2792480681_38502",
        "original_caption": "an adult in gray is behind another adult in dark color.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in gray is behind another adult in dark color happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                526
            ],
            "duration": 527,
            "token": {
                "<s0>": 420,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12624072313",
        "aid": "12624072313_38503",
        "original_caption": "a rightmost adult is away from another second adult on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the other second adult on the left from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1278
            ],
            "duration": 1279,
            "token": {
                "<s0>": 120,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38504",
        "original_caption": "there is a bench beneath an adult in red with pink hat in  the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bench from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bench beneath an adult in red with pink hat in  the gym."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 864,
                "<e0>": 1176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8315788918",
        "aid": "8315788918_38505",
        "original_caption": "an adult in blue holds a child in black in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue holds a child in black in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                1093
            ],
            "duration": 1094,
            "token": {
                "<s0>": 524,
                "<e0>": 634
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8315788918",
        "aid": "8315788918_38506",
        "original_caption": "an adult in blue holds a child in black in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue holds a child in black in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1093,
                1576
            ],
            "duration": 484,
            "token": {
                "<s0>": 459,
                "<e0>": 484
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_38507",
        "original_caption": "a child watches a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child watches a toy inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 1908,
                "<e0>": 2011
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_38508",
        "original_caption": "an adult in black leans on a brown sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black leans on a brown sofa at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_38509",
        "original_caption": "an adult in black leans on a brown sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black lean on at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                256,
                455
            ],
            "duration": 200,
            "token": {
                "<s0>": 73,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_38510",
        "original_caption": "an adult in black leans on a brown sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black leans on a brown sofa at home."
            }
        ],
        "meta": {
            "split": [
                455,
                1148
            ],
            "duration": 694,
            "token": {
                "<s0>": 74,
                "<e0>": 594
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_38511",
        "original_caption": "an adult in black leans on a brown sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black lean on at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                1148,
                1458
            ],
            "duration": 311,
            "token": {
                "<s0>": 100,
                "<e0>": 311
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38512",
        "original_caption": "a pink scooter is towards the gray car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A pink scooter is towards the gray car."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 0,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3099327773",
        "aid": "3099327773_38513",
        "original_caption": "an adult in white is behind a child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white is behind a child on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                1947
            ],
            "duration": 1948,
            "token": {
                "<s0>": 0,
                "<e0>": 168
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4235961238",
        "aid": "4235961238_38514",
        "original_caption": "a child grabs a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child grab on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                564
            ],
            "duration": 565,
            "token": {
                "<s0>": 0,
                "<e0>": 21
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_38515",
        "original_caption": "a baby leans on a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on a baby seat in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 0,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_38516",
        "original_caption": "a child in red is away from a baby outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is away from a baby outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 780,
                "<e0>": 870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6885068488",
        "aid": "6885068488_38517",
        "original_caption": "the baby watches at the toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The baby watches at the toy on the carpet."
            }
        ],
        "meta": {
            "split": [
                60,
                998
            ],
            "duration": 939,
            "token": {
                "<s0>": 25,
                "<e0>": 939
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8483279367",
        "aid": "8483279367_38518",
        "original_caption": "there is the guitar next to an adult on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the adult on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                752,
                875
            ],
            "duration": 124,
            "token": {
                "<s0>": 48,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38519",
        "original_caption": "a child is above another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the child in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 180,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_38520",
        "original_caption": "there is a grey sofa beneath a child in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sofa from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a grey sofa beneath a child in black."
            }
        ],
        "meta": {
            "split": [
                0,
                334
            ],
            "duration": 335,
            "token": {
                "<s0>": 60,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3142287520",
        "aid": "3142287520_38521",
        "original_caption": "an adult man in black is above a red car in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is above a red car in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 0,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8429686679",
        "aid": "8429686679_38522",
        "original_caption": "an adult chases another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult chases another adult on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1573
            ],
            "duration": 1574,
            "token": {
                "<s0>": 26,
                "<e0>": 617
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3848996383",
        "aid": "3848996383_38523",
        "original_caption": "an adult wearing a black hat is next to another adult wearing a red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the other adult wearing a red hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                739
            ],
            "duration": 740,
            "token": {
                "<s0>": 240,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_38524",
        "original_caption": "an adult wearing hats is beneath the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing hats is beneath the adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 325,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3937218319",
        "aid": "3937218319_38525",
        "original_caption": "an adult holds a beige dog in room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a beige dog in room."
            }
        ],
        "meta": {
            "split": [
                22,
                347
            ],
            "duration": 326,
            "token": {
                "<s0>": 11,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3937218319",
        "aid": "3937218319_38526",
        "original_caption": "an adult holds a beige dog in room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a beige dog in room."
            }
        ],
        "meta": {
            "split": [
                347,
                998
            ],
            "duration": 652,
            "token": {
                "<s0>": 129,
                "<e0>": 607
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3937218319",
        "aid": "3937218319_38527",
        "original_caption": "an adult holds a beige dog in room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a beige dog in room."
            }
        ],
        "meta": {
            "split": [
                998,
                1315
            ],
            "duration": 318,
            "token": {
                "<s0>": 45,
                "<e0>": 318
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38528",
        "original_caption": "an adult in dark blue leans on a table ouside the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in dark blue leans on a table ouside the room."
            }
        ],
        "meta": {
            "split": [
                0,
                918
            ],
            "duration": 919,
            "token": {
                "<s0>": 0,
                "<e0>": 804
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38529",
        "original_caption": "an adult in dark blue leans on a table ouside the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the table ouside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                918,
                2159
            ],
            "duration": 1242,
            "token": {
                "<s0>": 114,
                "<e0>": 1131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38530",
        "original_caption": "an adult in red is behind another adult in grey outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red is behind another adult in grey outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1229,
                "<e0>": 1349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_38531",
        "original_caption": "there is a cup above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table inside a room."
            }
        ],
        "meta": {
            "split": [
                395,
                637
            ],
            "duration": 243,
            "token": {
                "<s0>": 25,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38532",
        "original_caption": "a child is above another child on the slide.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is above another child on the slide."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 120,
                "<e0>": 166
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7093500213",
        "aid": "7093500213_38533",
        "original_caption": "an adult in white clothes is behind another adult in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes is behind another adult in yellow clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1109
            ],
            "duration": 1110,
            "token": {
                "<s0>": 1020,
                "<e0>": 1100
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_38534",
        "original_caption": "there is a blue watercraft beneath an adult on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue watercraft beneath an adult on the water."
            }
        ],
        "meta": {
            "split": [
                120,
                458
            ],
            "duration": 339,
            "token": {
                "<s0>": 30,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38535",
        "original_caption": "there is a brown table beneath a white cup outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the white cup outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38536",
        "original_caption": "there is a glass cup above a black table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the glass cup at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                452,
                793
            ],
            "duration": 342,
            "token": {
                "<s0>": 33,
                "<e0>": 341
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_38537",
        "original_caption": "a baby in red holds a bread on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in red holds a bread on the chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                145
            ],
            "duration": 146,
            "token": {
                "<s0>": 0,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_38538",
        "original_caption": "a baby in red holds a bread on the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in red holds a bread on the chair."
            }
        ],
        "meta": {
            "split": [
                145,
                250
            ],
            "duration": 106,
            "token": {
                "<s0>": 24,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3453984843",
        "aid": "3453984843_38539",
        "original_caption": "there is a motorcycle beneath an adult on the grassland.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a motorcycle beneath an adult on the grassland happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                514,
                816
            ],
            "duration": 303,
            "token": {
                "<s0>": 26,
                "<e0>": 296
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11585587124",
        "aid": "11585587124_38540",
        "original_caption": "an adult with white hat' hugs a dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult with white hat' hug  from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                1649
            ],
            "duration": 1650,
            "token": {
                "<s0>": 0,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_38541",
        "original_caption": "an adult touches a toy on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult touches a toy on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                998
            ],
            "duration": 999,
            "token": {
                "<s0>": 489,
                "<e0>": 522
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38542",
        "original_caption": "an adult is towards a stool in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult towards to in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A stool."
            }
        ],
        "meta": {
            "split": [
                765,
                1011
            ],
            "duration": 247,
            "token": {
                "<s0>": 15,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_38543",
        "original_caption": "an adult in purple clothes is next to another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in purple clothes is next to another adult in blue clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2698
            ],
            "duration": 2699,
            "token": {
                "<s0>": 0,
                "<e0>": 2699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4240545211",
        "aid": "4240545211_38544",
        "original_caption": "there is a bicycle beneath a backpack in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle beneath a backpack in the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                484
            ],
            "duration": 485,
            "token": {
                "<s0>": 152,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5139493061",
        "aid": "5139493061_38545",
        "original_caption": "an adult man in blue leans on another adult woman in black in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in blue leans on another adult woman in black in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1846
            ],
            "duration": 1847,
            "token": {
                "<s0>": 1286,
                "<e0>": 1421
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3779800369",
        "aid": "3779800369_38546",
        "original_caption": "an adult wearing a beige hat holds a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a beige hat holds a camera."
            }
        ],
        "meta": {
            "split": [
                307,
                956
            ],
            "duration": 650,
            "token": {
                "<s0>": 6,
                "<e0>": 35
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_38547",
        "original_caption": "stool in front of a child wearing a white shirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the stool from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Stool in front of a child wearing a white shirt."
            }
        ],
        "meta": {
            "split": [
                142,
                1343
            ],
            "duration": 1202,
            "token": {
                "<s0>": 23,
                "<e0>": 132
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38548",
        "original_caption": "there is an elephant next to an another elephant outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the other elephant outdoor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An elephant."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 370,
                "<e0>": 749
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12212857646",
        "aid": "12212857646_38549",
        "original_caption": "a child wearing a hat is towards an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing a hat is towards an adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1170
            ],
            "duration": 1171,
            "token": {
                "<s0>": 24,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_38550",
        "original_caption": "a child in red clothes speaks to an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes speaks to an adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                647
            ],
            "duration": 648,
            "token": {
                "<s0>": 149,
                "<e0>": 237
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_38551",
        "original_caption": "an adult woman in white is above a pale green sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in white is above a pale green sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38552",
        "original_caption": "a child in striped clothes holds a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in striped clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                270
            ],
            "duration": 271,
            "token": {
                "<s0>": 55,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38553",
        "original_caption": "a child in striped clothes holds a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in striped clothes holds a black cellphone."
            }
        ],
        "meta": {
            "split": [
                270,
                391
            ],
            "duration": 122,
            "token": {
                "<s0>": 51,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38554",
        "original_caption": "a child in striped clothes holds a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in striped clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                391,
                1349
            ],
            "duration": 959,
            "token": {
                "<s0>": 18,
                "<e0>": 959
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2551446323",
        "aid": "2551446323_38555",
        "original_caption": "an adult is away from a bird outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the bird outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                908
            ],
            "duration": 909,
            "token": {
                "<s0>": 90,
                "<e0>": 269
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_38556",
        "original_caption": "an adult in black rides a watercraft in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black rides a watercraft in the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                40,
                589
            ],
            "duration": 550,
            "token": {
                "<s0>": 13,
                "<e0>": 460
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6045154695",
        "aid": "6045154695_38557",
        "original_caption": "an adult is towards a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards a table inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1965
            ],
            "duration": 1966,
            "token": {
                "<s0>": 60,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_38558",
        "original_caption": "an adult man in black hugs another adult woman in wedding dresses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black hugs another adult woman in wedding dresses happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                149
            ],
            "duration": 150,
            "token": {
                "<s0>": 0,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_38559",
        "original_caption": "an adult man in black hugs another adult woman in wedding dresses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult man in black hug from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                149,
                338
            ],
            "duration": 190,
            "token": {
                "<s0>": 23,
                "<e0>": 104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_38560",
        "original_caption": "an adult man in black hugs another adult woman in wedding dresses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult man in black hug from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                338,
                535
            ],
            "duration": 198,
            "token": {
                "<s0>": 86,
                "<e0>": 198
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5296127747",
        "aid": "5296127747_38561",
        "original_caption": "an adult in white dress hugs another adult in black suit.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hugs the other adult in black suit from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 107,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38562",
        "original_caption": "there is a black rat behind a black rat on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black rat behind a black rat on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1620,
                "<e0>": 1690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38563",
        "original_caption": "a child is next to a skateboard in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the skateboard in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                333,
                411
            ],
            "duration": 79,
            "token": {
                "<s0>": 2,
                "<e0>": 26
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2560146457",
        "aid": "2560146457_38564",
        "original_caption": "an adult speaks to a child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                542
            ],
            "duration": 543,
            "token": {
                "<s0>": 246,
                "<e0>": 288
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2560146457",
        "aid": "2560146457_38565",
        "original_caption": "an adult speaks to a child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the child in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                542,
                833
            ],
            "duration": 292,
            "token": {
                "<s0>": 254,
                "<e0>": 274
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2560146457",
        "aid": "2560146457_38566",
        "original_caption": "an adult speaks to a child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                833,
                1122
            ],
            "duration": 290,
            "token": {
                "<s0>": 18,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38567",
        "original_caption": "there is a sports ball blue above a white table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sports ball blue above a white table in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7729753698",
        "aid": "7729753698_38568",
        "original_caption": "there is a red bottle behind an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a red bottle behind an adult in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 451
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13097816293",
        "aid": "13097816293_38569",
        "original_caption": "an adult is above a black sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the black sofa at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1104
            ],
            "duration": 1105,
            "token": {
                "<s0>": 0,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13899308375",
        "aid": "13899308375_38570",
        "original_caption": "a child in red clothes is away from a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is away from a car."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 0,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38571",
        "original_caption": "there is a sports ball next to another sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sports ball next to another sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 331,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_38572",
        "original_caption": "the leftmost child is next to a green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The leftmost child is next to a green toy."
            }
        ],
        "meta": {
            "split": [
                315,
                1385
            ],
            "duration": 1071,
            "token": {
                "<s0>": 105,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_38573",
        "original_caption": "an adult carries a backpack on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult carries a backpack on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                1106
            ],
            "duration": 1107,
            "token": {
                "<s0>": 0,
                "<e0>": 1052
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_38574",
        "original_caption": "an adult carries a backpack on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult carries a backpack on the snow."
            }
        ],
        "meta": {
            "split": [
                1106,
                1419
            ],
            "duration": 314,
            "token": {
                "<s0>": 55,
                "<e0>": 141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_38575",
        "original_caption": "an adult carries a backpack on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult carries a backpack on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1419,
                1644
            ],
            "duration": 226,
            "token": {
                "<s0>": 172,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_38576",
        "original_caption": "an adult carries a backpack on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult carry on the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                1696,
                2157
            ],
            "duration": 462,
            "token": {
                "<s0>": 5,
                "<e0>": 142
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12557550424",
        "aid": "12557550424_38577",
        "original_caption": "an adult in green plays the guitar in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the guitar in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                771
            ],
            "duration": 772,
            "token": {
                "<s0>": 252,
                "<e0>": 558
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12557550424",
        "aid": "12557550424_38578",
        "original_caption": "an adult in green plays the guitar in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green plays the guitar in the room."
            }
        ],
        "meta": {
            "split": [
                771,
                1259
            ],
            "duration": 489,
            "token": {
                "<s0>": 213,
                "<e0>": 489
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38579",
        "original_caption": "an adult in pink holds hand of a child in the restaurant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in pink holds hand of a child in the restaurant."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 457,
                "<e0>": 1069
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4868537195",
        "aid": "4868537195_38580",
        "original_caption": "there is a car in front of an adult man in white on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a car in front of an adult man in white on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                659
            ],
            "duration": 660,
            "token": {
                "<s0>": 300,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38581",
        "original_caption": "there is a black screen above an adult in a show room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the black screen in the show room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                872,
                2271
            ],
            "duration": 1400,
            "token": {
                "<s0>": 662,
                "<e0>": 1399
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2462607486",
        "aid": "2462607486_38582",
        "original_caption": "there are the guitar next to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there are the guitar next to an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1251
            ],
            "duration": 1252,
            "token": {
                "<s0>": 509,
                "<e0>": 1251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_38583",
        "original_caption": "an adult in black holds hand of another adult in blue at wedding.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the other adult in blue at wedding from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1442
            ],
            "duration": 1443,
            "token": {
                "<s0>": 0,
                "<e0>": 1441
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_38584",
        "original_caption": "an adult in black holds hand of another adult in blue at wedding.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the other adult in blue at wedding from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1442,
                1799
            ],
            "duration": 358,
            "token": {
                "<s0>": 2,
                "<e0>": 358
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_38585",
        "original_caption": "there is a yellow bottle above a purple sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a yellow bottle above a purple sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 133,
                "<e0>": 749
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5091773135",
        "aid": "5091773135_38586",
        "original_caption": "an adult in brown carries the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in brown carries the guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1770
            ],
            "duration": 1771,
            "token": {
                "<s0>": 1424,
                "<e0>": 1771
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38587",
        "original_caption": "an adult in blue clothes is in front of a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue clothes is in front of a child in blue clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 180,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38588",
        "original_caption": "an adult man in pink speaks to a child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the child in red from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 994,
                "<e0>": 1095
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_38589",
        "original_caption": "there is adult women in black behind of the car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is adult women in black behind of the car."
            }
        ],
        "meta": {
            "split": [
                1098,
                1709
            ],
            "duration": 612,
            "token": {
                "<s0>": 7,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_38590",
        "original_caption": "an adult in green speaks to a baby in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green speaks to a baby in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 14,
                "<e0>": 82
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_38591",
        "original_caption": "an adult woman in blue skirt holds hand of another adult man in black on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in blue skirt holds hand of another adult man in black on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1444
            ],
            "duration": 1445,
            "token": {
                "<s0>": 0,
                "<e0>": 1441
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_38592",
        "original_caption": "an adult woman in blue skirt holds hand of another adult man in black on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in blue skirt holds hand of another adult man in black on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1444,
                1799
            ],
            "duration": 356,
            "token": {
                "<s0>": 4,
                "<e0>": 356
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38593",
        "original_caption": "there is a silver sports ball towards an adult man in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a silver sports ball towards an adult man in blue happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3710885997",
        "aid": "3710885997_38594",
        "original_caption": "an adult with red pants is in front of a child by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with red pants is in front of a child by the sea."
            }
        ],
        "meta": {
            "split": [
                0,
                497
            ],
            "duration": 498,
            "token": {
                "<s0>": 360,
                "<e0>": 498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38595",
        "original_caption": "there is a stool beneath an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a stool beneath an adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 544,
                "<e0>": 840
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_38596",
        "original_caption": "the child in green is pressing the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is pressing the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 316,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7040233679",
        "aid": "7040233679_38597",
        "original_caption": "an adult in grey holds a cup in a shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in grey holds a cup in a shop."
            }
        ],
        "meta": {
            "split": [
                0,
                909
            ],
            "duration": 910,
            "token": {
                "<s0>": 22,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6991481998",
        "aid": "6991481998_38598",
        "original_caption": "an adult in green clothes pushes a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes pushes a child in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 795,
                "<e0>": 845
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4184884354",
        "aid": "4184884354_38599",
        "original_caption": "a child in black clothes caresses the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black clothes caresses the piano happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1502
            ],
            "duration": 1503,
            "token": {
                "<s0>": 898,
                "<e0>": 1503
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3145413102",
        "aid": "3145413102_38600",
        "original_caption": "there is a cup next to a male adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup next to a male adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                451,
                775
            ],
            "duration": 325,
            "token": {
                "<s0>": 269,
                "<e0>": 313
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10250170546",
        "aid": "10250170546_38601",
        "original_caption": "there is a chair behind an adult in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair behind an adult in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                393
            ],
            "duration": 394,
            "token": {
                "<s0>": 0,
                "<e0>": 394
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38602",
        "original_caption": "there is an elephant away another elephant on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is an elephant away another elephant on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1095,
                1814
            ],
            "duration": 720,
            "token": {
                "<s0>": 45,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6122666405",
        "aid": "6122666405_38603",
        "original_caption": "an adult with long hair is behind another adult wearing a blue hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with long hair is behind another adult wearing a blue hat."
            }
        ],
        "meta": {
            "split": [
                731,
                1668
            ],
            "duration": 938,
            "token": {
                "<s0>": 37,
                "<e0>": 938
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3711378974",
        "aid": "3711378974_38604",
        "original_caption": "there is a camera black next to a chair in the tent.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a camera black next to a chair in the tent."
            }
        ],
        "meta": {
            "split": [
                0,
                1143
            ],
            "duration": 1144,
            "token": {
                "<s0>": 360,
                "<e0>": 505
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_38605",
        "original_caption": "a child in pink is above a black chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink is above a black chair in the room."
            }
        ],
        "meta": {
            "split": [
                1222,
                2225
            ],
            "duration": 1004,
            "token": {
                "<s0>": 54,
                "<e0>": 307
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6243190450",
        "aid": "6243190450_38606",
        "original_caption": "there is a monitor next to an adult on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the screen/monitor from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a monitor next to an adult on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                402
            ],
            "duration": 403,
            "token": {
                "<s0>": 92,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_38607",
        "original_caption": "a male adult speaks to another adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the male adult speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                732
            ],
            "duration": 733,
            "token": {
                "<s0>": 685,
                "<e0>": 712
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_38608",
        "original_caption": "a male adult speaks to another adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A male adult speaks to another adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                732,
                979
            ],
            "duration": 248,
            "token": {
                "<s0>": 20,
                "<e0>": 36
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38609",
        "original_caption": "there is a white cake towards a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white cake towards a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 480,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38610",
        "original_caption": "there is a hamster away another hamster on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away the other hamster on the bed from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1560,
                "<e0>": 1690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38611",
        "original_caption": "there is a gray hamster beneath a gray hamster on the blanket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the gray hamster on the blanket from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                691,
                2639
            ],
            "duration": 1949,
            "token": {
                "<s0>": 303,
                "<e0>": 358
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4828544178",
        "aid": "4828544178_38612",
        "original_caption": "an adult man in black carries a backpack man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black carries a backpack man in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                344
            ],
            "duration": 345,
            "token": {
                "<s0>": 302,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_38613",
        "original_caption": "a child is in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of an adult."
            }
        ],
        "meta": {
            "split": [
                469,
                927
            ],
            "duration": 459,
            "token": {
                "<s0>": 260,
                "<e0>": 427
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38614",
        "original_caption": "a child in striped clothes is away a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away the baby seat in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 48
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6262219324",
        "aid": "6262219324_38615",
        "original_caption": "an adult woman in white lifts a baby in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in white lift from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                61,
                159
            ],
            "duration": 99,
            "token": {
                "<s0>": 43,
                "<e0>": 66
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6262219324",
        "aid": "6262219324_38616",
        "original_caption": "an adult woman in white lifts a baby in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in white lifts a baby in red."
            }
        ],
        "meta": {
            "split": [
                159,
                299
            ],
            "duration": 141,
            "token": {
                "<s0>": 33,
                "<e0>": 50
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3374974398",
        "aid": "3374974398_38617",
        "original_caption": "an adult rides a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult ride in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                292
            ],
            "duration": 293,
            "token": {
                "<s0>": 164,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11264199933",
        "aid": "11264199933_38618",
        "original_caption": "the adult with white pants is holding a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult with white pants is holding a cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                488
            ],
            "duration": 489,
            "token": {
                "<s0>": 0,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_38619",
        "original_caption": "an adult pulls a sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult pulls a sports ball in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                862
            ],
            "duration": 863,
            "token": {
                "<s0>": 621,
                "<e0>": 656
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_38620",
        "original_caption": "an adult pulls a sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult pulls a sports ball in the room."
            }
        ],
        "meta": {
            "split": [
                862,
                1435
            ],
            "duration": 574,
            "token": {
                "<s0>": 207,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4570227004",
        "aid": "4570227004_38621",
        "original_caption": "an adult pulls a sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult pulls a sports ball in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1435,
                2069
            ],
            "duration": 635,
            "token": {
                "<s0>": 328,
                "<e0>": 392
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3843663025",
        "aid": "3843663025_38622",
        "original_caption": "there is a ball next to a baby walker outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a ball next to a baby walker outside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                545
            ],
            "duration": 546,
            "token": {
                "<s0>": 0,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6991481998",
        "aid": "6991481998_38623",
        "original_caption": "an adult is away from a car in the field.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away from a car in the field."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 0,
                "<e0>": 254
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8115037154",
        "aid": "8115037154_38624",
        "original_caption": "the adult is in front of the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult is in front of the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1379
            ],
            "duration": 1380,
            "token": {
                "<s0>": 1080,
                "<e0>": 1261
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_38625",
        "original_caption": "there is a bottle in front of a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle in front of a child in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 0,
                "<e0>": 766
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3138328151",
        "aid": "3138328151_38626",
        "original_caption": "an adult in gray clothes kisses a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gray clothes kisses a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                194
            ],
            "duration": 195,
            "token": {
                "<s0>": 72,
                "<e0>": 181
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3138328151",
        "aid": "3138328151_38627",
        "original_caption": "an adult in gray clothes kisses a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in gray clothes kisses a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                194,
                314
            ],
            "duration": 121,
            "token": {
                "<s0>": 13,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3138328151",
        "aid": "3138328151_38628",
        "original_caption": "an adult in gray clothes kisses a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in gray clothes kisses a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                314,
                448
            ],
            "duration": 135,
            "token": {
                "<s0>": 12,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3138328151",
        "aid": "3138328151_38629",
        "original_caption": "an adult in gray clothes kisses a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gray clothes kisses a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                448,
                557
            ],
            "duration": 110,
            "token": {
                "<s0>": 13,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3138328151",
        "aid": "3138328151_38630",
        "original_caption": "an adult in gray clothes kisses a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in gray clothes kisses a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                557,
                704
            ],
            "duration": 148,
            "token": {
                "<s0>": 12,
                "<e0>": 128
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3138328151",
        "aid": "3138328151_38631",
        "original_caption": "an adult in gray clothes kisses a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in gray clothes kisses a baby in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                775,
                974
            ],
            "duration": 200,
            "token": {
                "<s0>": 34,
                "<e0>": 57
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_38632",
        "original_caption": "an adult in black is behind another adult in red in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black is behind another adult in red in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 748,
                "<e0>": 854
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_38633",
        "original_caption": "there is a car in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a car in front of a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 1020,
                "<e0>": 1459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5873013017",
        "aid": "5873013017_38634",
        "original_caption": "a baby knocks an adult in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby knocks an adult in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                1510
            ],
            "duration": 1511,
            "token": {
                "<s0>": 234,
                "<e0>": 281
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38635",
        "original_caption": "an adult carrying a red bag is towards another adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult carrying a red bag is towards another adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1380,
                "<e0>": 1590
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5994365464",
        "aid": "5994365464_38636",
        "original_caption": "a baby on the right touches another baby on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby on the right touches another baby on the left happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1347,
                "<e0>": 1454
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_38637",
        "original_caption": "an adult man in black is away from the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is away from the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                285,
                1788
            ],
            "duration": 1504,
            "token": {
                "<s0>": 75,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_38638",
        "original_caption": "there is a baby seat beneath a baby in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a baby seat beneath a baby in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                227,
                1756
            ],
            "duration": 1530,
            "token": {
                "<s0>": 37,
                "<e0>": 1422
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38639",
        "original_caption": "an adult with black hair is away from a bench in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with black hair is away from a bench in the gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 1152,
                "<e0>": 1224
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_38640",
        "original_caption": "there is a backpack behind an adult in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the adult in the wild from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 693,
                "<e0>": 800
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5211051388",
        "aid": "5211051388_38641",
        "original_caption": "a child is in front of a screen on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is in front of a screen on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                636
            ],
            "duration": 637,
            "token": {
                "<s0>": 0,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10250170546",
        "aid": "10250170546_38642",
        "original_caption": "there is a chair behind an adult in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair behind an adult in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                393
            ],
            "duration": 394,
            "token": {
                "<s0>": 0,
                "<e0>": 394
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_38643",
        "original_caption": "there is a gold chair in front of an adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 120,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_38644",
        "original_caption": "an adult is towards the piano inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is towards the piano inside a room."
            }
        ],
        "meta": {
            "split": [
                2024,
                2533
            ],
            "duration": 510,
            "token": {
                "<s0>": 16,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4276511080",
        "aid": "4276511080_38645",
        "original_caption": "the adult in black is playing (instrument) the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is playing the (instrument) the guitar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 379
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4276511080",
        "aid": "4276511080_38646",
        "original_caption": "the adult in black is playing (instrument) the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in black is playing (instrument) the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                450,
                2249
            ],
            "duration": 1800,
            "token": {
                "<s0>": 71,
                "<e0>": 1800
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_38647",
        "original_caption": "the black dog next to the car door is in front of another black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the black dog next to the car door is in front of another black dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 200,
                "<e0>": 324
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_38648",
        "original_caption": "a child in orange is towards a toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in orange is towards a toy at home."
            }
        ],
        "meta": {
            "split": [
                0,
                637
            ],
            "duration": 638,
            "token": {
                "<s0>": 12,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3482621813",
        "aid": "3482621813_38649",
        "original_caption": "an adult man in gray feeds a penguin.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in gray feeds a penguin."
            }
        ],
        "meta": {
            "split": [
                0,
                592
            ],
            "duration": 593,
            "token": {
                "<s0>": 385,
                "<e0>": 439
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_38650",
        "original_caption": "a child in pink rides a purple bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink rides a purple bicycle on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                174
            ],
            "duration": 175,
            "token": {
                "<s0>": 0,
                "<e0>": 141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_38651",
        "original_caption": "a child in pink rides a purple bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink rides a purple bicycle on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                174,
                290
            ],
            "duration": 117,
            "token": {
                "<s0>": 34,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_38652",
        "original_caption": "a child in pink rides a purple bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink rides a purple bicycle on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                290,
                410
            ],
            "duration": 121,
            "token": {
                "<s0>": 14,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_38653",
        "original_caption": "a child in pink rides a purple bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink rides a purple bicycle on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                410,
                718
            ],
            "duration": 309,
            "token": {
                "<s0>": 46,
                "<e0>": 281
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_38654",
        "original_caption": "a child in pink rides a purple bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in pink rides a purple bicycle on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                718,
                849
            ],
            "duration": 132,
            "token": {
                "<s0>": 28,
                "<e0>": 117
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_38655",
        "original_caption": "a child in pink rides a purple bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the purple bicycle on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                906,
                1007
            ],
            "duration": 102,
            "token": {
                "<s0>": 13,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_38656",
        "original_caption": "there is a white watercraft beneath an adult in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white watercraft beneath an adult in pink clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_38657",
        "original_caption": "there is a white ball in front of a dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white ball in front of a dog."
            }
        ],
        "meta": {
            "split": [
                1205,
                1336
            ],
            "duration": 132,
            "token": {
                "<s0>": 17,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38658",
        "original_caption": "an adult rides a watercraft on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a watercraft on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                137
            ],
            "duration": 138,
            "token": {
                "<s0>": 0,
                "<e0>": 99
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38659",
        "original_caption": "an adult rides a watercraft on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a watercraft on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                137,
                841
            ],
            "duration": 705,
            "token": {
                "<s0>": 38,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38660",
        "original_caption": "an adult rides a watercraft on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a watercraft on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                841,
                1478
            ],
            "duration": 638,
            "token": {
                "<s0>": 580,
                "<e0>": 638
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_38661",
        "original_caption": "an adult man in black carries a purple backpack outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black carries a purple backpack outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 612,
                "<e0>": 716
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_38662",
        "original_caption": "there is a black chair behind a child in skirt on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black chair behind a child in skirt on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38663",
        "original_caption": "there is a hamster beneath another rat on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a hamster beneath another rat on the carpet."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 660,
                "<e0>": 750
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_38664",
        "original_caption": "the watercraft is inside the adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is inside the adult in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38665",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                99
            ],
            "duration": 100,
            "token": {
                "<s0>": 6,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38666",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                99,
                209
            ],
            "duration": 111,
            "token": {
                "<s0>": 33,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38667",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the baby inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                209,
                332
            ],
            "duration": 124,
            "token": {
                "<s0>": 32,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38668",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult speaks to a baby inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                332,
                700
            ],
            "duration": 369,
            "token": {
                "<s0>": 12,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38669",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                700,
                1231
            ],
            "duration": 532,
            "token": {
                "<s0>": 294,
                "<e0>": 352
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38670",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult speak to inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                1231,
                1477
            ],
            "duration": 247,
            "token": {
                "<s0>": 179,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38671",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the baby inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1477,
                1579
            ],
            "duration": 103,
            "token": {
                "<s0>": 7,
                "<e0>": 95
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38672",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                1579,
                1687
            ],
            "duration": 109,
            "token": {
                "<s0>": 8,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38673",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                1687,
                1811
            ],
            "duration": 125,
            "token": {
                "<s0>": 67,
                "<e0>": 114
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38674",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                1864,
                1994
            ],
            "duration": 131,
            "token": {
                "<s0>": 15,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_38675",
        "original_caption": "an adult speaks to a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult speak to inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                2066,
                2696
            ],
            "duration": 631,
            "token": {
                "<s0>": 14,
                "<e0>": 131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38676",
        "original_caption": "a child in blue speaks to an in red adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue speaks to an in red adult at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 445,
                "<e0>": 554
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_38677",
        "original_caption": "there is a white dog chasing a grey dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white dog chasing a grey dog."
            }
        ],
        "meta": {
            "split": [
                0,
                2018
            ],
            "duration": 2019,
            "token": {
                "<s0>": 915,
                "<e0>": 967
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3710885997",
        "aid": "3710885997_38678",
        "original_caption": "a foremost child rides a yellow surfboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A foremost child rides a yellow surfboard."
            }
        ],
        "meta": {
            "split": [
                0,
                497
            ],
            "duration": 498,
            "token": {
                "<s0>": 452,
                "<e0>": 498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3432675366",
        "aid": "3432675366_38679",
        "original_caption": "an adult in black clothes is next to another adult wearing a hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes is next to another adult wearing a hat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                500
            ],
            "duration": 501,
            "token": {
                "<s0>": 361,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572174095",
        "aid": "8572174095_38680",
        "original_caption": "there is a black and white penguin watching a gray and white penguin.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black and white penguin watching a gray and white penguin."
            }
        ],
        "meta": {
            "split": [
                0,
                490
            ],
            "duration": 491,
            "token": {
                "<s0>": 447,
                "<e0>": 472
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4085549820",
        "aid": "4085549820_38681",
        "original_caption": "a car is in front of an another car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a car is in front of an another car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2100,
                "<e0>": 2175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11841865713",
        "aid": "11841865713_38682",
        "original_caption": "an adult in yellow clothes touches a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in yellow clothes touches a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                295
            ],
            "duration": 296,
            "token": {
                "<s0>": 159,
                "<e0>": 260
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11841865713",
        "aid": "11841865713_38683",
        "original_caption": "an adult in yellow clothes touches a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow clothes touches a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                295,
                674
            ],
            "duration": 380,
            "token": {
                "<s0>": 35,
                "<e0>": 138
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2538515654",
        "aid": "2538515654_38684",
        "original_caption": "there is a white surfboard beneath an adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the surfboard from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white surfboard beneath an adult man in black."
            }
        ],
        "meta": {
            "split": [
                0,
                452
            ],
            "duration": 453,
            "token": {
                "<s0>": 0,
                "<e0>": 377
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_38685",
        "original_caption": "the adult without clothes is pulling the watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult without clothes is pulling the watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 603,
                "<e0>": 810
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13828973545",
        "aid": "13828973545_38686",
        "original_caption": "there is a white dog hitting a yellow dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white dog hitting a yellow dog."
            }
        ],
        "meta": {
            "split": [
                0,
                624
            ],
            "duration": 625,
            "token": {
                "<s0>": 238,
                "<e0>": 262
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_38687",
        "original_caption": "there is a sports ball towards a child in red clothes on the basketball court.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sports ball towards a child in red clothes on the basketball court happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                345,
                743
            ],
            "duration": 399,
            "token": {
                "<s0>": 75,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6257015243",
        "aid": "6257015243_38688",
        "original_caption": "a baby is in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                551
            ],
            "duration": 552,
            "token": {
                "<s0>": 0,
                "<e0>": 552
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2494076437",
        "aid": "2494076437_38689",
        "original_caption": "a baby seat is next to the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                1421
            ],
            "duration": 1422,
            "token": {
                "<s0>": 1260,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8543058168",
        "aid": "8543058168_38690",
        "original_caption": "an adult in red watches a child with hulmet in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red watches a child with hulmet in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                344
            ],
            "duration": 345,
            "token": {
                "<s0>": 18,
                "<e0>": 45
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6806981046",
        "aid": "6806981046_38691",
        "original_caption": "an adult man in gray watches another adult man in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in gray watches another adult man in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 14,
                "<e0>": 82
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945234319",
        "aid": "5945234319_38692",
        "original_caption": "the orange child is away the electric fan.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The orange child is away the electric fan."
            }
        ],
        "meta": {
            "split": [
                0,
                1988
            ],
            "duration": 1989,
            "token": {
                "<s0>": 1900,
                "<e0>": 1952
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7808891456",
        "aid": "7808891456_38693",
        "original_caption": "an adult holds a white fish in a boat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a white fish in a boat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2047
            ],
            "duration": 2048,
            "token": {
                "<s0>": 1450,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_38694",
        "original_caption": "there is a white dog pulling a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat pulls the toy on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                1300
            ],
            "duration": 1301,
            "token": {
                "<s0>": 994,
                "<e0>": 1102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2538515654",
        "aid": "2538515654_38695",
        "original_caption": "an adult in black clothes rides a surfboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes rides a surfboard."
            }
        ],
        "meta": {
            "split": [
                0,
                452
            ],
            "duration": 453,
            "token": {
                "<s0>": 0,
                "<e0>": 377
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_38696",
        "original_caption": "there is a white dish above an orange wooden table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white dish above an orange wooden table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 0,
                "<e0>": 781
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7972054306",
        "aid": "7972054306_38697",
        "original_caption": "an adult in blue leans on a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue leans on a sofa in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                816
            ],
            "duration": 817,
            "token": {
                "<s0>": 300,
                "<e0>": 398
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_38698",
        "original_caption": "a naked baby holds a black and white toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A naked baby holds a black and white toy at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 530,
                "<e0>": 834
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_38699",
        "original_caption": "there is a dish above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dish above a table inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2573250257",
        "aid": "2573250257_38700",
        "original_caption": "an adult is towards a child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is towards a child on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 1186,
                "<e0>": 1274
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_38701",
        "original_caption": "an adult in orange is away an another adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away the adult  in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                285,
                1221
            ],
            "duration": 937,
            "token": {
                "<s0>": 135,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3342105817",
        "aid": "3342105817_38702",
        "original_caption": "a baby in striped clothes pushes a blue chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in striped clothes pushes a blue chair."
            }
        ],
        "meta": {
            "split": [
                0,
                637
            ],
            "duration": 638,
            "token": {
                "<s0>": 0,
                "<e0>": 638
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_38703",
        "original_caption": "a child in colorful is towards another child in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child in colorful towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1619,
                2159
            ],
            "duration": 541,
            "token": {
                "<s0>": 157,
                "<e0>": 277
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38704",
        "original_caption": "a child is away from a car outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is away from a car outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                91,
                371
            ],
            "duration": 281,
            "token": {
                "<s0>": 3,
                "<e0>": 55
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_38705",
        "original_caption": "there is a brown table next to a child on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown table next to a child on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 98,
                "<e0>": 1049
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4535557687",
        "aid": "4535557687_38706",
        "original_caption": "an adult in white holds the guitar in the dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white holds the guitar in the dark room."
            }
        ],
        "meta": {
            "split": [
                0,
                335
            ],
            "duration": 336,
            "token": {
                "<s0>": 261,
                "<e0>": 336
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38707",
        "original_caption": "there is an elephant away an another elephant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away the other elephant from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An elephant."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 960,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38708",
        "original_caption": "a child in black is behind another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the other child in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                219,
                518
            ],
            "duration": 300,
            "token": {
                "<s0>": 44,
                "<e0>": 170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_38709",
        "original_caption": "there is a toy next to a cat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the cat on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                1106,
                2144
            ],
            "duration": 1039,
            "token": {
                "<s0>": 76,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_38710",
        "original_caption": "an adult in black is riding the watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black is riding the watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38711",
        "original_caption": "there is a monitor behind another screen in a show room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a monitor behind another screen in a show room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38712",
        "original_caption": "an elephant is in front of another elephant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An elephant is in front of another elephant."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 0,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3282832711",
        "aid": "3282832711_38713",
        "original_caption": "there is a white sink beneath a faucet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sink from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white sink beneath a faucet."
            }
        ],
        "meta": {
            "split": [
                884,
                1419
            ],
            "duration": 536,
            "token": {
                "<s0>": 76,
                "<e0>": 526
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6121794107",
        "aid": "6121794107_38714",
        "original_caption": "a child with a grey hat watches a cup on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child with the grey hat watch on the grass from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                883
            ],
            "duration": 884,
            "token": {
                "<s0>": 195,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_38715",
        "original_caption": "a child in green clothes leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in green clothes lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 0,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_38716",
        "original_caption": "there is a cake in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cake from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cake in front of a child."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 0,
                "<e0>": 1080
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38717",
        "original_caption": "an adult is towards a cup inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the cup inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 480,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_38718",
        "original_caption": "a child in gray clothes leans on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in gray clothes lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 469,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_38719",
        "original_caption": "an adult holds a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a toy inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                385
            ],
            "duration": 386,
            "token": {
                "<s0>": 183,
                "<e0>": 235
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_38720",
        "original_caption": "an adult holds a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a toy inside a room."
            }
        ],
        "meta": {
            "split": [
                385,
                1314
            ],
            "duration": 930,
            "token": {
                "<s0>": 151,
                "<e0>": 228
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_38721",
        "original_caption": "a child in black leans on an adult women in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black leans on an adult women in green happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                334
            ],
            "duration": 335,
            "token": {
                "<s0>": 0,
                "<e0>": 335
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945234319",
        "aid": "5945234319_38722",
        "original_caption": "an adult woman in black leans on a gray sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black leans on a gray sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1988
            ],
            "duration": 1989,
            "token": {
                "<s0>": 1486,
                "<e0>": 1570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38723",
        "original_caption": "an adult leans on a stool inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult leans on a stool inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                693
            ],
            "duration": 694,
            "token": {
                "<s0>": 0,
                "<e0>": 669
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38724",
        "original_caption": "an adult leans on a stool inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult leans on a stool inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                693,
                1011
            ],
            "duration": 319,
            "token": {
                "<s0>": 25,
                "<e0>": 319
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38725",
        "original_caption": "a child watches a dog inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child watch inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                648,
                1441
            ],
            "duration": 794,
            "token": {
                "<s0>": 109,
                "<e0>": 313
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_38726",
        "original_caption": "an adult on the left is in front of the adult on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult on the left is in front of the adult on the right."
            }
        ],
        "meta": {
            "split": [
                657,
                929
            ],
            "duration": 273,
            "token": {
                "<s0>": 35,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2457895589",
        "aid": "2457895589_38727",
        "original_caption": "an adult in black is away from another adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black is away from another adult outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1752
            ],
            "duration": 1753,
            "token": {
                "<s0>": 1620,
                "<e0>": 1706
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38728",
        "original_caption": "there is a green sports ball above an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a green sports ball above an adult in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_38729",
        "original_caption": "the adult with a red scarf is riding a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult with a red scarf is riding a watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1081
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_38730",
        "original_caption": "there is a watercraft beneath an adult on the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a watercraft beneath an adult on the sea happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5429475861",
        "aid": "5429475861_38731",
        "original_caption": "an adult women is behind another adult women on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women is behind another adult women on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                143
            ],
            "duration": 144,
            "token": {
                "<s0>": 0,
                "<e0>": 144
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38732",
        "original_caption": "a baby is beneath a sports ball inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby is beneath a sports ball inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38733",
        "original_caption": "a child in yellow clothes is away from another child in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in yellow clothes is away from another child in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 180,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38734",
        "original_caption": "there is a table next to a black backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table next to a black backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_38735",
        "original_caption": "an adult wearing sunglasses is above a blue watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing sunglasses is above a blue watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_38736",
        "original_caption": "a child leans on a table at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child lean on at party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                606
            ],
            "duration": 607,
            "token": {
                "<s0>": 560,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_38737",
        "original_caption": "a child leans on a table at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child leans on a table at party happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                606,
                1079
            ],
            "duration": 474,
            "token": {
                "<s0>": 19,
                "<e0>": 127
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_38738",
        "original_caption": "a child in pale yellow is above a colorful toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in pale yellow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 986,
                "<e0>": 1041
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3588778325",
        "aid": "3588778325_38739",
        "original_caption": "an adult in grey clothes closes a laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in grey clothes closes a laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                391
            ],
            "duration": 392,
            "token": {
                "<s0>": 269,
                "<e0>": 283
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_38740",
        "original_caption": "a child in pink is towards a black chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in pink is towards a black chair in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2225
            ],
            "duration": 2226,
            "token": {
                "<s0>": 1860,
                "<e0>": 1950
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38741",
        "original_caption": "an adult is away from another adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the other adult at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 540,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3521372410",
        "aid": "3521372410_38742",
        "original_caption": "a baby in dark blue is in front of an adult woman on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in dark blue is in front of an adult woman on the floor."
            }
        ],
        "meta": {
            "split": [
                231,
                680
            ],
            "duration": 450,
            "token": {
                "<s0>": 144,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_38743",
        "original_caption": "an adult in green clothes is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 258,
                "<e0>": 474
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_38744",
        "original_caption": "there is a watercraft inside an adult in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a watercraft inside an adult in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 60,
                "<e0>": 500
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_38745",
        "original_caption": "there is a sofa beneath a bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sofa beneath a bottle at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 133,
                "<e0>": 689
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38746",
        "original_caption": "there is a rat behind another hamster on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a rat behind another hamster on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 720,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5134456273",
        "aid": "5134456273_38747",
        "original_caption": "an adult with black-hair touches a white sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with black-hair touches a white sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                842
            ],
            "duration": 843,
            "token": {
                "<s0>": 648,
                "<e0>": 696
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5134456273",
        "aid": "5134456273_38748",
        "original_caption": "an adult with black-hair touches a white sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with black-hair touches a white sports ball."
            }
        ],
        "meta": {
            "split": [
                842,
                1139
            ],
            "duration": 298,
            "token": {
                "<s0>": 147,
                "<e0>": 189
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5783801873",
        "aid": "5783801873_38749",
        "original_caption": "an adult in black clothes is above a motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is above a motorcycle."
            }
        ],
        "meta": {
            "split": [
                0,
                844
            ],
            "duration": 845,
            "token": {
                "<s0>": 161,
                "<e0>": 720
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4914011323",
        "aid": "4914011323_38750",
        "original_caption": "there is a black cat in front of a brown dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the black cat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                182
            ],
            "duration": 183,
            "token": {
                "<s0>": 0,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5867564434",
        "aid": "5867564434_38751",
        "original_caption": "a child in green with a hat leans on a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in green with a hat leans on a baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                944
            ],
            "duration": 945,
            "token": {
                "<s0>": 0,
                "<e0>": 945
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5429475861",
        "aid": "5429475861_38752",
        "original_caption": "an adult woman is in front of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other adult on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                143
            ],
            "duration": 144,
            "token": {
                "<s0>": 0,
                "<e0>": 144
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_38753",
        "original_caption": "a pink bottle is above the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a pink bottle is above the baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 0,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_38754",
        "original_caption": "a child in blue is behind an adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue is behind an adult on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 360,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_38755",
        "original_caption": "an adult in white is above a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white is above a watercraft on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3802656968",
        "aid": "3802656968_38756",
        "original_caption": "an adult wearing a watch is behind another adult wearing white scoks.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the other adult wearing white scoks from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1481
            ],
            "duration": 1482,
            "token": {
                "<s0>": 273,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3004044251",
        "aid": "3004044251_38757",
        "original_caption": "an adult in black holds a camera at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black holds a camera at home."
            }
        ],
        "meta": {
            "split": [
                0,
                663
            ],
            "duration": 664,
            "token": {
                "<s0>": 0,
                "<e0>": 664
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_38758",
        "original_caption": "a child is above a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is above a snowboard in the snow."
            }
        ],
        "meta": {
            "split": [
                645,
                818
            ],
            "duration": 174,
            "token": {
                "<s0>": 47,
                "<e0>": 164
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9038264963",
        "aid": "9038264963_38759",
        "original_caption": "there is a cup above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                5006
            ],
            "duration": 5007,
            "token": {
                "<s0>": 1920,
                "<e0>": 5007
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6115043636",
        "aid": "6115043636_38760",
        "original_caption": "a leftmost adult watches a shortest adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A leftmost adult watches a shortest adult."
            }
        ],
        "meta": {
            "split": [
                495,
                863
            ],
            "duration": 369,
            "token": {
                "<s0>": 109,
                "<e0>": 131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38761",
        "original_caption": "an adult man in black holds a black cellphone at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black holds a black cellphone at party."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2145,
                "<e0>": 2274
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_38762",
        "original_caption": "there is a chair beneath an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                1151,
                2114
            ],
            "duration": 964,
            "token": {
                "<s0>": 139,
                "<e0>": 558
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_38763",
        "original_caption": "an adult is above a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the snowboard in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 180,
                "<e0>": 228
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4672243606",
        "aid": "4672243606_38764",
        "original_caption": "a child in white speaks to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white speaks to an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                130
            ],
            "duration": 131,
            "token": {
                "<s0>": 0,
                "<e0>": 30
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4672243606",
        "aid": "4672243606_38765",
        "original_caption": "a child in white speaks to an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white speaks to an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                130,
                681
            ],
            "duration": 552,
            "token": {
                "<s0>": 101,
                "<e0>": 442
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_38766",
        "original_caption": "there is a bottle next to another bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle next to another bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                1649
            ],
            "duration": 1650,
            "token": {
                "<s0>": 330,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3521372410",
        "aid": "3521372410_38767",
        "original_caption": "an adult in black clothes is behind a baby in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                231,
                680
            ],
            "duration": 450,
            "token": {
                "<s0>": 144,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_38768",
        "original_caption": "a child in white is towards a silver car on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white is towards a silver car on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 300,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2882005417",
        "aid": "2882005417_38769",
        "original_caption": "an adult man uses a silver camera on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man uses a silver camera on the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                922
            ],
            "duration": 923,
            "token": {
                "<s0>": 643,
                "<e0>": 681
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3771729228",
        "aid": "3771729228_38770",
        "original_caption": "an adult wearing a hat waves a bat on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a hat waves a bat on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                399
            ],
            "duration": 400,
            "token": {
                "<s0>": 96,
                "<e0>": 143
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38771",
        "original_caption": "there is a table behind an adult woman in purple in kindergarten.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table behind an adult woman in purple in kindergarten happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                175,
                1094
            ],
            "duration": 920,
            "token": {
                "<s0>": 125,
                "<e0>": 215
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_38772",
        "original_caption": "an adult with glasses speaks to another adult with long hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with glasses speaks to another adult with long hair."
            }
        ],
        "meta": {
            "split": [
                0,
                1859
            ],
            "duration": 1860,
            "token": {
                "<s0>": 1270,
                "<e0>": 1751
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_38773",
        "original_caption": "an adult with glasses speaks to another adult with long hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult with glasses speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1859,
                2289
            ],
            "duration": 431,
            "token": {
                "<s0>": 109,
                "<e0>": 167
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_38774",
        "original_caption": "an adult with glasses speaks to another adult with long hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with glasses speaks to another adult with long hair."
            }
        ],
        "meta": {
            "split": [
                2289,
                2696
            ],
            "duration": 408,
            "token": {
                "<s0>": 264,
                "<e0>": 408
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_38775",
        "original_caption": "an adult in red speaks to a child in white dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in red speak to  from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1145
            ],
            "duration": 1146,
            "token": {
                "<s0>": 150,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_38776",
        "original_caption": "an adult in black is towards another adult in blue in the tent.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the other adult in blue in the tent from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                5394
            ],
            "duration": 5395,
            "token": {
                "<s0>": 3720,
                "<e0>": 3870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_38777",
        "original_caption": "an adult wearing a blue hat is behind another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a blue hat is behind another adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 737,
                "<e0>": 959
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3185202077",
        "aid": "3185202077_38778",
        "original_caption": "an adult wearing a blue hat is towards another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a blue hat is towards another adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                409
            ],
            "duration": 410,
            "token": {
                "<s0>": 90,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_38779",
        "original_caption": "a baby in yellow holds hand of an adult in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in yellow holds hand of an adult in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                703
            ],
            "duration": 704,
            "token": {
                "<s0>": 0,
                "<e0>": 442
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_38780",
        "original_caption": "a baby in yellow holds hand of an adult in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in yellow holds hand of an adult in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                703,
                1229
            ],
            "duration": 527,
            "token": {
                "<s0>": 262,
                "<e0>": 352
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_38781",
        "original_caption": "a baby in yellow holds hand of an adult in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in yellow holds hand of an adult in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                1229,
                1466
            ],
            "duration": 238,
            "token": {
                "<s0>": 175,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5345319548",
        "aid": "5345319548_38782",
        "original_caption": "the adult in glasses is waving the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in glasses is waving the toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                134,
                269
            ],
            "duration": 136,
            "token": {
                "<s0>": 71,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5345319548",
        "aid": "5345319548_38783",
        "original_caption": "the adult in glasses is waving the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is waving the toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                545,
                649
            ],
            "duration": 105,
            "token": {
                "<s0>": 29,
                "<e0>": 45
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5345319548",
        "aid": "5345319548_38784",
        "original_caption": "the adult in glasses is waving the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in glasses is waving the toy."
            }
        ],
        "meta": {
            "split": [
                649,
                790
            ],
            "duration": 142,
            "token": {
                "<s0>": 60,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_38785",
        "original_caption": "a child in blue and white clothes hits another child in grey clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue and white clothes hits another child in grey clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1472,
                "<e0>": 1530
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2571578063",
        "aid": "2571578063_38786",
        "original_caption": "there is an orange backpack next to an adult in yellow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the orange backpack next to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                158
            ],
            "duration": 159,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4452848541",
        "aid": "4452848541_38787",
        "original_caption": "an adult with plaid shirt holds a cellphone in the bus.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with plaid shirt holds a cellphone in the bus."
            }
        ],
        "meta": {
            "split": [
                0,
                839
            ],
            "duration": 840,
            "token": {
                "<s0>": 0,
                "<e0>": 410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_38788",
        "original_caption": "an adult in red clothes is away an adult in black pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes is away an adult in black pants."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 764,
                "<e0>": 854
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_38789",
        "original_caption": "an adult woman in purple plays a yellow guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in purple plays a yellow guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1204
            ],
            "duration": 1205,
            "token": {
                "<s0>": 0,
                "<e0>": 1120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_38790",
        "original_caption": "an adult woman in purple plays a yellow guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in purple plays a yellow guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                1204,
                2196
            ],
            "duration": 993,
            "token": {
                "<s0>": 84,
                "<e0>": 993
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6595030215",
        "aid": "6595030215_38791",
        "original_caption": "an adult in black clothes holds hand of a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes holds hand of a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                465
            ],
            "duration": 466,
            "token": {
                "<s0>": 0,
                "<e0>": 466
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38792",
        "original_caption": "there is a rat above another rat indoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the hamster/rat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a rat above another rat indoors."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1084,
                "<e0>": 1169
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_38793",
        "original_caption": "a child in red clothes watches an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red clothes watches an adult in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                682,
                1709
            ],
            "duration": 1028,
            "token": {
                "<s0>": 7,
                "<e0>": 33
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38794",
        "original_caption": "a child is towards a table at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child towards to at party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 360,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4491372354",
        "aid": "4491372354_38795",
        "original_caption": "a child in yellow carries a white handbag outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries the white handbag outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                312
            ],
            "duration": 313,
            "token": {
                "<s0>": 0,
                "<e0>": 313
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38796",
        "original_caption": "there is a bench in front of an adult in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in the gym from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bench."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 0,
                "<e0>": 72
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2400031830",
        "aid": "2400031830_38797",
        "original_caption": "a baby is in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                362
            ],
            "duration": 363,
            "token": {
                "<s0>": 0,
                "<e0>": 342
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_38798",
        "original_caption": "an adult in red is above a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red is above a chair at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1877
            ],
            "duration": 1878,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_38799",
        "original_caption": "an adult woman in black is towards another adult woman in black in the tent.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in black is towards another adult woman in black in the tent happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                5394
            ],
            "duration": 5395,
            "token": {
                "<s0>": 3720,
                "<e0>": 3870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7518834808",
        "aid": "7518834808_38800",
        "original_caption": "a baby in blue touches a sports ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in blue touches a sports ball on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 473,
                "<e0>": 663
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38801",
        "original_caption": "an adult in pink is beneath a monitor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pink is beneath a monitor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_38802",
        "original_caption": "there is a cake above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cake."
            }
        ],
        "meta": {
            "split": [
                433,
                979
            ],
            "duration": 547,
            "token": {
                "<s0>": 131,
                "<e0>": 295
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_38803",
        "original_caption": "a baby in orange grabs an orange toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in orange grabs an orange toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 584,
                "<e0>": 606
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_38804",
        "original_caption": "a baby in purple clothes is behind a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in purple clothes is behind a chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 100,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8973361272",
        "aid": "8973361272_38805",
        "original_caption": "a child holds a toy in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a toy in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                349
            ],
            "duration": 350,
            "token": {
                "<s0>": 0,
                "<e0>": 339
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8973361272",
        "aid": "8973361272_38806",
        "original_caption": "a child holds a toy in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child holds a toy in a room."
            }
        ],
        "meta": {
            "split": [
                486,
                600
            ],
            "duration": 115,
            "token": {
                "<s0>": 8,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_38807",
        "original_caption": "there is a red chair in front of an adult man in white on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult man in white on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                285,
                1424
            ],
            "duration": 1140,
            "token": {
                "<s0>": 15,
                "<e0>": 1125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_38808",
        "original_caption": "there is a monitor above a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a monitor above a bottle in the living room."
            }
        ],
        "meta": {
            "split": [
                1754,
                2696
            ],
            "duration": 943,
            "token": {
                "<s0>": 46,
                "<e0>": 943
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3656309376",
        "aid": "3656309376_38809",
        "original_caption": "an adult wearing a no.13 jersey grabs a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult wearing the no.13 jersey grab from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                374
            ],
            "duration": 375,
            "token": {
                "<s0>": 37,
                "<e0>": 52
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38810",
        "original_caption": "an adult caresses a hamster on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult caress on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                1648
            ],
            "duration": 1649,
            "token": {
                "<s0>": 1148,
                "<e0>": 1194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38811",
        "original_caption": "an adult caresses a hamster on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a hamster on the floor."
            }
        ],
        "meta": {
            "split": [
                1648,
                2639
            ],
            "duration": 992,
            "token": {
                "<s0>": 455,
                "<e0>": 499
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2468039507",
        "aid": "2468039507_38812",
        "original_caption": "an adult man in black is above a black gray motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black is above a black gray motorcycle."
            }
        ],
        "meta": {
            "split": [
                0,
                507
            ],
            "duration": 508,
            "token": {
                "<s0>": 0,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_38813",
        "original_caption": "the adult in jeans is waving hand to the adult in a short pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is waving hand to the adult in a short pants from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                788
            ],
            "duration": 789,
            "token": {
                "<s0>": 737,
                "<e0>": 771
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_38814",
        "original_caption": "the adult in jeans is waving hand to the adult in a short pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in jeans is waving hand to the adult in a short pants."
            }
        ],
        "meta": {
            "split": [
                788,
                1424
            ],
            "duration": 637,
            "token": {
                "<s0>": 17,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6485306977",
        "aid": "6485306977_38815",
        "original_caption": "there is a cup beneath a naked baby in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the naked baby in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                1889,
                2696
            ],
            "duration": 808,
            "token": {
                "<s0>": 62,
                "<e0>": 807
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12577546265",
        "aid": "12577546265_38816",
        "original_caption": "an adult in brown clothes rides a green snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in brown clothes rides a green snowboard happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                45,
                190
            ],
            "duration": 146,
            "token": {
                "<s0>": 21,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2729135977",
        "aid": "2729135977_38817",
        "original_caption": "a baby in brown pats a black chair outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in brown pats a black chair outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 256,
                "<e0>": 318
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_38818",
        "original_caption": "an adult in green rides a yellow watercraft in the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green rides a yellow watercraft in the river."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_38819",
        "original_caption": "the baby watches at the cat on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the baby watches at the cat on the carpet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1152,
                2144
            ],
            "duration": 993,
            "token": {
                "<s0>": 125,
                "<e0>": 599
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5053937486",
        "aid": "5053937486_38820",
        "original_caption": "an adult drives a black car in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult drives a black car in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                246
            ],
            "duration": 247,
            "token": {
                "<s0>": 0,
                "<e0>": 218
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_38821",
        "original_caption": "there is a black laptop above a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black laptop above a table."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 1697,
                "<e0>": 1756
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_38822",
        "original_caption": "an adult is behind another adult on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 338,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38823",
        "original_caption": "there is a black hamster leaning on another black hamster on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black hamster leaning on another black hamster on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 275,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_38824",
        "original_caption": "a baby in white clothes holds the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white clothes holds the fruits happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2147,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_38825",
        "original_caption": "an adult woman in black is in front of a screen in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black is in front of a screen in a room."
            }
        ],
        "meta": {
            "split": [
                464,
                611
            ],
            "duration": 148,
            "token": {
                "<s0>": 16,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6949702600",
        "aid": "6949702600_38826",
        "original_caption": "there is a gray handbag above a yellow chair on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a gray handbag above a yellow chair on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 378,
                "<e0>": 430
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38827",
        "original_caption": "there is a screen above an adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a screen above an adult inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_38828",
        "original_caption": "adults in striped clothes talk to adults in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho are the adults in striped clothes speaking to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                289
            ],
            "duration": 290,
            "token": {
                "<s0>": 0,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_38829",
        "original_caption": "adults in striped clothes talk to adults in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adults in striped clothes talk to adults in black clothes."
            }
        ],
        "meta": {
            "split": [
                289,
                929
            ],
            "duration": 641,
            "token": {
                "<s0>": 226,
                "<e0>": 277
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38830",
        "original_caption": "an adult is above a watercraft on the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is above a watercraft on the sea."
            }
        ],
        "meta": {
            "split": [
                905,
                1478
            ],
            "duration": 574,
            "token": {
                "<s0>": 516,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6913658789",
        "aid": "6913658789_38831",
        "original_caption": "a baby watches a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby watches a toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1530,
                2432
            ],
            "duration": 903,
            "token": {
                "<s0>": 855,
                "<e0>": 874
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_38832",
        "original_caption": "there is a pink toy behind a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 600,
                "<e0>": 689
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3561761322",
        "aid": "3561761322_38833",
        "original_caption": "an adult man in red is above a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in red is above a bicycle on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                125
            ],
            "duration": 126,
            "token": {
                "<s0>": 21,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_38834",
        "original_caption": "there is a brown wooden chair beneath a brown and white cat in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown wooden chair beneath a brown and white cat in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1271
            ],
            "duration": 1272,
            "token": {
                "<s0>": 0,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_38835",
        "original_caption": "a child is above a bicycle in the path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is above a bicycle in the path happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                121,
                927
            ],
            "duration": 807,
            "token": {
                "<s0>": 34,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38836",
        "original_caption": "an adult is above a watercraft on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a watercraft on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 486,
                "<e0>": 1393
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5202728101",
        "aid": "5202728101_38837",
        "original_caption": "a child in blue clothes presses a dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue clothes presses a dog."
            }
        ],
        "meta": {
            "split": [
                74,
                240
            ],
            "duration": 167,
            "token": {
                "<s0>": 32,
                "<e0>": 72
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_38838",
        "original_caption": "a male adult holds hand of another adult with white-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a male adult holds hand of another adult with white-hair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 0,
                "<e0>": 382
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_38839",
        "original_caption": "an adult in beige clothes watches the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in beige clothes watches the guitar."
            }
        ],
        "meta": {
            "split": [
                354,
                2249
            ],
            "duration": 1896,
            "token": {
                "<s0>": 40,
                "<e0>": 1896
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_38840",
        "original_caption": "an adult uses a laptop in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult uses a laptop in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                1319
            ],
            "duration": 1320,
            "token": {
                "<s0>": 169,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_38841",
        "original_caption": "an adult on the left speaks to a child in red outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult on the left speaks to a child in red outdoor."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 587,
                "<e0>": 643
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5302457137",
        "aid": "5302457137_38842",
        "original_caption": "there is a yellow cat above a sink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a yellow cat above a sink."
            }
        ],
        "meta": {
            "split": [
                0,
                521
            ],
            "duration": 522,
            "token": {
                "<s0>": 0,
                "<e0>": 521
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_38843",
        "original_caption": "there is a child riding the blue snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a child riding the blue snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_38844",
        "original_caption": "there is a golden chair behind a child in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a golden chair behind a child in white."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 120,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_38845",
        "original_caption": "a child is above another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the child in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 180,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_38846",
        "original_caption": "there is a toy beneath a child on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy beneath a child on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 0,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38847",
        "original_caption": "an adult is beneath a screen in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the screen in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_38848",
        "original_caption": "an adult man in dark blue carries a black handbag.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in dark blue carries a black handbag happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 903,
                "<e0>": 1025
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_38849",
        "original_caption": "a child in white is towards another child in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white is towards another child in green."
            }
        ],
        "meta": {
            "split": [
                1365,
                4260
            ],
            "duration": 2896,
            "token": {
                "<s0>": 735,
                "<e0>": 825
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_38850",
        "original_caption": "a child in blue is next to a toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue is next to a toy at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                396,
                1653
            ],
            "duration": 1258,
            "token": {
                "<s0>": 29,
                "<e0>": 1253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3783730077",
        "aid": "3783730077_38851",
        "original_caption": "an adult in a shirt is away from the adult in a kimono.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in a shirt is away from the adult in a kimono happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                963
            ],
            "duration": 964,
            "token": {
                "<s0>": 180,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2942623423",
        "aid": "2942623423_38852",
        "original_caption": "an adult woman is in front of another adult man in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman is in front of another adult man in the room."
            }
        ],
        "meta": {
            "split": [
                624,
                734
            ],
            "duration": 111,
            "token": {
                "<s0>": 17,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_38853",
        "original_caption": "an adult in white is beneath another adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white is beneath another adult outdoors."
            }
        ],
        "meta": {
            "split": [
                524,
                735
            ],
            "duration": 212,
            "token": {
                "<s0>": 16,
                "<e0>": 212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2503862291",
        "aid": "2503862291_38854",
        "original_caption": "a child in white is in front of an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white is in front of an adult in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                850
            ],
            "duration": 851,
            "token": {
                "<s0>": 188,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38855",
        "original_caption": "an adult rides a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                743
            ],
            "duration": 744,
            "token": {
                "<s0>": 0,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38856",
        "original_caption": "an adult rides a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                743,
                1478
            ],
            "duration": 736,
            "token": {
                "<s0>": 678,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4474456610",
        "aid": "4474456610_38857",
        "original_caption": "there is a toy behind a child in stride shirt in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy behind a child in stride shirt in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1517,
                "<e0>": 1589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3828002440",
        "aid": "3828002440_38858",
        "original_caption": "an adult hugs a baby in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult hugs a baby in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                289
            ],
            "duration": 290,
            "token": {
                "<s0>": 0,
                "<e0>": 290
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38859",
        "original_caption": "an adult in the middle grabs a cup in the middle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in the middle grabs a cup in the middle."
            }
        ],
        "meta": {
            "split": [
                1305,
                2159
            ],
            "duration": 855,
            "token": {
                "<s0>": 808,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6789657160",
        "aid": "6789657160_38860",
        "original_caption": "a child in white leans on an adult in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white leans on an adult in red."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 0,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_38861",
        "original_caption": "an adult in pink holds hand of another adult in black in the dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in pink holds hand of another adult in black in the dark room."
            }
        ],
        "meta": {
            "split": [
                72,
                163
            ],
            "duration": 92,
            "token": {
                "<s0>": 17,
                "<e0>": 55
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_38862",
        "original_caption": "an adult in pink holds hand of another adult in black in the dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in pink holds hand of another adult in black in the dark room."
            }
        ],
        "meta": {
            "split": [
                163,
                397
            ],
            "duration": 235,
            "token": {
                "<s0>": 37,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_38863",
        "original_caption": "an adult in pink holds hand of another adult in black in the dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in pink holds hand of another adult in black in the dark room."
            }
        ],
        "meta": {
            "split": [
                397,
                634
            ],
            "duration": 238,
            "token": {
                "<s0>": 179,
                "<e0>": 230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_38864",
        "original_caption": "an adult in pink holds hand of another adult in black in the dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in pink holds hand of another adult in black in the dark room."
            }
        ],
        "meta": {
            "split": [
                634,
                732
            ],
            "duration": 99,
            "token": {
                "<s0>": 7,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_38865",
        "original_caption": "an adult in pink holds hand of another adult in black in the dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in pink hold hand of in the dark room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                891,
                1034
            ],
            "duration": 144,
            "token": {
                "<s0>": 19,
                "<e0>": 48
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_38866",
        "original_caption": "an adult in black clothes is next to a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the backpack from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 249,
                "<e0>": 1049
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3898106739",
        "aid": "3898106739_38867",
        "original_caption": "a child is away from an adult in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from an adult in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                1232
            ],
            "duration": 1233,
            "token": {
                "<s0>": 1140,
                "<e0>": 1230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5202728101",
        "aid": "5202728101_38868",
        "original_caption": "a child in green chases a brown dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in green chases a brown dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 205
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13816283384",
        "aid": "13816283384_38869",
        "original_caption": "there is a cat above a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cat above a sofa at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                718
            ],
            "duration": 719,
            "token": {
                "<s0>": 0,
                "<e0>": 719
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2513630909",
        "aid": "2513630909_38870",
        "original_caption": "there is a dog watching another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the dog watch on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                1456
            ],
            "duration": 1457,
            "token": {
                "<s0>": 953,
                "<e0>": 1383
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2792480681",
        "aid": "2792480681_38871",
        "original_caption": "an adult in blue clothes is away from another adult in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes is away from another adult in pink clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                526
            ],
            "duration": 527,
            "token": {
                "<s0>": 420,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38872",
        "original_caption": "there is a cup above a table outside the door.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table outside the door."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10440265715",
        "aid": "10440265715_38873",
        "original_caption": "a child in blue is behind another child in red in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue is behind another child in red in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                3105,
                3799
            ],
            "duration": 695,
            "token": {
                "<s0>": 255,
                "<e0>": 465
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38874",
        "original_caption": "a sports ball is away a child .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A sports ball is away a child ."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 278,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38875",
        "original_caption": "there is a brown table next to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown table next to a child at home."
            }
        ],
        "meta": {
            "split": [
                237,
                1349
            ],
            "duration": 1113,
            "token": {
                "<s0>": 13,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6366208783",
        "aid": "6366208783_38876",
        "original_caption": "there is a monitor behind a child in a dress at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the child in a dress at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                502
            ],
            "duration": 503,
            "token": {
                "<s0>": 0,
                "<e0>": 503
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4569009647",
        "aid": "4569009647_38877",
        "original_caption": "an adult in blue speaks to another adult in red in the open air.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in blue speak to in the open air from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2436
            ],
            "duration": 2437,
            "token": {
                "<s0>": 303,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5994899092",
        "aid": "5994899092_38878",
        "original_caption": "an adult pushes a surfboard on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult pushes a surfboard on the beach happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 986,
                "<e0>": 1012
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10274034226",
        "aid": "10274034226_38879",
        "original_caption": "there is a beige dog towards a child in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a beige dog towards a child in pink clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                422
            ],
            "duration": 423,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3137412934",
        "aid": "3137412934_38880",
        "original_caption": "a child in white clothes holds a red cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white clothes holds a red cup."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 207,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3836995607",
        "aid": "3836995607_38881",
        "original_caption": "an adult man in white is away from another adult man in yellow in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white is away from another adult man in yellow in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                96
            ],
            "duration": 97,
            "token": {
                "<s0>": 32,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3145413102",
        "aid": "3145413102_38882",
        "original_caption": "an adult in blue clothes speaks to another adult with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue clothes speaks to another adult with glasses happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                775
            ],
            "duration": 776,
            "token": {
                "<s0>": 126,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38883",
        "original_caption": "there is a grey hamster towards a black hamster.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a grey hamster towards a black hamster."
            }
        ],
        "meta": {
            "split": [
                863,
                2639
            ],
            "duration": 1777,
            "token": {
                "<s0>": 37,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_38884",
        "original_caption": "there is an adult away from another adult .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is an adult away from another adult ."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 23,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_38885",
        "original_caption": "there is a blue cake above a brown table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a blue cake above a brown table."
            }
        ],
        "meta": {
            "split": [
                872,
                2225
            ],
            "duration": 1354,
            "token": {
                "<s0>": 7,
                "<e0>": 236
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38886",
        "original_caption": "there is a white laptop behind a child wearing striped shirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the child wearing striped shirt from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 200,
                "<e0>": 275
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6434469849",
        "aid": "6434469849_38887",
        "original_caption": "there is a black dog licking a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black dog licking a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                485
            ],
            "duration": 486,
            "token": {
                "<s0>": 93,
                "<e0>": 229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7972054306",
        "aid": "7972054306_38888",
        "original_caption": "an adult in blue clothes is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                816
            ],
            "duration": 817,
            "token": {
                "<s0>": 288,
                "<e0>": 398
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_38889",
        "original_caption": "there is a cake above a table in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cake above a table in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6134739139",
        "aid": "6134739139_38890",
        "original_caption": "there is a green toy above a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the chair at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1968
            ],
            "duration": 1969,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38891",
        "original_caption": "there is a silver ball behind an adult man in blue on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a silver ball behind an adult man in blue on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 240,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_38892",
        "original_caption": "there is a baby seat beneath a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_seat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a baby seat beneath a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                250
            ],
            "duration": 251,
            "token": {
                "<s0>": 0,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3282832711",
        "aid": "3282832711_38893",
        "original_caption": "there is a white faucet above a white sink in the kitchen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the faucet from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white faucet above a white sink in the kitchen."
            }
        ],
        "meta": {
            "split": [
                884,
                1419
            ],
            "duration": 536,
            "token": {
                "<s0>": 76,
                "<e0>": 526
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38894",
        "original_caption": "an adult points to a child on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho points to the child on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 333,
                "<e0>": 362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2815147671",
        "aid": "2815147671_38895",
        "original_caption": "an adult woman in gray white is towards another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray white is towards another adult."
            }
        ],
        "meta": {
            "split": [
                690,
                1233
            ],
            "duration": 544,
            "token": {
                "<s0>": 62,
                "<e0>": 119
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_38896",
        "original_caption": "a child in blue is behind an another child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue is behind an another child in red happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                524,
                681
            ],
            "duration": 158,
            "token": {
                "<s0>": 16,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38897",
        "original_caption": "an adult in multi-color is away a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                284,
                595
            ],
            "duration": 312,
            "token": {
                "<s0>": 76,
                "<e0>": 226
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_38898",
        "original_caption": "there is a bottle above a table on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle above a table on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38899",
        "original_caption": "an adult in red clothes is away from a bench.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the bench from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 1248,
                "<e0>": 1298
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3852871000",
        "aid": "3852871000_38900",
        "original_caption": "there is a long and yellow table beneath a white cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a long and yellow table beneath a white cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1949
            ],
            "duration": 1950,
            "token": {
                "<s0>": 0,
                "<e0>": 1950
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38901",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white and black speaks to another adult in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                413
            ],
            "duration": 414,
            "token": {
                "<s0>": 262,
                "<e0>": 355
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38902",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white and black speaks to another adult in black."
            }
        ],
        "meta": {
            "split": [
                413,
                726
            ],
            "duration": 314,
            "token": {
                "<s0>": 58,
                "<e0>": 237
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38903",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white and black speaks to another adult in black."
            }
        ],
        "meta": {
            "split": [
                726,
                889
            ],
            "duration": 164,
            "token": {
                "<s0>": 76,
                "<e0>": 128
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38904",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white and black speaks to another adult in black."
            }
        ],
        "meta": {
            "split": [
                889,
                1029
            ],
            "duration": 141,
            "token": {
                "<s0>": 36,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38905",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white and black speaks to another adult in black."
            }
        ],
        "meta": {
            "split": [
                1029,
                1251
            ],
            "duration": 223,
            "token": {
                "<s0>": 42,
                "<e0>": 189
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38906",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white and black speaks to another adult in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1251,
                1643
            ],
            "duration": 393,
            "token": {
                "<s0>": 33,
                "<e0>": 212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38907",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white and black speaks to another adult in black."
            }
        ],
        "meta": {
            "split": [
                1643,
                1951
            ],
            "duration": 309,
            "token": {
                "<s0>": 181,
                "<e0>": 219
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38908",
        "original_caption": "an adult in white and black speaks to another adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in white and black speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1951,
                2159
            ],
            "duration": 209,
            "token": {
                "<s0>": 90,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_38909",
        "original_caption": "an adult in blue grabs a blue toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho grabs the blue toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                892
            ],
            "duration": 893,
            "token": {
                "<s0>": 810,
                "<e0>": 880
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_38910",
        "original_caption": "an adult in blue grabs a blue toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue grabs a blue toy."
            }
        ],
        "meta": {
            "split": [
                892,
                998
            ],
            "duration": 107,
            "token": {
                "<s0>": 13,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_38911",
        "original_caption": "there is a chair next to the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair next to the table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 553,
                "<e0>": 1349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3304644092",
        "aid": "3304644092_38912",
        "original_caption": "an adult in red holds a handbag in the shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red holds a handbag in the shop happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                200
            ],
            "duration": 201,
            "token": {
                "<s0>": 0,
                "<e0>": 114
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3304644092",
        "aid": "3304644092_38913",
        "original_caption": "an adult in red holds a handbag in the shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red holds a handbag in the shop happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                200,
                623
            ],
            "duration": 424,
            "token": {
                "<s0>": 86,
                "<e0>": 244
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3304644092",
        "aid": "3304644092_38914",
        "original_caption": "an adult in red holds a handbag in the shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red holds a handbag in the shop happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                623,
                927
            ],
            "duration": 305,
            "token": {
                "<s0>": 179,
                "<e0>": 230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7122184611",
        "aid": "7122184611_38915",
        "original_caption": "there are the guitar next to an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there are the guitar next to an adult in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1458
            ],
            "duration": 1459,
            "token": {
                "<s0>": 0,
                "<e0>": 1459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10440265715",
        "aid": "10440265715_38916",
        "original_caption": "a child in red is towards another child in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the other child in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                2954,
                3799
            ],
            "duration": 846,
            "token": {
                "<s0>": 586,
                "<e0>": 846
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4656902106",
        "aid": "4656902106_38917",
        "original_caption": "a child in red is towards an adult in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is towards an adult in the forest happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_38918",
        "original_caption": "a newborn baby is above a white sink in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A newborn baby is above a white sink in a room."
            }
        ],
        "meta": {
            "split": [
                817,
                915
            ],
            "duration": 99,
            "token": {
                "<s0>": 40,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3855730364",
        "aid": "3855730364_38919",
        "original_caption": "there is a fish above another fish in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a fish above another fish in the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 240,
                "<e0>": 419
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_38920",
        "original_caption": "a baby leans on a baby seat in the study.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby leans on a baby seat in the study."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 0,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_38921",
        "original_caption": "a baby leans on a baby seat in the study.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby leans on a baby seat in the study."
            }
        ],
        "meta": {
            "split": [
                357,
                794
            ],
            "duration": 438,
            "token": {
                "<s0>": 290,
                "<e0>": 438
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3561761322",
        "aid": "3561761322_38922",
        "original_caption": "there is a bicycle beneath an adult man in red on th road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bicycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bicycle beneath an adult man in red on th road."
            }
        ],
        "meta": {
            "split": [
                0,
                125
            ],
            "duration": 126,
            "token": {
                "<s0>": 21,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_38923",
        "original_caption": "an adult man holds a baby in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man holds a baby in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                760
            ],
            "duration": 761,
            "token": {
                "<s0>": 714,
                "<e0>": 761
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4231951231",
        "aid": "4231951231_38924",
        "original_caption": "an adult in black hits an adult in red .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho hits the adult in red from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                754
            ],
            "duration": 755,
            "token": {
                "<s0>": 522,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3520546318",
        "aid": "3520546318_38925",
        "original_caption": "a baby in red leans on an adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the baby in red lean on on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                207
            ],
            "duration": 208,
            "token": {
                "<s0>": 0,
                "<e0>": 207
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6644166529",
        "aid": "6644166529_38926",
        "original_caption": "there is a dish above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dish from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dish above a table in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_38927",
        "original_caption": "an adult in blue clothes is towards a child wearing blue pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes is towards a child wearing blue pants."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38928",
        "original_caption": "an adult in white suit is away from another adult in black suit.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the other adult in black suit from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                555,
                1011
            ],
            "duration": 457,
            "token": {
                "<s0>": 45,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_38929",
        "original_caption": "there is a black camera above a brown yellow wooden stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the brown yellow wooden stool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A camera."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 678,
                "<e0>": 780
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38930",
        "original_caption": "an adult is towards another adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is towards another adult in the room."
            }
        ],
        "meta": {
            "split": [
                1935,
                2271
            ],
            "duration": 337,
            "token": {
                "<s0>": 105,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_38931",
        "original_caption": "an adult man is watch the adult women.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man is watch the adult women."
            }
        ],
        "meta": {
            "split": [
                963,
                1323
            ],
            "duration": 361,
            "token": {
                "<s0>": 24,
                "<e0>": 137
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_38932",
        "original_caption": "there is a black table beneath a glass cup on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the glass cup on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 60,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_38933",
        "original_caption": "the adult man in white is walking towards the adult woman with black sleeves .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is walking towards the adult woman from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 420,
                "<e0>": 472
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6967372488",
        "aid": "6967372488_38934",
        "original_caption": "an adult in black leans on a table in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black lean on in the classroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                613
            ],
            "duration": 614,
            "token": {
                "<s0>": 0,
                "<e0>": 597
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6967372488",
        "aid": "6967372488_38935",
        "original_caption": "an adult in black leans on a table in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in black lean on in the classroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                613,
                989
            ],
            "duration": 377,
            "token": {
                "<s0>": 16,
                "<e0>": 377
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3144421811",
        "aid": "3144421811_38936",
        "original_caption": "an adult presses another adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult presses another adult in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                179
            ],
            "duration": 180,
            "token": {
                "<s0>": 0,
                "<e0>": 180
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10729424884",
        "aid": "10729424884_38937",
        "original_caption": "an adult woman is next to another adult man in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman is next to another adult man in a bar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                699
            ],
            "duration": 700,
            "token": {
                "<s0>": 360,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_38938",
        "original_caption": "there is child in red towards adult women.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards adult women from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 600,
                "<e0>": 675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38939",
        "original_caption": "an adult in gery clothes pulls a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in gery clothes pulls a cake."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2302,
                "<e0>": 2396
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3315181459",
        "aid": "3315181459_38940",
        "original_caption": "an adult in white speaks to another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white speaks to another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                694
            ],
            "duration": 695,
            "token": {
                "<s0>": 0,
                "<e0>": 635
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_38941",
        "original_caption": "there is a gray sofa above a child in black at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a gray sofa above a child in black at home."
            }
        ],
        "meta": {
            "split": [
                0,
                334
            ],
            "duration": 335,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8290475933",
        "aid": "8290475933_38942",
        "original_caption": "an adult with glasses hugs a female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with glasses hugs a female adult."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 0,
                "<e0>": 870
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3710885997",
        "aid": "3710885997_38943",
        "original_caption": "an adult is in front of a child .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is in front of a child ."
            }
        ],
        "meta": {
            "split": [
                0,
                497
            ],
            "duration": 498,
            "token": {
                "<s0>": 436,
                "<e0>": 497
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_38944",
        "original_caption": "there is a dog beneath a black car outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog beneath a black car outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 200,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_38945",
        "original_caption": "there is a watercraft beneath an adult on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a watercraft beneath an adult on the lake."
            }
        ],
        "meta": {
            "split": [
                841,
                1478
            ],
            "duration": 638,
            "token": {
                "<s0>": 580,
                "<e0>": 628
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5504745801",
        "aid": "5504745801_38946",
        "original_caption": "a child is next to a ski in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the ski in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                203
            ],
            "duration": 204,
            "token": {
                "<s0>": 0,
                "<e0>": 204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_38947",
        "original_caption": "there is a laptop above a table in the study room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the laptop in the study room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                1930,
                2533
            ],
            "duration": 604,
            "token": {
                "<s0>": 290,
                "<e0>": 461
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2567306378",
        "aid": "2567306378_38948",
        "original_caption": "an adult is in front of an another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is in front of an another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                241
            ],
            "duration": 242,
            "token": {
                "<s0>": 122,
                "<e0>": 206
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_38949",
        "original_caption": "a child in red is in front of another child in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red is in front of another child in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 180,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_38950",
        "original_caption": "an adult is next to a backpack on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the backpack on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 300,
                "<e0>": 332
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_38951",
        "original_caption": "there is an elephant towards another elephant on th wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is an elephant towards another elephant on th wild."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 1740,
                "<e0>": 1815
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_38952",
        "original_caption": "an adult in jeans is next to another adult in white and black dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in jeans is next to another adult in white and black dress."
            }
        ],
        "meta": {
            "split": [
                225,
                810
            ],
            "duration": 586,
            "token": {
                "<s0>": 75,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7465682132",
        "aid": "7465682132_38953",
        "original_caption": "a child with glasses hugs another child in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with glasses hugs another child in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 0,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_38954",
        "original_caption": "there is a red cup towards a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a red cup towards a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_38955",
        "original_caption": "a child in black is behind another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child in black in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                333,
                411
            ],
            "duration": 79,
            "token": {
                "<s0>": 2,
                "<e0>": 26
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8429686679",
        "aid": "8429686679_38956",
        "original_caption": "an male adult is behind another female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the other female adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1573
            ],
            "duration": 1574,
            "token": {
                "<s0>": 26,
                "<e0>": 617
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_38957",
        "original_caption": "an adult is in front of the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is in front of the child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 0,
                "<e0>": 44
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_38958",
        "original_caption": "a child is above a bicycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is above a bicycle on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 44,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_38959",
        "original_caption": "a child in green clothes presses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in green clothes presses a cellphone happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                507
            ],
            "duration": 508,
            "token": {
                "<s0>": 233,
                "<e0>": 392
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_38960",
        "original_caption": "a child in green clothes presses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in green clothes press from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                507,
                1004
            ],
            "duration": 498,
            "token": {
                "<s0>": 116,
                "<e0>": 176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_38961",
        "original_caption": "a child in green clothes presses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in green clothes presses a cellphone."
            }
        ],
        "meta": {
            "split": [
                1004,
                1417
            ],
            "duration": 414,
            "token": {
                "<s0>": 321,
                "<e0>": 377
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_38962",
        "original_caption": "a child in green clothes presses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in green clothes presses a cellphone."
            }
        ],
        "meta": {
            "split": [
                1417,
                1729
            ],
            "duration": 313,
            "token": {
                "<s0>": 37,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_38963",
        "original_caption": "a child in green clothes presses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in green clothes presses a cellphone happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1729,
                2247
            ],
            "duration": 519,
            "token": {
                "<s0>": 153,
                "<e0>": 437
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_38964",
        "original_caption": "a child in green clothes presses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in green clothes presses a cellphone."
            }
        ],
        "meta": {
            "split": [
                2247,
                2696
            ],
            "duration": 450,
            "token": {
                "<s0>": 82,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7907275512",
        "aid": "7907275512_38965",
        "original_caption": "a child in black leans on a yellow bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black leans on a yellow bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                1715
            ],
            "duration": 1716,
            "token": {
                "<s0>": 1352,
                "<e0>": 1498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_38966",
        "original_caption": "an adult in striped clothes is away from another adult wearing a plaid clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in striped clothes is away from another adult wearing a plaid clothes."
            }
        ],
        "meta": {
            "split": [
                2055,
                2271
            ],
            "duration": 217,
            "token": {
                "<s0>": 45,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3120535570",
        "aid": "3120535570_38967",
        "original_caption": "there is an adult watching the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is an adult watching the adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                147
            ],
            "duration": 148,
            "token": {
                "<s0>": 0,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11018431523",
        "aid": "11018431523_38968",
        "original_caption": "a child in blue is above a black bicycle on a road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the black bicycle on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                591
            ],
            "duration": 592,
            "token": {
                "<s0>": 0,
                "<e0>": 592
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_38969",
        "original_caption": "a child holds a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child holds a toy inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 1479,
                "<e0>": 1845
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6115043636",
        "aid": "6115043636_38970",
        "original_caption": "an older adult is towards to a young adult outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An older adult is towards to a young adult outdoor."
            }
        ],
        "meta": {
            "split": [
                365,
                863
            ],
            "duration": 499,
            "token": {
                "<s0>": 13,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_38971",
        "original_caption": "there is a bicycle beneath an adult on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle beneath an adult on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1571,
                2100
            ],
            "duration": 530,
            "token": {
                "<s0>": 14,
                "<e0>": 529
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_38972",
        "original_caption": "there is a white baby seat beneath a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_seat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white baby seat beneath a toy."
            }
        ],
        "meta": {
            "split": [
                1116,
                2696
            ],
            "duration": 1581,
            "token": {
                "<s0>": 24,
                "<e0>": 354
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_38973",
        "original_caption": "there is a gray cat behind a yellow wooden adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a gray cat behind a yellow wooden adult."
            }
        ],
        "meta": {
            "split": [
                1215,
                2114
            ],
            "duration": 900,
            "token": {
                "<s0>": 50,
                "<e0>": 434
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5622139741",
        "aid": "5622139741_38974",
        "original_caption": "there is a bigger fish behind a smaller fish.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bigger fish behind a smaller fish."
            }
        ],
        "meta": {
            "split": [
                0,
                311
            ],
            "duration": 312,
            "token": {
                "<s0>": 120,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_38975",
        "original_caption": "a baby in red is inside a brown baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in red is inside a brown baby seat at home."
            }
        ],
        "meta": {
            "split": [
                0,
                250
            ],
            "duration": 251,
            "token": {
                "<s0>": 0,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_38976",
        "original_caption": "an adult caresses a black hamster on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult caresses a black hamster on the ground."
            }
        ],
        "meta": {
            "split": [
                1337,
                2639
            ],
            "duration": 1303,
            "token": {
                "<s0>": 109,
                "<e0>": 155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_38977",
        "original_caption": "a baby in white is above a gray sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white is above a gray sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 0,
                "<e0>": 475
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6106626461",
        "aid": "6106626461_38978",
        "original_caption": "the adult in red is towards the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in red is towards the adult in black."
            }
        ],
        "meta": {
            "split": [
                114,
                520
            ],
            "duration": 407,
            "token": {
                "<s0>": 7,
                "<e0>": 25
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_38979",
        "original_caption": "there is a brown cat away an adult man in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away the adult man in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1260,
                "<e0>": 1347
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5296127747",
        "aid": "5296127747_38980",
        "original_caption": "an adult with glasses holds hand of another adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the other adult in white clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 107,
                "<e0>": 333
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_38981",
        "original_caption": "an adult is behind a dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 960,
                "<e0>": 1055
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_38982",
        "original_caption": "a child in blue is behind another child in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child in blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                2144,
                2696
            ],
            "duration": 553,
            "token": {
                "<s0>": 196,
                "<e0>": 346
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38983",
        "original_caption": "an adult man in white holds hand of another adult woman in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult man in white hold hand of from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                350
            ],
            "duration": 351,
            "token": {
                "<s0>": 0,
                "<e0>": 324
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_38984",
        "original_caption": "an adult man in white holds hand of another adult woman in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white holds hand of another adult woman in black."
            }
        ],
        "meta": {
            "split": [
                350,
                1011
            ],
            "duration": 662,
            "token": {
                "<s0>": 26,
                "<e0>": 662
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_38985",
        "original_caption": "a child in ywllow clothes is away from another child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in ywllow clothes is away from another child in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1343
            ],
            "duration": 1344,
            "token": {
                "<s0>": 0,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2414954342",
        "aid": "2414954342_38986",
        "original_caption": "a baby in white holds a red and white toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white holds a red and white toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                400
            ],
            "duration": 401,
            "token": {
                "<s0>": 0,
                "<e0>": 294
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2414954342",
        "aid": "2414954342_38987",
        "original_caption": "a baby in white holds a red and white toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white holds a red and white toy."
            }
        ],
        "meta": {
            "split": [
                400,
                1444
            ],
            "duration": 1045,
            "token": {
                "<s0>": 106,
                "<e0>": 1004
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2414954342",
        "aid": "2414954342_38988",
        "original_caption": "a baby in white holds a red and white toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white holds a red and white toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1444,
                1865
            ],
            "duration": 422,
            "token": {
                "<s0>": 40,
                "<e0>": 422
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_38989",
        "original_caption": "there is a chair next to another chair inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a chair next to another chair inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 96,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38990",
        "original_caption": "an adult in a coat holds a white cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in a coat holds a white cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1522
            ],
            "duration": 1523,
            "token": {
                "<s0>": 839,
                "<e0>": 955
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_38991",
        "original_caption": "an adult in a coat holds a white cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in a coat holds a white cup."
            }
        ],
        "meta": {
            "split": [
                1522,
                2159
            ],
            "duration": 638,
            "token": {
                "<s0>": 567,
                "<e0>": 638
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6789657160",
        "aid": "6789657160_38992",
        "original_caption": "a child in white holds a beige sports ball in a restaurant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white holds a beige sports ball in a restaurant."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 0,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_38993",
        "original_caption": "an adult in red clothes watches a child without dress.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red clothes watches a child without dress happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                180,
                735
            ],
            "duration": 556,
            "token": {
                "<s0>": 77,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_38994",
        "original_caption": "an adult woman in white speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in white speaks to another adult man in black."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 334,
                "<e0>": 393
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6542785403",
        "aid": "6542785403_38995",
        "original_caption": "an adult in red shorts watches another adult in black pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red shorts watches another adult in black pants."
            }
        ],
        "meta": {
            "split": [
                0,
                530
            ],
            "duration": 531,
            "token": {
                "<s0>": 0,
                "<e0>": 26
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5244251013",
        "aid": "5244251013_38996",
        "original_caption": "an adult man in gray speaks to another adult man in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in gray speaks to another adult man in striped clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                655
            ],
            "duration": 656,
            "token": {
                "<s0>": 0,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5244251013",
        "aid": "5244251013_38997",
        "original_caption": "an adult man in gray speaks to another adult man in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in gray speaks to another adult man in striped clothes."
            }
        ],
        "meta": {
            "split": [
                655,
                1618
            ],
            "duration": 964,
            "token": {
                "<s0>": 533,
                "<e0>": 558
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5258789985",
        "aid": "5258789985_38998",
        "original_caption": "an adult in red is next to another adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red is next to another adult on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                544
            ],
            "duration": 545,
            "token": {
                "<s0>": 0,
                "<e0>": 545
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_38999",
        "original_caption": "an adult in brown is towards a laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the laptop from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1319
            ],
            "duration": 1320,
            "token": {
                "<s0>": 120,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_39000",
        "original_caption": "a baby with blond hair is above a baby walker.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby with blond hair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_walker."
            }
        ],
        "meta": {
            "split": [
                1013,
                1516
            ],
            "duration": 504,
            "token": {
                "<s0>": 38,
                "<e0>": 138
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5417864623",
        "aid": "5417864623_39001",
        "original_caption": "a child in pink is above a ski in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink is above a ski in the snow."
            }
        ],
        "meta": {
            "split": [
                79,
                374
            ],
            "duration": 296,
            "token": {
                "<s0>": 21,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39002",
        "original_caption": "an adult is towards another adult in the evening.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards another adult in the evening happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                315,
                793
            ],
            "duration": 479,
            "token": {
                "<s0>": 105,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6247340440",
        "aid": "6247340440_39003",
        "original_caption": "an adult in orange clothes rides a ski.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in orange clothes rides a ski."
            }
        ],
        "meta": {
            "split": [
                0,
                387
            ],
            "duration": 388,
            "token": {
                "<s0>": 314,
                "<e0>": 327
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10250170546",
        "aid": "10250170546_39004",
        "original_caption": "a child presses an adult woman in black in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child presses an adult woman in black in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                393
            ],
            "duration": 394,
            "token": {
                "<s0>": 10,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_39005",
        "original_caption": "an adult in black hits a child on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black hits a child on a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 138,
                "<e0>": 158
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6501432541",
        "aid": "6501432541_39006",
        "original_caption": "a child wearing a black hat is in front of a faucet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing a black hat is in front of a faucet happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                173
            ],
            "duration": 174,
            "token": {
                "<s0>": 0,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11018431523",
        "aid": "11018431523_39007",
        "original_caption": "an adult holds a child in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a child in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                366
            ],
            "duration": 367,
            "token": {
                "<s0>": 0,
                "<e0>": 324
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11018431523",
        "aid": "11018431523_39008",
        "original_caption": "an adult holds a child in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a child in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                366,
                591
            ],
            "duration": 226,
            "token": {
                "<s0>": 42,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10304757716",
        "aid": "10304757716_39009",
        "original_caption": "a baby in green presses a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby in green press in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                651
            ],
            "duration": 652,
            "token": {
                "<s0>": 0,
                "<e0>": 555
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10304757716",
        "aid": "10304757716_39010",
        "original_caption": "a baby in green presses a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in green presses a chair in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                651,
                1622
            ],
            "duration": 972,
            "token": {
                "<s0>": 96,
                "<e0>": 897
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3482621813",
        "aid": "3482621813_39011",
        "original_caption": "there is a penguin in front of an another penguin.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the penguin from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a penguin in front of an another penguin."
            }
        ],
        "meta": {
            "split": [
                234,
                592
            ],
            "duration": 359,
            "token": {
                "<s0>": 186,
                "<e0>": 276
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39012",
        "original_caption": "an adult is away from a green toy in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the green toy in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1110,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_39013",
        "original_caption": "a baby in yellow clothes lifts a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in yellow clothes lifts a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 1102,
                "<e0>": 1374
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_39014",
        "original_caption": "a child is above a snowboard on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is above a snowboard on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 94,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_39015",
        "original_caption": "a child is towards a toy in red on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is towards a toy in red on the beach."
            }
        ],
        "meta": {
            "split": [
                0,
                1385
            ],
            "duration": 1386,
            "token": {
                "<s0>": 60,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_39016",
        "original_caption": "an adult lifts a baby on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult lifts a baby on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                760
            ],
            "duration": 761,
            "token": {
                "<s0>": 667,
                "<e0>": 710
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7424038414",
        "aid": "7424038414_39017",
        "original_caption": "an adult wearing red scoks pushes another adult wearing a no.8 jersey.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing red scoks pushes another adult wearing a no.8 jersey."
            }
        ],
        "meta": {
            "split": [
                0,
                100
            ],
            "duration": 101,
            "token": {
                "<s0>": 0,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_39018",
        "original_caption": "a child in pink speaks to an adult woman at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink speaks to an adult woman at home."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 253,
                "<e0>": 322
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_39019",
        "original_caption": "there is adult in white holding hand of the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is adult in white holding hand of the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 605,
                "<e0>": 869
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_39020",
        "original_caption": "a child with blond-hair is away from an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the adult in blue clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1238
            ],
            "duration": 1239,
            "token": {
                "<s0>": 181,
                "<e0>": 251
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_39021",
        "original_caption": "an adult woman in purple is away a child in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in purple is away a child in white."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3873350747",
        "aid": "3873350747_39022",
        "original_caption": "a baby pushes a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby pushes a toy in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                201
            ],
            "duration": 202,
            "token": {
                "<s0>": 89,
                "<e0>": 139
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3873350747",
        "aid": "3873350747_39023",
        "original_caption": "a baby pushes a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby pushes a toy in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                201,
                563
            ],
            "duration": 363,
            "token": {
                "<s0>": 63,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_39024",
        "original_caption": "an adult is towards a watercraft on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult towards on the river from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 150,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39025",
        "original_caption": "an adult in purple is in front of a yellow cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the adult in purple from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1500,
                "<e0>": 1699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39026",
        "original_caption": "an adult points to a child holding a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult points to a child holding a yellow toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                493
            ],
            "duration": 494,
            "token": {
                "<s0>": 435,
                "<e0>": 481
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39027",
        "original_caption": "an adult points to a child holding a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult points to a child holding a yellow toy."
            }
        ],
        "meta": {
            "split": [
                493,
                1314
            ],
            "duration": 822,
            "token": {
                "<s0>": 13,
                "<e0>": 32
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39028",
        "original_caption": "there is a cup next to a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup next to a bottle in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                611
            ],
            "duration": 612,
            "token": {
                "<s0>": 360,
                "<e0>": 612
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8994675143",
        "aid": "8994675143_39029",
        "original_caption": "there is a chair beneath an adult on an airplane.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair beneath an adult on an airplane happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                487,
                1005
            ],
            "duration": 519,
            "token": {
                "<s0>": 56,
                "<e0>": 518
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4656902106",
        "aid": "4656902106_39030",
        "original_caption": "a child in red is towards a ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red is towards a ball on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_39031",
        "original_caption": "there is a black cat away a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the black cat away from from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                1725,
                2144
            ],
            "duration": 420,
            "token": {
                "<s0>": 15,
                "<e0>": 131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_39032",
        "original_caption": "a baby leans on an adult on the flor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult on the flor."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 106,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3862213653",
        "aid": "3862213653_39033",
        "original_caption": "an adult man in blue gray uses a black laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho uses the black laptop from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                275
            ],
            "duration": 276,
            "token": {
                "<s0>": 155,
                "<e0>": 276
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3099327773",
        "aid": "3099327773_39034",
        "original_caption": "a child in white leans on another child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white leans on another child on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                1947
            ],
            "duration": 1948,
            "token": {
                "<s0>": 1596,
                "<e0>": 1948
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39035",
        "original_caption": "an adult is behind another adult at the children's park.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult at the children's park from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1211,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39036",
        "original_caption": "there is a cup beneath a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup beneath a sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 601
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_39037",
        "original_caption": "there is a toy away another toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy away another toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 600,
                "<e0>": 659
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39038",
        "original_caption": "there is a sports ball towards a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sports ball towards a child."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 180,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_39039",
        "original_caption": "an adult in red leans on a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red leans on a chair in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1145
            ],
            "duration": 1146,
            "token": {
                "<s0>": 0,
                "<e0>": 464
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7290684468",
        "aid": "7290684468_39040",
        "original_caption": "a baby in pink clothes pats a white-blue toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in pink clothes pats a white-blue toy."
            }
        ],
        "meta": {
            "split": [
                401,
                569
            ],
            "duration": 169,
            "token": {
                "<s0>": 75,
                "<e0>": 97
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39041",
        "original_caption": "an adult holds a cellphone in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a cellphone in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 0,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39042",
        "original_caption": "an adult holds a cellphone in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a cellphone in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                371,
                864
            ],
            "duration": 494,
            "token": {
                "<s0>": 207,
                "<e0>": 353
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39043",
        "original_caption": "an adult holds a cellphone in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cellphone in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                864,
                1441
            ],
            "duration": 578,
            "token": {
                "<s0>": 141,
                "<e0>": 173
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_39044",
        "original_caption": "a male adult is next to a child with black skin.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A male adult is next to a child with black skin."
            }
        ],
        "meta": {
            "split": [
                0,
                1063
            ],
            "duration": 1064,
            "token": {
                "<s0>": 240,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5477125287",
        "aid": "5477125287_39045",
        "original_caption": "there is a dog next to the adult in jeans.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog next to the adult in jeans."
            }
        ],
        "meta": {
            "split": [
                1348,
                1769
            ],
            "duration": 422,
            "token": {
                "<s0>": 120,
                "<e0>": 421
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8994675143",
        "aid": "8994675143_39046",
        "original_caption": "an adult wearing a watch speaks to a female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a watch speaks to a female adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1005
            ],
            "duration": 1006,
            "token": {
                "<s0>": 813,
                "<e0>": 833
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_39047",
        "original_caption": "a baby in orange clothes holds an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in orange clothes holds an orange toy."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 159,
                "<e0>": 457
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_39048",
        "original_caption": "there is a white watercraft beneath an adult in red on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in red on the river from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_39049",
        "original_caption": "an adult man in black is away another adult man in red on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black is away another adult man in red on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 60,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39050",
        "original_caption": "the dog in the child's hand is next to the adult around him.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next_to adults from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                1158,
                1441
            ],
            "duration": 284,
            "token": {
                "<s0>": 111,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4827728106",
        "aid": "4827728106_39051",
        "original_caption": "an adult wearing a plaid clothes throws a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a plaid clothes throws a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                100
            ],
            "duration": 101,
            "token": {
                "<s0>": 39,
                "<e0>": 58
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047872014",
        "aid": "6047872014_39052",
        "original_caption": "the adult in white is hugging the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is hugging the adult in black from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 56,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13503103965",
        "aid": "13503103965_39053",
        "original_caption": "a child on the right holds hand of another child in the middle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child on the right holds hand of another child in the middle."
            }
        ],
        "meta": {
            "split": [
                0,
                330
            ],
            "duration": 331,
            "token": {
                "<s0>": 0,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3212132295",
        "aid": "3212132295_39054",
        "original_caption": "there is a black dog smelling a grey toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black dog smelling a grey toy on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1132
            ],
            "duration": 1133,
            "token": {
                "<s0>": 797,
                "<e0>": 890
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_39055",
        "original_caption": "a child in white is behind another child in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white is behind another child in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 200,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39056",
        "original_caption": "an adult in white clothes is away from another adult in grey clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes is away from another adult in grey clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1336
            ],
            "duration": 1337,
            "token": {
                "<s0>": 180,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4670796220",
        "aid": "4670796220_39057",
        "original_caption": "there is a baby walker towards an adult on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_walker from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a baby walker towards an adult on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 0,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39058",
        "original_caption": "there is a glass cup above a black table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a glass cup above a black table at home."
            }
        ],
        "meta": {
            "split": [
                452,
                793
            ],
            "duration": 342,
            "token": {
                "<s0>": 33,
                "<e0>": 341
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_39059",
        "original_caption": "a baby in white clothes presses a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes presses a toy."
            }
        ],
        "meta": {
            "split": [
                0,
                324
            ],
            "duration": 325,
            "token": {
                "<s0>": 179,
                "<e0>": 207
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_39060",
        "original_caption": "a baby in white clothes presses a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes presses a toy."
            }
        ],
        "meta": {
            "split": [
                589,
                875
            ],
            "duration": 287,
            "token": {
                "<s0>": 138,
                "<e0>": 155
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_39061",
        "original_caption": "a baby in white clothes presses a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes presses a toy."
            }
        ],
        "meta": {
            "split": [
                875,
                1139
            ],
            "duration": 265,
            "token": {
                "<s0>": 131,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_39062",
        "original_caption": "a baby in white clothes presses a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white clothes presses a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1139,
                1401
            ],
            "duration": 263,
            "token": {
                "<s0>": 111,
                "<e0>": 132
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_39063",
        "original_caption": "a baby in white clothes presses a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes presses a toy."
            }
        ],
        "meta": {
            "split": [
                1401,
                1651
            ],
            "duration": 251,
            "token": {
                "<s0>": 131,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_39064",
        "original_caption": "a baby in white clothes presses a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white clothes presses a toy."
            }
        ],
        "meta": {
            "split": [
                1651,
                1868
            ],
            "duration": 218,
            "token": {
                "<s0>": 105,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_39065",
        "original_caption": "a female adult hugs a baby on sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A female adult hugs a baby on sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                419
            ],
            "duration": 420,
            "token": {
                "<s0>": 0,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_39066",
        "original_caption": "a baby wearing a gray hat leans on a green sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the green sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6572270403",
        "aid": "6572270403_39067",
        "original_caption": "an adult holds a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 304,
                "<e0>": 681
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4731482395",
        "aid": "4731482395_39068",
        "original_caption": "a child in colorful holds a blue cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in colorful holds a blue cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                241
            ],
            "duration": 242,
            "token": {
                "<s0>": 0,
                "<e0>": 176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4731482395",
        "aid": "4731482395_39069",
        "original_caption": "a child in colorful holds a blue cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in colorful hold in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                241,
                633
            ],
            "duration": 393,
            "token": {
                "<s0>": 65,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4731482395",
        "aid": "4731482395_39070",
        "original_caption": "a child in colorful holds a blue cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in colorful hold in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                633,
                963
            ],
            "duration": 331,
            "token": {
                "<s0>": 264,
                "<e0>": 331
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_39071",
        "original_caption": "there is a goat behind another goat outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the goat outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sheep/goat."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 720,
                "<e0>": 796
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39072",
        "original_caption": "there is a white table beneath a green bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the green bottle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_39073",
        "original_caption": "an adult man in black is inside a watercraft white on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black is inside a watercraft white on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 60,
                "<e0>": 500
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4063402763",
        "aid": "4063402763_39074",
        "original_caption": "a baby in green is inside a gray baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in green is inside a gray baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                790
            ],
            "duration": 791,
            "token": {
                "<s0>": 0,
                "<e0>": 791
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_39075",
        "original_caption": "a child in black clothes is towards another child in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black clothes is towards another child in pink clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 180,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3395849259",
        "aid": "3395849259_39076",
        "original_caption": "an adult touches a baby on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the baby on the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                227
            ],
            "duration": 228,
            "token": {
                "<s0>": 102,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3395849259",
        "aid": "3395849259_39077",
        "original_caption": "an adult touches a baby on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult touches a baby on the sofa."
            }
        ],
        "meta": {
            "split": [
                227,
                528
            ],
            "duration": 302,
            "token": {
                "<s0>": 45,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3395849259",
        "aid": "3395849259_39078",
        "original_caption": "an adult touches a baby on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult touches a baby on the sofa."
            }
        ],
        "meta": {
            "split": [
                528,
                797
            ],
            "duration": 270,
            "token": {
                "<s0>": 76,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_39079",
        "original_caption": "a bigger child is above a brown chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a bigger child is above a brown chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4656902106",
        "aid": "4656902106_39080",
        "original_caption": "a child in red is towards an adult in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red is towards an adult in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_39081",
        "original_caption": "there is a bicycle beneath a blue backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the blue backpack from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 120,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_39082",
        "original_caption": "there is a bicycle in white towards a scooter on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the bicycle in white towards to on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A scooter."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 310,
                "<e0>": 371
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9970084224",
        "aid": "9970084224_39083",
        "original_caption": "there is a white dog hugging a black dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white dog hugging a black dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                116
            ],
            "duration": 117,
            "token": {
                "<s0>": 0,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9970084224",
        "aid": "9970084224_39084",
        "original_caption": "there is a white dog hugging a black dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white dog hugging a black dog on the ground."
            }
        ],
        "meta": {
            "split": [
                116,
                583
            ],
            "duration": 468,
            "token": {
                "<s0>": 16,
                "<e0>": 418
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9970084224",
        "aid": "9970084224_39085",
        "original_caption": "there is a white dog hugging a black dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat hugs the black dog on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                583,
                1781
            ],
            "duration": 1199,
            "token": {
                "<s0>": 50,
                "<e0>": 443
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_39086",
        "original_caption": "a child is in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is in front of an adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 50,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6949702600",
        "aid": "6949702600_39087",
        "original_caption": "there is a chair beneath a handbag in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair beneath a handbag in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 378,
                "<e0>": 430
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39088",
        "original_caption": "there is a bottle in front of a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 720,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6106626461",
        "aid": "6106626461_39089",
        "original_caption": "an adult in red clothes uses a cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes uses a cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                520
            ],
            "duration": 521,
            "token": {
                "<s0>": 16,
                "<e0>": 45
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5844813529",
        "aid": "5844813529_39090",
        "original_caption": "there is a white cat above another cat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the other cat on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                1682
            ],
            "duration": 1683,
            "token": {
                "<s0>": 0,
                "<e0>": 1675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39091",
        "original_caption": "a child in red clothes is away from a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is away from a sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 540,
                "<e0>": 596
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4524702622",
        "aid": "4524702622_39092",
        "original_caption": "an adult is behind a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is behind a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1098
            ],
            "duration": 1099,
            "token": {
                "<s0>": 720,
                "<e0>": 770
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_39093",
        "original_caption": "an adult man in black plays the guitar in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black plays the guitar in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 349,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_39094",
        "original_caption": "an adult in blue clothes is away from a groom adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the groom adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 60,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_39095",
        "original_caption": "there is a black dog away from a white dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is away from the white dog outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                2018
            ],
            "duration": 2019,
            "token": {
                "<s0>": 1560,
                "<e0>": 1610
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39096",
        "original_caption": "there is a table in front of an adult wearing glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table in front of an adult wearing glasses."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 0,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39097",
        "original_caption": "there is a white cup above a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white cup above a table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39098",
        "original_caption": "there is a monitor next to another monitor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a monitor next to another monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11018431523",
        "aid": "11018431523_39099",
        "original_caption": "a child in blue rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                591
            ],
            "duration": 592,
            "token": {
                "<s0>": 0,
                "<e0>": 592
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_39100",
        "original_caption": "a child in white clothes with blue sleeves is behind another child in gray in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes with blue sleeves is behind another child in gray in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                2052,
                2696
            ],
            "duration": 645,
            "token": {
                "<s0>": 228,
                "<e0>": 318
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_39101",
        "original_caption": "the toy bobbin is token towards the toy castle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the toy bobbin is token towards the toy castle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 240,
                "<e0>": 285
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39102",
        "original_caption": "an adult in a blue t-shirt holds a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in a blue t-shirt holds a child."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 539,
                "<e0>": 596
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_39103",
        "original_caption": "there is a tan table in front of a child white and blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a tan table in front of a child white and blue happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8157245482",
        "aid": "8157245482_39104",
        "original_caption": "an adult in purple is beneath a child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the child in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                191
            ],
            "duration": 192,
            "token": {
                "<s0>": 144,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6121794107",
        "aid": "6121794107_39105",
        "original_caption": "there is a blue ball next to a red sports ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue ball next to a red sports ball on the grass."
            }
        ],
        "meta": {
            "split": [
                573,
                883
            ],
            "duration": 311,
            "token": {
                "<s0>": 207,
                "<e0>": 282
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_39106",
        "original_caption": "an adult in blue clothes watches another adult in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes watches another adult in striped clothes."
            }
        ],
        "meta": {
            "split": [
                767,
                1424
            ],
            "duration": 658,
            "token": {
                "<s0>": 15,
                "<e0>": 162
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_39107",
        "original_caption": "there is a blue car above a brown dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a blue car above a brown dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 200,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2503862291",
        "aid": "2503862291_39108",
        "original_caption": "an adult is towards a grey baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult towards to at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                850
            ],
            "duration": 851,
            "token": {
                "<s0>": 188,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5680184714",
        "aid": "5680184714_39109",
        "original_caption": "there is a black cat on the right hitting black cat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black cat on the right hitting black cat on the left."
            }
        ],
        "meta": {
            "split": [
                0,
                1599
            ],
            "duration": 1600,
            "token": {
                "<s0>": 1059,
                "<e0>": 1097
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39110",
        "original_caption": "an adult man in dark blue grabs a white cup outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in dark blue grabs a white cup outdoors."
            }
        ],
        "meta": {
            "split": [
                1449,
                2159
            ],
            "duration": 711,
            "token": {
                "<s0>": 609,
                "<e0>": 641
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_39111",
        "original_caption": "an adult wearing red pants pushes a green watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing red pants pushes a green watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 491,
                "<e0>": 635
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_39112",
        "original_caption": "there is a handbag away a chair in a convenience store.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a handbag away a chair in a convenience store."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 960,
                "<e0>": 1025
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5153854160",
        "aid": "5153854160_39113",
        "original_caption": "there is a brown table beneath a sliver laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown table beneath a sliver laptop happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2264
            ],
            "duration": 2265,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3642481017",
        "aid": "3642481017_39114",
        "original_caption": "an adult in black is behind the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in black on stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                508,
                2024
            ],
            "duration": 1517,
            "token": {
                "<s0>": 32,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39115",
        "original_caption": "there is a table beneath a cup outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cup outside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5139493061",
        "aid": "5139493061_39116",
        "original_caption": "an adult with blond-hair is behind another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult with blond-hair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                675,
                1846
            ],
            "duration": 1172,
            "token": {
                "<s0>": 585,
                "<e0>": 1075
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13884124143",
        "aid": "13884124143_39117",
        "original_caption": "an adult rides a surfboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a surfboard in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                356
            ],
            "duration": 357,
            "token": {
                "<s0>": 0,
                "<e0>": 350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13884124143",
        "aid": "13884124143_39118",
        "original_caption": "an adult rides a surfboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a surfboard in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                356,
                852
            ],
            "duration": 497,
            "token": {
                "<s0>": 6,
                "<e0>": 384
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4329580374",
        "aid": "4329580374_39119",
        "original_caption": "a baby on the left touches a baby on the right .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the baby on the right from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                590,
                711
            ],
            "duration": 122,
            "token": {
                "<s0>": 19,
                "<e0>": 36
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_39120",
        "original_caption": "a baby in white holds a toy in the yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy in the yard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                353
            ],
            "duration": 354,
            "token": {
                "<s0>": 0,
                "<e0>": 272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_39121",
        "original_caption": "a baby in white holds a toy in the yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white holds a toy in the yard."
            }
        ],
        "meta": {
            "split": [
                353,
                459
            ],
            "duration": 107,
            "token": {
                "<s0>": 81,
                "<e0>": 99
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_39122",
        "original_caption": "a baby in white holds a toy in the yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy in the yard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                459,
                998
            ],
            "duration": 540,
            "token": {
                "<s0>": 8,
                "<e0>": 540
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39123",
        "original_caption": "there is a sofa beneath a dog inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the sofa inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                1355,
                1441
            ],
            "duration": 87,
            "token": {
                "<s0>": 37,
                "<e0>": 87
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3898106739",
        "aid": "3898106739_39124",
        "original_caption": "there is an adult man in front of an adult woman.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult woman from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                558,
                1232
            ],
            "duration": 675,
            "token": {
                "<s0>": 128,
                "<e0>": 671
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3920356362",
        "aid": "3920356362_39125",
        "original_caption": "there is a bear toy next to a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bear toy next to a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                355
            ],
            "duration": 356,
            "token": {
                "<s0>": 213,
                "<e0>": 269
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5867564434",
        "aid": "5867564434_39126",
        "original_caption": "the child is eating inside the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The child is eating inside the baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                944
            ],
            "duration": 945,
            "token": {
                "<s0>": 0,
                "<e0>": 930
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_39127",
        "original_caption": "an adult in red leans on a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red leans on a chair in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1333
            ],
            "duration": 1334,
            "token": {
                "<s0>": 0,
                "<e0>": 1328
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_39128",
        "original_caption": "an adult in red leans on a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the chair in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1333,
                1877
            ],
            "duration": 545,
            "token": {
                "<s0>": 5,
                "<e0>": 80
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39129",
        "original_caption": "there is a blue ball above a cup at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a blue ball above a cup at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7040233679",
        "aid": "7040233679_39130",
        "original_caption": "an adult in green grabs a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in green grabs a cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                909
            ],
            "duration": 910,
            "token": {
                "<s0>": 0,
                "<e0>": 23
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_39131",
        "original_caption": "an adult in bule suit is beneath an another adult in red suit.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the other adult in red suit from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                191,
                735
            ],
            "duration": 545,
            "token": {
                "<s0>": 134,
                "<e0>": 544
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39132",
        "original_caption": "a child in red is towards a sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the sports ball in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 331,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3855730364",
        "aid": "3855730364_39133",
        "original_caption": "there is a fish chasing another fish in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a fish chasing another fish in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 20,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39134",
        "original_caption": "a child watches a cake in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child watches a cake in the room."
            }
        ],
        "meta": {
            "split": [
                721,
                872
            ],
            "duration": 152,
            "token": {
                "<s0>": 96,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_39135",
        "original_caption": "an adult man in yellow rides a white watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in yellow rides a white watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                464
            ],
            "duration": 465,
            "token": {
                "<s0>": 47,
                "<e0>": 401
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_39136",
        "original_caption": "an adult man in yellow rides a white watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in yellow rides a white watercraft on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                464,
                1403
            ],
            "duration": 940,
            "token": {
                "<s0>": 63,
                "<e0>": 924
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_39137",
        "original_caption": "a child with black hair throws a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho throws the ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 283,
                "<e0>": 298
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_39138",
        "original_caption": "a child with black hair throws a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with black hair throws a ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                407,
                743
            ],
            "duration": 337,
            "token": {
                "<s0>": 109,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5399895838",
        "aid": "5399895838_39139",
        "original_caption": "there is a table in front of a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table in front of a chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1048
            ],
            "duration": 1049,
            "token": {
                "<s0>": 0,
                "<e0>": 468
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_39140",
        "original_caption": "there is a silver screen behind an adult in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a silver screen behind an adult in striped clothes."
            }
        ],
        "meta": {
            "split": [
                887,
                1305
            ],
            "duration": 419,
            "token": {
                "<s0>": 145,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39141",
        "original_caption": "a child in black clothes holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black clothes holds a toy."
            }
        ],
        "meta": {
            "split": [
                403,
                765
            ],
            "duration": 363,
            "token": {
                "<s0>": 223,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39142",
        "original_caption": "a child in black clothes holds a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black clothes holds a toy."
            }
        ],
        "meta": {
            "split": [
                765,
                1028
            ],
            "duration": 264,
            "token": {
                "<s0>": 105,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39143",
        "original_caption": "a child in blue hugs a brown dog in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue hugs a brown dog in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                683
            ],
            "duration": 684,
            "token": {
                "<s0>": 551,
                "<e0>": 634
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39144",
        "original_caption": "a child in blue hugs a brown dog in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in blue hug in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                683,
                1032
            ],
            "duration": 350,
            "token": {
                "<s0>": 50,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39145",
        "original_caption": "a child in blue hugs a brown dog in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue hugs a brown dog in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1032,
                1334
            ],
            "duration": 303,
            "token": {
                "<s0>": 237,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39146",
        "original_caption": "a child in blue hugs a brown dog in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue hugs a brown dog in a room."
            }
        ],
        "meta": {
            "split": [
                1334,
                1441
            ],
            "duration": 108,
            "token": {
                "<s0>": 46,
                "<e0>": 81
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_39147",
        "original_caption": "there is a baby seat beneath a baby in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a baby seat beneath a baby in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39148",
        "original_caption": "a child in pink is towards an adult woman in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink is towards an adult woman in gray."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1046,
                "<e0>": 1229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4861754967",
        "aid": "4861754967_39149",
        "original_caption": "an adult is in front of a laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is in front of a laptop."
            }
        ],
        "meta": {
            "split": [
                562,
                755
            ],
            "duration": 194,
            "token": {
                "<s0>": 62,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_39150",
        "original_caption": "an adult is beneath another adult in purple clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is beneath another adult in purple clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 540,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3433142502",
        "aid": "3433142502_39151",
        "original_caption": "a baby leans on a baby walker in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on a baby walker in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                768
            ],
            "duration": 769,
            "token": {
                "<s0>": 0,
                "<e0>": 769
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3754789709",
        "aid": "3754789709_39152",
        "original_caption": "an adult carries a red backpack in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult carries a red backpack in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                397
            ],
            "duration": 398,
            "token": {
                "<s0>": 134,
                "<e0>": 398
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3761379939",
        "aid": "3761379939_39153",
        "original_caption": "a child in white clothes leans on an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1380
            ],
            "duration": 1381,
            "token": {
                "<s0>": 0,
                "<e0>": 864
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5767341241",
        "aid": "5767341241_39154",
        "original_caption": "there is a gray bird feeding a white and black bird.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray bird feeding a white and black bird happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                331
            ],
            "duration": 332,
            "token": {
                "<s0>": 147,
                "<e0>": 173
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7397286464",
        "aid": "7397286464_39155",
        "original_caption": "an adult in red holds a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red holds a baby in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                944
            ],
            "duration": 945,
            "token": {
                "<s0>": 0,
                "<e0>": 945
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_39156",
        "original_caption": "an adult woman in blue carries a purple handbag on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in blue carries a purple handbag on the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 693,
                "<e0>": 960
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4524702622",
        "aid": "4524702622_39157",
        "original_caption": "a child in skirt presses a white table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in skirt presses a white table in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1098
            ],
            "duration": 1099,
            "token": {
                "<s0>": 931,
                "<e0>": 991
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_39158",
        "original_caption": "there is a black backpack above a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the backpack from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black backpack above a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 249,
                "<e0>": 1049
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_39159",
        "original_caption": "a child in yellow leans on a table in the big room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in yellow lean on in the big room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                448
            ],
            "duration": 449,
            "token": {
                "<s0>": 0,
                "<e0>": 431
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_39160",
        "original_caption": "a child in yellow leans on a table in the big room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in yellow leans on a table in the big room."
            }
        ],
        "meta": {
            "split": [
                448,
                1094
            ],
            "duration": 647,
            "token": {
                "<s0>": 18,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39161",
        "original_caption": "there is a golden dog chasing a white sports ball on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a golden dog chasing a white sports ball on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                508
            ],
            "duration": 509,
            "token": {
                "<s0>": 480,
                "<e0>": 503
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39162",
        "original_caption": "there is a golden dog chasing a white sports ball on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat chases the white sports ball on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                508,
                646
            ],
            "duration": 139,
            "token": {
                "<s0>": 6,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39163",
        "original_caption": "there is a golden dog chasing a white sports ball on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a golden dog chasing a white sports ball on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                646,
                1033
            ],
            "duration": 388,
            "token": {
                "<s0>": 61,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39164",
        "original_caption": "there is a golden dog chasing a white sports ball on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a golden dog chasing a white sports ball on the ground."
            }
        ],
        "meta": {
            "split": [
                1033,
                1336
            ],
            "duration": 304,
            "token": {
                "<s0>": 270,
                "<e0>": 294
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_39165",
        "original_caption": "an adult woman in striped clothes points to a white cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in striped clothes points to a white cake."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 193,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5153854160",
        "aid": "5153854160_39166",
        "original_caption": "an adult in purple uses a cellphone in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in purple uses a cellphone in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 386,
                "<e0>": 440
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13503103965",
        "aid": "13503103965_39167",
        "original_caption": "a child with brown hair is behind another child with black hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with brown hair is behind another child with black hair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                330
            ],
            "duration": 331,
            "token": {
                "<s0>": 155,
                "<e0>": 269
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4866672246",
        "aid": "4866672246_39168",
        "original_caption": "there is a dog lying down behind a brown dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog lying down behind a brown dog happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                246,
                1259
            ],
            "duration": 1014,
            "token": {
                "<s0>": 9,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_39169",
        "original_caption": "a child touchs a cellphone in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child touchs a cellphone in a car."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1649,
                "<e0>": 1821
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5195700916",
        "aid": "5195700916_39170",
        "original_caption": "an adult in black speaks to another adult in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black speaks to another adult in pink."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 700,
                "<e0>": 800
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7907275512",
        "aid": "7907275512_39171",
        "original_caption": "a child in black gets on a yellow bicycle on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black gets on a yellow bicycle on the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                1715
            ],
            "duration": 1716,
            "token": {
                "<s0>": 1188,
                "<e0>": 1300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_39172",
        "original_caption": "a baby in yellow is away from an orange fruits outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in yellow is away from an orange fruits outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1466
            ],
            "duration": 1467,
            "token": {
                "<s0>": 497,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4240545211",
        "aid": "4240545211_39173",
        "original_caption": "an adult wearing a blue hat is above a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a blue hat is above a bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                484
            ],
            "duration": 485,
            "token": {
                "<s0>": 69,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6697646843",
        "aid": "6697646843_39174",
        "original_caption": "there is adult in front of the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is adult in front of the child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1033,
                2099
            ],
            "duration": 1067,
            "token": {
                "<s0>": 183,
                "<e0>": 1066
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7290684468",
        "aid": "7290684468_39175",
        "original_caption": "a baby in pink watches a red sports ball at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in pink watches a red sports ball at home."
            }
        ],
        "meta": {
            "split": [
                0,
                569
            ],
            "duration": 570,
            "token": {
                "<s0>": 354,
                "<e0>": 386
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_39176",
        "original_caption": "an adult watches another adult in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult watches another adult in the classroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 714,
                "<e0>": 752
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7631378506",
        "aid": "7631378506_39177",
        "original_caption": "an adult watches another adult on the watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult watches another adult on the watercraft."
            }
        ],
        "meta": {
            "split": [
                564,
                1180
            ],
            "duration": 617,
            "token": {
                "<s0>": 20,
                "<e0>": 58
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3802656968",
        "aid": "3802656968_39178",
        "original_caption": "the adult in white shirt is holding a snake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is holding a snake from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1481
            ],
            "duration": 1482,
            "token": {
                "<s0>": 133,
                "<e0>": 189
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6997648741",
        "aid": "6997648741_39179",
        "original_caption": "an adult is towards another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is towards another adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                194
            ],
            "duration": 195,
            "token": {
                "<s0>": 155,
                "<e0>": 194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_39180",
        "original_caption": "a baby in pink holds hand of an adult woman in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in pink holds hand of an adult woman in white."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 605,
                "<e0>": 874
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39181",
        "original_caption": "there is a silver sports ball behind a child in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a silver sports ball behind a child in red clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_39182",
        "original_caption": "there is a car away from a baby seat on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the car away from on the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                1000,
                1113
            ],
            "duration": 114,
            "token": {
                "<s0>": 52,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5607360009",
        "aid": "5607360009_39183",
        "original_caption": "an adult man in black chases a child on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black chases a child on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                927
            ],
            "duration": 928,
            "token": {
                "<s0>": 820,
                "<e0>": 896
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6806981046",
        "aid": "6806981046_39184",
        "original_caption": "there is a yellow bus behind an adult in gray clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the adult in gray clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bus/truck."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 0,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_39185",
        "original_caption": "an adult in black clothes is towards another adult sitting in chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is towards another adult sitting in chair."
            }
        ],
        "meta": {
            "split": [
                3785,
                5394
            ],
            "duration": 1610,
            "token": {
                "<s0>": 5,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5647072246",
        "aid": "5647072246_39186",
        "original_caption": "an adult in white chases another adult on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white chases another adult on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                364
            ],
            "duration": 365,
            "token": {
                "<s0>": 259,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6595030215",
        "aid": "6595030215_39187",
        "original_caption": "an adult in black watches a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black watches a baby in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                465
            ],
            "duration": 466,
            "token": {
                "<s0>": 0,
                "<e0>": 454
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_39188",
        "original_caption": "there is a table beneath a cake inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cake inside a room."
            }
        ],
        "meta": {
            "split": [
                872,
                2225
            ],
            "duration": 1354,
            "token": {
                "<s0>": 7,
                "<e0>": 236
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39189",
        "original_caption": "there is a cup away an adult in the dining room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the cup away in the dining room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 485,
                "<e0>": 689
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39190",
        "original_caption": "an adult woman in gray is away a child in colorful.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in gray is away a child in colorful happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1110,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_39191",
        "original_caption": "an adult in gray clothes is next to a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in gray clothes is next to a chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1145
            ],
            "duration": 1146,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39192",
        "original_caption": "a child is away an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is away an adult at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 60,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "14003830086",
        "aid": "14003830086_39193",
        "original_caption": "an adult man in wathet blue holds an orange wooden guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in wathet blue holds an orange wooden guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1583
            ],
            "duration": 1584,
            "token": {
                "<s0>": 135,
                "<e0>": 342
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2932667685",
        "aid": "2932667685_39194",
        "original_caption": "an adult woman in gray carries a blue backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries the blue backpack from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                485
            ],
            "duration": 486,
            "token": {
                "<s0>": 0,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2932667685",
        "aid": "2932667685_39195",
        "original_caption": "an adult woman in gray carries a blue backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray carries a blue backpack."
            }
        ],
        "meta": {
            "split": [
                485,
                1167
            ],
            "duration": 683,
            "token": {
                "<s0>": 393,
                "<e0>": 432
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2945751196",
        "aid": "2945751196_39196",
        "original_caption": "an adult is next to a bottle inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to a bottle inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                903
            ],
            "duration": 904,
            "token": {
                "<s0>": 0,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_39197",
        "original_caption": "a child wearing a red hat kicks a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child wearing a red hat kicks a sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 192,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_39198",
        "original_caption": "an adult is in front of another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is in front of another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 60,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_39199",
        "original_caption": "an adult is beneath a screen in a big room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is beneath a screen in a big room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 1691
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3343411237",
        "aid": "3343411237_39200",
        "original_caption": "there is a surfboard away from an adult in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the surfboard away from in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                926
            ],
            "duration": 927,
            "token": {
                "<s0>": 500,
                "<e0>": 575
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953736795",
        "aid": "6953736795_39201",
        "original_caption": "an adult in red pats another adult in black in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pats the other adult in black in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                133
            ],
            "duration": 134,
            "token": {
                "<s0>": 57,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_39202",
        "original_caption": "adult in white blouse and shorts carrying a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is carrying the camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_39203",
        "original_caption": "an adult hugs another adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult hugs another adult inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1051
            ],
            "duration": 1052,
            "token": {
                "<s0>": 527,
                "<e0>": 1005
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_39204",
        "original_caption": "an adult hugs another adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult hugs another adult inside a room."
            }
        ],
        "meta": {
            "split": [
                1051,
                1446
            ],
            "duration": 396,
            "token": {
                "<s0>": 46,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39205",
        "original_caption": "an adult in white carries a backpack in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white carries a backpack in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1218,
                "<e0>": 1315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39206",
        "original_caption": "an adult in black is behind of the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind of by the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1231,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_39207",
        "original_caption": "an adult speaks to a child in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the child in living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                289
            ],
            "duration": 290,
            "token": {
                "<s0>": 76,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_39208",
        "original_caption": "an adult speaks to a child in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child in living room."
            }
        ],
        "meta": {
            "split": [
                289,
                460
            ],
            "duration": 172,
            "token": {
                "<s0>": 39,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_39209",
        "original_caption": "an adult speaks to a child in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the child in living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                460,
                745
            ],
            "duration": 286,
            "token": {
                "<s0>": 79,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_39210",
        "original_caption": "an adult speaks to a child in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child in living room."
            }
        ],
        "meta": {
            "split": [
                745,
                894
            ],
            "duration": 150,
            "token": {
                "<s0>": 112,
                "<e0>": 128
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_39211",
        "original_caption": "an adult speaks to a child in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the child in living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                894,
                1047
            ],
            "duration": 154,
            "token": {
                "<s0>": 21,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_39212",
        "original_caption": "there is a monitor above an adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the adult in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_39213",
        "original_caption": "a baby rides a baby walker outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the baby walker outside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                873
            ],
            "duration": 874,
            "token": {
                "<s0>": 743,
                "<e0>": 839
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_39214",
        "original_caption": "a baby rides a baby walker outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby rides a baby walker outside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                873,
                1516
            ],
            "duration": 644,
            "token": {
                "<s0>": 34,
                "<e0>": 80
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_39215",
        "original_caption": "a child is beneath another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 360,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39216",
        "original_caption": "an adult at the table watches a baby in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult at the table watches a baby in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 23
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39217",
        "original_caption": "an adult in jeans is hold the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is holding the toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 722,
                "<e0>": 801
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13884124143",
        "aid": "13884124143_39218",
        "original_caption": "an adult with no shirt is above a surfboard on the stream.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with no shirt is above a surfboard on the stream happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                356,
                852
            ],
            "duration": 497,
            "token": {
                "<s0>": 6,
                "<e0>": 384
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3120535570",
        "aid": "3120535570_39219",
        "original_caption": "an adult on the right is next to an adult on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult on the right is next to an adult on the left."
            }
        ],
        "meta": {
            "split": [
                0,
                147
            ],
            "duration": 148,
            "token": {
                "<s0>": 0,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39220",
        "original_caption": "there is a cup towards an adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the cup towards to inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 480,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_39221",
        "original_caption": "a child in orange clothes is towards a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in orange clothes is towards a table."
            }
        ],
        "meta": {
            "split": [
                0,
                637
            ],
            "duration": 638,
            "token": {
                "<s0>": 0,
                "<e0>": 66
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4235961238",
        "aid": "4235961238_39222",
        "original_caption": "there is a yellow toy in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a yellow toy in front of a child."
            }
        ],
        "meta": {
            "split": [
                0,
                564
            ],
            "duration": 565,
            "token": {
                "<s0>": 0,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_39223",
        "original_caption": "an adult in red is behind another adult in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red is behind another adult in gray."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2425461420",
        "aid": "2425461420_39224",
        "original_caption": "there is a cat pressing another cat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat pressing another cat on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 110,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2425461420",
        "aid": "2425461420_39225",
        "original_caption": "there is a cat pressing another cat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cat pressing another cat on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                299,
                520
            ],
            "duration": 222,
            "token": {
                "<s0>": 165,
                "<e0>": 207
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2425461420",
        "aid": "2425461420_39226",
        "original_caption": "there is a cat pressing another cat on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat presses the other cat on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                669,
                1797
            ],
            "duration": 1129,
            "token": {
                "<s0>": 42,
                "<e0>": 70
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13486822104",
        "aid": "13486822104_39227",
        "original_caption": "there is a black bird beneath a brown bird.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black bird beneath a brown bird."
            }
        ],
        "meta": {
            "split": [
                0,
                688
            ],
            "duration": 689,
            "token": {
                "<s0>": 150,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_39228",
        "original_caption": "there is a sofa next to a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a sofa next to a baby."
            }
        ],
        "meta": {
            "split": [
                300,
                760
            ],
            "duration": 461,
            "token": {
                "<s0>": 36,
                "<e0>": 252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_39229",
        "original_caption": "an adult leans on a wooden watercraft on the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult leans on a wooden watercraft on the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                2186
            ],
            "duration": 2187,
            "token": {
                "<s0>": 408,
                "<e0>": 693
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39230",
        "original_caption": "an adult in black is above a black guitar in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black is above a black guitar in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                611
            ],
            "duration": 612,
            "token": {
                "<s0>": 540,
                "<e0>": 612
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39231",
        "original_caption": "a child in black rides a skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the skateboard in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                330
            ],
            "duration": 331,
            "token": {
                "<s0>": 308,
                "<e0>": 323
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39232",
        "original_caption": "a child in black rides a skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in black rides a skateboard in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                330,
                411
            ],
            "duration": 82,
            "token": {
                "<s0>": 8,
                "<e0>": 25
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_39233",
        "original_caption": "there is a bicycle man in black beneath an adult on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle man in black beneath an adult on the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 16,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39234",
        "original_caption": "there is a beige table beneath a white dish.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a beige table beneath a white dish."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3077362332",
        "aid": "3077362332_39235",
        "original_caption": "there is adult women next to the another adult women.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is adult women next to the another adult women."
            }
        ],
        "meta": {
            "split": [
                1160,
                1913
            ],
            "duration": 754,
            "token": {
                "<s0>": 172,
                "<e0>": 248
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_39236",
        "original_caption": "there is a golden chair beneath an adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a golden chair beneath an adult in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 0,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_39237",
        "original_caption": "an adult is above a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult on the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                2186
            ],
            "duration": 2187,
            "token": {
                "<s0>": 0,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6194807654",
        "aid": "6194807654_39238",
        "original_caption": "an adult man in brown watches another adult man in black in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in brown watches another adult man in black in the forest."
            }
        ],
        "meta": {
            "split": [
                1220,
                2123
            ],
            "duration": 904,
            "token": {
                "<s0>": 199,
                "<e0>": 224
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13887084254",
        "aid": "13887084254_39239",
        "original_caption": "there is a baby seat beneath a bottle inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_seat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a baby seat beneath a bottle inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                722
            ],
            "duration": 723,
            "token": {
                "<s0>": 360,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_39240",
        "original_caption": "an adult rides a bicycle on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 16,
                "<e0>": 220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5018588436",
        "aid": "5018588436_39241",
        "original_caption": "an adult with glasses is towards a monitor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult with glasses towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 510,
                "<e0>": 555
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39242",
        "original_caption": "an adult in purple is next to a cake in the dining room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in purple is next to a cake in the dining room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                561,
                872
            ],
            "duration": 312,
            "token": {
                "<s0>": 172,
                "<e0>": 308
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3811600452",
        "aid": "3811600452_39243",
        "original_caption": "there is a gray cat behind a balck cat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a gray cat behind a balck cat in the room."
            }
        ],
        "meta": {
            "split": [
                1261,
                2157
            ],
            "duration": 897,
            "token": {
                "<s0>": 374,
                "<e0>": 586
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3963443256",
        "aid": "3963443256_39244",
        "original_caption": "an adult is towards an another adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards an another adult in white."
            }
        ],
        "meta": {
            "split": [
                0,
                1115
            ],
            "duration": 1116,
            "token": {
                "<s0>": 987,
                "<e0>": 1049
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_39245",
        "original_caption": "an adult in gray rides a watercraft on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in gray ride on the river from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7506103208",
        "aid": "7506103208_39246",
        "original_caption": "an adult man is beneath a stool on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man is beneath a stool on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                645,
                1283
            ],
            "duration": 639,
            "token": {
                "<s0>": 375,
                "<e0>": 585
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_39247",
        "original_caption": "there is a stool beneath an adult with blond-hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a stool beneath an adult with blond-hair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                5394
            ],
            "duration": 5395,
            "token": {
                "<s0>": 10,
                "<e0>": 1589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39248",
        "original_caption": "a child in a red suit is away from the ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in a red suit is away from the ball."
            }
        ],
        "meta": {
            "split": [
                401,
                595
            ],
            "duration": 195,
            "token": {
                "<s0>": 139,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39249",
        "original_caption": "an adult in white clothes is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes is above a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 265,
                "<e0>": 474
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_39250",
        "original_caption": "there is a toy in front of a child in red on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy in front of a child in red on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 1901,
                "<e0>": 2104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_39251",
        "original_caption": "a child watches another child in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child watches another child in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 161,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7308772034",
        "aid": "7308772034_39252",
        "original_caption": "a child with blond-hair speaks to an adult in striped clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child with blond-hair speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2456
            ],
            "duration": 2457,
            "token": {
                "<s0>": 1929,
                "<e0>": 1979
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_39253",
        "original_caption": "an adult hugs a baby on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult hugs a baby on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 702,
                "<e0>": 743
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_39254",
        "original_caption": "a standing adult is towards a sitting male adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A standing adult is towards a sitting male adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 1260,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_39255",
        "original_caption": "a child in blue is above a chair wooden at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue is above a chair wooden at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 0,
                "<e0>": 300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5441859967",
        "aid": "5441859967_39256",
        "original_caption": "there is an empty cup in front of an adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in black from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                623
            ],
            "duration": 624,
            "token": {
                "<s0>": 0,
                "<e0>": 624
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39257",
        "original_caption": "an adult man in shirt touches a silver laptop in a classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in shirt touches a silver laptop in a classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                140
            ],
            "duration": 141,
            "token": {
                "<s0>": 0,
                "<e0>": 130
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39258",
        "original_caption": "an adult man in shirt touches a silver laptop in a classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in shirt touches a silver laptop in a classroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                140,
                329
            ],
            "duration": 190,
            "token": {
                "<s0>": 11,
                "<e0>": 154
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39259",
        "original_caption": "an adult man in shirt touches a silver laptop in a classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in shirt touches a silver laptop in a classroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                329,
                442
            ],
            "duration": 114,
            "token": {
                "<s0>": 36,
                "<e0>": 53
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39260",
        "original_caption": "an adult man in shirt touches a silver laptop in a classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in shirt touches a silver laptop in a classroom."
            }
        ],
        "meta": {
            "split": [
                442,
                606
            ],
            "duration": 165,
            "token": {
                "<s0>": 60,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39261",
        "original_caption": "an adult man in shirt touches a silver laptop in a classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in shirt touches a silver laptop in a classroom."
            }
        ],
        "meta": {
            "split": [
                606,
                712
            ],
            "duration": 107,
            "token": {
                "<s0>": 55,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39262",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds a yellow toy."
            }
        ],
        "meta": {
            "split": [
                0,
                124
            ],
            "duration": 125,
            "token": {
                "<s0>": 24,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39263",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds a yellow toy."
            }
        ],
        "meta": {
            "split": [
                176,
                253
            ],
            "duration": 78,
            "token": {
                "<s0>": 13,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39264",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the yellow toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                253,
                594
            ],
            "duration": 342,
            "token": {
                "<s0>": 9,
                "<e0>": 215
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39265",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair holds a yellow toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                594,
                871
            ],
            "duration": 278,
            "token": {
                "<s0>": 127,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39266",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds a yellow toy."
            }
        ],
        "meta": {
            "split": [
                959,
                1139
            ],
            "duration": 181,
            "token": {
                "<s0>": 10,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39267",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds a yellow toy."
            }
        ],
        "meta": {
            "split": [
                1139,
                1247
            ],
            "duration": 109,
            "token": {
                "<s0>": 31,
                "<e0>": 95
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39268",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair holds a yellow toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1247,
                1411
            ],
            "duration": 165,
            "token": {
                "<s0>": 14,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39269",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair holds a yellow toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1528,
                1684
            ],
            "duration": 157,
            "token": {
                "<s0>": 10,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2647914610",
        "aid": "2647914610_39270",
        "original_caption": "a child with blond-hair holds a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the yellow toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1684,
                2157
            ],
            "duration": 474,
            "token": {
                "<s0>": 58,
                "<e0>": 221
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_39271",
        "original_caption": "there is a small car behind a big car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a small car behind a big car."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 0,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_39272",
        "original_caption": "an adult in green clothes is next to a baby in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes is next to a baby in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                245
            ],
            "duration": 246,
            "token": {
                "<s0>": 48,
                "<e0>": 120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_39273",
        "original_caption": "a child leans on a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child lean on at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                162
            ],
            "duration": 163,
            "token": {
                "<s0>": 0,
                "<e0>": 45
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_39274",
        "original_caption": "a child leans on a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child leans on a chair at home."
            }
        ],
        "meta": {
            "split": [
                162,
                733
            ],
            "duration": 572,
            "token": {
                "<s0>": 117,
                "<e0>": 445
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_39275",
        "original_caption": "a child leans on a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child leans on a chair at home."
            }
        ],
        "meta": {
            "split": [
                733,
                1226
            ],
            "duration": 494,
            "token": {
                "<s0>": 126,
                "<e0>": 443
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_39276",
        "original_caption": "a child leans on a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child lean on at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                1226,
                2225
            ],
            "duration": 1000,
            "token": {
                "<s0>": 50,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_39277",
        "original_caption": "a child in blue clothes leans on a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue clothes leans on a table."
            }
        ],
        "meta": {
            "split": [
                0,
                1653
            ],
            "duration": 1654,
            "token": {
                "<s0>": 425,
                "<e0>": 1654
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2945751196",
        "aid": "2945751196_39278",
        "original_caption": "there is a glass bottle in front of a chair wooden in the bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the glass bottle in the bar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                903
            ],
            "duration": 904,
            "token": {
                "<s0>": 0,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3068708457",
        "aid": "3068708457_39279",
        "original_caption": "an adult in pink is behind another adult with stride shirt outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pink is behind another adult with stride shirt outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1151
            ],
            "duration": 1152,
            "token": {
                "<s0>": 960,
                "<e0>": 1109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2401316165",
        "aid": "2401316165_39280",
        "original_caption": "there is a guitar above an adult man in gray on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the guitar on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                261
            ],
            "duration": 262,
            "token": {
                "<s0>": 0,
                "<e0>": 262
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_39281",
        "original_caption": "an adult caresses a dog outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult caresses a dog outside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                315
            ],
            "duration": 316,
            "token": {
                "<s0>": 261,
                "<e0>": 297
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_39282",
        "original_caption": "an adult caresses a dog outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult caresses a dog outside a room."
            }
        ],
        "meta": {
            "split": [
                315,
                706
            ],
            "duration": 392,
            "token": {
                "<s0>": 19,
                "<e0>": 392
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_39283",
        "original_caption": "a child in black is above a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black is above a brown sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 480,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_39284",
        "original_caption": "there is a monitor above an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a monitor above an adult in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39285",
        "original_caption": "there is a silver bottle above a colorful table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a silver bottle above a colorful table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_39286",
        "original_caption": "an adult wearing sunglasses rides a green watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing sunglasses rides a green watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2634,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3190385624",
        "aid": "3190385624_39287",
        "original_caption": "there is a toy above a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy above a table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1460
            ],
            "duration": 1461,
            "token": {
                "<s0>": 1232,
                "<e0>": 1460
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_39288",
        "original_caption": "an adult woman in white speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in white speaks to another adult man in black."
            }
        ],
        "meta": {
            "split": [
                0,
                716
            ],
            "duration": 717,
            "token": {
                "<s0>": 627,
                "<e0>": 698
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_39289",
        "original_caption": "an adult woman in white speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in white speak to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                716,
                830
            ],
            "duration": 115,
            "token": {
                "<s0>": 18,
                "<e0>": 94
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_39290",
        "original_caption": "an adult woman in white speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in white speaks to another adult man in black."
            }
        ],
        "meta": {
            "split": [
                830,
                1276
            ],
            "duration": 447,
            "token": {
                "<s0>": 21,
                "<e0>": 44
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_39291",
        "original_caption": "an adult woman in white speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in white speaks to another adult man in black."
            }
        ],
        "meta": {
            "split": [
                1276,
                1772
            ],
            "duration": 497,
            "token": {
                "<s0>": 402,
                "<e0>": 472
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3314671628",
        "aid": "3314671628_39292",
        "original_caption": "an adult woman in white speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in white speaks to another adult man in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1772,
                2696
            ],
            "duration": 925,
            "token": {
                "<s0>": 25,
                "<e0>": 85
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4231951231",
        "aid": "4231951231_39293",
        "original_caption": "an adult with black clothes hugs an another adult with red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with black clothes hugs an another adult with red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                754
            ],
            "duration": 755,
            "token": {
                "<s0>": 538,
                "<e0>": 616
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4827728106",
        "aid": "4827728106_39294",
        "original_caption": "a child with blond-hair is towards a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair is towards a table."
            }
        ],
        "meta": {
            "split": [
                0,
                235
            ],
            "duration": 236,
            "token": {
                "<s0>": 120,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3219139415",
        "aid": "3219139415_39295",
        "original_caption": "there is a toy beneath an adult in the building.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy beneath an adult in the building."
            }
        ],
        "meta": {
            "split": [
                0,
                202
            ],
            "duration": 203,
            "token": {
                "<s0>": 0,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39296",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult man in dark blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                546
            ],
            "duration": 547,
            "token": {
                "<s0>": 384,
                "<e0>": 435
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39297",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt speaks to another adult man in dark blue."
            }
        ],
        "meta": {
            "split": [
                546,
                827
            ],
            "duration": 282,
            "token": {
                "<s0>": 112,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39298",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in plaid shirt speaks to another adult man in dark blue happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                827,
                974
            ],
            "duration": 148,
            "token": {
                "<s0>": 29,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39299",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt speaks to another adult man in dark blue."
            }
        ],
        "meta": {
            "split": [
                974,
                1164
            ],
            "duration": 191,
            "token": {
                "<s0>": 38,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39300",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult man in dark blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1164,
                1368
            ],
            "duration": 205,
            "token": {
                "<s0>": 65,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39301",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt speaks to another adult man in dark blue."
            }
        ],
        "meta": {
            "split": [
                1368,
                1610
            ],
            "duration": 243,
            "token": {
                "<s0>": 99,
                "<e0>": 211
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39302",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in plaid shirt speaks to another adult man in dark blue happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1610,
                1740
            ],
            "duration": 131,
            "token": {
                "<s0>": 32,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39303",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt speaks to another adult man in dark blue."
            }
        ],
        "meta": {
            "split": [
                1740,
                1844
            ],
            "duration": 105,
            "token": {
                "<s0>": 32,
                "<e0>": 82
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39304",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult man in dark blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1844,
                1963
            ],
            "duration": 120,
            "token": {
                "<s0>": 22,
                "<e0>": 100
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39305",
        "original_caption": "an adult man in plaid shirt speaks to another adult man in dark blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt speaks to another adult man in dark blue."
            }
        ],
        "meta": {
            "split": [
                1963,
                2159
            ],
            "duration": 197,
            "token": {
                "<s0>": 20,
                "<e0>": 77
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_39306",
        "original_caption": "an adult wearing sunglasses is above a blue watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing sunglasses is above a blue watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_39307",
        "original_caption": "an adult woman in white speaks to another adult man in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in white speaks to another adult man in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 334,
                "<e0>": 393
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5669212370",
        "aid": "5669212370_39308",
        "original_caption": "an adult watches another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult watches another adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                145
            ],
            "duration": 146,
            "token": {
                "<s0>": 0,
                "<e0>": 25
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3066398259",
        "aid": "3066398259_39309",
        "original_caption": "a baby in red leans on a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in red leans on a sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                251
            ],
            "duration": 252,
            "token": {
                "<s0>": 0,
                "<e0>": 243
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3066398259",
        "aid": "3066398259_39310",
        "original_caption": "a baby in red leans on a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in red leans on a sofa at home."
            }
        ],
        "meta": {
            "split": [
                251,
                629
            ],
            "duration": 379,
            "token": {
                "<s0>": 9,
                "<e0>": 378
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_39311",
        "original_caption": "an adult with glasses holds a cup outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses holds a cup outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                920
            ],
            "duration": 921,
            "token": {
                "<s0>": 441,
                "<e0>": 561
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_39312",
        "original_caption": "an adult with glasses holds a cup outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cup outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                920,
                1649
            ],
            "duration": 730,
            "token": {
                "<s0>": 359,
                "<e0>": 730
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_39313",
        "original_caption": "an adult in purple is away an adult in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in purple is away an adult in white outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 300,
                "<e0>": 362
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_39314",
        "original_caption": "an adult in red holds a bench in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red holds a bench in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                769
            ],
            "duration": 770,
            "token": {
                "<s0>": 670,
                "<e0>": 732
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_39315",
        "original_caption": "an adult in red holds a bench in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red holds a bench in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                769,
                968
            ],
            "duration": 200,
            "token": {
                "<s0>": 38,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_39316",
        "original_caption": "an adult in red holds a bench in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red holds a bench in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                968,
                1323
            ],
            "duration": 356,
            "token": {
                "<s0>": 136,
                "<e0>": 172
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5244251013",
        "aid": "5244251013_39317",
        "original_caption": "an adult speaks to another adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult speaks to another adult in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1618
            ],
            "duration": 1619,
            "token": {
                "<s0>": 645,
                "<e0>": 684
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_39318",
        "original_caption": "an adult in white clothes holds a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes holds a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_39319",
        "original_caption": "an adult in black gets on a bench on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black gets on a bench on the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 745,
                "<e0>": 766
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_39320",
        "original_caption": "an adult in black gets on a bench on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black gets on a bench on the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                808,
                946
            ],
            "duration": 139,
            "token": {
                "<s0>": 42,
                "<e0>": 70
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_39321",
        "original_caption": "an adult in black gets on a bench on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black gets on a bench on the playground."
            }
        ],
        "meta": {
            "split": [
                946,
                1323
            ],
            "duration": 378,
            "token": {
                "<s0>": 69,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39322",
        "original_caption": "an adult in pink is towards another adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in pink is towards another adult in white."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1229,
                "<e0>": 1347
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39323",
        "original_caption": "a child wearing pink shoes holds a green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing pink shoes holds a green toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 915,
                "<e0>": 1315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39324",
        "original_caption": "an adult man watches another adult man outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the other adult man outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1964,
                2159
            ],
            "duration": 196,
            "token": {
                "<s0>": 27,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8015524320",
        "aid": "8015524320_39325",
        "original_caption": "there is a cup next to a child in green in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup next to a child in green in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                435
            ],
            "duration": 436,
            "token": {
                "<s0>": 240,
                "<e0>": 286
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6644166529",
        "aid": "6644166529_39326",
        "original_caption": "there is a table beneath a dish at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a dish at home."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8847930035",
        "aid": "8847930035_39327",
        "original_caption": "a child pats a sports ball in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pats the sports ball in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                325
            ],
            "duration": 326,
            "token": {
                "<s0>": 0,
                "<e0>": 154
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39328",
        "original_caption": "an adult woman touches a ball silver on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult woman touch on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 25,
                "<e0>": 61
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39329",
        "original_caption": "an adult woman touches a ball silver on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult woman touch on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                239,
                595
            ],
            "duration": 357,
            "token": {
                "<s0>": 178,
                "<e0>": 292
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_39330",
        "original_caption": "there is a yellow chair behind a girl child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a yellow chair behind a girl child."
            }
        ],
        "meta": {
            "split": [
                0,
                4260
            ],
            "duration": 4261,
            "token": {
                "<s0>": 300,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_39331",
        "original_caption": "there is a red toy away another toy in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the red toy away in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                2052,
                2159
            ],
            "duration": 108,
            "token": {
                "<s0>": 12,
                "<e0>": 49
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6372875655",
        "aid": "6372875655_39332",
        "original_caption": "there is a blue bottle behind an adult in green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue bottle behind an adult in green clothes."
            }
        ],
        "meta": {
            "split": [
                754,
                1114
            ],
            "duration": 361,
            "token": {
                "<s0>": 146,
                "<e0>": 205
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6879186481",
        "aid": "6879186481_39333",
        "original_caption": "a child throwes a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child throwes a toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                113
            ],
            "duration": 114,
            "token": {
                "<s0>": 66,
                "<e0>": 80
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_39334",
        "original_caption": "a child in blue watches another child in red outside the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue watches another child in red outside the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 430,
                "<e0>": 508
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39335",
        "original_caption": "there is a rat away an adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the hamster/rat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a rat away an adult on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1560,
                "<e0>": 1690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8483279367",
        "aid": "8483279367_39336",
        "original_caption": "an adult man in shirt is behind an orange guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the orange guitar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 381,
                "<e0>": 691
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39337",
        "original_caption": "there is a hamster towards another rat on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the hamster towards to on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1380,
                "<e0>": 1470
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11566933123",
        "aid": "11566933123_39338",
        "original_caption": "a child in green clothes pulls a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in green clothes pull from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                867
            ],
            "duration": 868,
            "token": {
                "<s0>": 326,
                "<e0>": 366
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_39339",
        "original_caption": "there is a cat above a chair next to the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat above a chair next to the adult."
            }
        ],
        "meta": {
            "split": [
                1151,
                2114
            ],
            "duration": 964,
            "token": {
                "<s0>": 139,
                "<e0>": 558
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_39340",
        "original_caption": "a child wearing a halmet is above a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing a halmet is above a bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 94,
                "<e0>": 371
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39341",
        "original_caption": "there is a bottle above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bottle above a table in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                611
            ],
            "duration": 612,
            "token": {
                "<s0>": 360,
                "<e0>": 612
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3741114842",
        "aid": "3741114842_39342",
        "original_caption": "there is a cake in front of an adult in black in the kitchen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cake in front of an adult in black in the kitchen."
            }
        ],
        "meta": {
            "split": [
                0,
                482
            ],
            "duration": 483,
            "token": {
                "<s0>": 93,
                "<e0>": 269
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_39343",
        "original_caption": "a child is above another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is above another child in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 120,
                "<e0>": 166
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4154183202",
        "aid": "4154183202_39344",
        "original_caption": "a child in red watches a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red watches a toy on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                315,
                782
            ],
            "duration": 468,
            "token": {
                "<s0>": 145,
                "<e0>": 300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39345",
        "original_caption": "an adult is towards a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is towards a sports ball in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6501432541",
        "aid": "6501432541_39346",
        "original_caption": "there is a faucet above a sink inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a faucet above a sink inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                173
            ],
            "duration": 174,
            "token": {
                "<s0>": 0,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39347",
        "original_caption": "there is a table behind a laptop inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table behind a laptop inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 0,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39348",
        "original_caption": "there is a gray ball towards an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray ball towards an adult in blue clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                329,
                595
            ],
            "duration": 267,
            "token": {
                "<s0>": 119,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_39349",
        "original_caption": "an adult man in gray rides a watercraft on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in gray rides a watercraft on the lake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2186
            ],
            "duration": 2187,
            "token": {
                "<s0>": 0,
                "<e0>": 363
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_39350",
        "original_caption": "an adult man speaks to a child in white on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man speaks to a child in white on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 470,
                "<e0>": 785
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6106626461",
        "aid": "6106626461_39351",
        "original_caption": "an adult holds a cellphone in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a cellphone in the playground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                520
            ],
            "duration": 521,
            "token": {
                "<s0>": 16,
                "<e0>": 45
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3754789709",
        "aid": "3754789709_39352",
        "original_caption": "a child in blue clothes carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in blue clothes carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                397
            ],
            "duration": 398,
            "token": {
                "<s0>": 325,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8429686679",
        "aid": "8429686679_39353",
        "original_caption": "the adult is away from the adult in short pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult is away from the adult in short pants happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1573
            ],
            "duration": 1574,
            "token": {
                "<s0>": 26,
                "<e0>": 79
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39354",
        "original_caption": "an adult is in front of a cellphone at a party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is in front of a cellphone at a party."
            }
        ],
        "meta": {
            "split": [
                434,
                1441
            ],
            "duration": 1008,
            "token": {
                "<s0>": 125,
                "<e0>": 645
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_39355",
        "original_caption": "a child in a dress holds a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1065
            ],
            "duration": 1066,
            "token": {
                "<s0>": 553,
                "<e0>": 723
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_39356",
        "original_caption": "a child in a dress holds a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1065,
                1446
            ],
            "duration": 382,
            "token": {
                "<s0>": 342,
                "<e0>": 363
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4021620287",
        "aid": "4021620287_39357",
        "original_caption": "there is a dish in front of an adult at wedding.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dish in front of an adult at wedding happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1799
            ],
            "duration": 1800,
            "token": {
                "<s0>": 1421,
                "<e0>": 1460
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_39358",
        "original_caption": "a child touches a laptop in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child touch in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                868
            ],
            "duration": 869,
            "token": {
                "<s0>": 675,
                "<e0>": 778
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_39359",
        "original_caption": "a child touches a laptop in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child touches a laptop in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                868,
                1349
            ],
            "duration": 482,
            "token": {
                "<s0>": 91,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_39360",
        "original_caption": "an adult in black clothes carries a green snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes carries a green snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 180,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_39361",
        "original_caption": "an adult woman hugs a child with green swimming pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman hugs a child with green swimming pants."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 346,
                "<e0>": 422
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6896590813",
        "aid": "6896590813_39362",
        "original_caption": "a child in grey is towards another child in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in grey is towards another child in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 180,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39363",
        "original_caption": "there is a child in white leaning on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a child in white leaning on the table."
            }
        ],
        "meta": {
            "split": [
                0,
                114
            ],
            "duration": 115,
            "token": {
                "<s0>": 21,
                "<e0>": 66
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39364",
        "original_caption": "there is a child in white leaning on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a child in white leaning on the table."
            }
        ],
        "meta": {
            "split": [
                114,
                872
            ],
            "duration": 759,
            "token": {
                "<s0>": 48,
                "<e0>": 169
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6572270403",
        "aid": "6572270403_39365",
        "original_caption": "an adult is beneath a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is beneath a child at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39366",
        "original_caption": "an adult in black is next to a skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the skateboard in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                108,
                411
            ],
            "duration": 304,
            "token": {
                "<s0>": 3,
                "<e0>": 104
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3754789709",
        "aid": "3754789709_39367",
        "original_caption": "a child is in front of another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is in front of another child."
            }
        ],
        "meta": {
            "split": [
                0,
                397
            ],
            "duration": 398,
            "token": {
                "<s0>": 319,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39368",
        "original_caption": "there is a yellow table beneath a cake at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the yellow table at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cake."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_39369",
        "original_caption": "there is a white pig in front of an adult woman in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white pig in front of an adult woman in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                495,
                869
            ],
            "duration": 375,
            "token": {
                "<s0>": 45,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7246410056",
        "aid": "7246410056_39370",
        "original_caption": "an adult in white holds a child in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white holds a child in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                951
            ],
            "duration": 952,
            "token": {
                "<s0>": 209,
                "<e0>": 896
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7246410056",
        "aid": "7246410056_39371",
        "original_caption": "an adult in white holds a child in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the child in blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                951,
                1212
            ],
            "duration": 262,
            "token": {
                "<s0>": 56,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8994675143",
        "aid": "8994675143_39372",
        "original_caption": "an adult is above a chair in the plane.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a chair in the plane happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                511,
                1005
            ],
            "duration": 495,
            "token": {
                "<s0>": 29,
                "<e0>": 495
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6247340440",
        "aid": "6247340440_39373",
        "original_caption": "an adult in red rides a ski on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the ski on the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                387
            ],
            "duration": 388,
            "token": {
                "<s0>": 0,
                "<e0>": 381
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2683780802",
        "aid": "2683780802_39374",
        "original_caption": "a child on the right pats another child on the left in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child on the right pats another child on the left in the swimming pool happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                115,
                208
            ],
            "duration": 94,
            "token": {
                "<s0>": 6,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39375",
        "original_caption": "a child in green clothes is next to a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child in green clothes next to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                681,
                872
            ],
            "duration": 192,
            "token": {
                "<s0>": 18,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12620917425",
        "aid": "12620917425_39376",
        "original_caption": "there is a smallest elephant towards another elephant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the elephant from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a smallest elephant towards another elephant."
            }
        ],
        "meta": {
            "split": [
                0,
                1814
            ],
            "duration": 1815,
            "token": {
                "<s0>": 1740,
                "<e0>": 1815
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_39377",
        "original_caption": "a child is next to a bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is next to a bottle at home."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 0,
                "<e0>": 781
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5048454031",
        "aid": "5048454031_39378",
        "original_caption": "an adult in a hat points to a bird.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho points to the bird from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                320,
                659
            ],
            "duration": 340,
            "token": {
                "<s0>": 66,
                "<e0>": 176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3077081235",
        "aid": "3077081235_39379",
        "original_caption": "an adult standing is away a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult standing is away a chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                538
            ],
            "duration": 539,
            "token": {
                "<s0>": 480,
                "<e0>": 539
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2867108011",
        "aid": "2867108011_39380",
        "original_caption": "a child leans on a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child leans on a table inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                875
            ],
            "duration": 876,
            "token": {
                "<s0>": 0,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_39381",
        "original_caption": "there is a black camera in front of an adult woman in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the black camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                571,
                735
            ],
            "duration": 165,
            "token": {
                "<s0>": 29,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5049587564",
        "aid": "5049587564_39382",
        "original_caption": "a child is next to another child on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is next to another child on the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                719
            ],
            "duration": 720,
            "token": {
                "<s0>": 0,
                "<e0>": 720
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6086390405",
        "aid": "6086390405_39383",
        "original_caption": "a child in orange clothes is away from a suv car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in orange clothes is away from a suv car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1301
            ],
            "duration": 1302,
            "token": {
                "<s0>": 180,
                "<e0>": 262
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8426046231",
        "aid": "8426046231_39384",
        "original_caption": "a baby with blond-hair is next to a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby with blond-hair is next to a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                530
            ],
            "duration": 531,
            "token": {
                "<s0>": 0,
                "<e0>": 531
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_39385",
        "original_caption": "a child in red is towards a car silver.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red is towards a car silver."
            }
        ],
        "meta": {
            "split": [
                0,
                1709
            ],
            "duration": 1710,
            "token": {
                "<s0>": 720,
                "<e0>": 810
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39386",
        "original_caption": "there is a hamster above another hamster in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the hamster/rat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a hamster above another hamster in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1020,
                "<e0>": 1170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3900000605",
        "aid": "3900000605_39387",
        "original_caption": "an adult in white watches a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white watches a child outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                404
            ],
            "duration": 405,
            "token": {
                "<s0>": 219,
                "<e0>": 353
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7614020956",
        "aid": "7614020956_39388",
        "original_caption": "there is a motorcycle beneath an adult wearing red shoes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a motorcycle beneath an adult wearing red shoes."
            }
        ],
        "meta": {
            "split": [
                0,
                706
            ],
            "duration": 707,
            "token": {
                "<s0>": 120,
                "<e0>": 707
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39389",
        "original_caption": "there is a bottle in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 480,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2551446323",
        "aid": "2551446323_39390",
        "original_caption": "an adult man in black is next to a black bird outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult man in black next to outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bird."
            }
        ],
        "meta": {
            "split": [
                345,
                908
            ],
            "duration": 564,
            "token": {
                "<s0>": 15,
                "<e0>": 365
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10011555465",
        "aid": "10011555465_39391",
        "original_caption": "an adult in white hits another adult in white on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white hits another adult in white on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                800
            ],
            "duration": 801,
            "token": {
                "<s0>": 538,
                "<e0>": 580
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39392",
        "original_caption": "an adult in grey presses a brown table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in grey presses a brown table at home."
            }
        ],
        "meta": {
            "split": [
                44,
                672
            ],
            "duration": 629,
            "token": {
                "<s0>": 28,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8223287911",
        "aid": "8223287911_39393",
        "original_caption": "an adult is towards a baby on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards a baby on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1484
            ],
            "duration": 1485,
            "token": {
                "<s0>": 1383,
                "<e0>": 1474
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_39394",
        "original_caption": "a child in red leans on a bicycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red leans on a bicycle on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 36,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3561761322",
        "aid": "3561761322_39395",
        "original_caption": "an adult in red clothes rides a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes rides a bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                125
            ],
            "duration": 126,
            "token": {
                "<s0>": 21,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4408638205",
        "aid": "4408638205_39396",
        "original_caption": "an adult in red clothes holds a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in red clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                2186
            ],
            "duration": 2187,
            "token": {
                "<s0>": 1750,
                "<e0>": 1804
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39397",
        "original_caption": "an adult woman in green lifts a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in green lifts a baby in white."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 114,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_39398",
        "original_caption": "there is a handbag away a chair in a convenience store.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a handbag away a chair in a convenience store."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 960,
                "<e0>": 1025
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39399",
        "original_caption": "there is a toy above a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy above a baby seat."
            }
        ],
        "meta": {
            "split": [
                1116,
                2696
            ],
            "duration": 1581,
            "token": {
                "<s0>": 24,
                "<e0>": 354
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6789657160",
        "aid": "6789657160_39400",
        "original_caption": "an adult speaks to a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult speaks to a child in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 93,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4466788724",
        "aid": "4466788724_39401",
        "original_caption": "a baby leans on an adult with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult with glasses."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 0,
                "<e0>": 2215
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114352772",
        "aid": "8114352772_39402",
        "original_caption": "an adult holds a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult hold in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                449
            ],
            "duration": 450,
            "token": {
                "<s0>": 307,
                "<e0>": 435
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11585587124",
        "aid": "11585587124_39403",
        "original_caption": "there is a black and white dog away from an adult in black outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black and white dog away from an adult in black outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1649
            ],
            "duration": 1650,
            "token": {
                "<s0>": 12,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3099327773",
        "aid": "3099327773_39404",
        "original_caption": "a child in white hugs another child in white on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white hugs another child in white on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1947
            ],
            "duration": 1948,
            "token": {
                "<s0>": 1757,
                "<e0>": 1948
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_39405",
        "original_caption": "there is a bird towards an another bird.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bird towards an another bird happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                165,
                599
            ],
            "duration": 435,
            "token": {
                "<s0>": 15,
                "<e0>": 165
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3076771705",
        "aid": "3076771705_39406",
        "original_caption": "an adult in green clothes plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green clothes plays the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                533
            ],
            "duration": 534,
            "token": {
                "<s0>": 266,
                "<e0>": 415
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_39407",
        "original_caption": "an adult leans on a stool on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult leans on a stool on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                5394
            ],
            "duration": 5395,
            "token": {
                "<s0>": 22,
                "<e0>": 1507
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_39408",
        "original_caption": "a child with blond-hair is above a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair is above a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 0,
                "<e0>": 781
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5913888440",
        "aid": "5913888440_39409",
        "original_caption": "there is a backpack behind an adult in green.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is behind the adult in green from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                317,
                803
            ],
            "duration": 487,
            "token": {
                "<s0>": 117,
                "<e0>": 252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39410",
        "original_caption": "there is a hamster towards another hamster on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the hamster towards to on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1380,
                "<e0>": 1590
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_39411",
        "original_caption": "there is a snowboard towards another snowboard on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the snowboard from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a snowboard towards another snowboard on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 691,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_39412",
        "original_caption": "there is a red chair behind a laptop in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a red chair behind a laptop in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2533
            ],
            "duration": 2534,
            "token": {
                "<s0>": 2220,
                "<e0>": 2370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_39413",
        "original_caption": "a child presses a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child presses a table inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 35,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2852706689",
        "aid": "2852706689_39414",
        "original_caption": "there is a toy above a baby seat in the car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy above a baby seat in the car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                648
            ],
            "duration": 649,
            "token": {
                "<s0>": 0,
                "<e0>": 648
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5647072246",
        "aid": "5647072246_39415",
        "original_caption": "an adult in white grabs a sports ball outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white grabs a sports ball outdoor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                364
            ],
            "duration": 365,
            "token": {
                "<s0>": 259,
                "<e0>": 278
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4867428780",
        "aid": "4867428780_39416",
        "original_caption": "a child is away from another child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the other child in the swimming pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                615,
                884
            ],
            "duration": 270,
            "token": {
                "<s0>": 45,
                "<e0>": 179
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39417",
        "original_caption": "an adult holding a cup speaks to an adult in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the adult in blue outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1477
            ],
            "duration": 1478,
            "token": {
                "<s0>": 1274,
                "<e0>": 1397
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39418",
        "original_caption": "an adult holding a cup speaks to an adult in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holding a cup speaks to an adult in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                1477,
                1648
            ],
            "duration": 172,
            "token": {
                "<s0>": 81,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39419",
        "original_caption": "an adult holding a cup speaks to an adult in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holding a cup speaks to an adult in blue outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1648,
                1850
            ],
            "duration": 203,
            "token": {
                "<s0>": 46,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39420",
        "original_caption": "an adult holding a cup speaks to an adult in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holding a cup speaks to an adult in blue outdoors."
            }
        ],
        "meta": {
            "split": [
                1850,
                2159
            ],
            "duration": 310,
            "token": {
                "<s0>": 88,
                "<e0>": 310
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_39421",
        "original_caption": "a baby in yellow grabs a toy little.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby in yellow grab from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                102
            ],
            "duration": 103,
            "token": {
                "<s0>": 11,
                "<e0>": 61
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_39422",
        "original_caption": "a baby in yellow grabs a toy little.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in yellow grabs a toy little happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                102,
                824
            ],
            "duration": 723,
            "token": {
                "<s0>": 41,
                "<e0>": 71
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39423",
        "original_caption": "there is a rat above another rat on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the hamster/rat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a rat above another rat on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1880,
                "<e0>": 2009
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_39424",
        "original_caption": "a child in orange clothes is next to a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in orange clothes is next to a table."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 211,
                "<e0>": 310
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39425",
        "original_caption": "there is a dark gray rat in front of a dark gray hamster.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dark gray rat in front of a dark gray hamster."
            }
        ],
        "meta": {
            "split": [
                1264,
                2639
            ],
            "duration": 1376,
            "token": {
                "<s0>": 71,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6197272373",
        "aid": "6197272373_39426",
        "original_caption": "there is a cup in front of an adult in black suits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup in front of an adult in black suits happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                319,
                638
            ],
            "duration": 320,
            "token": {
                "<s0>": 12,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3078133866",
        "aid": "3078133866_39427",
        "original_caption": "an adult hugs a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult hugs a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1438
            ],
            "duration": 1439,
            "token": {
                "<s0>": 0,
                "<e0>": 1016
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39428",
        "original_caption": "there is a golden dog towards an adult woman in pale purple.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the golden dog towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1336
            ],
            "duration": 1337,
            "token": {
                "<s0>": 420,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_39429",
        "original_caption": "there is a screen woman in blue in front of an adult in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in the classroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                629,
                1319
            ],
            "duration": 691,
            "token": {
                "<s0>": 244,
                "<e0>": 298
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6844936082",
        "aid": "6844936082_39430",
        "original_caption": "a child speaks to another child in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child speaks to another child in a car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1620
            ],
            "duration": 1621,
            "token": {
                "<s0>": 1565,
                "<e0>": 1613
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8283493827",
        "aid": "8283493827_39431",
        "original_caption": "an adult is hold hand of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is hold hand of the adult."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 0,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_39432",
        "original_caption": "an adult in blue carries a backpack in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue carries a backpack in the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 293,
                "<e0>": 308
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3521372410",
        "aid": "3521372410_39433",
        "original_caption": "a baby on the right pats another baby on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby on the right pats another baby on the left."
            }
        ],
        "meta": {
            "split": [
                0,
                680
            ],
            "duration": 681,
            "token": {
                "<s0>": 354,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_39434",
        "original_caption": "an adult man in black is above a wooden stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black is above a wooden stool happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 544,
                "<e0>": 840
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39435",
        "original_caption": "an adult with long hair watches another adult in black coat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with long hair watches another adult in black coat."
            }
        ],
        "meta": {
            "split": [
                1701,
                2159
            ],
            "duration": 459,
            "token": {
                "<s0>": 102,
                "<e0>": 338
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_39436",
        "original_caption": "there is a brown sofa beneath an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown sofa beneath an adult in blue clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                4260
            ],
            "duration": 4261,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39437",
        "original_caption": "a cellphone is token towards an adult with blue shirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a cellphone is token towards an adult with blue shirt happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                737,
                1441
            ],
            "duration": 705,
            "token": {
                "<s0>": 522,
                "<e0>": 582
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_39438",
        "original_caption": "a child is behind a sliver car outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is behind a sliver car outdoors."
            }
        ],
        "meta": {
            "split": [
                1327,
                1709
            ],
            "duration": 383,
            "token": {
                "<s0>": 17,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12577546265",
        "aid": "12577546265_39439",
        "original_caption": "an adult in black clothes watches another adult in beige clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black clothes watch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                190
            ],
            "duration": 191,
            "token": {
                "<s0>": 0,
                "<e0>": 31
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_39440",
        "original_caption": "a child wearing blue pants presses an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing blue pants presses an adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                670
            ],
            "duration": 671,
            "token": {
                "<s0>": 523,
                "<e0>": 638
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_39441",
        "original_caption": "a child wearing blue pants presses an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing blue pants presses an adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                745,
                1115
            ],
            "duration": 371,
            "token": {
                "<s0>": 32,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_39442",
        "original_caption": "a child wearing blue pants presses an adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing blue pants presses an adult in black clothes."
            }
        ],
        "meta": {
            "split": [
                1115,
                1458
            ],
            "duration": 344,
            "token": {
                "<s0>": 311,
                "<e0>": 344
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8157245482",
        "aid": "8157245482_39443",
        "original_caption": "the adult with sunglasses is hugging the child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult with sunglasses is hugging the child in red."
            }
        ],
        "meta": {
            "split": [
                0,
                191
            ],
            "duration": 192,
            "token": {
                "<s0>": 88,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6400812635",
        "aid": "6400812635_39444",
        "original_caption": "an adult presses another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult presses another adult on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                212
            ],
            "duration": 213,
            "token": {
                "<s0>": 124,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_39445",
        "original_caption": "a child wearing a red hat kicks a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho kicks the sports ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 192,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13097816293",
        "aid": "13097816293_39446",
        "original_caption": "an adult in beige clothes is away from a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in beige clothes is away from a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1104
            ],
            "duration": 1105,
            "token": {
                "<s0>": 96,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_39447",
        "original_caption": "there is a cup half full of red wine above a black table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup half full of red wine above a black table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 60,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_39448",
        "original_caption": "there is a watercraft towards a white watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a watercraft towards a white watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 150,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7363189682",
        "aid": "7363189682_39449",
        "original_caption": "the child riding a bicycle is behind the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The child riding a bicycle is behind the adult."
            }
        ],
        "meta": {
            "split": [
                892,
                1007
            ],
            "duration": 116,
            "token": {
                "<s0>": 23,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_39450",
        "original_caption": "an adult uses a laptop in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult uses a laptop in the classroom happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1319
            ],
            "duration": 1320,
            "token": {
                "<s0>": 169,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6991481998",
        "aid": "6991481998_39451",
        "original_caption": "an adult carries a backpack on the way up the mountain.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult carries a backpack on the way up the mountain."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 375,
                "<e0>": 1554
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7803526566",
        "aid": "7803526566_39452",
        "original_caption": "an adult in blue clothes plays the piano.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes plays the piano."
            }
        ],
        "meta": {
            "split": [
                0,
                748
            ],
            "duration": 749,
            "token": {
                "<s0>": 0,
                "<e0>": 749
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39453",
        "original_caption": "there is a cellphone towards a beige dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cellphone towards a beige dog."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 1269,
                "<e0>": 1319
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39454",
        "original_caption": "there is a table beneath a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the bottle in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                275,
                611
            ],
            "duration": 337,
            "token": {
                "<s0>": 6,
                "<e0>": 336
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_39455",
        "original_caption": "an adult man in black is above another adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is above another adult outdoors."
            }
        ],
        "meta": {
            "split": [
                504,
                735
            ],
            "duration": 232,
            "token": {
                "<s0>": 10,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6134739139",
        "aid": "6134739139_39456",
        "original_caption": "a child in red leans on a chair in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red leans on a chair in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                1968
            ],
            "duration": 1969,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6298848190",
        "aid": "6298848190_39457",
        "original_caption": "an adult women points to a child outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult women points to a child outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1171
            ],
            "duration": 1172,
            "token": {
                "<s0>": 1069,
                "<e0>": 1138
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39458",
        "original_caption": "an adult in yellow speaks to another adult man in blue outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in yellow speaks to another adult man in blue outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 1356,
                "<e0>": 1481
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39459",
        "original_caption": "there is a cake towards a child at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the cake towards to at party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 244,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_39460",
        "original_caption": "there is a chair beneath a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair beneath a child in blue clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_39461",
        "original_caption": "an adult man in gray holds a black and white camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult man in gray hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A camera."
            }
        ],
        "meta": {
            "split": [
                0,
                806
            ],
            "duration": 807,
            "token": {
                "<s0>": 349,
                "<e0>": 520
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_39462",
        "original_caption": "an adult man in gray holds a black and white camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult man in gray hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A camera."
            }
        ],
        "meta": {
            "split": [
                806,
                2196
            ],
            "duration": 1391,
            "token": {
                "<s0>": 286,
                "<e0>": 314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8616874413",
        "aid": "8616874413_39463",
        "original_caption": "an adult watches a lion on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult watches a lion on the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 81,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_39464",
        "original_caption": "the adult standing in the middle is behind the second adult on the right. \u00a0",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult standing in the middle is behind the second adult on the right. \u00a0"
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 1200,
                "<e0>": 1256
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_39465",
        "original_caption": "there is a table beneath a camera in the kindergarten.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table beneath a camera in the kindergarten happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 182,
                "<e0>": 407
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8543058168",
        "aid": "8543058168_39466",
        "original_caption": "a child in white is behind another child in pink in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white is behind another child in pink in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                344
            ],
            "duration": 345,
            "token": {
                "<s0>": 120,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39467",
        "original_caption": "an adult in white holds a handbag in the museum.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white holds a handbag in the museum."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 883,
                "<e0>": 980
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_39468",
        "original_caption": "an adult wearing a black hat pulls a horse.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult wearing the black hat pull from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A horse."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 37
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4935150377",
        "aid": "4935150377_39469",
        "original_caption": "an adult carries a backpack on the bridge.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult carries a backpack on the bridge."
            }
        ],
        "meta": {
            "split": [
                0,
                197
            ],
            "duration": 198,
            "token": {
                "<s0>": 0,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3151486948",
        "aid": "3151486948_39470",
        "original_caption": "there is baby leaning on the adult man.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is baby leaning on the adult man happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                372
            ],
            "duration": 373,
            "token": {
                "<s0>": 0,
                "<e0>": 373
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39471",
        "original_caption": "there is a golden and white dog above a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a golden and white dog above a brown sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1162,
                1441
            ],
            "duration": 280,
            "token": {
                "<s0>": 107,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2717467340",
        "aid": "2717467340_39472",
        "original_caption": "an adult in red holds hand of a child in white outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds hand of the child in white outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                506
            ],
            "duration": 507,
            "token": {
                "<s0>": 353,
                "<e0>": 507
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7161995226",
        "aid": "7161995226_39473",
        "original_caption": "a child in blue holds a yellow toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue holds a yellow toy at home."
            }
        ],
        "meta": {
            "split": [
                0,
                171
            ],
            "duration": 172,
            "token": {
                "<s0>": 0,
                "<e0>": 100
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39474",
        "original_caption": "the child is in front of the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The child is in front of the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 480
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3898106739",
        "aid": "3898106739_39475",
        "original_caption": "a child waves hand to an adult in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child waves hand to an adult in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                1232
            ],
            "duration": 1233,
            "token": {
                "<s0>": 323,
                "<e0>": 468
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8973361272",
        "aid": "8973361272_39476",
        "original_caption": "a child with blond-hair waves a red toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair waves a red toy."
            }
        ],
        "meta": {
            "split": [
                0,
                108
            ],
            "duration": 109,
            "token": {
                "<s0>": 80,
                "<e0>": 99
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8973361272",
        "aid": "8973361272_39477",
        "original_caption": "a child with blond-hair waves a red toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair waves a red toy."
            }
        ],
        "meta": {
            "split": [
                153,
                600
            ],
            "duration": 448,
            "token": {
                "<s0>": 13,
                "<e0>": 53
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39478",
        "original_caption": "an adult woman in green leans on a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in green leans on a sofa at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                279
            ],
            "duration": 280,
            "token": {
                "<s0>": 0,
                "<e0>": 258
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39479",
        "original_caption": "an adult woman in green leans on a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in green leans on a sofa at home."
            }
        ],
        "meta": {
            "split": [
                279,
                474
            ],
            "duration": 196,
            "token": {
                "<s0>": 22,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5155578777",
        "aid": "5155578777_39480",
        "original_caption": "adults in black clothes are hugging adults in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adults in black clothes are hugging adults in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 99,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39481",
        "original_caption": "there is a cellphone in front of a dog at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the dog at party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                683,
                1441
            ],
            "duration": 759,
            "token": {
                "<s0>": 50,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_39482",
        "original_caption": "an adult with glasses leans on a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses leans on a table at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 85,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2551446323",
        "aid": "2551446323_39483",
        "original_caption": "a camera is next to an adult outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a camera is next to an adult outdoor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                908
            ],
            "duration": 909,
            "token": {
                "<s0>": 720,
                "<e0>": 769
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4827728106",
        "aid": "4827728106_39484",
        "original_caption": "a child in green is towards an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in green is towards an adult in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                235
            ],
            "duration": 236,
            "token": {
                "<s0>": 120,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39485",
        "original_caption": "an adult in a blue t-shirt holds a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in a blue t-shirt holds a child."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 539,
                "<e0>": 596
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39486",
        "original_caption": "there is a red cup above a black table in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the red cup in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                102,
                611
            ],
            "duration": 510,
            "token": {
                "<s0>": 26,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_39487",
        "original_caption": "a child in a dress is above a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in a dress is above a toy."
            }
        ],
        "meta": {
            "split": [
                1406,
                1516
            ],
            "duration": 111,
            "token": {
                "<s0>": 45,
                "<e0>": 110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2492711005",
        "aid": "2492711005_39488",
        "original_caption": "the adult feeds the baby behind the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult feeds the baby behind the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1111
            ],
            "duration": 1112,
            "token": {
                "<s0>": 0,
                "<e0>": 1110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39489",
        "original_caption": "an adult is above a sofa at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a sofa at party happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1343,
                1441
            ],
            "duration": 99,
            "token": {
                "<s0>": 25,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2513630909",
        "aid": "2513630909_39490",
        "original_caption": "there is a table above a dog in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a table above a dog in a room."
            }
        ],
        "meta": {
            "split": [
                855,
                1456
            ],
            "duration": 602,
            "token": {
                "<s0>": 45,
                "<e0>": 555
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39491",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black cat touching a sports ball in a room."
            }
        ],
        "meta": {
            "split": [
                275,
                409
            ],
            "duration": 135,
            "token": {
                "<s0>": 7,
                "<e0>": 26
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39492",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black cat touching a sports ball in a room."
            }
        ],
        "meta": {
            "split": [
                409,
                541
            ],
            "duration": 133,
            "token": {
                "<s0>": 108,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39493",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black cat touching a sports ball in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                541,
                700
            ],
            "duration": 160,
            "token": {
                "<s0>": 8,
                "<e0>": 122
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39494",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black cat touching a sports ball in a room."
            }
        ],
        "meta": {
            "split": [
                700,
                877
            ],
            "duration": 178,
            "token": {
                "<s0>": 38,
                "<e0>": 167
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39495",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black cat touching a sports ball in a room."
            }
        ],
        "meta": {
            "split": [
                932,
                1136
            ],
            "duration": 205,
            "token": {
                "<s0>": 18,
                "<e0>": 184
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39496",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black cat touching a sports ball in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1136,
                1259
            ],
            "duration": 124,
            "token": {
                "<s0>": 21,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39497",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black cat touching a sports ball in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1259,
                1489
            ],
            "duration": 231,
            "token": {
                "<s0>": 63,
                "<e0>": 177
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2958836509",
        "aid": "2958836509_39498",
        "original_caption": "there is a black cat touching a sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black cat touching a sports ball in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1489,
                1647
            ],
            "duration": 159,
            "token": {
                "<s0>": 53,
                "<e0>": 159
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_39499",
        "original_caption": "a child is above another child in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is above another child in the playground."
            }
        ],
        "meta": {
            "split": [
                219,
                518
            ],
            "duration": 300,
            "token": {
                "<s0>": 44,
                "<e0>": 230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_39500",
        "original_caption": "a baby in pink holds hand of an adult woman in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in pink holds hand of an adult woman in white."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 605,
                "<e0>": 874
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_39501",
        "original_caption": "there is a cellphone above a toy inside car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the toy inside car from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1620,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39502",
        "original_caption": "an adult in pale purple holds a white ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pale purple holds a white ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                133
            ],
            "duration": 134,
            "token": {
                "<s0>": 29,
                "<e0>": 101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39503",
        "original_caption": "an adult in pale purple holds a white ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pale purple holds a white ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                133,
                236
            ],
            "duration": 104,
            "token": {
                "<s0>": 32,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39504",
        "original_caption": "an adult in pale purple holds a white ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in pale purple holds a white ball."
            }
        ],
        "meta": {
            "split": [
                236,
                693
            ],
            "duration": 458,
            "token": {
                "<s0>": 45,
                "<e0>": 218
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39505",
        "original_caption": "an adult in pale purple holds a white ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pale purple holds a white ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                955,
                1085
            ],
            "duration": 131,
            "token": {
                "<s0>": 10,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39506",
        "original_caption": "an adult in pale purple holds a white ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pale purple holds a white ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1085,
                1205
            ],
            "duration": 121,
            "token": {
                "<s0>": 52,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39507",
        "original_caption": "an adult in pale purple holds a white ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the white ball from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1205,
                1336
            ],
            "duration": 132,
            "token": {
                "<s0>": 17,
                "<e0>": 38
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3763213054",
        "aid": "3763213054_39508",
        "original_caption": "an adult in a shirt plays the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in a shirt plays the guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1052
            ],
            "duration": 1053,
            "token": {
                "<s0>": 0,
                "<e0>": 1053
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_39509",
        "original_caption": "there is a long and big cat biting a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a long and big cat biting a brown cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                392
            ],
            "duration": 393,
            "token": {
                "<s0>": 347,
                "<e0>": 371
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_39510",
        "original_caption": "there is a long and big cat biting a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a long and big cat biting a brown cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                392,
                923
            ],
            "duration": 532,
            "token": {
                "<s0>": 22,
                "<e0>": 50
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4322158071",
        "aid": "4322158071_39511",
        "original_caption": "an adult is towards another adult in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards another adult in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                314
            ],
            "duration": 315,
            "token": {
                "<s0>": 0,
                "<e0>": 315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_39512",
        "original_caption": "a child in red pulls another child in blue in a hotal.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red pulls another child in blue in a hotal."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 6,
                "<e0>": 28
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5293233413",
        "aid": "5293233413_39513",
        "original_caption": "there is a dog leaning on an adult on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog leaning on an adult on the sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                211
            ],
            "duration": 212,
            "token": {
                "<s0>": 0,
                "<e0>": 115
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5293233413",
        "aid": "5293233413_39514",
        "original_caption": "there is a dog leaning on an adult on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dog leaning on an adult on the sofa."
            }
        ],
        "meta": {
            "split": [
                211,
                662
            ],
            "duration": 452,
            "token": {
                "<s0>": 97,
                "<e0>": 452
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39515",
        "original_caption": "there is a sports ball towards another sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sports ball towards another sports ball in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 25,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9345245716",
        "aid": "9345245716_39516",
        "original_caption": "an adult in blue clothes carries a backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes carries a backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                485
            ],
            "duration": 486,
            "token": {
                "<s0>": 219,
                "<e0>": 425
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2492711005",
        "aid": "2492711005_39517",
        "original_caption": "a baby leans on an adult in living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on an adult in living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1111
            ],
            "duration": 1112,
            "token": {
                "<s0>": 0,
                "<e0>": 1112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_39518",
        "original_caption": "there is a crocodile next to another crocodile in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a crocodile next to another crocodile in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 80,
                "<e0>": 599
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4866672246",
        "aid": "4866672246_39519",
        "original_caption": "a small dog is towards the big dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A small dog is towards the big dog."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 1080,
                "<e0>": 1170
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3924748616",
        "aid": "3924748616_39520",
        "original_caption": "there is a skateboard beneath an adult in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the skateboard in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                153,
                255
            ],
            "duration": 103,
            "token": {
                "<s0>": 5,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2538515654",
        "aid": "2538515654_39521",
        "original_caption": "a surfing adult man is watching an adult man.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a surfing adult man is watching an adult man happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                217,
                452
            ],
            "duration": 236,
            "token": {
                "<s0>": 207,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_39522",
        "original_caption": "a child in blue clothes is above a ski.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the ski from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                647
            ],
            "duration": 648,
            "token": {
                "<s0>": 447,
                "<e0>": 647
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13486822104",
        "aid": "13486822104_39523",
        "original_caption": "there is a brown bird above a gray bird on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bird from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown bird above a gray bird on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                688
            ],
            "duration": 689,
            "token": {
                "<s0>": 100,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_39524",
        "original_caption": "there is a chair beneath a child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a chair beneath a child in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_39525",
        "original_caption": "a child in white is in front of another child boy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white is in front of another child boy on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 43,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4656902106",
        "aid": "4656902106_39526",
        "original_caption": "an adult holds a ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a ball on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                98
            ],
            "duration": 99,
            "token": {
                "<s0>": 0,
                "<e0>": 29
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6782047586",
        "aid": "6782047586_39527",
        "original_caption": "an adult woman in black points to a screen in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black points to a screen in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1707
            ],
            "duration": 1708,
            "token": {
                "<s0>": 236,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_39528",
        "original_caption": "an adult wearing a black hat lifts a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a black hat lifts a cup."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 521,
                "<e0>": 578
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953995558",
        "aid": "6953995558_39529",
        "original_caption": "there is a table behind a girl child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table behind a girl child in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 1020,
                "<e0>": 1080
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_39530",
        "original_caption": "a child on the left is above another child on the right.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child on the left is above another child on the right."
            }
        ],
        "meta": {
            "split": [
                219,
                518
            ],
            "duration": 300,
            "token": {
                "<s0>": 44,
                "<e0>": 230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39531",
        "original_caption": "there is a sofa next to an adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sofa next to an adult inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                474
            ],
            "duration": 475,
            "token": {
                "<s0>": 247,
                "<e0>": 474
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11264199933",
        "aid": "11264199933_39532",
        "original_caption": "the adult in blue is using the cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in blue is using the cellphone happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                488
            ],
            "duration": 489,
            "token": {
                "<s0>": 14,
                "<e0>": 179
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2955299637",
        "aid": "2955299637_39533",
        "original_caption": "an adult is above a horse on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a horse on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                629
            ],
            "duration": 630,
            "token": {
                "<s0>": 58,
                "<e0>": 574
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3249035877",
        "aid": "3249035877_39534",
        "original_caption": "there is a penguin in front of another penguin in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a penguin in front of another penguin in the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                529,
                821
            ],
            "duration": 293,
            "token": {
                "<s0>": 105,
                "<e0>": 286
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_39535",
        "original_caption": "a baby in purple is next to a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in purple is next to a child in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 183,
                "<e0>": 240
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_39536",
        "original_caption": "a child is next to an adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is next to an adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 605,
                "<e0>": 869
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_39537",
        "original_caption": "the adult with jeans is in front of the adult with white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult with jeans is in front of the adult with white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1788
            ],
            "duration": 1789,
            "token": {
                "<s0>": 180,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_39538",
        "original_caption": "there is a cup above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cup from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 0,
                "<e0>": 72
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_39539",
        "original_caption": "an adult man is away a monitor in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man is away a monitor in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 1320,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7528671560",
        "aid": "7528671560_39540",
        "original_caption": "a child wearing a blue hat is above a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing a blue hat is above a bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                539
            ],
            "duration": 540,
            "token": {
                "<s0>": 0,
                "<e0>": 540
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39541",
        "original_caption": "there is a ball above a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a ball above a toy inside a room."
            }
        ],
        "meta": {
            "split": [
                510,
                2696
            ],
            "duration": 2187,
            "token": {
                "<s0>": 11,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5082198541",
        "aid": "5082198541_39542",
        "original_caption": "a baby with blond-hair kisses a toy on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho kisses the toy on the carpet from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                2144
            ],
            "duration": 2145,
            "token": {
                "<s0>": 2036,
                "<e0>": 2116
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_39543",
        "original_caption": "an adult is behind another adult on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                818
            ],
            "duration": 819,
            "token": {
                "<s0>": 23,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39544",
        "original_caption": "there is a brown sofa behind a black cellphone at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown sofa behind a black cellphone at party."
            }
        ],
        "meta": {
            "split": [
                876,
                1441
            ],
            "duration": 566,
            "token": {
                "<s0>": 84,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_39545",
        "original_caption": "an adult in blue is next to a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the sofa in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 0,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_39546",
        "original_caption": "there is a black sofa beneath a child in white at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black sofa beneath a child in white at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1062,
                1818
            ],
            "duration": 757,
            "token": {
                "<s0>": 138,
                "<e0>": 263
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11841865713",
        "aid": "11841865713_39547",
        "original_caption": "a baby in white leans on an adult in yellow in the clinic.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white leans on an adult in yellow in the clinic."
            }
        ],
        "meta": {
            "split": [
                0,
                674
            ],
            "duration": 675,
            "token": {
                "<s0>": 1,
                "<e0>": 675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39548",
        "original_caption": "an adult woman in gray plays a black guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray plays a black guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                110
            ],
            "duration": 111,
            "token": {
                "<s0>": 0,
                "<e0>": 76
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39549",
        "original_caption": "an adult woman in gray plays a black guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray plays a black guitar."
            }
        ],
        "meta": {
            "split": [
                110,
                330
            ],
            "duration": 221,
            "token": {
                "<s0>": 35,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39550",
        "original_caption": "an adult woman in gray plays a black guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in gray plays a black guitar."
            }
        ],
        "meta": {
            "split": [
                330,
                611
            ],
            "duration": 282,
            "token": {
                "<s0>": 156,
                "<e0>": 282
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9196423005",
        "aid": "9196423005_39551",
        "original_caption": "a baby is above an adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby is above an adult in the living room."
            }
        ],
        "meta": {
            "split": [
                0,
                760
            ],
            "duration": 761,
            "token": {
                "<s0>": 720,
                "<e0>": 761
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_39552",
        "original_caption": "a child in pink is towards a laptop with the screen off.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink is towards a laptop with the screen off."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 500,
                "<e0>": 675
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3374974398",
        "aid": "3374974398_39553",
        "original_caption": "there is a snowboard beneath an adult in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a snowboard beneath an adult in the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                292
            ],
            "duration": 293,
            "token": {
                "<s0>": 164,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3520546318",
        "aid": "3520546318_39554",
        "original_caption": "an adult hugs a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult hugs a baby inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                207
            ],
            "duration": 208,
            "token": {
                "<s0>": 0,
                "<e0>": 207
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3190385624",
        "aid": "3190385624_39555",
        "original_caption": "there is a red table beneath a colorful toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the colorful toy in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                1460
            ],
            "duration": 1461,
            "token": {
                "<s0>": 1232,
                "<e0>": 1460
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39556",
        "original_caption": "an adult is towards a bottle in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult towards to in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 480,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_39557",
        "original_caption": "there is a beige table beneath a colorful cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a beige table beneath a colorful cake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                433,
                979
            ],
            "duration": 547,
            "token": {
                "<s0>": 131,
                "<e0>": 295
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5783801873",
        "aid": "5783801873_39558",
        "original_caption": "an adult man in black drives a motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black drives a motorcycle."
            }
        ],
        "meta": {
            "split": [
                0,
                844
            ],
            "duration": 845,
            "token": {
                "<s0>": 161,
                "<e0>": 720
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39559",
        "original_caption": "an adult lifts another adult in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult lifts another adult in a bar."
            }
        ],
        "meta": {
            "split": [
                0,
                1011
            ],
            "duration": 1012,
            "token": {
                "<s0>": 882,
                "<e0>": 917
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8429686679",
        "aid": "8429686679_39560",
        "original_caption": "an adult is away from another adult on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                1573
            ],
            "duration": 1574,
            "token": {
                "<s0>": 26,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39561",
        "original_caption": "an adult in red clothes releases a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red clothes releases a cake."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 257,
                "<e0>": 397
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4524702622",
        "aid": "4524702622_39562",
        "original_caption": "there is a blue chair next to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the child from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                254,
                1098
            ],
            "duration": 845,
            "token": {
                "<s0>": 46,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5504745801",
        "aid": "5504745801_39563",
        "original_caption": "there is a black ski beneath a child in pale purple.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black ski beneath a child in pale purple happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                203
            ],
            "duration": 204,
            "token": {
                "<s0>": 0,
                "<e0>": 204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39564",
        "original_caption": "an adult man in white is towards another adult man in black in the bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in white is towards another adult man in black in the bar."
            }
        ],
        "meta": {
            "split": [
                465,
                1011
            ],
            "duration": 547,
            "token": {
                "<s0>": 195,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047707188",
        "aid": "6047707188_39565",
        "original_caption": "an adult on the right watches an another adult on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult on the right watches an another adult on the left."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 52,
                "<e0>": 56
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39566",
        "original_caption": "there is a table towards an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table towards an adult at home."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5270774640",
        "aid": "5270774640_39567",
        "original_caption": "an adult in black clothes hugs a dog on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes hugs a dog on the left happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                222
            ],
            "duration": 223,
            "token": {
                "<s0>": 0,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4717834858",
        "aid": "4717834858_39568",
        "original_caption": "a baby with blond-hair is inside a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby with blond-hair is inside a baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                213
            ],
            "duration": 214,
            "token": {
                "<s0>": 0,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11566933123",
        "aid": "11566933123_39569",
        "original_caption": "a child in green watches a toy at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in green watches a toy at home."
            }
        ],
        "meta": {
            "split": [
                410,
                867
            ],
            "duration": 458,
            "token": {
                "<s0>": 34,
                "<e0>": 458
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7162478518",
        "aid": "7162478518_39570",
        "original_caption": "an adult in black plays the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black plays the guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                610
            ],
            "duration": 611,
            "token": {
                "<s0>": 0,
                "<e0>": 611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_39571",
        "original_caption": "an adult is in front of a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is in front of a toy."
            }
        ],
        "meta": {
            "split": [
                1060,
                2696
            ],
            "duration": 1637,
            "token": {
                "<s0>": 20,
                "<e0>": 76
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3150999885",
        "aid": "3150999885_39572",
        "original_caption": "there is a screen behind an adult in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the screen/monitor from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a screen behind an adult in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1770
            ],
            "duration": 1771,
            "token": {
                "<s0>": 0,
                "<e0>": 1770
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_39573",
        "original_caption": "an adult is away a child in the middle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away a child in the middle at home."
            }
        ],
        "meta": {
            "split": [
                517,
                1079
            ],
            "duration": 563,
            "token": {
                "<s0>": 443,
                "<e0>": 533
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39574",
        "original_caption": "there is a table beneath a cake inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a cake inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_39575",
        "original_caption": "there is a toy behind a baby in orange on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the toy on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 314,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9105762820",
        "aid": "9105762820_39576",
        "original_caption": "there is a sofa beneath an adult in green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2698
            ],
            "duration": 2699,
            "token": {
                "<s0>": 0,
                "<e0>": 2699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_39577",
        "original_caption": "an adult in blue hugs a baby in the washroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue hugs a baby in the washroom."
            }
        ],
        "meta": {
            "split": [
                0,
                813
            ],
            "duration": 814,
            "token": {
                "<s0>": 0,
                "<e0>": 793
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_39578",
        "original_caption": "an adult in blue hugs a baby in the washroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue hugs a baby in the washroom."
            }
        ],
        "meta": {
            "split": [
                813,
                915
            ],
            "duration": 103,
            "token": {
                "<s0>": 21,
                "<e0>": 102
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_39579",
        "original_caption": "an adult is above a watercraft on the fucking water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is above a watercraft on the fucking water."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1136
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4485229025",
        "aid": "4485229025_39580",
        "original_caption": "there is a dog behind another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog behind another dog on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1173,
                2018
            ],
            "duration": 846,
            "token": {
                "<s0>": 207,
                "<e0>": 417
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3471851958",
        "aid": "3471851958_39581",
        "original_caption": "an adult in white clothes is next to a motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the motorcycle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                179
            ],
            "duration": 180,
            "token": {
                "<s0>": 0,
                "<e0>": 180
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39582",
        "original_caption": "a child is towards a ball inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is towards a ball inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 360,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_39583",
        "original_caption": "an adult is above a watercraft on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is above a watercraft on the river."
            }
        ],
        "meta": {
            "split": [
                120,
                458
            ],
            "duration": 339,
            "token": {
                "<s0>": 30,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39584",
        "original_caption": "a baby leans on an adult on a grey sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult on a grey sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                279
            ],
            "duration": 280,
            "token": {
                "<s0>": 0,
                "<e0>": 258
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39585",
        "original_caption": "a baby leans on an adult on a grey sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby leans on an adult on a grey sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                279,
                474
            ],
            "duration": 196,
            "token": {
                "<s0>": 22,
                "<e0>": 196
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39586",
        "original_caption": "an adult is away from a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away from a cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 360,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_39587",
        "original_caption": "a child is above another child girl on the slide.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is above another child girl on the slide happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                218,
                518
            ],
            "duration": 301,
            "token": {
                "<s0>": 33,
                "<e0>": 231
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3004044251",
        "aid": "3004044251_39588",
        "original_caption": "an adult in black kisses a child in the bathroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black kisses a child in the bathroom."
            }
        ],
        "meta": {
            "split": [
                0,
                663
            ],
            "duration": 664,
            "token": {
                "<s0>": 315,
                "<e0>": 332
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5091773135",
        "aid": "5091773135_39589",
        "original_caption": "an adult with glasses carries the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses carries the guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1770
            ],
            "duration": 1771,
            "token": {
                "<s0>": 1288,
                "<e0>": 1771
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11018431523",
        "aid": "11018431523_39590",
        "original_caption": "there is a bicycle beneath a child in blue on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bicycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bicycle beneath a child in blue on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                591
            ],
            "duration": 592,
            "token": {
                "<s0>": 0,
                "<e0>": 592
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8542940315",
        "aid": "8542940315_39591",
        "original_caption": "an adult squeezes a dog on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult squeeze on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                172
            ],
            "duration": 173,
            "token": {
                "<s0>": 61,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8542940315",
        "aid": "8542940315_39592",
        "original_caption": "an adult squeezes a dog on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult squeezes a dog on the floor."
            }
        ],
        "meta": {
            "split": [
                172,
                387
            ],
            "duration": 216,
            "token": {
                "<s0>": 27,
                "<e0>": 74
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8542940315",
        "aid": "8542940315_39593",
        "original_caption": "an adult squeezes a dog on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult squeezes a dog on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                387,
                622
            ],
            "duration": 236,
            "token": {
                "<s0>": 141,
                "<e0>": 164
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3743036769",
        "aid": "3743036769_39594",
        "original_caption": "there is a sink beneath a faucet inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sink beneath a faucet inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                821,
                915
            ],
            "duration": 95,
            "token": {
                "<s0>": 45,
                "<e0>": 94
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_39595",
        "original_caption": "there is a gray dog towards a red bottle in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the gray dog towards to in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                645,
                1469
            ],
            "duration": 825,
            "token": {
                "<s0>": 315,
                "<e0>": 405
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5399895838",
        "aid": "5399895838_39596",
        "original_caption": "there is a table beneath a white cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table beneath a white cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1048
            ],
            "duration": 1049,
            "token": {
                "<s0>": 0,
                "<e0>": 857
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10250170546",
        "aid": "10250170546_39597",
        "original_caption": "an adult holds hand of a child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of a child in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                393
            ],
            "duration": 394,
            "token": {
                "<s0>": 247,
                "<e0>": 338
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_39598",
        "original_caption": "an adult is away from a child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away from a child inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1063
            ],
            "duration": 1064,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6262219324",
        "aid": "6262219324_39599",
        "original_caption": "an adult in white is in front of a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white is in front of a baby at home."
            }
        ],
        "meta": {
            "split": [
                0,
                299
            ],
            "duration": 300,
            "token": {
                "<s0>": 0,
                "<e0>": 300
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39600",
        "original_caption": "a child is towards an adult in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is towards an adult in the playground."
            }
        ],
        "meta": {
            "split": [
                333,
                411
            ],
            "duration": 79,
            "token": {
                "<s0>": 2,
                "<e0>": 15
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8616874413",
        "aid": "8616874413_39601",
        "original_caption": "the adult with hat is holding the camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is holding the camera from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3811600452",
        "aid": "3811600452_39602",
        "original_caption": "there is a cat behind another cat on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cat behind another cat on the bed."
            }
        ],
        "meta": {
            "split": [
                1585,
                2157
            ],
            "duration": 573,
            "token": {
                "<s0>": 479,
                "<e0>": 551
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6501432541",
        "aid": "6501432541_39603",
        "original_caption": "a child wearing a black hat leans on a sink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child wearing a black hat leans on a sink."
            }
        ],
        "meta": {
            "split": [
                0,
                173
            ],
            "duration": 174,
            "token": {
                "<s0>": 0,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3271408229",
        "aid": "3271408229_39604",
        "original_caption": "an adult in green clothes is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green clothes is above a sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                334
            ],
            "duration": 335,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_39605",
        "original_caption": "there is a snowboard in front of an adult on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a snowboard in front of an adult on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 186,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_39606",
        "original_caption": "an adult speaks to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult speaks to a child at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1063
            ],
            "duration": 1064,
            "token": {
                "<s0>": 795,
                "<e0>": 953
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39607",
        "original_caption": "a child is away from a toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from a toy in the room."
            }
        ],
        "meta": {
            "split": [
                443,
                1314
            ],
            "duration": 872,
            "token": {
                "<s0>": 8,
                "<e0>": 85
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3849812732",
        "aid": "3849812732_39608",
        "original_caption": "an adult in black plays the guitar outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black plays the guitar outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                184
            ],
            "duration": 185,
            "token": {
                "<s0>": 0,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3849812732",
        "aid": "3849812732_39609",
        "original_caption": "an adult in black plays the guitar outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho plays the guitar outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                184,
                611
            ],
            "duration": 428,
            "token": {
                "<s0>": 38,
                "<e0>": 428
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_39610",
        "original_caption": "the adult whith blue helmet is above the watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult whith blue helmet is above the watercraft happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3708144633",
        "aid": "3708144633_39611",
        "original_caption": "there is a white car behind a white dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white car behind a white dog."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 1610,
                "<e0>": 1847
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39612",
        "original_caption": "a child with black-hair leans on an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with black-hair leans on an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_39613",
        "original_caption": "there is a table beneath a bottle in the dining room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the bottle in the dining room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 61,
                "<e0>": 780
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10022946583",
        "aid": "10022946583_39614",
        "original_caption": "a child in blue watches a monitor at the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue watches a monitor at the table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                117,
                299
            ],
            "duration": 183,
            "token": {
                "<s0>": 7,
                "<e0>": 142
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2400031830",
        "aid": "2400031830_39615",
        "original_caption": "an adult in black touches a baby with blond hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black touches a baby with blond hair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                146
            ],
            "duration": 147,
            "token": {
                "<s0>": 100,
                "<e0>": 117
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_39616",
        "original_caption": "there is a sofa beneath an adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sofa beneath an adult inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                245
            ],
            "duration": 246,
            "token": {
                "<s0>": 96,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_39617",
        "original_caption": "an adult is beneath another adult in the cave.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is beneath another adult in the cave."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 600,
                "<e0>": 736
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_39618",
        "original_caption": "there is a white dish in front of an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dish from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a white dish in front of an adult at home."
            }
        ],
        "meta": {
            "split": [
                1140,
                1470
            ],
            "duration": 331,
            "token": {
                "<s0>": 34,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379879696",
        "aid": "5379879696_39619",
        "original_caption": "an adult rides a ski on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a ski on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                359
            ],
            "duration": 360,
            "token": {
                "<s0>": 98,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4154183202",
        "aid": "4154183202_39620",
        "original_caption": "a child in red clothes presses a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes presses a yellow toy."
            }
        ],
        "meta": {
            "split": [
                0,
                541
            ],
            "duration": 542,
            "token": {
                "<s0>": 84,
                "<e0>": 437
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4154183202",
        "aid": "4154183202_39621",
        "original_caption": "a child in red clothes presses a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes presses a yellow toy."
            }
        ],
        "meta": {
            "split": [
                541,
                782
            ],
            "duration": 242,
            "token": {
                "<s0>": 105,
                "<e0>": 242
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39622",
        "original_caption": "a child in blue is away from a sofa at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue is away from a sofa at party."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 240,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_39623",
        "original_caption": "there is a toy away from another toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy away from another toy on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 700,
                "<e0>": 743
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_39624",
        "original_caption": "there is an apple laptop above a brown table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is an apple laptop above a brown table."
            }
        ],
        "meta": {
            "split": [
                0,
                1271
            ],
            "duration": 1272,
            "token": {
                "<s0>": 890,
                "<e0>": 997
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39625",
        "original_caption": "there is a chair beneath a child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the chair from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a chair beneath a child inside a room."
            }
        ],
        "meta": {
            "split": [
                84,
                872
            ],
            "duration": 789,
            "token": {
                "<s0>": 36,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2422958285",
        "aid": "2422958285_39626",
        "original_caption": "an adult in grey is behind a sofa at office.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the sofa at office from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                186,
                456
            ],
            "duration": 271,
            "token": {
                "<s0>": 54,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3058094185",
        "aid": "3058094185_39627",
        "original_caption": "a child with brown-hair is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with brown-hair is above a sofa."
            }
        ],
        "meta": {
            "split": [
                1145,
                1458
            ],
            "duration": 314,
            "token": {
                "<s0>": 113,
                "<e0>": 313
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_39628",
        "original_caption": "an adult man in black carries a purple backpack outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black carries a purple backpack outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 612,
                "<e0>": 716
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39629",
        "original_caption": "there is a gray rat above a gray rat on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray rat above a gray rat on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1140,
                "<e0>": 1194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39630",
        "original_caption": "there is a table beneath a bottle at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table beneath a bottle at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 30,
                "<e0>": 492
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5048454031",
        "aid": "5048454031_39631",
        "original_caption": "there is a hemp bird next to a hemp bird outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the hemp bird outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bird."
            }
        ],
        "meta": {
            "split": [
                0,
                659
            ],
            "duration": 660,
            "token": {
                "<s0>": 24,
                "<e0>": 659
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_39632",
        "original_caption": "a baby in white is lifting the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in white is lifting the toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                615
            ],
            "duration": 616,
            "token": {
                "<s0>": 494,
                "<e0>": 563
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_39633",
        "original_caption": "a baby in white is lifting the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is lifting the toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                615,
                794
            ],
            "duration": 180,
            "token": {
                "<s0>": 53,
                "<e0>": 152
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_39634",
        "original_caption": "a baby in white is lifting the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in white is lifting the toy."
            }
        ],
        "meta": {
            "split": [
                794,
                998
            ],
            "duration": 205,
            "token": {
                "<s0>": 27,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3145413102",
        "aid": "3145413102_39635",
        "original_caption": "an adult is next to a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is next to a bottle in the living room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                444,
                775
            ],
            "duration": 332,
            "token": {
                "<s0>": 276,
                "<e0>": 332
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4142450052",
        "aid": "4142450052_39636",
        "original_caption": "there is a golden yellow dog next to a red frisbee.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a golden yellow dog next to a red frisbee happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                503
            ],
            "duration": 504,
            "token": {
                "<s0>": 0,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39637",
        "original_caption": "a child is behind another child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                333,
                411
            ],
            "duration": 79,
            "token": {
                "<s0>": 2,
                "<e0>": 26
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_39638",
        "original_caption": "a leftmost adult is above a yellow watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the leftmost adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1081
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3315181459",
        "aid": "3315181459_39639",
        "original_caption": "an adult woman in black shakes hand with another adult man in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black shakes hand with another adult man in white."
            }
        ],
        "meta": {
            "split": [
                0,
                694
            ],
            "duration": 695,
            "token": {
                "<s0>": 652,
                "<e0>": 695
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39640",
        "original_caption": "there is a brown sofa beneath a child in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a brown sofa beneath a child in blue happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1158,
                1441
            ],
            "duration": 284,
            "token": {
                "<s0>": 96,
                "<e0>": 161
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_39641",
        "original_caption": "there is a yellow cup above a brown table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a yellow cup above a brown table at home."
            }
        ],
        "meta": {
            "split": [
                1632,
                2225
            ],
            "duration": 594,
            "token": {
                "<s0>": 528,
                "<e0>": 594
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_39642",
        "original_caption": "there is an old adult woman above a dark red chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above a chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1145
            ],
            "duration": 1146,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_39643",
        "original_caption": "an adult with glasses caresses a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with glasses caresses a brown cat."
            }
        ],
        "meta": {
            "split": [
                0,
                571
            ],
            "duration": 572,
            "token": {
                "<s0>": 387,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_39644",
        "original_caption": "an adult with glasses caresses a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult with glasses caresses a brown cat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                571,
                885
            ],
            "duration": 315,
            "token": {
                "<s0>": 8,
                "<e0>": 275
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_39645",
        "original_caption": "an adult with glasses caresses a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with glasses caresses a brown cat."
            }
        ],
        "meta": {
            "split": [
                885,
                1238
            ],
            "duration": 354,
            "token": {
                "<s0>": 39,
                "<e0>": 152
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_39646",
        "original_caption": "a child in white is above a brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the brown sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1062,
                1818
            ],
            "duration": 757,
            "token": {
                "<s0>": 88,
                "<e0>": 263
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10626519064",
        "aid": "10626519064_39647",
        "original_caption": "a child wearing white shoes is behind a silver car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child wearing white shoes is behind a silver car."
            }
        ],
        "meta": {
            "split": [
                1327,
                1709
            ],
            "duration": 383,
            "token": {
                "<s0>": 17,
                "<e0>": 107
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6068085283",
        "aid": "6068085283_39648",
        "original_caption": "a baby in red leans on an adult in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in red leans on an adult in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                1112
            ],
            "duration": 1113,
            "token": {
                "<s0>": 0,
                "<e0>": 1003
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6068085283",
        "aid": "6068085283_39649",
        "original_caption": "a baby in red leans on an adult in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in red leans on an adult in the forest."
            }
        ],
        "meta": {
            "split": [
                1112,
                1781
            ],
            "duration": 670,
            "token": {
                "<s0>": 110,
                "<e0>": 670
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_39650",
        "original_caption": "a baby in diaper holds a blue and black toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the blue and black toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 0,
                "<e0>": 162
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_39651",
        "original_caption": "a baby in diaper holds a blue and black toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in diaper holds a blue and black toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                735,
                1609
            ],
            "duration": 875,
            "token": {
                "<s0>": 574,
                "<e0>": 732
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_39652",
        "original_caption": "a baby in diaper holds a blue and black toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in diaper holds a blue and black toy."
            }
        ],
        "meta": {
            "split": [
                1609,
                2174
            ],
            "duration": 566,
            "token": {
                "<s0>": 142,
                "<e0>": 375
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_39653",
        "original_caption": "a baby in diaper holds a blue and black toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in diaper holds a blue and black toy."
            }
        ],
        "meta": {
            "split": [
                2174,
                2696
            ],
            "duration": 523,
            "token": {
                "<s0>": 190,
                "<e0>": 507
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_39654",
        "original_caption": "a child waves hand to a baby next to the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child waves hand to a baby next to the table."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 497,
                "<e0>": 526
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_39655",
        "original_caption": "an adult in black leans on a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black leans on a chair in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 0,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_39656",
        "original_caption": "there is a white and black dog towards a grey dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white and black dog towards a grey dog."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 200,
                "<e0>": 275
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6728626829",
        "aid": "6728626829_39657",
        "original_caption": "an adult in white is above a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the snowboard in the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                460,
                818
            ],
            "duration": 359,
            "token": {
                "<s0>": 161,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5310031663",
        "aid": "5310031663_39658",
        "original_caption": "an adult grabs a cup in a restaurant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult grabs a cup in a restaurant happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 384,
                "<e0>": 406
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3862213653",
        "aid": "3862213653_39659",
        "original_caption": "an adult in blue clothes is above a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue clothes is above a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                275
            ],
            "duration": 276,
            "token": {
                "<s0>": 0,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11432719626",
        "aid": "11432719626_39660",
        "original_caption": "a child in red holds a yellow cup at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red holds a yellow cup at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                110
            ],
            "duration": 111,
            "token": {
                "<s0>": 11,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11432719626",
        "aid": "11432719626_39661",
        "original_caption": "a child in red holds a yellow cup at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red holds a yellow cup at home."
            }
        ],
        "meta": {
            "split": [
                178,
                572
            ],
            "duration": 395,
            "token": {
                "<s0>": 20,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7040233679",
        "aid": "7040233679_39662",
        "original_caption": "an adult holds a cellphone inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a cellphone inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 458,
                "<e0>": 609
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7040233679",
        "aid": "7040233679_39663",
        "original_caption": "an adult holds a cellphone inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a cellphone inside a room."
            }
        ],
        "meta": {
            "split": [
                681,
                909
            ],
            "duration": 229,
            "token": {
                "<s0>": 72,
                "<e0>": 186
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8608466102",
        "aid": "8608466102_39664",
        "original_caption": "a child wearing striped shirt rides a red bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho rides the red bicycle from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                371
            ],
            "duration": 372,
            "token": {
                "<s0>": 94,
                "<e0>": 372
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11432719626",
        "aid": "11432719626_39665",
        "original_caption": "a child in red clothes holds a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes holds a cup."
            }
        ],
        "meta": {
            "split": [
                0,
                572
            ],
            "duration": 573,
            "token": {
                "<s0>": 6,
                "<e0>": 131
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_39666",
        "original_caption": "an adult in white is in front of an adult in brown in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult in brown in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5195700916",
        "aid": "5195700916_39667",
        "original_caption": "an adult woman in white watches another adult man in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in white watches another adult man in pink."
            }
        ],
        "meta": {
            "split": [
                455,
                1805
            ],
            "duration": 1351,
            "token": {
                "<s0>": 222,
                "<e0>": 249
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4827728106",
        "aid": "4827728106_39668",
        "original_caption": "a child in gray grabs a khaki toy in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in gray grab in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                235
            ],
            "duration": 236,
            "token": {
                "<s0>": 48,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6598464203",
        "aid": "6598464203_39669",
        "original_caption": "there is a cat on the right above another cat on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the cat on the right from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                1462,
                2249
            ],
            "duration": 788,
            "token": {
                "<s0>": 238,
                "<e0>": 363
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39670",
        "original_caption": "there is a bottle towards a white cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a bottle towards a white cake."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 480,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39671",
        "original_caption": "a child in black clothes is towards an adult wearing white pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in black clothes is towards an adult wearing white pants."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1110,
                "<e0>": 1229
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2953174101",
        "aid": "2953174101_39672",
        "original_caption": "a baby leans on an adult on the flor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult on the flor."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 106,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2588643984",
        "aid": "2588643984_39673",
        "original_caption": "an adult on the right is towards to an adult on the left outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult on the right is towards to an adult on the left outdoor."
            }
        ],
        "meta": {
            "split": [
                0,
                239
            ],
            "duration": 240,
            "token": {
                "<s0>": 182,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5258789985",
        "aid": "5258789985_39674",
        "original_caption": "an adult wearing black masks is behind another adult wearing a red hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing black masks is behind another adult wearing a red hat."
            }
        ],
        "meta": {
            "split": [
                366,
                544
            ],
            "duration": 179,
            "token": {
                "<s0>": 19,
                "<e0>": 148
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_39675",
        "original_caption": "there is a motorcycle behind a bicycle in the evening.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the motorcycle in the evening from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bicycle."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 120,
                "<e0>": 295
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39676",
        "original_caption": "there is a cat towards an adult beside the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the cat towards to beside the river from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1270,
                "<e0>": 1469
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8670554760",
        "aid": "8670554760_39677",
        "original_caption": "an adult holds a bat in the contest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a bat in the contest."
            }
        ],
        "meta": {
            "split": [
                0,
                132
            ],
            "duration": 133,
            "token": {
                "<s0>": 43,
                "<e0>": 77
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8670554760",
        "aid": "8670554760_39678",
        "original_caption": "an adult holds a bat in the contest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult hold in the contest from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bat."
            }
        ],
        "meta": {
            "split": [
                132,
                331
            ],
            "duration": 200,
            "token": {
                "<s0>": 56,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39679",
        "original_caption": "an adult wearing a black hat is in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a black hat is in front of a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 288,
                "<e0>": 348
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8470950730",
        "aid": "8470950730_39680",
        "original_caption": "there is a long wooden bench beneath an adult woman in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult woman in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bench."
            }
        ],
        "meta": {
            "split": [
                0,
                1323
            ],
            "duration": 1324,
            "token": {
                "<s0>": 720,
                "<e0>": 1224
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_39681",
        "original_caption": "a child in green watches a black laptop in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in green watches a black laptop in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 0,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_39682",
        "original_caption": "an adult in green is above a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green is above a sofa at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                245
            ],
            "duration": 246,
            "token": {
                "<s0>": 96,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39683",
        "original_caption": "an adult with glasses is next to a rightmost adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with glasses is next to a rightmost adult."
            }
        ],
        "meta": {
            "split": [
                0,
                611
            ],
            "duration": 612,
            "token": {
                "<s0>": 480,
                "<e0>": 542
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_39684",
        "original_caption": "there is a cake in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cake in front of an adult."
            }
        ],
        "meta": {
            "split": [
                344,
                1047
            ],
            "duration": 704,
            "token": {
                "<s0>": 196,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2642700076",
        "aid": "2642700076_39685",
        "original_caption": "there is a surfboard beneath an adult wearing red pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a surfboard beneath an adult wearing red pants."
            }
        ],
        "meta": {
            "split": [
                100,
                554
            ],
            "duration": 455,
            "token": {
                "<s0>": 20,
                "<e0>": 455
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_39686",
        "original_caption": "an adult is above a watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the watercraft on the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6997433070",
        "aid": "6997433070_39687",
        "original_caption": "a child in red is away another child in yellow in yard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red is away another child in yellow in yard."
            }
        ],
        "meta": {
            "split": [
                0,
                113
            ],
            "duration": 114,
            "token": {
                "<s0>": 0,
                "<e0>": 95
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39688",
        "original_caption": "an adult woman in red is next to a child in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in red is next to a child in pink happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1800,
                "<e0>": 1890
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_39689",
        "original_caption": "an adult plays a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult play on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1293
            ],
            "duration": 1294,
            "token": {
                "<s0>": 0,
                "<e0>": 1271
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4573056419",
        "aid": "4573056419_39690",
        "original_caption": "an adult plays a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult plays a guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                1293,
                1788
            ],
            "duration": 496,
            "token": {
                "<s0>": 23,
                "<e0>": 496
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39691",
        "original_caption": "an adult man in white hugs another adult in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white hugs another adult in a bar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                353
            ],
            "duration": 354,
            "token": {
                "<s0>": 0,
                "<e0>": 328
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39692",
        "original_caption": "an adult man in white hugs another adult in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white hugs another adult in a bar."
            }
        ],
        "meta": {
            "split": [
                353,
                483
            ],
            "duration": 131,
            "token": {
                "<s0>": 25,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39693",
        "original_caption": "an adult man in white hugs another adult in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white hugs another adult in a bar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                483,
                642
            ],
            "duration": 160,
            "token": {
                "<s0>": 24,
                "<e0>": 144
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39694",
        "original_caption": "an adult man in white hugs another adult in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in white hugs another adult in a bar."
            }
        ],
        "meta": {
            "split": [
                642,
                834
            ],
            "duration": 193,
            "token": {
                "<s0>": 16,
                "<e0>": 141
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39695",
        "original_caption": "an adult man in white hugs another adult in a bar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white hugs another adult in a bar."
            }
        ],
        "meta": {
            "split": [
                834,
                1011
            ],
            "duration": 178,
            "token": {
                "<s0>": 51,
                "<e0>": 178
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4009568977",
        "aid": "4009568977_39696",
        "original_caption": "there is a bread above a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the bread in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                144,
                250
            ],
            "duration": 107,
            "token": {
                "<s0>": 25,
                "<e0>": 106
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6197272373",
        "aid": "6197272373_39697",
        "original_caption": "an adult is next to a cup at meeting.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is next to a cup at meeting."
            }
        ],
        "meta": {
            "split": [
                319,
                638
            ],
            "duration": 320,
            "token": {
                "<s0>": 12,
                "<e0>": 67
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4635017196",
        "aid": "4635017196_39698",
        "original_caption": "a child with blond-hair is behind another child with black long hair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair is behind another child with black long hair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                348
            ],
            "duration": 349,
            "token": {
                "<s0>": 0,
                "<e0>": 349
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39699",
        "original_caption": "a child in red is away a colorful sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child in red away from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 360,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379354799",
        "aid": "5379354799_39700",
        "original_caption": "an adult in blue clothes touches the fruits.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue clothes touches the fruits happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1466
            ],
            "duration": 1467,
            "token": {
                "<s0>": 522,
                "<e0>": 591
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_39701",
        "original_caption": "an adult in white is towards another adult by the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the adult in white towards to by the pool from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1140,
                "<e0>": 1220
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12158830025",
        "aid": "12158830025_39702",
        "original_caption": "adults in green clothes next to the backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "Adults in green clothes next to the backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1368
            ],
            "duration": 1369,
            "token": {
                "<s0>": 840,
                "<e0>": 910
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6624003603",
        "aid": "6624003603_39703",
        "original_caption": "an adult is behind another adult on the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult on the sea from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1247
            ],
            "duration": 1248,
            "token": {
                "<s0>": 0,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833887719",
        "aid": "4833887719_39704",
        "original_caption": "there is a chair behind a standing adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair behind a standing adult happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                808
            ],
            "duration": 809,
            "token": {
                "<s0>": 720,
                "<e0>": 809
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8572776945",
        "aid": "8572776945_39705",
        "original_caption": "there is a baby seat next to a table on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby_seat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a baby seat next to a table on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 826
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7246410056",
        "aid": "7246410056_39706",
        "original_caption": "a child in blue leans on an adult in white on the playgrounds.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue leans on an adult in white on the playgrounds."
            }
        ],
        "meta": {
            "split": [
                0,
                1212
            ],
            "duration": 1213,
            "token": {
                "<s0>": 0,
                "<e0>": 29
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_39707",
        "original_caption": "there is a table beneath a cellphone inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a table beneath a cellphone inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 650,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_39708",
        "original_caption": "there is a chair in a red coat beneath an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1877
            ],
            "duration": 1878,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5392563097",
        "aid": "5392563097_39709",
        "original_caption": "an adult in red feeds an elephant by the tree.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red feeds an elephant by the tree happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                91
            ],
            "duration": 92,
            "token": {
                "<s0>": 41,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6115043636",
        "aid": "6115043636_39710",
        "original_caption": "an adult is next to an another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is next to an another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                863
            ],
            "duration": 864,
            "token": {
                "<s0>": 378,
                "<e0>": 863
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3482621813",
        "aid": "3482621813_39711",
        "original_caption": "an adult in white feeds a penguin outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white feeds a penguin outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                592
            ],
            "duration": 593,
            "token": {
                "<s0>": 47,
                "<e0>": 200
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7229381106",
        "aid": "7229381106_39712",
        "original_caption": "a child in red clothes touches a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes touches a yellow toy."
            }
        ],
        "meta": {
            "split": [
                0,
                620
            ],
            "duration": 621,
            "token": {
                "<s0>": 123,
                "<e0>": 157
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2942623423",
        "aid": "2942623423_39713",
        "original_caption": "an adult is away from another adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                734
            ],
            "duration": 735,
            "token": {
                "<s0>": 60,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3828002440",
        "aid": "3828002440_39714",
        "original_caption": "a baby leans on an adult in the pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby leans on an adult in the pool."
            }
        ],
        "meta": {
            "split": [
                0,
                289
            ],
            "duration": 290,
            "token": {
                "<s0>": 0,
                "<e0>": 290
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_39715",
        "original_caption": "an adult in red clothes watches another adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red clothes watches another adult in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 678,
                "<e0>": 732
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_39716",
        "original_caption": "an adult holds another adult at birthday party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the other adult at birthday party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                225
            ],
            "duration": 226,
            "token": {
                "<s0>": 19,
                "<e0>": 191
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_39717",
        "original_caption": "an adult holds another adult at birthday party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds another adult at birthday party."
            }
        ],
        "meta": {
            "split": [
                225,
                1446
            ],
            "duration": 1222,
            "token": {
                "<s0>": 35,
                "<e0>": 139
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39718",
        "original_caption": "there is a dark gray rat in front of a dark gray hamster.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dark gray rat in front of a dark gray hamster."
            }
        ],
        "meta": {
            "split": [
                1264,
                2639
            ],
            "duration": 1376,
            "token": {
                "<s0>": 71,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3874789174",
        "aid": "3874789174_39719",
        "original_caption": "the adult in blue is leaning on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is leaning on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1094
            ],
            "duration": 1095,
            "token": {
                "<s0>": 0,
                "<e0>": 360
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_39720",
        "original_caption": "the baby is in front of the toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the toy from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 85,
                "<e0>": 124
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10274034226",
        "aid": "10274034226_39721",
        "original_caption": "there is a dog in front of another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dog in front of another dog on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                422
            ],
            "duration": 423,
            "token": {
                "<s0>": 259,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2955299637",
        "aid": "2955299637_39722",
        "original_caption": "an adult rides a horse on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a horse on the grass."
            }
        ],
        "meta": {
            "split": [
                44,
                629
            ],
            "duration": 586,
            "token": {
                "<s0>": 14,
                "<e0>": 537
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7122184611",
        "aid": "7122184611_39723",
        "original_caption": "an adult holding a violin watches another adult holding a microphone on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holding a violin watches another adult holding a microphone on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                598,
                1458
            ],
            "duration": 861,
            "token": {
                "<s0>": 269,
                "<e0>": 404
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5504745801",
        "aid": "5504745801_39724",
        "original_caption": "a child watches an adult in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child watches an adult in yellow clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                203
            ],
            "duration": 204,
            "token": {
                "<s0>": 0,
                "<e0>": 204
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_39725",
        "original_caption": "there is a cat leaning on a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cat leaning on a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                2114
            ],
            "duration": 2115,
            "token": {
                "<s0>": 1290,
                "<e0>": 1712
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7518834808",
        "aid": "7518834808_39726",
        "original_caption": "a baby holds a purple ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby holds a purple ball on the grass."
            }
        ],
        "meta": {
            "split": [
                0,
                946
            ],
            "duration": 947,
            "token": {
                "<s0>": 860,
                "<e0>": 919
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7518834808",
        "aid": "7518834808_39727",
        "original_caption": "a baby holds a purple ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby holds a purple ball on the grass."
            }
        ],
        "meta": {
            "split": [
                946,
                1072
            ],
            "duration": 127,
            "token": {
                "<s0>": 27,
                "<e0>": 83
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7518834808",
        "aid": "7518834808_39728",
        "original_caption": "a baby holds a purple ball on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby holds a purple ball on the grass."
            }
        ],
        "meta": {
            "split": [
                1072,
                2696
            ],
            "duration": 1625,
            "token": {
                "<s0>": 44,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2425461420",
        "aid": "2425461420_39729",
        "original_caption": "there is a black handbag next to a cat on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black handbag next to a cat on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                1797
            ],
            "duration": 1798,
            "token": {
                "<s0>": 0,
                "<e0>": 1798
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3149819375",
        "aid": "3149819375_39730",
        "original_caption": "there is a baby seat next to an adult on the beach.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the adult on the beach from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                1113
            ],
            "duration": 1114,
            "token": {
                "<s0>": 1052,
                "<e0>": 1109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_39731",
        "original_caption": "a chair is next to a table .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A chair is next to a table ."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_39732",
        "original_caption": "there is a baby seat beneath a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the baby from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_seat."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 0,
                "<e0>": 1806
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6115043636",
        "aid": "6115043636_39733",
        "original_caption": "an adult in red is in front of another adult in red on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red is in front of another adult in red on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                863
            ],
            "duration": 864,
            "token": {
                "<s0>": 18,
                "<e0>": 244
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_39734",
        "original_caption": "an adult plays a guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult plays a guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                2196
            ],
            "duration": 2197,
            "token": {
                "<s0>": 1124,
                "<e0>": 1282
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_39735",
        "original_caption": "there is a cake next to a child on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the child on the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cake."
            }
        ],
        "meta": {
            "split": [
                0,
                2225
            ],
            "duration": 2226,
            "token": {
                "<s0>": 1980,
                "<e0>": 2190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5195700916",
        "aid": "5195700916_39736",
        "original_caption": "there is a green bottle next to an adult in pink in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a green bottle next to an adult in pink in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 300,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047872014",
        "aid": "6047872014_39737",
        "original_caption": "an adult woman in black hugs another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in black hug from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 57,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8059684971",
        "aid": "8059684971_39738",
        "original_caption": "a child is above a sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is above a sofa in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                585,
                1379
            ],
            "duration": 795,
            "token": {
                "<s0>": 195,
                "<e0>": 795
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39739",
        "original_caption": "an adult is towards a bottle inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is towards a bottle inside a room."
            }
        ],
        "meta": {
            "split": [
                105,
                793
            ],
            "duration": 689,
            "token": {
                "<s0>": 15,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4204053300",
        "aid": "4204053300_39740",
        "original_caption": "an adult in black is behind a child on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black is behind a child on the floor happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                450
            ],
            "duration": 451,
            "token": {
                "<s0>": 0,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047872014",
        "aid": "6047872014_39741",
        "original_caption": "an adult in black clothes kisses another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black clothes kiss from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                64
            ],
            "duration": 65,
            "token": {
                "<s0>": 57,
                "<e0>": 65
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_39742",
        "original_caption": "an adult rides a blue watercraft blue on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a blue watercraft blue on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                121
            ],
            "duration": 122,
            "token": {
                "<s0>": 0,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_39743",
        "original_caption": "an adult rides a blue watercraft blue on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a blue watercraft blue on the water."
            }
        ],
        "meta": {
            "split": [
                121,
                458
            ],
            "duration": 338,
            "token": {
                "<s0>": 29,
                "<e0>": 338
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_39744",
        "original_caption": "an adult is inside a watercraft on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is inside a watercraft on the lake."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_39745",
        "original_caption": "there is a monitor above a beige sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a monitor above a beige sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                747
            ],
            "duration": 748,
            "token": {
                "<s0>": 0,
                "<e0>": 748
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3733190941",
        "aid": "3733190941_39746",
        "original_caption": "there is an big elephant pushing the little elephant.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is an big elephant pushing the little elephant happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2012
            ],
            "duration": 2013,
            "token": {
                "<s0>": 471,
                "<e0>": 512
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953143775",
        "aid": "6953143775_39747",
        "original_caption": "an adult in black clothes pushes another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes pushes another adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                99,
                188
            ],
            "duration": 90,
            "token": {
                "<s0>": 8,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5625562611",
        "aid": "5625562611_39748",
        "original_caption": "there is a silver bottle behind an adult man in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a silver bottle behind an adult man in gray happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                736
            ],
            "duration": 737,
            "token": {
                "<s0>": 480,
                "<e0>": 737
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_39749",
        "original_caption": "there is a watercraft inside an adult on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is inside the adult on the river from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5270774640",
        "aid": "5270774640_39750",
        "original_caption": "a white adult hugs a dog in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a white adult hugs a dog in black happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                222
            ],
            "duration": 223,
            "token": {
                "<s0>": 0,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39751",
        "original_caption": "a child girl in gray is towards another child in pink in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child girl in gray is towards another child in pink in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1200,
                "<e0>": 1315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12158830025",
        "aid": "12158830025_39752",
        "original_caption": "an adult is towards a backpack on the ice.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards a backpack on the ice happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1368
            ],
            "duration": 1369,
            "token": {
                "<s0>": 780,
                "<e0>": 930
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8623061698",
        "aid": "8623061698_39753",
        "original_caption": "there is a table beneath a cake at birthday party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the cake at birthday party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                1079
            ],
            "duration": 1080,
            "token": {
                "<s0>": 0,
                "<e0>": 1080
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4142450052",
        "aid": "4142450052_39754",
        "original_caption": "a yellow dog is biting the red frisbee.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A yellow dog is biting the red frisbee."
            }
        ],
        "meta": {
            "split": [
                0,
                503
            ],
            "duration": 504,
            "token": {
                "<s0>": 365,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5345319548",
        "aid": "5345319548_39755",
        "original_caption": "an adult in black is behind another adult in the gaming room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult in black in the gaming room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                383,
                790
            ],
            "duration": 408,
            "token": {
                "<s0>": 6,
                "<e0>": 59
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_39756",
        "original_caption": "an adult in black suit watches another adult in white skirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in black suit watch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 84,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_39757",
        "original_caption": "there is a bottle above a table in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle above a table in the living room."
            }
        ],
        "meta": {
            "split": [
                102,
                611
            ],
            "duration": 510,
            "token": {
                "<s0>": 26,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_39758",
        "original_caption": "an adult in orange rides a white watercraft in the ocean.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in orange rides a white watercraft in the ocean."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 486,
                "<e0>": 1394
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_39759",
        "original_caption": "an adult is away from another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is away from the other adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1582
            ],
            "duration": 1583,
            "token": {
                "<s0>": 938,
                "<e0>": 1069
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_39760",
        "original_caption": "the adult in orange is in front of the child in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the child in pink from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1582
            ],
            "duration": 1583,
            "token": {
                "<s0>": 1049,
                "<e0>": 1101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3146965691",
        "aid": "3146965691_39761",
        "original_caption": "an adult plays the guitar on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult plays the guitar on stage."
            }
        ],
        "meta": {
            "split": [
                0,
                1745
            ],
            "duration": 1746,
            "token": {
                "<s0>": 0,
                "<e0>": 1746
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3035546777",
        "aid": "3035546777_39762",
        "original_caption": "an adult with white coats and red sleeve is above a bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with white coats and red sleeve is above a bicycle."
            }
        ],
        "meta": {
            "split": [
                1571,
                2100
            ],
            "duration": 530,
            "token": {
                "<s0>": 14,
                "<e0>": 529
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_39763",
        "original_caption": "an adult man in black rides a white watercraft on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in black rides a white watercraft on the river."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39764",
        "original_caption": "an adult grabs a rat on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult grabs a rat on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                1763
            ],
            "duration": 1764,
            "token": {
                "<s0>": 950,
                "<e0>": 998
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39765",
        "original_caption": "an adult grabs a rat on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult grabs a rat on the bed."
            }
        ],
        "meta": {
            "split": [
                1763,
                2639
            ],
            "duration": 877,
            "token": {
                "<s0>": 765,
                "<e0>": 791
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6644166529",
        "aid": "6644166529_39766",
        "original_caption": "there is a dish above a table at the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a dish above a table at the table happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1766,
                "<e0>": 2658
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_39767",
        "original_caption": "an adult in pink clothes is in front of a child wearing blue pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in pink clothes is in front of a child wearing blue pants."
            }
        ],
        "meta": {
            "split": [
                465,
                735
            ],
            "duration": 271,
            "token": {
                "<s0>": 15,
                "<e0>": 105
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3482621813",
        "aid": "3482621813_39768",
        "original_caption": "there is a penguin behind another penguin outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the penguin from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a penguin behind another penguin outdoors."
            }
        ],
        "meta": {
            "split": [
                495,
                592
            ],
            "duration": 98,
            "token": {
                "<s0>": 45,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39769",
        "original_caption": "there is a cat behind an adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cat behind an adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1620,
                "<e0>": 1699
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13945442936",
        "aid": "13945442936_39770",
        "original_caption": "there is a laptop above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the laptop inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                949
            ],
            "duration": 950,
            "token": {
                "<s0>": 70,
                "<e0>": 874
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10403393365",
        "aid": "10403393365_39771",
        "original_caption": "a child in white is above a pink bicycle on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white is above a pink bicycle on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                341
            ],
            "duration": 342,
            "token": {
                "<s0>": 0,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5708481466",
        "aid": "5708481466_39772",
        "original_caption": "a child drives a toy on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child drives a toy on the grass."
            }
        ],
        "meta": {
            "split": [
                71,
                267
            ],
            "duration": 197,
            "token": {
                "<s0>": 21,
                "<e0>": 88
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5708481466",
        "aid": "5708481466_39773",
        "original_caption": "a child drives a toy on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child drives a toy on the grass."
            }
        ],
        "meta": {
            "split": [
                267,
                1289
            ],
            "duration": 1023,
            "token": {
                "<s0>": 108,
                "<e0>": 643
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_39774",
        "original_caption": "an adult carries a backpack on the mountain.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult carries a backpack on the mountain."
            }
        ],
        "meta": {
            "split": [
                0,
                181
            ],
            "duration": 182,
            "token": {
                "<s0>": 72,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_39775",
        "original_caption": "an adult carries a backpack on the mountain.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult carries a backpack on the mountain."
            }
        ],
        "meta": {
            "split": [
                181,
                357
            ],
            "duration": 177,
            "token": {
                "<s0>": 84,
                "<e0>": 151
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8068324821",
        "aid": "8068324821_39776",
        "original_caption": "a child rides a bicycle on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child rides a bicycle on the street."
            }
        ],
        "meta": {
            "split": [
                0,
                286
            ],
            "duration": 287,
            "token": {
                "<s0>": 0,
                "<e0>": 260
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8068324821",
        "aid": "8068324821_39777",
        "original_caption": "a child rides a bicycle on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child rides a bicycle on the street."
            }
        ],
        "meta": {
            "split": [
                286,
                469
            ],
            "duration": 184,
            "token": {
                "<s0>": 27,
                "<e0>": 184
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_39778",
        "original_caption": "an adult woman in black is towards another adult woman in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black is towards another adult woman in white."
            }
        ],
        "meta": {
            "split": [
                0,
                535
            ],
            "duration": 536,
            "token": {
                "<s0>": 403,
                "<e0>": 449
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_39779",
        "original_caption": "an adult woman in blue is in front of a pig.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in blue is in front of a pig happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 60,
                "<e0>": 690
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6451361497",
        "aid": "6451361497_39780",
        "original_caption": "an adult releases a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho releases the toy inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                824
            ],
            "duration": 825,
            "token": {
                "<s0>": 77,
                "<e0>": 93
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_39781",
        "original_caption": "an adult in black clothes speaks to a child in pink clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes speaks to a child in pink clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                647
            ],
            "duration": 648,
            "token": {
                "<s0>": 229,
                "<e0>": 338
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8616874413",
        "aid": "8616874413_39782",
        "original_caption": "an adult man in black uses a black camera outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black uses a black camera outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                825
            ],
            "duration": 826,
            "token": {
                "<s0>": 0,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39783",
        "original_caption": "there is a plastic bottle beneath a blue sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a plastic bottle beneath a blue sports ball in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 459,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_39784",
        "original_caption": "a child in blue clothes touches a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in blue clothes touch from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                187
            ],
            "duration": 188,
            "token": {
                "<s0>": 0,
                "<e0>": 35
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4902063863",
        "aid": "4902063863_39785",
        "original_caption": "a child in blue clothes touches a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue clothes touches a screen happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                524,
                747
            ],
            "duration": 224,
            "token": {
                "<s0>": 19,
                "<e0>": 224
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39786",
        "original_caption": "a child is next to a cup at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the child next to at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 794
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4452848541",
        "aid": "4452848541_39787",
        "original_caption": "an adult driving the bus is next to a cellphone in the bus.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult driving the bus next to in the bus from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                839
            ],
            "duration": 840,
            "token": {
                "<s0>": 0,
                "<e0>": 410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4866672246",
        "aid": "4866672246_39788",
        "original_caption": "there is a yelllow dog next to a black dish.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a yelllow dog next to a black dish."
            }
        ],
        "meta": {
            "split": [
                0,
                1259
            ],
            "duration": 1260,
            "token": {
                "<s0>": 1080,
                "<e0>": 1230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3282832711",
        "aid": "3282832711_39789",
        "original_caption": "there is a dish next to a black dog in the kitchen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dish next to a black dog in the kitchen."
            }
        ],
        "meta": {
            "split": [
                897,
                1419
            ],
            "duration": 523,
            "token": {
                "<s0>": 71,
                "<e0>": 512
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_39790",
        "original_caption": "there is a ski beneath an adult on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the ski on the snow from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 134,
                "<e0>": 193
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39791",
        "original_caption": "a child is in front of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 589
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5091773135",
        "aid": "5091773135_39792",
        "original_caption": "an adult in brown clothes plays the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in brown clothes plays the guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                1770
            ],
            "duration": 1771,
            "token": {
                "<s0>": 0,
                "<e0>": 1396
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11264199933",
        "aid": "11264199933_39793",
        "original_caption": "an adult is next to a brown dog outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is next to a brown dog outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                488
            ],
            "duration": 489,
            "token": {
                "<s0>": 0,
                "<e0>": 50
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3099327773",
        "aid": "3099327773_39794",
        "original_caption": "a child in white is above another child in white on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white is above another child in white on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1947
            ],
            "duration": 1948,
            "token": {
                "<s0>": 1740,
                "<e0>": 1948
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3145413102",
        "aid": "3145413102_39795",
        "original_caption": "an adult in white holds a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white holds a cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                775
            ],
            "duration": 776,
            "token": {
                "<s0>": 398,
                "<e0>": 446
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8716087070",
        "aid": "8716087070_39796",
        "original_caption": "an adult women is away an aircraft on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult women is away an aircraft on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                771
            ],
            "duration": 772,
            "token": {
                "<s0>": 506,
                "<e0>": 566
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10602702615",
        "aid": "10602702615_39797",
        "original_caption": "a child in red watches an adult on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red watches an adult on a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 261,
                "<e0>": 331
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5096827532",
        "aid": "5096827532_39798",
        "original_caption": "a child in gray clothes is next to another child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in gray clothes is next to another child in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                672
            ],
            "duration": 673,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4827728106",
        "aid": "4827728106_39799",
        "original_caption": "an adult man in plaid shirt is towards a child in gray in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt is towards a child in gray in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                235
            ],
            "duration": 236,
            "token": {
                "<s0>": 0,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_39800",
        "original_caption": "an adult man in gray plays a brown guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in gray plays a brown guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                859
            ],
            "duration": 860,
            "token": {
                "<s0>": 135,
                "<e0>": 818
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_39801",
        "original_caption": "an adult man in gray plays a brown guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in gray plays a brown guitar happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                859,
                2249
            ],
            "duration": 1391,
            "token": {
                "<s0>": 42,
                "<e0>": 1391
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_39802",
        "original_caption": "there is a glass bottle above a black table on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the glass bottle on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 1320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_39803",
        "original_caption": "there is a sofa in front of a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a sofa in front of a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 50,
                "<e0>": 239
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_39804",
        "original_caption": "a child is towards a motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is towards a motorcycle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 243,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7808891456",
        "aid": "7808891456_39805",
        "original_caption": "there is a black fish towards an adult in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the fish from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black fish towards an adult in the water."
            }
        ],
        "meta": {
            "split": [
                915,
                2047
            ],
            "duration": 1133,
            "token": {
                "<s0>": 465,
                "<e0>": 555
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4063402763",
        "aid": "4063402763_39806",
        "original_caption": "a baby in green clothes watches an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in green clothes watches an adult."
            }
        ],
        "meta": {
            "split": [
                347,
                790
            ],
            "duration": 444,
            "token": {
                "<s0>": 249,
                "<e0>": 286
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3900000605",
        "aid": "3900000605_39807",
        "original_caption": "the child in a blue shirt touches the adult around him.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child touching from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                404
            ],
            "duration": 405,
            "token": {
                "<s0>": 266,
                "<e0>": 284
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39808",
        "original_caption": "an adult is towards another adult inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards another adult inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_39809",
        "original_caption": "a child with blond-hair holds an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds an orange toy."
            }
        ],
        "meta": {
            "split": [
                0,
                360
            ],
            "duration": 361,
            "token": {
                "<s0>": 0,
                "<e0>": 351
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_39810",
        "original_caption": "a child with blond-hair holds an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds an orange toy."
            }
        ],
        "meta": {
            "split": [
                360,
                605
            ],
            "duration": 246,
            "token": {
                "<s0>": 10,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_39811",
        "original_caption": "a child with blond-hair holds an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child with blond-hair hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                605,
                855
            ],
            "duration": 251,
            "token": {
                "<s0>": 20,
                "<e0>": 246
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_39812",
        "original_caption": "a child with blond-hair holds an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds an orange toy."
            }
        ],
        "meta": {
            "split": [
                928,
                1064
            ],
            "duration": 137,
            "token": {
                "<s0>": 19,
                "<e0>": 121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_39813",
        "original_caption": "a child with blond-hair holds an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child with blond-hair holds an orange toy."
            }
        ],
        "meta": {
            "split": [
                1190,
                1283
            ],
            "duration": 94,
            "token": {
                "<s0>": 11,
                "<e0>": 83
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4903182028",
        "aid": "4903182028_39814",
        "original_caption": "a child with blond-hair holds an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child with blond-hair holds an orange toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1283,
                1385
            ],
            "duration": 103,
            "token": {
                "<s0>": 10,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6777058251",
        "aid": "6777058251_39815",
        "original_caption": "an adult in pink is behind a child in white .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pink is behind a child in white  happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1321
            ],
            "duration": 1322,
            "token": {
                "<s0>": 0,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2457895589",
        "aid": "2457895589_39816",
        "original_caption": "an adult is in front of the child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is in front of the child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1752
            ],
            "duration": 1753,
            "token": {
                "<s0>": 0,
                "<e0>": 1753
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8782055272",
        "aid": "8782055272_39817",
        "original_caption": "a blue and yellow adult is above a bicycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A blue and yellow adult is above a bicycle outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 61,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39818",
        "original_caption": "there is a cyan ball above a baby in white at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cyan ball above a baby in white at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 420,
                "<e0>": 630
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3557382625",
        "aid": "3557382625_39819",
        "original_caption": "an adult is next to another adult in the cave.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is next to another adult in the cave happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                735
            ],
            "duration": 736,
            "token": {
                "<s0>": 424,
                "<e0>": 509
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3499817916",
        "aid": "3499817916_39820",
        "original_caption": "a baby is above a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby is above a chair in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                726
            ],
            "duration": 727,
            "token": {
                "<s0>": 613,
                "<e0>": 661
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_39821",
        "original_caption": "there is a screen above an adult at the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is beneath the screen at the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                872,
                2271
            ],
            "duration": 1400,
            "token": {
                "<s0>": 662,
                "<e0>": 1399
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4184884354",
        "aid": "4184884354_39822",
        "original_caption": "a child plays the piano at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child plays the piano at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1502
            ],
            "duration": 1503,
            "token": {
                "<s0>": 455,
                "<e0>": 643
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3120535570",
        "aid": "3120535570_39823",
        "original_caption": "there is an adult watching the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is an adult watching the adult in black."
            }
        ],
        "meta": {
            "split": [
                0,
                147
            ],
            "duration": 148,
            "token": {
                "<s0>": 0,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5468020076",
        "aid": "5468020076_39824",
        "original_caption": "there is a table beneath a screen in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a table beneath a screen in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                712
            ],
            "duration": 713,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4717834858",
        "aid": "4717834858_39825",
        "original_caption": "there is a baby leaning on the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a baby leaning on the baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                213
            ],
            "duration": 214,
            "token": {
                "<s0>": 0,
                "<e0>": 214
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_39826",
        "original_caption": "a child in yellow is inside a green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in yellow is inside a green toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                930
            ],
            "duration": 931,
            "token": {
                "<s0>": 556,
                "<e0>": 629
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_39827",
        "original_caption": "there is a cup above a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the table inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 115,
                "<e0>": 237
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_39828",
        "original_caption": "an adult in gray clothes is in front of another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the adult in gray clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 0,
                "<e0>": 270
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39829",
        "original_caption": "the adult is in front of the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult is in front of the sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 960,
                "<e0>": 1095
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39830",
        "original_caption": "an adult in red dress carries a cake to the children.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries a cake to the children from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                116
            ],
            "duration": 117,
            "token": {
                "<s0>": 32,
                "<e0>": 68
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39831",
        "original_caption": "an adult in red dress carries a cake to the children.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in red dress carries a cake to the children happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                116,
                872
            ],
            "duration": 757,
            "token": {
                "<s0>": 48,
                "<e0>": 234
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9189821251",
        "aid": "9189821251_39832",
        "original_caption": "there is a beige dog towards an adult wearing black pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a beige dog towards an adult wearing black pants happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1336
            ],
            "duration": 1337,
            "token": {
                "<s0>": 120,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_39833",
        "original_caption": "an adult with glasses caresses a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult with glasses caress  from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cat."
            }
        ],
        "meta": {
            "split": [
                0,
                571
            ],
            "duration": 572,
            "token": {
                "<s0>": 387,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_39834",
        "original_caption": "an adult with glasses caresses a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with glasses caresses a brown cat."
            }
        ],
        "meta": {
            "split": [
                571,
                885
            ],
            "duration": 315,
            "token": {
                "<s0>": 8,
                "<e0>": 275
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4451729145",
        "aid": "4451729145_39835",
        "original_caption": "an adult with glasses caresses a brown cat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with glasses caresses a brown cat."
            }
        ],
        "meta": {
            "split": [
                885,
                1238
            ],
            "duration": 354,
            "token": {
                "<s0>": 39,
                "<e0>": 152
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_39836",
        "original_caption": "a child in pink clothes is away from another child in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in pink clothes is away from another child in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 120,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_39837",
        "original_caption": "an adult man with gray shirt speaks to an adult man in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is speaking to the adult man in red from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                318
            ],
            "duration": 319,
            "token": {
                "<s0>": 0,
                "<e0>": 308
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_39838",
        "original_caption": "an adult man with gray shirt speaks to an adult man in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man with gray shirt speaks to an adult man in red."
            }
        ],
        "meta": {
            "split": [
                318,
                1338
            ],
            "duration": 1021,
            "token": {
                "<s0>": 10,
                "<e0>": 1010
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12357929995",
        "aid": "12357929995_39839",
        "original_caption": "an adult man with gray shirt speaks to an adult man in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man with gray shirt speaks to an adult man in red."
            }
        ],
        "meta": {
            "split": [
                1338,
                1877
            ],
            "duration": 540,
            "token": {
                "<s0>": 10,
                "<e0>": 294
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3778771350",
        "aid": "3778771350_39840",
        "original_caption": "there are a yellow guitar in front of an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the guitar from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There are a yellow guitar in front of an adult in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                2196
            ],
            "duration": 2197,
            "token": {
                "<s0>": 540,
                "<e0>": 990
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2538515654",
        "aid": "2538515654_39841",
        "original_caption": "an adult man in black is above a white surfboard on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in black is above a white surfboard on the water happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                452
            ],
            "duration": 453,
            "token": {
                "<s0>": 0,
                "<e0>": 377
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_39842",
        "original_caption": "a child is in green is in front of the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1425,
                4260
            ],
            "duration": 2836,
            "token": {
                "<s0>": 450,
                "<e0>": 806
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8136606220",
        "aid": "8136606220_39843",
        "original_caption": "an adult is above a surfboard on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the surfboard on the water from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                260
            ],
            "duration": 261,
            "token": {
                "<s0>": 48,
                "<e0>": 212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2955299637",
        "aid": "2955299637_39844",
        "original_caption": "there is a brown horse carrying an adult woman in wathet blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown horse carrying an adult woman in wathet blue."
            }
        ],
        "meta": {
            "split": [
                44,
                629
            ],
            "duration": 586,
            "token": {
                "<s0>": 14,
                "<e0>": 537
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2494076437",
        "aid": "2494076437_39845",
        "original_caption": "a baby in pink is above a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in pink is above a baby seat in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                1421
            ],
            "duration": 1422,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4462691651",
        "aid": "4462691651_39846",
        "original_caption": "an adult in black is in front of another adult on stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black is in front of another adult on stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                749
            ],
            "duration": 750,
            "token": {
                "<s0>": 0,
                "<e0>": 597
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_39847",
        "original_caption": "an adult rides a bicycle in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult rides a bicycle in the forest."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 0,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12212857646",
        "aid": "12212857646_39848",
        "original_caption": "an adult woman in black hugs a child in purple outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black hugs a child in purple outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1170
            ],
            "duration": 1171,
            "token": {
                "<s0>": 438,
                "<e0>": 698
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8850274965",
        "aid": "8850274965_39849",
        "original_caption": "there is a stool in front of an adult in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in white clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A stool."
            }
        ],
        "meta": {
            "split": [
                0,
                5394
            ],
            "duration": 5395,
            "token": {
                "<s0>": 10,
                "<e0>": 5394
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3924748616",
        "aid": "3924748616_39850",
        "original_caption": "an adult in white holds a skateboard in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in white hold in the playground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A skateboard."
            }
        ],
        "meta": {
            "split": [
                0,
                255
            ],
            "duration": 256,
            "token": {
                "<s0>": 170,
                "<e0>": 202
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5467613963",
        "aid": "5467613963_39851",
        "original_caption": "a child hugs a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child hugs a toy on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                794
            ],
            "duration": 795,
            "token": {
                "<s0>": 577,
                "<e0>": 667
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39852",
        "original_caption": "there is a black skateboard away a red skateboard on the training ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a black skateboard away a red skateboard on the training ground."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 144,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_39853",
        "original_caption": "an adult in pink clothes is beneath a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in pink clothes is beneath a screen happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5379879696",
        "aid": "5379879696_39854",
        "original_caption": "an adult in black is above a ski on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black is above a ski on the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                359
            ],
            "duration": 360,
            "token": {
                "<s0>": 310,
                "<e0>": 359
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2852706689",
        "aid": "2852706689_39855",
        "original_caption": "a baby in blue leans on a baby seat in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho leans on the baby seat in the car from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                648
            ],
            "duration": 649,
            "token": {
                "<s0>": 0,
                "<e0>": 649
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3779800369",
        "aid": "3779800369_39856",
        "original_caption": "an adult leans on a motorcycle in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult leans on a motorcycle in the wild happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                956
            ],
            "duration": 957,
            "token": {
                "<s0>": 428,
                "<e0>": 456
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8223287911",
        "aid": "8223287911_39857",
        "original_caption": "an adult woman in white holds a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult woman in white hold at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                0,
                1484
            ],
            "duration": 1485,
            "token": {
                "<s0>": 1451,
                "<e0>": 1485
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6777058251",
        "aid": "6777058251_39858",
        "original_caption": "the child in light blue watches the adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The child in light blue watches the adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1321
            ],
            "duration": 1322,
            "token": {
                "<s0>": 230,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8068324821",
        "aid": "8068324821_39859",
        "original_caption": "a child in red is above a blue bicycle on a road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red is above a blue bicycle on a road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                286,
                469
            ],
            "duration": 184,
            "token": {
                "<s0>": 27,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_39860",
        "original_caption": "a child is away from an adult insdie a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away from an adult insdie a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1145
            ],
            "duration": 1146,
            "token": {
                "<s0>": 420,
                "<e0>": 507
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_39861",
        "original_caption": "there is a watercraft beneath an adult on the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a watercraft beneath an adult on the river."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8115037154",
        "aid": "8115037154_39862",
        "original_caption": "an adult in black holds a baby on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black holds a baby on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1379
            ],
            "duration": 1380,
            "token": {
                "<s0>": 788,
                "<e0>": 875
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_39863",
        "original_caption": "a child presses a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child press on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1258
            ],
            "duration": 1259,
            "token": {
                "<s0>": 416,
                "<e0>": 467
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5312036289",
        "aid": "5312036289_39864",
        "original_caption": "a child presses a toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child presses a toy on the floor."
            }
        ],
        "meta": {
            "split": [
                1258,
                2157
            ],
            "duration": 900,
            "token": {
                "<s0>": 792,
                "<e0>": 861
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_39865",
        "original_caption": "a child is next to an another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child is next to an another child."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 0,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5837297505",
        "aid": "5837297505_39866",
        "original_caption": "a leftmost adult carries the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A leftmost adult carries the guitar on the stage."
            }
        ],
        "meta": {
            "split": [
                0,
                132
            ],
            "duration": 133,
            "token": {
                "<s0>": 0,
                "<e0>": 43
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5837297505",
        "aid": "5837297505_39867",
        "original_caption": "a leftmost adult carries the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a leftmost adult carries the guitar on the stage happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                132,
                304
            ],
            "duration": 173,
            "token": {
                "<s0>": 90,
                "<e0>": 123
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5837297505",
        "aid": "5837297505_39868",
        "original_caption": "a leftmost adult carries the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho carries the guitar on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                304,
                584
            ],
            "duration": 281,
            "token": {
                "<s0>": 50,
                "<e0>": 160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5837297505",
        "aid": "5837297505_39869",
        "original_caption": "a leftmost adult carries the guitar on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the leftmost adult carry on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A guitar."
            }
        ],
        "meta": {
            "split": [
                584,
                800
            ],
            "duration": 217,
            "token": {
                "<s0>": 120,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6121794107",
        "aid": "6121794107_39870",
        "original_caption": "there is a clear bottle behind a child in red on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a clear bottle behind a child in red on the grass."
            }
        ],
        "meta": {
            "split": [
                751,
                883
            ],
            "duration": 133,
            "token": {
                "<s0>": 69,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_39871",
        "original_caption": "an adult in a shirt plays a guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in a shirt plays a guitar."
            }
        ],
        "meta": {
            "split": [
                0,
                587
            ],
            "duration": 588,
            "token": {
                "<s0>": 350,
                "<e0>": 464
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_39872",
        "original_caption": "an adult in a shirt plays a guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in a shirt plays a guitar."
            }
        ],
        "meta": {
            "split": [
                587,
                744
            ],
            "duration": 158,
            "token": {
                "<s0>": 124,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6842600348",
        "aid": "6842600348_39873",
        "original_caption": "an adult in a shirt plays a guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in a shirt plays a guitar."
            }
        ],
        "meta": {
            "split": [
                744,
                1955
            ],
            "duration": 1212,
            "token": {
                "<s0>": 13,
                "<e0>": 1212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3396832512",
        "aid": "3396832512_39874",
        "original_caption": "an adult woman in black is above a brown wooden chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult woman in black is above a brown wooden chair."
            }
        ],
        "meta": {
            "split": [
                1151,
                2114
            ],
            "duration": 964,
            "token": {
                "<s0>": 139,
                "<e0>": 558
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_39875",
        "original_caption": "an adult is next to a toy at party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult next to at party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 746,
                "<e0>": 989
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_39876",
        "original_caption": "an adult holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of another adult on the floor."
            }
        ],
        "meta": {
            "split": [
                0,
                934
            ],
            "duration": 935,
            "token": {
                "<s0>": 743,
                "<e0>": 787
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_39877",
        "original_caption": "an adult holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of another adult on the floor."
            }
        ],
        "meta": {
            "split": [
                934,
                1109
            ],
            "duration": 176,
            "token": {
                "<s0>": 147,
                "<e0>": 171
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5570785480",
        "aid": "5570785480_39878",
        "original_caption": "an adult holds hand of another adult on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds hand of another adult on the floor."
            }
        ],
        "meta": {
            "split": [
                1109,
                1305
            ],
            "duration": 197,
            "token": {
                "<s0>": 4,
                "<e0>": 37
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8068324821",
        "aid": "8068324821_39879",
        "original_caption": "an adult woman in black pushes an orange and blue bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in black pushes an orange and blue bicycle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                203
            ],
            "duration": 204,
            "token": {
                "<s0>": 0,
                "<e0>": 176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8068324821",
        "aid": "8068324821_39880",
        "original_caption": "an adult woman in black pushes an orange and blue bicycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in black pushes an orange and blue bicycle."
            }
        ],
        "meta": {
            "split": [
                203,
                469
            ],
            "duration": 267,
            "token": {
                "<s0>": 27,
                "<e0>": 224
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7843288978",
        "aid": "7843288978_39881",
        "original_caption": "there is a cellphone above a toy inside car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cellphone from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cellphone above a toy inside car."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 1620,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4367310435",
        "aid": "4367310435_39882",
        "original_caption": "an adult speaks to a child in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult speaks to a child in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                56,
                264
            ],
            "duration": 209,
            "token": {
                "<s0>": 26,
                "<e0>": 46
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4670796220",
        "aid": "4670796220_39883",
        "original_caption": "an adult in gray pushes a red toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in gray pushes a red toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 0,
                "<e0>": 100
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4672243606",
        "aid": "4672243606_39884",
        "original_caption": "a child in white clothes watches an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white clothes watches an adult."
            }
        ],
        "meta": {
            "split": [
                340,
                681
            ],
            "duration": 342,
            "token": {
                "<s0>": 26,
                "<e0>": 342
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2735742477",
        "aid": "2735742477_39885",
        "original_caption": "a child in red clothes is towards a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is towards a baby."
            }
        ],
        "meta": {
            "split": [
                705,
                959
            ],
            "duration": 255,
            "token": {
                "<s0>": 195,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_39886",
        "original_caption": "there is a monitor above an adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the screen/monitor from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a monitor above an adult in a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665030691",
        "aid": "8665030691_39887",
        "original_caption": "there is a black car behind another white car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the car from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black car behind another white car."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 0,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5202728101",
        "aid": "5202728101_39888",
        "original_caption": "there is a yellow dog next to a chair at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a yellow dog next to a chair at home."
            }
        ],
        "meta": {
            "split": [
                0,
                240
            ],
            "duration": 241,
            "token": {
                "<s0>": 0,
                "<e0>": 221
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3136397594",
        "aid": "3136397594_39889",
        "original_caption": "an adult wearing jeans leans on a snake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult wearing jeans lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A snake."
            }
        ],
        "meta": {
            "split": [
                0,
                169
            ],
            "duration": 170,
            "token": {
                "<s0>": 0,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3136397594",
        "aid": "3136397594_39890",
        "original_caption": "an adult wearing jeans leans on a snake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing jeans leans on a snake."
            }
        ],
        "meta": {
            "split": [
                169,
                763
            ],
            "duration": 595,
            "token": {
                "<s0>": 44,
                "<e0>": 514
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_39891",
        "original_caption": "an adult pushes a green watercraft by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult pushes a green watercraft by the sea."
            }
        ],
        "meta": {
            "split": [
                0,
                673
            ],
            "duration": 674,
            "token": {
                "<s0>": 453,
                "<e0>": 505
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_39892",
        "original_caption": "an adult pushes a green watercraft by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult pushes a green watercraft by the sea."
            }
        ],
        "meta": {
            "split": [
                673,
                1723
            ],
            "duration": 1051,
            "token": {
                "<s0>": 168,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6006751278",
        "aid": "6006751278_39893",
        "original_caption": "an adult pushes a green watercraft by the sea.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pushes the green watercraft by the sea from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                1723,
                2696
            ],
            "duration": 974,
            "token": {
                "<s0>": 662,
                "<e0>": 777
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39894",
        "original_caption": "a child in pink leans on a wooden chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in pink lean on in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A chair."
            }
        ],
        "meta": {
            "split": [
                78,
                872
            ],
            "duration": 795,
            "token": {
                "<s0>": 30,
                "<e0>": 99
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_39895",
        "original_caption": "a child wearing blue pants is towards an adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child wearing blue pants is towards an adult in blue clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_39896",
        "original_caption": "an adult in white clothes plays a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes plays a table."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1425
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3227968260",
        "aid": "3227968260_39897",
        "original_caption": "there is adult with red head band holding the hand of another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is adult with red head band holding the hand of another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                929
            ],
            "duration": 930,
            "token": {
                "<s0>": 0,
                "<e0>": 579
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39898",
        "original_caption": "an adult women in red is behind of the adult women in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult women in red is behind of the adult women in black."
            }
        ],
        "meta": {
            "split": [
                1749,
                2024
            ],
            "duration": 276,
            "token": {
                "<s0>": 51,
                "<e0>": 201
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4022210944",
        "aid": "4022210944_39899",
        "original_caption": "an adult women is next to the adult women in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult women is next to the adult women in white."
            }
        ],
        "meta": {
            "split": [
                147,
                535
            ],
            "duration": 389,
            "token": {
                "<s0>": 16,
                "<e0>": 62
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7972054306",
        "aid": "7972054306_39900",
        "original_caption": "a child watches an adult in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the child watch in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                816
            ],
            "duration": 817,
            "token": {
                "<s0>": 119,
                "<e0>": 143
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5270774640",
        "aid": "5270774640_39901",
        "original_caption": "there is a dog leaning on an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a dog leaning on an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                222
            ],
            "duration": 223,
            "token": {
                "<s0>": 0,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39902",
        "original_caption": "an adult woman in colorful holds a plastic bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman in colorful holds a plastic bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                146
            ],
            "duration": 147,
            "token": {
                "<s0>": 0,
                "<e0>": 84
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8646868308",
        "aid": "8646868308_39903",
        "original_caption": "an adult woman in colorful holds a plastic bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult woman in colorful holds a plastic bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                146,
                2159
            ],
            "duration": 2014,
            "token": {
                "<s0>": 63,
                "<e0>": 180
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_39904",
        "original_caption": "a lovely baby leans on a baby seat at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a lovely baby leans on a baby seat at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 0,
                "<e0>": 1806
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6040353632",
        "aid": "6040353632_39905",
        "original_caption": "there is a blue ball in front of a child in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ball/sports_ball from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue ball in front of a child in yellow clothes."
            }
        ],
        "meta": {
            "split": [
                365,
                1343
            ],
            "duration": 979,
            "token": {
                "<s0>": 17,
                "<e0>": 959
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5310031663",
        "aid": "5310031663_39906",
        "original_caption": "an adult lifts a cup outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult lifts a cup outside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 440,
                "<e0>": 477
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5052259273",
        "aid": "5052259273_39907",
        "original_caption": "there is a black dog leaning on an adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a black dog leaning on an adult in black."
            }
        ],
        "meta": {
            "split": [
                250,
                499
            ],
            "duration": 250,
            "token": {
                "<s0>": 41,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3852871000",
        "aid": "3852871000_39908",
        "original_caption": "there is a white cup above a yellow wooden table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the yellow wooden table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                1949
            ],
            "duration": 1950,
            "token": {
                "<s0>": 0,
                "<e0>": 1950
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6777058251",
        "aid": "6777058251_39909",
        "original_caption": "a child in a hat hugs a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in a hat hugs a bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                1321
            ],
            "duration": 1322,
            "token": {
                "<s0>": 709,
                "<e0>": 1045
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39910",
        "original_caption": "there is a cat away an adult on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cat away an adult on the street happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1200,
                "<e0>": 1429
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4833782462",
        "aid": "4833782462_39911",
        "original_caption": "there is a bicycle behind the adult with hat .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle behind the adult with hat  happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                703
            ],
            "duration": 704,
            "token": {
                "<s0>": 308,
                "<e0>": 629
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_39912",
        "original_caption": "an adult is above a watercraft.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is above a watercraft."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 486,
                "<e0>": 1394
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_39913",
        "original_caption": "there is a black table in front of an adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black table in front of an adult in red clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3018394896",
        "aid": "3018394896_39914",
        "original_caption": "an adult in yellow clothes holds hand of another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in yellow clothes holds hand of another adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                810
            ],
            "duration": 811,
            "token": {
                "<s0>": 0,
                "<e0>": 83
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9670369477",
        "aid": "9670369477_39915",
        "original_caption": "an adult in black clothes is next to another adult in green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes is next to another adult in green clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1063
            ],
            "duration": 1064,
            "token": {
                "<s0>": 660,
                "<e0>": 1050
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11329995395",
        "aid": "11329995395_39916",
        "original_caption": "a child in gray is above a khaki sofa in the classroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in gray is above a khaki sofa in the classroom."
            }
        ],
        "meta": {
            "split": [
                0,
                666
            ],
            "duration": 667,
            "token": {
                "<s0>": 459,
                "<e0>": 595
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_39917",
        "original_caption": "a child in red is towards the motorcycle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red is towards the motorcycle."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 0,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3145413102",
        "aid": "3145413102_39918",
        "original_caption": "an adult in brown holds a cup in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in brown hold in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cup."
            }
        ],
        "meta": {
            "split": [
                0,
                775
            ],
            "duration": 776,
            "token": {
                "<s0>": 288,
                "<e0>": 358
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_39919",
        "original_caption": "an adult wearing a white hat is in front of another adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing a white hat is in front of another adult in red clothes."
            }
        ],
        "meta": {
            "split": [
                614,
                854
            ],
            "duration": 241,
            "token": {
                "<s0>": 134,
                "<e0>": 218
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9351597802",
        "aid": "9351597802_39920",
        "original_caption": "a baby in pink is in front of an adult in green in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in pink is in front of an adult in green in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                245
            ],
            "duration": 246,
            "token": {
                "<s0>": 0,
                "<e0>": 224
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9975070616",
        "aid": "9975070616_39921",
        "original_caption": "a baby in shirts is above an adult in the bedroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in shirts is above an adult in the bedroom."
            }
        ],
        "meta": {
            "split": [
                0,
                660
            ],
            "duration": 661,
            "token": {
                "<s0>": 0,
                "<e0>": 661
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39922",
        "original_caption": "there is a tan hamster in front of a tan rat on the blanket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a tan hamster in front of a tan rat on the blanket happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1711,
                2639
            ],
            "duration": 929,
            "token": {
                "<s0>": 123,
                "<e0>": 202
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6997433070",
        "aid": "6997433070_39923",
        "original_caption": "a child on red is away from a toy outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child on red is away from a toy outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                113
            ],
            "duration": 114,
            "token": {
                "<s0>": 0,
                "<e0>": 95
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6220387865",
        "aid": "6220387865_39924",
        "original_caption": "an adult in white clothes holds a cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white clothes holds a cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                480,
                900
            ],
            "duration": 421,
            "token": {
                "<s0>": 321,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11854356446",
        "aid": "11854356446_39925",
        "original_caption": "there is a chair beneath a black backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the chair from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                1160
            ],
            "duration": 1161,
            "token": {
                "<s0>": 249,
                "<e0>": 1049
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2801868426",
        "aid": "2801868426_39926",
        "original_caption": "an adult in black is above a bicycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black is above a bicycle outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                898,
                1312
            ],
            "duration": 415,
            "token": {
                "<s0>": 188,
                "<e0>": 414
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_39927",
        "original_caption": "there is a toy above a baby inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy above a baby inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 522,
                "<e0>": 605
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39928",
        "original_caption": "an adult is away from a cup in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is away from a cup in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 360,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_39929",
        "original_caption": "the adult in red is in front of the child .",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The adult in red is in front of the child ."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 564
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_39930",
        "original_caption": "an adult in white is towards a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white is towards a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2024
            ],
            "duration": 2025,
            "token": {
                "<s0>": 1334,
                "<e0>": 1611
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3943678441",
        "aid": "3943678441_39931",
        "original_caption": "an adult wearing striped shirt carries a black backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing striped shirt carries a black backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                381
            ],
            "duration": 382,
            "token": {
                "<s0>": 203,
                "<e0>": 382
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_39932",
        "original_caption": "an adult is towards a table on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the adult towards to on the stage from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 1260,
                "<e0>": 1350
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3049423208",
        "aid": "3049423208_39933",
        "original_caption": "an adult is towards another adult outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards another adult outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                399
            ],
            "duration": 400,
            "token": {
                "<s0>": 180,
                "<e0>": 262
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5590135575",
        "aid": "5590135575_39934",
        "original_caption": "a baby in brown is above a baby seat in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in brown is above a baby seat in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                773
            ],
            "duration": 774,
            "token": {
                "<s0>": 0,
                "<e0>": 774
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4163033472",
        "aid": "4163033472_39935",
        "original_caption": "a child in colorful holds a red toy in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in colorful holds a red toy in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 1948,
                "<e0>": 2121
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3779800369",
        "aid": "3779800369_39936",
        "original_caption": "there is a motorcycle beneath an adult in green outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a motorcycle beneath an adult in green outdoors."
            }
        ],
        "meta": {
            "split": [
                311,
                956
            ],
            "duration": 646,
            "token": {
                "<s0>": 80,
                "<e0>": 645
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9562161527",
        "aid": "9562161527_39937",
        "original_caption": "a child is behind another child in the swimming pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is behind another child in the swimming pool."
            }
        ],
        "meta": {
            "split": [
                0,
                189
            ],
            "duration": 190,
            "token": {
                "<s0>": 74,
                "<e0>": 149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3348930430",
        "aid": "3348930430_39938",
        "original_caption": "an adult is above another adult in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above another adult in the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2157
            ],
            "duration": 2158,
            "token": {
                "<s0>": 0,
                "<e0>": 252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7093500213",
        "aid": "7093500213_39939",
        "original_caption": "an adult in orange is in front of another adult in a shirt.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in orange is in front of another adult in a shirt."
            }
        ],
        "meta": {
            "split": [
                914,
                1109
            ],
            "duration": 196,
            "token": {
                "<s0>": 106,
                "<e0>": 186
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_39940",
        "original_caption": "a child in yellow presses an orange toy in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in yellow presses an orange toy in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                930
            ],
            "duration": 931,
            "token": {
                "<s0>": 578,
                "<e0>": 626
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4638209108",
        "aid": "4638209108_39941",
        "original_caption": "the bird is away from the adult  back to the lens.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The bird is away from the adult  back to the lens."
            }
        ],
        "meta": {
            "split": [
                0,
                599
            ],
            "duration": 600,
            "token": {
                "<s0>": 337,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39942",
        "original_caption": "an adult sitting in a wheelchair uses a white cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult sitting in the wheelchair use from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A cellphone."
            }
        ],
        "meta": {
            "split": [
                175,
                434
            ],
            "duration": 260,
            "token": {
                "<s0>": 55,
                "<e0>": 135
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_39943",
        "original_caption": "an adult sitting in a wheelchair uses a white cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult sitting in a wheelchair uses a white cellphone."
            }
        ],
        "meta": {
            "split": [
                434,
                1441
            ],
            "duration": 1008,
            "token": {
                "<s0>": 125,
                "<e0>": 647
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_39944",
        "original_caption": "there is a pig on the right towards another pig on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the pig on the right towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A pig."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 275,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3763213054",
        "aid": "3763213054_39945",
        "original_caption": "an adult in gray is in front of a chair empty on the stage.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in gray is in front of a chair empty on the stage."
            }
        ],
        "meta": {
            "split": [
                720,
                1052
            ],
            "duration": 333,
            "token": {
                "<s0>": 60,
                "<e0>": 330
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9511286003",
        "aid": "9511286003_39946",
        "original_caption": "an adult is away from another adult in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is away from another adult in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                854
            ],
            "duration": 855,
            "token": {
                "<s0>": 60,
                "<e0>": 310
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3091550860",
        "aid": "3091550860_39947",
        "original_caption": "there is a bottle next to another bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a bottle next to another bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                1649
            ],
            "duration": 1650,
            "token": {
                "<s0>": 330,
                "<e0>": 389
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5302457137",
        "aid": "5302457137_39948",
        "original_caption": "there is a sink beneath a cat in the kitchen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the sink from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a sink beneath a cat in the kitchen."
            }
        ],
        "meta": {
            "split": [
                0,
                521
            ],
            "duration": 522,
            "token": {
                "<s0>": 0,
                "<e0>": 521
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_39949",
        "original_caption": "a child in red watches an adult woman in purple.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the adult woman in purple from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                373,
                1145
            ],
            "duration": 773,
            "token": {
                "<s0>": 66,
                "<e0>": 90
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_39950",
        "original_caption": "a baby in yellow is away from a sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in yellow is away from a sofa at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 840,
                "<e0>": 990
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_39951",
        "original_caption": "an adult kisses a child with red nail polish.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho kisses the child with red nail polish from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 670,
                "<e0>": 693
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8157245482",
        "aid": "8157245482_39952",
        "original_caption": "a child in red is above an adult in the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red is above an adult in the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                191
            ],
            "duration": 192,
            "token": {
                "<s0>": 144,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_39953",
        "original_caption": "an adult in green is above a sofa in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in green in the living room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                279,
                474
            ],
            "duration": 196,
            "token": {
                "<s0>": 22,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_39954",
        "original_caption": "an adult man holds hand of a child in orange outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult man hold hand of outdoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 18,
                "<e0>": 64
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_39955",
        "original_caption": "an adult in green clothes holds a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in green clothes holds a sports ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                346
            ],
            "duration": 347,
            "token": {
                "<s0>": 210,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_39956",
        "original_caption": "an adult in green clothes holds a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in green clothes holds a sports ball."
            }
        ],
        "meta": {
            "split": [
                346,
                557
            ],
            "duration": 212,
            "token": {
                "<s0>": 96,
                "<e0>": 126
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4591061010",
        "aid": "4591061010_39957",
        "original_caption": "an adult in green clothes holds a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in green clothes hold from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports_ball."
            }
        ],
        "meta": {
            "split": [
                557,
                693
            ],
            "duration": 137,
            "token": {
                "<s0>": 85,
                "<e0>": 108
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6824723803",
        "aid": "6824723803_39958",
        "original_caption": "there is a white goat towards a white and black pig on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white goat towards a white and black pig on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                869
            ],
            "duration": 870,
            "token": {
                "<s0>": 60,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9038264963",
        "aid": "9038264963_39959",
        "original_caption": "there is a cup above a table in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cup above a table in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                5006
            ],
            "duration": 5007,
            "token": {
                "<s0>": 1920,
                "<e0>": 5007
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4754310333",
        "aid": "4754310333_39960",
        "original_caption": "there is a white and black dog pulling a black and gray toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a white and black dog pulling a black and gray toy."
            }
        ],
        "meta": {
            "split": [
                0,
                1300
            ],
            "duration": 1301,
            "token": {
                "<s0>": 972,
                "<e0>": 1083
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6047939514",
        "aid": "6047939514_39961",
        "original_caption": "a baby in black clothes watches a child in the bathtub.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in black clothes watches a child in the bathtub."
            }
        ],
        "meta": {
            "split": [
                175,
                627
            ],
            "duration": 453,
            "token": {
                "<s0>": 56,
                "<e0>": 212
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "13816283384",
        "aid": "13816283384_39962",
        "original_caption": "a cute cat  shakes her tail leaned on the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cat from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A cute cat  shakes her tail leaned on the sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                718
            ],
            "duration": 719,
            "token": {
                "<s0>": 0,
                "<e0>": 719
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6298848190",
        "aid": "6298848190_39963",
        "original_caption": "a child in blue clothes holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue clothes holds hand of an adult."
            }
        ],
        "meta": {
            "split": [
                0,
                862
            ],
            "duration": 863,
            "token": {
                "<s0>": 641,
                "<e0>": 844
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6298848190",
        "aid": "6298848190_39964",
        "original_caption": "a child in blue clothes holds hand of an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in blue clothes holds hand of an adult."
            }
        ],
        "meta": {
            "split": [
                862,
                1171
            ],
            "duration": 310,
            "token": {
                "<s0>": 18,
                "<e0>": 60
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_39965",
        "original_caption": "there is a toy above a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy above a baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 522,
                "<e0>": 605
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_39966",
        "original_caption": "there is an adult in a shirt is away from the little child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is an adult in a shirt is away from the little child."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1200,
                "<e0>": 1315
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_39967",
        "original_caption": "there are the fruits inside a baby in white on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there are the fruits inside a baby in white on the bed happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 2119,
                "<e0>": 2249
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2852706689",
        "aid": "2852706689_39968",
        "original_caption": "a baby in blue is inside the baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby in blue is inside the baby seat happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                648
            ],
            "duration": 649,
            "token": {
                "<s0>": 0,
                "<e0>": 648
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5769181881",
        "aid": "5769181881_39969",
        "original_caption": "there is a skateboard towards a child inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is towards the child inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A skateboard."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 126,
                "<e0>": 188
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5153854160",
        "aid": "5153854160_39970",
        "original_caption": "there is a brown table beneath a sliver laptop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a brown table beneath a sliver laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                2264
            ],
            "duration": 2265,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3510473333",
        "aid": "3510473333_39971",
        "original_caption": "a baby is inside a baby walker on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is outside the baby on the road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby_walker."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 0,
                "<e0>": 575
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3855730364",
        "aid": "3855730364_39972",
        "original_caption": "there is a fish towards another fish in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a fish towards another fish in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                458
            ],
            "duration": 459,
            "token": {
                "<s0>": 300,
                "<e0>": 390
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_39973",
        "original_caption": "there is a black sofa beneath an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                419
            ],
            "duration": 420,
            "token": {
                "<s0>": 0,
                "<e0>": 420
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6913658789",
        "aid": "6913658789_39974",
        "original_caption": "an adult holds a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a toy on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                620
            ],
            "duration": 621,
            "token": {
                "<s0>": 565,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6913658789",
        "aid": "6913658789_39975",
        "original_caption": "an adult holds a toy on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the toy on the ground from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                620,
                2432
            ],
            "duration": 1813,
            "token": {
                "<s0>": 33,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6269049659",
        "aid": "6269049659_39976",
        "original_caption": "there is a motorcycle behind a child on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the motorcycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a motorcycle behind a child on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                411
            ],
            "duration": 412,
            "token": {
                "<s0>": 120,
                "<e0>": 290
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8183766541",
        "aid": "8183766541_39977",
        "original_caption": "a child in white clothes hits a bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the child in white clothes hit from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 2608,
                "<e0>": 2697
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5945234319",
        "aid": "5945234319_39978",
        "original_caption": "an adult is above a grey sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is above a grey sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1988
            ],
            "duration": 1989,
            "token": {
                "<s0>": 1486,
                "<e0>": 1570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5310031663",
        "aid": "5310031663_39979",
        "original_caption": "an adult holds a cup in a shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult holds a cup in a shop."
            }
        ],
        "meta": {
            "split": [
                0,
                866
            ],
            "duration": 867,
            "token": {
                "<s0>": 440,
                "<e0>": 601
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5343144349",
        "aid": "5343144349_39980",
        "original_caption": "there is a clear bottle above a brown table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bottle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a clear bottle above a brown table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                780
            ],
            "duration": 781,
            "token": {
                "<s0>": 0,
                "<e0>": 781
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6134739139",
        "aid": "6134739139_39981",
        "original_caption": "a child in red clothes speaks to another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red clothes speaks to another child."
            }
        ],
        "meta": {
            "split": [
                0,
                1968
            ],
            "duration": 1969,
            "token": {
                "<s0>": 694,
                "<e0>": 758
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_39982",
        "original_caption": "a small hamster/rat is above the big hamster/rat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat above the big hamster/rat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1440,
                "<e0>": 1530
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2462607486",
        "aid": "2462607486_39983",
        "original_caption": "adult in white suit is playing the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is playing the guitar from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                464
            ],
            "duration": 465,
            "token": {
                "<s0>": 0,
                "<e0>": 445
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2462607486",
        "aid": "2462607486_39984",
        "original_caption": "adult in white suit is playing the guitar.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adult in white suit is playing the guitar."
            }
        ],
        "meta": {
            "split": [
                464,
                1251
            ],
            "duration": 788,
            "token": {
                "<s0>": 19,
                "<e0>": 788
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3848996383",
        "aid": "3848996383_39985",
        "original_caption": "the strong adult is holding the transparent cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "The strong adult is holding the transparent cup."
            }
        ],
        "meta": {
            "split": [
                0,
                739
            ],
            "duration": 740,
            "token": {
                "<s0>": 0,
                "<e0>": 20
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3843663025",
        "aid": "3843663025_39986",
        "original_caption": "a child in white rides a bicycle outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white rides a bicycle outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                545
            ],
            "duration": 546,
            "token": {
                "<s0>": 132,
                "<e0>": 460
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_39987",
        "original_caption": "a female adult feeds a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A female adult feeds a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                402
            ],
            "duration": 403,
            "token": {
                "<s0>": 91,
                "<e0>": 291
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_39988",
        "original_caption": "a female adult feeds a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the female adult feed from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                402,
                823
            ],
            "duration": 422,
            "token": {
                "<s0>": 112,
                "<e0>": 293
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_39989",
        "original_caption": "a female adult feeds a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A female adult feeds a baby in white clothes."
            }
        ],
        "meta": {
            "split": [
                823,
                1322
            ],
            "duration": 500,
            "token": {
                "<s0>": 128,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_39990",
        "original_caption": "a female adult feeds a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a female adult feeds a baby in white clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1322,
                1712
            ],
            "duration": 391,
            "token": {
                "<s0>": 171,
                "<e0>": 359
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990716415",
        "aid": "3990716415_39991",
        "original_caption": "a female adult feeds a baby in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the female adult feed from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                1712,
                1805
            ],
            "duration": 94,
            "token": {
                "<s0>": 31,
                "<e0>": 94
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_39992",
        "original_caption": "an adult women speaks to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult women speak to at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 43,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_39993",
        "original_caption": "an adult women speaks to a child at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult women speaks to a child at home."
            }
        ],
        "meta": {
            "split": [
                173,
                1145
            ],
            "duration": 973,
            "token": {
                "<s0>": 28,
                "<e0>": 241
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3886832609",
        "aid": "3886832609_39994",
        "original_caption": "there is an orange watercraft inside an adult in the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the watercraft from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is an orange watercraft inside an adult in the water."
            }
        ],
        "meta": {
            "split": [
                0,
                589
            ],
            "duration": 590,
            "token": {
                "<s0>": 0,
                "<e0>": 370
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3059960651",
        "aid": "3059960651_39995",
        "original_caption": "a child in blue leans on a black baby seat in a car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue leans on a black baby seat in a car happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                319
            ],
            "duration": 320,
            "token": {
                "<s0>": 0,
                "<e0>": 320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6311624192",
        "aid": "6311624192_39996",
        "original_caption": "a child in red leans on an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red leans on an adult at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1047
            ],
            "duration": 1048,
            "token": {
                "<s0>": 0,
                "<e0>": 1048
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_39997",
        "original_caption": "an adult is towards a monitor at the show.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards a monitor at the show."
            }
        ],
        "meta": {
            "split": [
                555,
                1011
            ],
            "duration": 457,
            "token": {
                "<s0>": 105,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5209164320",
        "aid": "5209164320_39998",
        "original_caption": "an adult hugs the guitar at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult hugs the guitar at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1138
            ],
            "duration": 1139,
            "token": {
                "<s0>": 75,
                "<e0>": 128
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_39999",
        "original_caption": "there is a brown dog above a black dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown dog above a black dog."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 200,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5606187654",
        "aid": "5606187654_40000",
        "original_caption": "a child in red pulls an adult in yellow at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red pulls an adult in yellow at home."
            }
        ],
        "meta": {
            "split": [
                0,
                363
            ],
            "duration": 364,
            "token": {
                "<s0>": 303,
                "<e0>": 320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_40001",
        "original_caption": "an adult in blue watches another adult in palm green at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in blue watch at home from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 0,
                "<e0>": 566
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3232121640",
        "aid": "3232121640_40002",
        "original_caption": "the ski is in front of the adult in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the ski from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The ski is in front of the adult in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                647
            ],
            "duration": 648,
            "token": {
                "<s0>": 447,
                "<e0>": 647
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4937342819",
        "aid": "4937342819_40003",
        "original_caption": "a baby wearing pink pants is in front of an adult in green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby wearing pink pants is in front of an adult in green clothes."
            }
        ],
        "meta": {
            "split": [
                279,
                474
            ],
            "duration": 196,
            "token": {
                "<s0>": 22,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_40004",
        "original_caption": "a child in red clothes is away from a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in red clothes is away from a sports ball happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 540,
                "<e0>": 596
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2852706689",
        "aid": "2852706689_40005",
        "original_caption": "there is a toy next to a baby in a baby chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy next to a baby in a baby chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                648
            ],
            "duration": 649,
            "token": {
                "<s0>": 0,
                "<e0>": 648
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_40006",
        "original_caption": "there is a rat beneath another hamster on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a rat beneath another hamster on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1834,
                "<e0>": 1889
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_40007",
        "original_caption": "an adult is above a sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is above a sofa in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                705
            ],
            "duration": 706,
            "token": {
                "<s0>": 281,
                "<e0>": 557
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8093267471",
        "aid": "8093267471_40008",
        "original_caption": "there is a watercraft towards another watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a watercraft towards another watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                1478
            ],
            "duration": 1479,
            "token": {
                "<s0>": 60,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6025039044",
        "aid": "6025039044_40009",
        "original_caption": "a baby in white pushes a red toy on the floor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the baby in white push on the floor from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                128
            ],
            "duration": 129,
            "token": {
                "<s0>": 0,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7803526566",
        "aid": "7803526566_40010",
        "original_caption": "an adult man in gray hugs a baby at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in gray hugs a baby at home."
            }
        ],
        "meta": {
            "split": [
                0,
                748
            ],
            "duration": 749,
            "token": {
                "<s0>": 0,
                "<e0>": 749
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3277823769",
        "aid": "3277823769_40011",
        "original_caption": "a baby is away from a toy on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby is away from a toy on the bed happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 500,
                "<e0>": 625
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_40012",
        "original_caption": "an adult in white clothes is towards another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes is towards another adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1314
            ],
            "duration": 1315,
            "token": {
                "<s0>": 1231,
                "<e0>": 1314
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2945751196",
        "aid": "2945751196_40013",
        "original_caption": "an adult is towards a chair in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards a chair in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                903
            ],
            "duration": 904,
            "token": {
                "<s0>": 60,
                "<e0>": 247
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3142287520",
        "aid": "3142287520_40014",
        "original_caption": "there is a red car next to a white car.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is next to the white car from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A car."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 0,
                "<e0>": 232
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6034557181",
        "aid": "6034557181_40015",
        "original_caption": "there is a cat away a table inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cat away a table inside a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                780,
                1271
            ],
            "duration": 492,
            "token": {
                "<s0>": 180,
                "<e0>": 228
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5398268379",
        "aid": "5398268379_40016",
        "original_caption": "there is a cake towards to a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a cake towards to a child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                872
            ],
            "duration": 873,
            "token": {
                "<s0>": 224,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5953150738",
        "aid": "5953150738_40017",
        "original_caption": "a child in orange caresses a black horse on the grass.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in orange caresses a black horse on the grass happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 39,
                "<e0>": 83
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_40018",
        "original_caption": "there is a white table beneath a biggest bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the white table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_40019",
        "original_caption": "an adult in blue clothes pushes a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in blue clothes pushes a cake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 543,
                "<e0>": 578
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4142450052",
        "aid": "4142450052_40020",
        "original_caption": "there is a red frisbee towards a beige dog.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is towards the beige dog from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A frisbee."
            }
        ],
        "meta": {
            "split": [
                0,
                503
            ],
            "duration": 504,
            "token": {
                "<s0>": 50,
                "<e0>": 125
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5049587564",
        "aid": "5049587564_40021",
        "original_caption": "an adult in black clothes is in front of a child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes is in front of a child in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                719
            ],
            "duration": 720,
            "token": {
                "<s0>": 0,
                "<e0>": 175
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4038861632",
        "aid": "4038861632_40022",
        "original_caption": "a child in colorful is towards an adult woman in dark purple.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child in colorful towards to from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1446
            ],
            "duration": 1447,
            "token": {
                "<s0>": 420,
                "<e0>": 510
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6134739139",
        "aid": "6134739139_40023",
        "original_caption": "a child in red clothes is above a chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in red clothes is above a chair."
            }
        ],
        "meta": {
            "split": [
                0,
                1968
            ],
            "duration": 1969,
            "token": {
                "<s0>": 0,
                "<e0>": 1969
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5581572407",
        "aid": "5581572407_40024",
        "original_caption": "an adult is towards a backpack on the street.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards a backpack on the street."
            }
        ],
        "meta": {
            "split": [
                1695,
                2024
            ],
            "duration": 330,
            "token": {
                "<s0>": 85,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8404701108",
        "aid": "8404701108_40025",
        "original_caption": "there is a monitor above a bottle in the living room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the screen/monitor from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a monitor above a bottle in the living room."
            }
        ],
        "meta": {
            "split": [
                1754,
                2696
            ],
            "duration": 943,
            "token": {
                "<s0>": 46,
                "<e0>": 943
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_40026",
        "original_caption": "an adult holds a rat on the blanket.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a rat on the blanket."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 935,
                "<e0>": 1149
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8782055272",
        "aid": "8782055272_40027",
        "original_caption": "an adult man in blue rides a black bicycle on the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in blue rides a black bicycle on the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 61,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4239231056",
        "aid": "4239231056_40028",
        "original_caption": "there is a snowboard towards an adult woman in red on the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a snowboard towards an adult woman in red on the snow happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                329
            ],
            "duration": 330,
            "token": {
                "<s0>": 186,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5913888440",
        "aid": "5913888440_40029",
        "original_caption": "an adult man in green carries a green backpack in the forest.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in green carries a green backpack in the forest happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                803
            ],
            "duration": 804,
            "token": {
                "<s0>": 0,
                "<e0>": 677
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6813862571",
        "aid": "6813862571_40030",
        "original_caption": "an adult wearing blue headphones watches another adult with glasses.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing blue headphones watches another adult with glasses."
            }
        ],
        "meta": {
            "split": [
                0,
                1754
            ],
            "duration": 1755,
            "token": {
                "<s0>": 753,
                "<e0>": 830
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3243801466",
        "aid": "3243801466_40031",
        "original_caption": "an adult in gray is next to a child standing in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in gray is next to a child standing in the room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                173,
                1145
            ],
            "duration": 973,
            "token": {
                "<s0>": 28,
                "<e0>": 334
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7506103208",
        "aid": "7506103208_40032",
        "original_caption": "there is a wooden stool above an adult man in whiet trousers.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the stool from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a wooden stool above an adult man in whiet trousers."
            }
        ],
        "meta": {
            "split": [
                645,
                1283
            ],
            "duration": 639,
            "token": {
                "<s0>": 375,
                "<e0>": 639
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6115043636",
        "aid": "6115043636_40033",
        "original_caption": "an adult is towards another adult in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is towards another adult in the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                863
            ],
            "duration": 864,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6076335753",
        "aid": "6076335753_40034",
        "original_caption": "there is a cake away a chair inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the cake from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a cake away a chair inside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2225
            ],
            "duration": 2226,
            "token": {
                "<s0>": 1020,
                "<e0>": 1082
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_40035",
        "original_caption": "a baby with blond-hair touches a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a baby with blond-hair touches a cake happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 1593,
                "<e0>": 1629
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_40036",
        "original_caption": "a baby with blond-hair touches a cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby with blond-hair touches a cake."
            }
        ],
        "meta": {
            "split": [
                1679,
                2696
            ],
            "duration": 1018,
            "token": {
                "<s0>": 50,
                "<e0>": 153
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_40037",
        "original_caption": "an adult woman in black watches another adult man in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the other adult man in gray from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                986
            ],
            "duration": 987,
            "token": {
                "<s0>": 432,
                "<e0>": 614
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6088483591",
        "aid": "6088483591_40038",
        "original_caption": "a child is next to a sports ball in the gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child is next to a sports ball in the gym happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                714,
                1246
            ],
            "duration": 533,
            "token": {
                "<s0>": 24,
                "<e0>": 532
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5318884262",
        "aid": "5318884262_40039",
        "original_caption": "a child in black clothes is above a snowboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the child in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A snowboard."
            }
        ],
        "meta": {
            "split": [
                0,
                195
            ],
            "duration": 196,
            "token": {
                "<s0>": 36,
                "<e0>": 195
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_40040",
        "original_caption": "there is a monitor above an adult in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the adult in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A screen/monitor."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 1691
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8114859483",
        "aid": "8114859483_40041",
        "original_caption": "an adult man in gray holds a camera outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in gray holds a camera outdoors happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                231
            ],
            "duration": 232,
            "token": {
                "<s0>": 0,
                "<e0>": 208
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3264417873",
        "aid": "3264417873_40042",
        "original_caption": "an adult man in orange speaks to a child in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in orange speaks to a child in gray."
            }
        ],
        "meta": {
            "split": [
                0,
                788
            ],
            "duration": 789,
            "token": {
                "<s0>": 231,
                "<e0>": 325
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3264417873",
        "aid": "3264417873_40043",
        "original_caption": "an adult man in orange speaks to a child in gray.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in orange speaks to a child in gray happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                788,
                1385
            ],
            "duration": 598,
            "token": {
                "<s0>": 463,
                "<e0>": 501
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_40044",
        "original_caption": "an adult in white clothes is away from a leftmost female adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white clothes is away from a leftmost female adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1582
            ],
            "duration": 1583,
            "token": {
                "<s0>": 1440,
                "<e0>": 1583
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8082308738",
        "aid": "8082308738_40045",
        "original_caption": "an adult in striped clothes is behind another adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in striped clothes is behind another adult in black clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                460
            ],
            "duration": 461,
            "token": {
                "<s0>": 120,
                "<e0>": 326
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_40046",
        "original_caption": "an adult is above a stool in the dancing pool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is above a stool in the dancing pool."
            }
        ],
        "meta": {
            "split": [
                0,
                1011
            ],
            "duration": 1012,
            "token": {
                "<s0>": 0,
                "<e0>": 1012
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_40047",
        "original_caption": "a ball/sports ball is towards another ball/sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A ball/sports ball is towards another ball/sports ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 25,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_40048",
        "original_caption": "an adult is towards a cup at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is towards a cup at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 420,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7290684468",
        "aid": "7290684468_40049",
        "original_caption": "there is a toy in front of an adult man in red at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a toy in front of an adult man in red at home."
            }
        ],
        "meta": {
            "split": [
                0,
                569
            ],
            "duration": 570,
            "token": {
                "<s0>": 0,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3633340560",
        "aid": "3633340560_40050",
        "original_caption": "a child in red watches an adult woman in gray at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in red watches an adult woman in gray at home."
            }
        ],
        "meta": {
            "split": [
                0,
                243
            ],
            "duration": 244,
            "token": {
                "<s0>": 44,
                "<e0>": 133
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12326753325",
        "aid": "12326753325_40051",
        "original_caption": "an adult caresses a brown cat on the brown sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult caresses a brown cat on the brown sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                997
            ],
            "duration": 998,
            "token": {
                "<s0>": 92,
                "<e0>": 288
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4823372280",
        "aid": "4823372280_40052",
        "original_caption": "an adult wearing a black hat is away from a stool.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a black hat is away from a stool."
            }
        ],
        "meta": {
            "split": [
                675,
                1011
            ],
            "duration": 337,
            "token": {
                "<s0>": 165,
                "<e0>": 255
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40053",
        "original_caption": "an adult holds a cellphone in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult holds a cellphone in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                128
            ],
            "duration": 129,
            "token": {
                "<s0>": 77,
                "<e0>": 114
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40054",
        "original_caption": "an adult holds a cellphone in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the cellphone in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                128,
                1441
            ],
            "duration": 1314,
            "token": {
                "<s0>": 14,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7051512715",
        "aid": "7051512715_40055",
        "original_caption": "an adult leans on a sofa in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult leans on a sofa in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                208
            ],
            "duration": 209,
            "token": {
                "<s0>": 0,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_40056",
        "original_caption": "a child in white clothes is inside an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in white clothes is inside an orange toy."
            }
        ],
        "meta": {
            "split": [
                0,
                270
            ],
            "duration": 271,
            "token": {
                "<s0>": 142,
                "<e0>": 209
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_40057",
        "original_caption": "a child in white clothes is inside an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes is inside an orange toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                270,
                614
            ],
            "duration": 345,
            "token": {
                "<s0>": 62,
                "<e0>": 179
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_40058",
        "original_caption": "a child in white clothes is inside an orange toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in white clothes is inside an orange toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                614,
                930
            ],
            "duration": 317,
            "token": {
                "<s0>": 166,
                "<e0>": 316
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3315181459",
        "aid": "3315181459_40059",
        "original_caption": "a adult women is touching another adult man.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho touches the other adult man from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                694
            ],
            "duration": 695,
            "token": {
                "<s0>": 672,
                "<e0>": 695
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_40060",
        "original_caption": "an adult in blue is towards a ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in blue is towards a ball."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 448,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3219139415",
        "aid": "3219139415_40061",
        "original_caption": "an adult in grey clothes rides a toy inside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in grey clothes ride inside the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A toy."
            }
        ],
        "meta": {
            "split": [
                0,
                202
            ],
            "duration": 203,
            "token": {
                "<s0>": 0,
                "<e0>": 203
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6206478063",
        "aid": "6206478063_40062",
        "original_caption": "an adult man in black is behind another adult woman in white on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in black is behind another adult woman in white on the water."
            }
        ],
        "meta": {
            "split": [
                120,
                458
            ],
            "duration": 339,
            "token": {
                "<s0>": 30,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6953143775",
        "aid": "6953143775_40063",
        "original_caption": "the adult in blue is pushing the adult in black.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is pushing the adult in black from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                188
            ],
            "duration": 189,
            "token": {
                "<s0>": 24,
                "<e0>": 52
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6789657160",
        "aid": "6789657160_40064",
        "original_caption": "an adult watches a child on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult watches a child on the ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                829
            ],
            "duration": 830,
            "token": {
                "<s0>": 0,
                "<e0>": 37
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3952824958",
        "aid": "3952824958_40065",
        "original_caption": "there is a toy next to a sports ball.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy next to a sports ball."
            }
        ],
        "meta": {
            "split": [
                1474,
                1868
            ],
            "duration": 395,
            "token": {
                "<s0>": 216,
                "<e0>": 394
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_40066",
        "original_caption": "an adult holds hand of a child in red besidethe sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult hold hand of besidethe sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                200
            ],
            "duration": 201,
            "token": {
                "<s0>": 21,
                "<e0>": 53
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_40067",
        "original_caption": "an adult holds hand of a child in red besidethe sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds hand of a child in red besidethe sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                200,
                523
            ],
            "duration": 324,
            "token": {
                "<s0>": 148,
                "<e0>": 174
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_40068",
        "original_caption": "an adult holds hand of a child in red besidethe sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult hold hand of besidethe sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                523,
                1133
            ],
            "duration": 611,
            "token": {
                "<s0>": 150,
                "<e0>": 216
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6090062913",
        "aid": "6090062913_40069",
        "original_caption": "an adult holds hand of a child in red besidethe sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds hand of a child in red besidethe sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1133,
                1574
            ],
            "duration": 442,
            "token": {
                "<s0>": 394,
                "<e0>": 419
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_40070",
        "original_caption": "a adult in white speaks to an adult in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A adult in white speaks to an adult in orange."
            }
        ],
        "meta": {
            "split": [
                0,
                313
            ],
            "duration": 314,
            "token": {
                "<s0>": 95,
                "<e0>": 266
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_40071",
        "original_caption": "a adult in white speaks to an adult in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the adult  in orange from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                313,
                720
            ],
            "duration": 408,
            "token": {
                "<s0>": 48,
                "<e0>": 264
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5875096370",
        "aid": "5875096370_40072",
        "original_caption": "a adult in white speaks to an adult in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a adult in white speaks to an adult in orange happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                720,
                1221
            ],
            "duration": 502,
            "token": {
                "<s0>": 144,
                "<e0>": 327
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5787984923",
        "aid": "5787984923_40073",
        "original_caption": "an adult man in yellow rides a wooden watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in yellow rides a wooden watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                301
            ],
            "duration": 302,
            "token": {
                "<s0>": 0,
                "<e0>": 302
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5590135575",
        "aid": "5590135575_40074",
        "original_caption": "a baby in green clothes leans on a baby seat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in green clothes leans on a baby seat."
            }
        ],
        "meta": {
            "split": [
                0,
                773
            ],
            "duration": 774,
            "token": {
                "<s0>": 0,
                "<e0>": 774
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4624548287",
        "aid": "4624548287_40075",
        "original_caption": "an adult holds a scooter in the evening.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult holds a scooter in the evening happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                671
            ],
            "duration": 672,
            "token": {
                "<s0>": 567,
                "<e0>": 590
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3510473333",
        "aid": "3510473333_40076",
        "original_caption": "a baby wearing a white hat rides a red baby walker.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby wearing a white hat rides a red baby walker."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 0,
                "<e0>": 585
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4184884354",
        "aid": "4184884354_40077",
        "original_caption": "there is a red stool in front of a child in black at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the stool from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a red stool in front of a child in black at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1502
            ],
            "duration": 1503,
            "token": {
                "<s0>": 150,
                "<e0>": 225
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3078133866",
        "aid": "3078133866_40078",
        "original_caption": "a baby in blue watches an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby in blue watches an adult at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1438
            ],
            "duration": 1439,
            "token": {
                "<s0>": 202,
                "<e0>": 421
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3783730077",
        "aid": "3783730077_40079",
        "original_caption": "an adult in white touches an a fmale adult at the show.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in white touch at the show from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                963
            ],
            "duration": 964,
            "token": {
                "<s0>": 15,
                "<e0>": 41
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5799956920",
        "aid": "5799956920_40080",
        "original_caption": "there is a blue toy in front of an adult in green clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a blue toy in front of an adult in green clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                998
            ],
            "duration": 999,
            "token": {
                "<s0>": 0,
                "<e0>": 236
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5195700916",
        "aid": "5195700916_40081",
        "original_caption": "an adult in white is holding the bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in white is holding the bottle happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1805
            ],
            "duration": 1806,
            "token": {
                "<s0>": 296,
                "<e0>": 459
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5153854160",
        "aid": "5153854160_40082",
        "original_caption": "there is a brown wooden table beneath a black cellphone.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a brown wooden table beneath a black cellphone."
            }
        ],
        "meta": {
            "split": [
                0,
                2264
            ],
            "duration": 2265,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5154636418",
        "aid": "5154636418_40083",
        "original_caption": "an adult is in front of an another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is  in front of the other adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                284
            ],
            "duration": 285,
            "token": {
                "<s0>": 0,
                "<e0>": 210
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6612282627",
        "aid": "6612282627_40084",
        "original_caption": "a baby waves a toy on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby waves a toy on the bed."
            }
        ],
        "meta": {
            "split": [
                0,
                1617
            ],
            "duration": 1618,
            "token": {
                "<s0>": 419,
                "<e0>": 454
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4828544178",
        "aid": "4828544178_40085",
        "original_caption": "an adult in black clothes holds a camera.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes holds a camera."
            }
        ],
        "meta": {
            "split": [
                0,
                344
            ],
            "duration": 345,
            "token": {
                "<s0>": 305,
                "<e0>": 345
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9181873351",
        "aid": "9181873351_40086",
        "original_caption": "a child in white leans on an orange toy in the shop.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in white leans on an orange toy in the shop."
            }
        ],
        "meta": {
            "split": [
                0,
                930
            ],
            "duration": 931,
            "token": {
                "<s0>": 877,
                "<e0>": 931
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8157245482",
        "aid": "8157245482_40087",
        "original_caption": "the adult with sunglasses is hugging the child in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult with sunglasses is hugging the child in red."
            }
        ],
        "meta": {
            "split": [
                0,
                191
            ],
            "duration": 192,
            "token": {
                "<s0>": 88,
                "<e0>": 192
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5295783476",
        "aid": "5295783476_40088",
        "original_caption": "an adult rides a ski in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a ski in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                389
            ],
            "duration": 390,
            "token": {
                "<s0>": 47,
                "<e0>": 66
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8716087070",
        "aid": "8716087070_40089",
        "original_caption": "an adult man in white carries a red and gray backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in white carries a red and gray backpack happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                437
            ],
            "duration": 438,
            "token": {
                "<s0>": 0,
                "<e0>": 434
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8716087070",
        "aid": "8716087070_40090",
        "original_caption": "an adult man in white carries a red and gray backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult man in white carry from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                437,
                556
            ],
            "duration": 120,
            "token": {
                "<s0>": 3,
                "<e0>": 33
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8716087070",
        "aid": "8716087070_40091",
        "original_caption": "an adult man in white carries a red and gray backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in white carries a red and gray backpack."
            }
        ],
        "meta": {
            "split": [
                556,
                771
            ],
            "duration": 216,
            "token": {
                "<s0>": 87,
                "<e0>": 112
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6068085283",
        "aid": "6068085283_40092",
        "original_caption": "an adult in red hugs a baby in pink outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red hugs a baby in pink outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                1112
            ],
            "duration": 1113,
            "token": {
                "<s0>": 0,
                "<e0>": 1003
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6068085283",
        "aid": "6068085283_40093",
        "original_caption": "an adult in red hugs a baby in pink outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in red hugs a baby in pink outdoors."
            }
        ],
        "meta": {
            "split": [
                1112,
                1781
            ],
            "duration": 670,
            "token": {
                "<s0>": 110,
                "<e0>": 670
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_40094",
        "original_caption": "an adult in blue is towards a child in a gym.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in blue is towards a child in a gym."
            }
        ],
        "meta": {
            "split": [
                389,
                595
            ],
            "duration": 207,
            "token": {
                "<s0>": 59,
                "<e0>": 206
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_40095",
        "original_caption": "an adult wearing a hat carries a blue backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult wearing a hat carries a blue backpack happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 107,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "12624072313",
        "aid": "12624072313_40096",
        "original_caption": "an adult is behind another adult on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is behind another adult on the road."
            }
        ],
        "meta": {
            "split": [
                0,
                1278
            ],
            "duration": 1279,
            "token": {
                "<s0>": 120,
                "<e0>": 260
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_40097",
        "original_caption": "an adult without dress chases another adult in gray clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho chases the other adult in gray clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 60,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_40098",
        "original_caption": "there is a white table beneath a blue sports ball in a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a white table beneath a blue sports ball in a room happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 483,
                "<e0>": 587
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_40099",
        "original_caption": "a child in black holds a yellow green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black holds a yellow green toy."
            }
        ],
        "meta": {
            "split": [
                0,
                341
            ],
            "duration": 342,
            "token": {
                "<s0>": 44,
                "<e0>": 146
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4534736385",
        "aid": "4534736385_40100",
        "original_caption": "a child in black holds a yellow green toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A child in black holds a yellow green toy."
            }
        ],
        "meta": {
            "split": [
                341,
                1314
            ],
            "duration": 974,
            "token": {
                "<s0>": 195,
                "<e0>": 230
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_40101",
        "original_caption": "an adult rides a watercraft in the river.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult rides a watercraft in the river happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 257
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7639717122",
        "aid": "7639717122_40102",
        "original_caption": "there is a blue bicycle beneath a shirtless child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the bicycle from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a blue bicycle beneath a shirtless child."
            }
        ],
        "meta": {
            "split": [
                0,
                123
            ],
            "duration": 124,
            "token": {
                "<s0>": 44,
                "<e0>": 98
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4670796220",
        "aid": "4670796220_40103",
        "original_caption": "adults in purple clothes speak to the baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "Adults in purple clothes speak to the baby."
            }
        ],
        "meta": {
            "split": [
                0,
                407
            ],
            "duration": 408,
            "token": {
                "<s0>": 367,
                "<e0>": 386
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2940234006",
        "aid": "2940234006_40104",
        "original_caption": "an adult is in front of an another adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is in front of the other adult from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                979
            ],
            "duration": 980,
            "token": {
                "<s0>": 516,
                "<e0>": 979
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3078133866",
        "aid": "3078133866_40105",
        "original_caption": "an adult in white speaks to a baby in white in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in white speaks to a baby in white in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                80
            ],
            "duration": 81,
            "token": {
                "<s0>": 55,
                "<e0>": 69
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10712559773",
        "aid": "10712559773_40106",
        "original_caption": "a child in red is behind an adult in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the adult in blue from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                595
            ],
            "duration": 596,
            "token": {
                "<s0>": 187,
                "<e0>": 263
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2852706689",
        "aid": "2852706689_40107",
        "original_caption": "there is a gray baby seat beneath a yellow toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a gray baby seat beneath a yellow toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                648
            ],
            "duration": 649,
            "token": {
                "<s0>": 0,
                "<e0>": 648
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2538515654",
        "aid": "2538515654_40108",
        "original_caption": "an adult man watches a surfboard on the lake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man watches a surfboard on the lake."
            }
        ],
        "meta": {
            "split": [
                268,
                452
            ],
            "duration": 185,
            "token": {
                "<s0>": 48,
                "<e0>": 109
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_40109",
        "original_caption": "there is a blue backpack above an adult wearing a hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the adult wearing a hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 120,
                "<e0>": 183
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4400119620",
        "aid": "4400119620_40110",
        "original_caption": "an adult in black speaks to another adult in a dark room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho speaks to the other adult in the dark room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                479
            ],
            "duration": 480,
            "token": {
                "<s0>": 156,
                "<e0>": 190
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8665362025",
        "aid": "8665362025_40111",
        "original_caption": "an adult rides a white watercraft on the water.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult rides a white watercraft on the water."
            }
        ],
        "meta": {
            "split": [
                0,
                256
            ],
            "duration": 257,
            "token": {
                "<s0>": 0,
                "<e0>": 134
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_40112",
        "original_caption": "an adult woman pulls a white cake in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult woman pulls a white cake in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 546,
                "<e0>": 621
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40113",
        "original_caption": "an adult in black clothes uses a cellphone at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes uses a cellphone at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                190
            ],
            "duration": 191,
            "token": {
                "<s0>": 66,
                "<e0>": 136
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40114",
        "original_caption": "an adult in black clothes uses a cellphone at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes uses a cellphone at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                190,
                432
            ],
            "duration": 243,
            "token": {
                "<s0>": 55,
                "<e0>": 237
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40115",
        "original_caption": "an adult in black clothes uses a cellphone at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes uses a cellphone at home."
            }
        ],
        "meta": {
            "split": [
                432,
                1441
            ],
            "duration": 1010,
            "token": {
                "<s0>": 6,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7972054306",
        "aid": "7972054306_40116",
        "original_caption": "a shirtless child pushes an adult in gray beside the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the shirtless child push beside the sofa from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                816
            ],
            "duration": 817,
            "token": {
                "<s0>": 230,
                "<e0>": 250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8295398331",
        "aid": "8295398331_40117",
        "original_caption": "an adult kneeling on the ground is behind a child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult kneeling on the ground is behind a child."
            }
        ],
        "meta": {
            "split": [
                304,
                705
            ],
            "duration": 402,
            "token": {
                "<s0>": 35,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10011555465",
        "aid": "10011555465_40118",
        "original_caption": "an adult in white hits another adult in white on the training ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in white hits another adult in white on the training ground."
            }
        ],
        "meta": {
            "split": [
                0,
                800
            ],
            "duration": 801,
            "token": {
                "<s0>": 439,
                "<e0>": 516
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6991481998",
        "aid": "6991481998_40119",
        "original_caption": "a child is away a car in the path.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child is away a car in the path."
            }
        ],
        "meta": {
            "split": [
                0,
                1679
            ],
            "duration": 1680,
            "token": {
                "<s0>": 0,
                "<e0>": 147
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5840186446",
        "aid": "5840186446_40120",
        "original_caption": "an adult is above a bicycle in the wild.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult is above a bicycle in the wild."
            }
        ],
        "meta": {
            "split": [
                0,
                196
            ],
            "duration": 197,
            "token": {
                "<s0>": 0,
                "<e0>": 185
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10304757716",
        "aid": "10304757716_40121",
        "original_caption": "there is a stool beneath a baby in green at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the stool from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a stool beneath a baby in green at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1622
            ],
            "duration": 1623,
            "token": {
                "<s0>": 0,
                "<e0>": 1623
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5153854160",
        "aid": "5153854160_40122",
        "original_caption": "there is a white laptop above a brown table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the white laptop from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A table."
            }
        ],
        "meta": {
            "split": [
                0,
                2264
            ],
            "duration": 2265,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3707868675",
        "aid": "3707868675_40123",
        "original_caption": "there is a black table beneath a transparent cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black table beneath a transparent cup happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                793
            ],
            "duration": 794,
            "token": {
                "<s0>": 0,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8082308738",
        "aid": "8082308738_40124",
        "original_caption": "an adult in black holds a cellphone outdoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black holds a cellphone outdoors."
            }
        ],
        "meta": {
            "split": [
                0,
                460
            ],
            "duration": 461,
            "token": {
                "<s0>": 295,
                "<e0>": 386
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_40125",
        "original_caption": "there is a rat beneath another rat on the carpet.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a rat beneath another rat on the carpet."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1140,
                "<e0>": 1194
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4142450052",
        "aid": "4142450052_40126",
        "original_caption": "there is a golden yellow dog next to a red frisbee.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a golden yellow dog next to a red frisbee."
            }
        ],
        "meta": {
            "split": [
                0,
                503
            ],
            "duration": 504,
            "token": {
                "<s0>": 0,
                "<e0>": 504
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10083879466",
        "aid": "10083879466_40127",
        "original_caption": "a child holds hand of the another child.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child holds hand of the another child happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                681
            ],
            "duration": 682,
            "token": {
                "<s0>": 0,
                "<e0>": 673
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5290336869",
        "aid": "5290336869_40128",
        "original_caption": "there is a chair in front of a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair in front of a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2533
            ],
            "duration": 2534,
            "token": {
                "<s0>": 1980,
                "<e0>": 2070
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_40129",
        "original_caption": "an adult is next to a backpack on the road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult is next to a backpack on the road happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 300,
                "<e0>": 332
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_40130",
        "original_caption": "the table is next to the adult women.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the table from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The table is next to the adult women."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 780,
                "<e0>": 990
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3374974398",
        "aid": "3374974398_40131",
        "original_caption": "an adult is above a snowboard in the snow.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult is above a snowboard in the snow."
            }
        ],
        "meta": {
            "split": [
                0,
                292
            ],
            "duration": 293,
            "token": {
                "<s0>": 164,
                "<e0>": 253
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_40132",
        "original_caption": "there is a cup above a table outside a room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table outside a room."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 0,
                "<e0>": 2160
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9620459628",
        "aid": "9620459628_40133",
        "original_caption": "there is a cup above a table at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "There is a cup above a table at home."
            }
        ],
        "meta": {
            "split": [
                0,
                263
            ],
            "duration": 264,
            "token": {
                "<s0>": 48,
                "<e0>": 118
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_40134",
        "original_caption": "the adult in black is holding the adult in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult in black is holding the adult in pink."
            }
        ],
        "meta": {
            "split": [
                0,
                107
            ],
            "duration": 108,
            "token": {
                "<s0>": 0,
                "<e0>": 73
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_40135",
        "original_caption": "the adult in black is holding the adult in pink.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult in black is holding the adult in pink happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                107,
                2271
            ],
            "duration": 2165,
            "token": {
                "<s0>": 35,
                "<e0>": 78
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4202270666",
        "aid": "4202270666_40136",
        "original_caption": "there is a monitor above an adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a monitor above an adult in red clothes happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2271
            ],
            "duration": 2272,
            "token": {
                "<s0>": 0,
                "<e0>": 2272
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3761379939",
        "aid": "3761379939_40137",
        "original_caption": "an adult in black clothes is above a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is beneath the adult in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1380
            ],
            "duration": 1381,
            "token": {
                "<s0>": 0,
                "<e0>": 864
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_40138",
        "original_caption": "the adult man in black pulls the adult woman in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pull the adult woman from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                441
            ],
            "duration": 442,
            "token": {
                "<s0>": 95,
                "<e0>": 113
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_40139",
        "original_caption": "the adult man in black pulls the adult woman in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the adult man in black pulls the adult woman in red happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                441,
                856
            ],
            "duration": 416,
            "token": {
                "<s0>": 328,
                "<e0>": 348
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3313957446",
        "aid": "3313957446_40140",
        "original_caption": "the adult man in black pulls the adult woman in red.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho pull the adult woman from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                856,
                1034
            ],
            "duration": 179,
            "token": {
                "<s0>": 67,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9015675343",
        "aid": "9015675343_40141",
        "original_caption": "a baby in yellow leans on a purple sofa at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the baby from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A baby in yellow leans on a purple sofa at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1469
            ],
            "duration": 1470,
            "token": {
                "<s0>": 0,
                "<e0>": 570
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3990712537",
        "aid": "3990712537_40142",
        "original_caption": "there is a chair next to an adult at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a chair next to an adult at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1470
            ],
            "duration": 1471,
            "token": {
                "<s0>": 808,
                "<e0>": 910
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6025039044",
        "aid": "6025039044_40143",
        "original_caption": "there is a red toy beneath a baby in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a red toy beneath a baby in white happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                128
            ],
            "duration": 129,
            "token": {
                "<s0>": 0,
                "<e0>": 129
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3993424608",
        "aid": "3993424608_40144",
        "original_caption": "there is a white laptop above a yellow table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is above the yellow table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A laptop."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 0,
                "<e0>": 1265
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_40145",
        "original_caption": "there is a hamster towards another rat on the bed.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is the hamster towards to on the bed from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A hamster/rat."
            }
        ],
        "meta": {
            "split": [
                1264,
                2639
            ],
            "duration": 1376,
            "token": {
                "<s0>": 71,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5912451153",
        "aid": "5912451153_40146",
        "original_caption": "there is a toy in front of an adult beside the sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a toy in front of an adult beside the sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                131,
                637
            ],
            "duration": 507,
            "token": {
                "<s0>": 22,
                "<e0>": 498
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9365549235",
        "aid": "9365549235_40147",
        "original_caption": "an adult with a tail holds a bat on the playground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with a tail holds a bat on the playground."
            }
        ],
        "meta": {
            "split": [
                0,
                119
            ],
            "duration": 120,
            "token": {
                "<s0>": 0,
                "<e0>": 120
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_40148",
        "original_caption": "an adult in green clothes is behind another adult in black clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is behind the other adult in black clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 0,
                "<e0>": 150
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_40149",
        "original_caption": "an adult in black clothes holds a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes holds a baby."
            }
        ],
        "meta": {
            "split": [
                0,
                367
            ],
            "duration": 368,
            "token": {
                "<s0>": 0,
                "<e0>": 346
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5144319075",
        "aid": "5144319075_40150",
        "original_caption": "an adult in black clothes holds a baby.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes holds a baby happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                408,
                1197
            ],
            "duration": 790,
            "token": {
                "<s0>": 16,
                "<e0>": 790
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6832416998",
        "aid": "6832416998_40151",
        "original_caption": "a child watches an adult wearing a white hat.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho watches the adult wearing a white hat from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                728
            ],
            "duration": 729,
            "token": {
                "<s0>": 688,
                "<e0>": 729
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4615486172",
        "aid": "4615486172_40152",
        "original_caption": "an adult wearing earrings releases a white cake.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult wearing earrings releases a white cake."
            }
        ],
        "meta": {
            "split": [
                0,
                2696
            ],
            "duration": 2697,
            "token": {
                "<s0>": 746,
                "<e0>": 880
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6154068154",
        "aid": "6154068154_40153",
        "original_caption": "an adult man in wathet blue is behind a guitar in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in wathet blue is behind a guitar in the room."
            }
        ],
        "meta": {
            "split": [
                0,
                2249
            ],
            "duration": 2250,
            "token": {
                "<s0>": 0,
                "<e0>": 2250
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6005023595",
        "aid": "6005023595_40154",
        "original_caption": "a baby in colorful clothes leans on an adult.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the baby in colorful clothes lean on from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                584
            ],
            "duration": 585,
            "token": {
                "<s0>": 0,
                "<e0>": 585
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4501209164",
        "aid": "4501209164_40155",
        "original_caption": "there is a bird on the right away another bird on the left.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bird on the right away another bird on the left happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                955
            ],
            "duration": 956,
            "token": {
                "<s0>": 300,
                "<e0>": 450
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3848996383",
        "aid": "3848996383_40156",
        "original_caption": "an adult sitting on a bed watches an adult standing.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult sitting on a bed watches an adult standing happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                739
            ],
            "duration": 740,
            "token": {
                "<s0>": 708,
                "<e0>": 727
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6692501229",
        "aid": "6692501229_40157",
        "original_caption": "an standing adult in white clothes is next to a table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the table from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                1424
            ],
            "duration": 1425,
            "token": {
                "<s0>": 0,
                "<e0>": 1410
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_40158",
        "original_caption": "an female adult in gray clothes holds a skateboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An female adult in gray clothes holds a skateboard."
            }
        ],
        "meta": {
            "split": [
                0,
                362
            ],
            "duration": 363,
            "token": {
                "<s0>": 6,
                "<e0>": 289
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_40159",
        "original_caption": "an female adult in gray clothes holds a skateboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An female adult in gray clothes holds a skateboard."
            }
        ],
        "meta": {
            "split": [
                362,
                780
            ],
            "duration": 419,
            "token": {
                "<s0>": 73,
                "<e0>": 252
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5807111717",
        "aid": "5807111717_40160",
        "original_caption": "an female adult in gray clothes holds a skateboard.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the skateboard from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                780,
                986
            ],
            "duration": 207,
            "token": {
                "<s0>": 166,
                "<e0>": 207
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8023214726",
        "aid": "8023214726_40161",
        "original_caption": "the adult man in blue is moving towards the empty bottle.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The adult man in blue is moving towards the empty bottle."
            }
        ],
        "meta": {
            "split": [
                0,
                1349
            ],
            "duration": 1350,
            "token": {
                "<s0>": 1260,
                "<e0>": 1320
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2815147671",
        "aid": "2815147671_40162",
        "original_caption": "an adult wearing a black hat watches another adult in yellow clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a black hat watches another adult in yellow clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1233
            ],
            "duration": 1234,
            "token": {
                "<s0>": 555,
                "<e0>": 588
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3304644092",
        "aid": "3304644092_40163",
        "original_caption": "an adult in red watches another adult in black in the mall.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in red watches another adult in black in the mall."
            }
        ],
        "meta": {
            "split": [
                236,
                927
            ],
            "duration": 692,
            "token": {
                "<s0>": 183,
                "<e0>": 199
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2664151010",
        "aid": "2664151010_40164",
        "original_caption": "the child in orange pants is next to the child in green pants.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "The child in orange pants is next to the child in green pants."
            }
        ],
        "meta": {
            "split": [
                525,
                735
            ],
            "duration": 211,
            "token": {
                "<s0>": 75,
                "<e0>": 158
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40165",
        "original_caption": "a child is above a sofa at a party.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is above the sofa at the party from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                1158,
                1441
            ],
            "duration": 284,
            "token": {
                "<s0>": 96,
                "<e0>": 161
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6039815844",
        "aid": "6039815844_40166",
        "original_caption": "there is a brown dog in front of an adult in the bathroom.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is in front of the adult in the bathroom from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                473,
                2696
            ],
            "duration": 2224,
            "token": {
                "<s0>": 204,
                "<e0>": 876
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4401948869",
        "aid": "4401948869_40167",
        "original_caption": "an adult in blue clothes carries a backpack on the mountain road.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat does the adult in blue clothes carry on the mountain road from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A backpack."
            }
        ],
        "meta": {
            "split": [
                0,
                357
            ],
            "duration": 358,
            "token": {
                "<s0>": 218,
                "<e0>": 358
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6698703081",
        "aid": "6698703081_40168",
        "original_caption": "an adult wearing a blue hat is behind another adult in blue clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult wearing a blue hat is behind another adult in blue clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                959
            ],
            "duration": 960,
            "token": {
                "<s0>": 737,
                "<e0>": 959
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4569009647",
        "aid": "4569009647_40169",
        "original_caption": "an adult women in red is carrying the backpack.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult women in red is carrying the backpack happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2436
            ],
            "duration": 2437,
            "token": {
                "<s0>": 1838,
                "<e0>": 1913
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6086390405",
        "aid": "6086390405_40170",
        "original_caption": "there is a bicycle with only one wheel beneath a child in orange.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a bicycle with only one wheel beneath a child in orange happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                1301
            ],
            "duration": 1302,
            "token": {
                "<s0>": 0,
                "<e0>": 668
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "5865340395",
        "aid": "5865340395_40171",
        "original_caption": "an adult in green is next to an another adult in white.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is next to the other adult in white from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                368
            ],
            "duration": 369,
            "token": {
                "<s0>": 44,
                "<e0>": 89
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40172",
        "original_caption": "a child in blue holds a dog at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the child from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "A child in blue holds a dog at home."
            }
        ],
        "meta": {
            "split": [
                0,
                1441
            ],
            "duration": 1442,
            "token": {
                "<s0>": 1414,
                "<e0>": 1442
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3289328444",
        "aid": "3289328444_40173",
        "original_caption": "an adult singing is next to a bottle on the table.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult singing is next to a bottle on the table."
            }
        ],
        "meta": {
            "split": [
                0,
                611
            ],
            "duration": 612,
            "token": {
                "<s0>": 63,
                "<e0>": 145
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_40174",
        "original_caption": "an adult in fancy clothes speaks to a baby in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in fancy clothes speaks to a baby in blue."
            }
        ],
        "meta": {
            "split": [
                0,
                173
            ],
            "duration": 174,
            "token": {
                "<s0>": 0,
                "<e0>": 103
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7121723227",
        "aid": "7121723227_40175",
        "original_caption": "an adult in fancy clothes speaks to a baby in blue.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho does the adult in fancy clothes speak to  from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A baby."
            }
        ],
        "meta": {
            "split": [
                173,
                419
            ],
            "duration": 247,
            "token": {
                "<s0>": 71,
                "<e0>": 173
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6220387865",
        "aid": "6220387865_40176",
        "original_caption": "an adult man in white is towards another adult man in black at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult man in white is towards another adult man in black at home."
            }
        ],
        "meta": {
            "split": [
                0,
                900
            ],
            "duration": 901,
            "token": {
                "<s0>": 151,
                "<e0>": 198
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2436501360",
        "aid": "2436501360_40177",
        "original_caption": "a baby waves a toy on a sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "A baby waves a toy on a sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                1756
            ],
            "duration": 1757,
            "token": {
                "<s0>": 799,
                "<e0>": 834
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "4149141971",
        "aid": "4149141971_40178",
        "original_caption": "an adult with white hair is in front of a screen.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult with white hair is in front of a screen."
            }
        ],
        "meta": {
            "split": [
                0,
                1319
            ],
            "duration": 1320,
            "token": {
                "<s0>": 157,
                "<e0>": 329
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40179",
        "original_caption": "an adult man in plaid shirt leans on a tan sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt leans on a tan sofa."
            }
        ],
        "meta": {
            "split": [
                0,
                442
            ],
            "duration": 443,
            "token": {
                "<s0>": 0,
                "<e0>": 303
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40180",
        "original_caption": "an adult man in plaid shirt leans on a tan sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt leans on a tan sofa."
            }
        ],
        "meta": {
            "split": [
                442,
                1151
            ],
            "duration": 710,
            "token": {
                "<s0>": 140,
                "<e0>": 606
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40181",
        "original_caption": "an adult man in plaid shirt leans on a tan sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult man in plaid shirt leans on a tan sofa happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1151,
                1350
            ],
            "duration": 200,
            "token": {
                "<s0>": 103,
                "<e0>": 163
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40182",
        "original_caption": "an adult man in plaid shirt leans on a tan sofa.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nCan you describe what occurred from <s0> to <e0> in the video?"
            },
            {
                "from": "gpt",
                "value": "An adult man in plaid shirt leans on a tan sofa."
            }
        ],
        "meta": {
            "split": [
                1350,
                1441
            ],
            "duration": 92,
            "token": {
                "<s0>": 36,
                "<e0>": 92
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3742817599",
        "aid": "3742817599_40183",
        "original_caption": "there is black hamster in front of the another hamster.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is black hamster in front of the another hamster happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                2639
            ],
            "duration": 2640,
            "token": {
                "<s0>": 1560,
                "<e0>": 1617
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "11278818844",
        "aid": "11278818844_40184",
        "original_caption": "a child in pink  is towards an adult in orange indoors.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is towards the adult in orange indoors from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                1582
            ],
            "duration": 1583,
            "token": {
                "<s0>": 1049,
                "<e0>": 1101
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40185",
        "original_caption": "an adult in black clothes uses a cellphone at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes uses a cellphone at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                190
            ],
            "duration": 191,
            "token": {
                "<s0>": 66,
                "<e0>": 136
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40186",
        "original_caption": "an adult in black clothes uses a cellphone at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult in black clothes uses a cellphone at home."
            }
        ],
        "meta": {
            "split": [
                190,
                432
            ],
            "duration": 243,
            "token": {
                "<s0>": 55,
                "<e0>": 237
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "8316378691",
        "aid": "8316378691_40187",
        "original_caption": "an adult in black clothes uses a cellphone at home.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see an adult in black clothes uses a cellphone at home happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                432,
                1441
            ],
            "duration": 1010,
            "token": {
                "<s0>": 6,
                "<e0>": 223
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9114498568",
        "aid": "9114498568_40188",
        "original_caption": "a child is away from another child on the slide.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho is the child away from on the slide from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                518
            ],
            "duration": 519,
            "token": {
                "<s0>": 120,
                "<e0>": 176
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "2699087442",
        "aid": "2699087442_40189",
        "original_caption": "there is a black cat licking another cat on the white ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see there is a black cat licking another cat on the white ground happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                923
            ],
            "duration": 924,
            "token": {
                "<s0>": 42,
                "<e0>": 156
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6393253995",
        "aid": "6393253995_40190",
        "original_caption": "an adult man in black holds a white cup.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the white cup from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "An adult."
            }
        ],
        "meta": {
            "split": [
                0,
                2159
            ],
            "duration": 2160,
            "token": {
                "<s0>": 521,
                "<e0>": 619
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3711378974",
        "aid": "3711378974_40191",
        "original_caption": "an adult with glasses holds a camera outdoor.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the adult from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "An adult with glasses holds a camera outdoor."
            }
        ],
        "meta": {
            "split": [
                0,
                1143
            ],
            "duration": 1144,
            "token": {
                "<s0>": 337,
                "<e0>": 517
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "6982872008",
        "aid": "6982872008_40192",
        "original_caption": "a child in blue clothes watches a toy.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see a child in blue clothes watches a toy happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                1442,
                1653
            ],
            "duration": 212,
            "token": {
                "<s0>": 25,
                "<e0>": 63
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3920356362",
        "aid": "3920356362_40193",
        "original_caption": "a child in white holds an orange sports ball in the room.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWho holds the orange sports ball in the room from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A child."
            }
        ],
        "meta": {
            "split": [
                0,
                355
            ],
            "duration": 356,
            "token": {
                "<s0>": 0,
                "<e0>": 86
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "3408077386",
        "aid": "3408077386_40194",
        "original_caption": "there is a toy beneath a child in white clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the toy from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a toy beneath a child in white clothes."
            }
        ],
        "meta": {
            "split": [
                0,
                1516
            ],
            "duration": 1517,
            "token": {
                "<s0>": 986,
                "<e0>": 1041
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "10196789535",
        "aid": "10196789535_40195",
        "original_caption": "there is a dog behind another dog on the ground.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDescribe the action of the dog from <s0> to <e0>."
            },
            {
                "from": "gpt",
                "value": "There is a dog behind another dog on the ground."
            }
        ],
        "meta": {
            "split": [
                0,
                443
            ],
            "duration": 444,
            "token": {
                "<s0>": 0,
                "<e0>": 75
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "9755380174",
        "aid": "9755380174_40196",
        "original_caption": "the child in dancing is heading towards the chair.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nDuring which frames can we see the child in dancing is heading towards the chair happening in the video?"
            },
            {
                "from": "gpt",
                "value": "From <s0> to <e0>."
            }
        ],
        "meta": {
            "split": [
                0,
                4260
            ],
            "duration": 4261,
            "token": {
                "<s0>": 4020,
                "<e0>": 4110
            }
        },
        "source": "vidstg"
    },
    {
        "vid": "7290684468",
        "aid": "7290684468_40197",
        "original_caption": "there is a dog towards an adult in red clothes.",
        "conversations": [
            {
                "from": "human",
                "value": "<video>\nWhat is towards the adult in red clothes from <s0> to <e0>?"
            },
            {
                "from": "gpt",
                "value": "A dog."
            }
        ],
        "meta": {
            "split": [
                0,
                569
            ],
            "duration": 570,
            "token": {
                "<s0>": 503,
                "<e0>": 569
            }
        },
        "source": "vidstg"
    }
]